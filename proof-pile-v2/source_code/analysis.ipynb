{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d946c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ndjson\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318021ac",
   "metadata": {},
   "source": [
    "# The Stack Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce03f576",
   "metadata": {},
   "source": [
    "Stack stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbd1a41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATLAB\n",
      "tokens: 0.0001 B\n",
      "size: 0.0003 GB\n",
      "\n",
      "JULIA\n",
      "tokens: 0.6699 B\n",
      "size: 1.7519 GB\n",
      "\n",
      "R\n",
      "tokens: 0.1243 B\n",
      "size: 0.2889 GB\n",
      "\n",
      "SAGE\n",
      "tokens: 0.0063 B\n",
      "size: 0.0148 GB\n",
      "\n",
      "MATHEMATICA\n",
      "tokens: 0.8235 B\n",
      "size: 1.7000 GB\n",
      "\n",
      "MAPLE\n",
      "tokens: 0.0085 B\n",
      "size: 0.0154 GB\n",
      "\n",
      "GAP\n",
      "tokens: 0.0053 B\n",
      "size: 0.0126 GB\n",
      "\n",
      "LEAN\n",
      "tokens: 0.0695 B\n",
      "size: 0.1628 GB\n",
      "\n",
      "ISABELLE\n",
      "tokens: 0.0393 B\n",
      "size: 0.0989 GB\n",
      "\n",
      "PYTHON\n",
      "tokens: 6.8227 B\n",
      "size: 21.0366 GB\n",
      "\n",
      "C\n",
      "tokens: 0.0254 B\n",
      "size: 0.0680 GB\n",
      "\n",
      "C++\n",
      "tokens: 1.3958 B\n",
      "size: 4.2658 GB\n",
      "\n",
      "TEX\n",
      "tokens: 0.6872 B\n",
      "size: 2.1816 GB\n",
      "\n",
      "CUMULATIVE:\n",
      "tokens: 10.6778 B\n",
      "size: 31.5977 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cumsize = 0\n",
    "cumtokens = 0\n",
    "with open(\"stack-code/stats.json\") as f: \n",
    "    stats = json.load(f)\n",
    "    \n",
    "for key in stats:\n",
    "    print(key.upper())\n",
    "    tokens = stats[key][\"neox_tokens\"]/10**9\n",
    "    cumtokens += tokens\n",
    "    print(f\"tokens: {tokens:.4f} B\")\n",
    "    size = stats[key][\"size\"]/10**9\n",
    "    cumsize += size\n",
    "    print(f\"size: {size:.4f} GB\\n\")\n",
    "\n",
    "print(\"CUMULATIVE:\")\n",
    "print(f\"tokens: {cumtokens:.4f} B\")\n",
    "print(f\"size: {cumsize:.4f} GB\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52e126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [(key.title(), stats[key][\"neox_tokens\"]) for key in stats]\n",
    "\n",
    "pairs = sorted(pairs, key = lambda x: -x[1])\n",
    "\n",
    "plt.bar([x[0] for x in pairs], [x[1] for x in pairs])\n",
    "plt.ylabel('Tokens')\n",
    "plt.yscale('log')\n",
    "plt.xticks(rotation=-60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d1f6c4",
   "metadata": {},
   "source": [
    "**Problems with the stack**\n",
    "- Issue: Matlab is wrong. There are only 111 matlab files that match the regex `[a-df-zA-Z]`. Looks like most of the matlab files are just arrays saved as text. Very little of the actual code was captured. \n",
    "    - [x] Fix 1: Regex filter to delete arrays\n",
    "    - [ ] Fix 2: Find rest of matlab files\n",
    "- Issue: The R data contains MacOS \"resource fork\" files that aren't related to R at all. \n",
    "    - [x] Fix: filter out resource forks\n",
    "- Issue: .sagews files have a bunch of hashes all over the place.\n",
    "    - [ ] Fix: figure out how to delete hashes, or render notebooks. \n",
    "- Issue: .sage files tend to have a bunch of long strings of hardcode numbers. Is this ok? e.g `ClathomasPrime/CompetitiveStableMatching:Plotting/plots.sage`\n",
    "- Issue: Wolfram mathematica has three file formats:`.wls`: Wolfram language script, handled ok; `.m`Wolfram language package, handled ok; `.nb`: notebook, the plaintext has a bunch of noise. Need to export as `.wls`. \n",
    "    - [ ] Fix: convert notebooks to tex or wls\n",
    "- Issue: There is one mathematica repo, `dendaxD/QAOA-MaxCut-amplitudes`, that contains about half of all mathematica files in the stack. All these files are extremely similar and should be included on data diversity grounds\n",
    "    - [x] Fix: filter out this repo. \n",
    "- Issue: Some maple files are actually xml\n",
    "    - [x] Fix: filter out xml\n",
    "- Issue: Lots of auto-generated tex files in directories called `latex`. \n",
    "    - [x] Fix: remove these\n",
    "\n",
    "Languages the stack does ok:\n",
    "- Lean is fine\n",
    "- Julia is fine (possibly want to remove files that meet jsonl spec)\n",
    "- Python is clean (maybe get rid of Chinese characters?)\n",
    "\n",
    "I'm not sure if my C/C++ filtering is good at all. Am I getting too many `.h` files?\n",
    "\n",
    "Do we want Chinese in our Python?\n",
    "\n",
    "Another issue to consider: Non-latin characters, e.g Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "id": "dddc7dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len:  100000\n"
     ]
    }
   ],
   "source": [
    "lang = \"python\"\n",
    "with open(f\"stack-code/{lang}/0000000.jsonl\") as f: \n",
    "    ds = ndjson.load(f)\n",
    "\n",
    "print(\"len: \", len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1276,
   "id": "68de09e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ex(example): \n",
    "    print(text[\"max_stars_repo_name\"])\n",
    "    print(text[\"max_stars_repo_path\"] + \"\\n\" + \"#\"*40 + \"\\n\")\n",
    "    print(text[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1266,
   "id": "82654d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 \n",
    "random.shuffle(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1277,
   "id": "a314231a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "samesense/chilin\n",
      "software/mdseqpos/lib/pwmclus_motif_comp.py\n",
      "########################################\n",
      "\n",
      "#!/usr/bin/env python\n",
      "#coding: utf-8\n",
      "\n",
      "\"\"\"Reference: http://nar.oxfordjournals.org/content/early/2013/12/23/nar.gkt1302.full\n",
      "\n",
      "Created by: Jian Ma 2014-03-15\n",
      "Modiied by: Jian Ma 2014-04-14\n",
      "\"\"\"\n",
      "import math\n",
      "import numpy\n",
      "import mdseqpos\n",
      "#import MotifParser as mp\n",
      "\n",
      "def sum_IC(m1):\n",
      "    \"\"\"sum of IC of each column in the matrix\n",
      "    \"\"\"\n",
      "    ic = [IC(t) for t in m1]\n",
      "    return sum(ic)\n",
      "\n",
      "def IC(v1):\n",
      "    \"\"\"IC of a vector\n",
      "    \"\"\"\n",
      "    total = sum(v1)\n",
      "    v1 = [t * 1.0 / total for t in v1]\n",
      "    return 2 + sum([t * math.log(t, 2) for t in v1])\n",
      "\n",
      "def pcc_vector(v1, v2):\n",
      "    \"\"\"Pearson Correlation Coefficient for 2 vectors\n",
      "    \"\"\"\n",
      "    len1 = len(v1)\n",
      "    len2 = len(v2)\n",
      "    if len1 != len2:\n",
      "        return None\n",
      "    else:\n",
      "        length = len1\n",
      "    avg1 = 1.0 * sum(v1) / len(v1)\n",
      "    avg2 = 1.0 * sum(v2) / len(v2)\n",
      "    dxy = [(v1[i] - avg1) * (v2[i] - avg2) for i in range(length)]\n",
      "    dx2 = [(v1[i] - avg1) ** 2 for i in range(length)]\n",
      "    dy2 = [(v2[i] - avg2) ** 2 for i in range(length)]\n",
      "    return sum(dxy) / (sum(dx2) * sum(dy2)) ** 0.5\n",
      "\n",
      "def pcc_matrix_IC(m1, m2):\n",
      "    \"\"\"IC weighted pcc score of each column, and get a sum\n",
      "    \n",
      "    The sharp of m1 and m2 should be same\n",
      "    \"\"\"\n",
      "    if len(m1) != len(m2):\n",
      "        return None\n",
      "    weighted_pcc = 0\n",
      "    for pos in range(len(m1)):\n",
      "        ic_x = IC(m1[pos])\n",
      "        ic_y = IC(m2[pos])\n",
      "        #print ic_x, ic_y\n",
      "        ic_xy = (ic_x * ic_y) ** 0.5\n",
      "        pcc = pcc_vector(m1[pos], m2[pos])\n",
      "        \n",
      "        #if ic_x >= 0.2 and ic_y >= 0.2:\n",
      "        #    ic = ic_xy\n",
      "        #elif ic_x >= 0.2:\n",
      "        #    ic = ic_x\n",
      "        #elif ic_y >= 0.2:\n",
      "        #    ic = ic_y\n",
      "        #else:\n",
      "        #    ic = 0\n",
      "        #weighted_pcc += ic * pcc\n",
      "        weighted_pcc += ic_xy * pcc\n",
      "    return weighted_pcc\n",
      "\n",
      "def similarity(m1, m2):\n",
      "    len1 = len(m1)\n",
      "    len2 = len(m2)\n",
      "    if len1 < len2:\n",
      "        m1, m2 = m2, m1 #ensure m1 > m2\n",
      "        len1, len2 = len2, len1\n",
      "        #print range(0, len2 - len1 + 1)\n",
      "    max_score = 0\n",
      "    shift_pos = None\n",
      "    reverse = None\n",
      "    for shift in range(1-len2, len1):\n",
      "        if shift < 0:\n",
      "            m1new = m1[:len2+shift]\n",
      "            m2new = m2[-shift:]\n",
      "            m2rev = [t[::-1] for t in m2[::-1]][-shift:] # important: reverse first, then slice\n",
      "        elif shift <= len1 - len2:\n",
      "            m1new = m1[shift:shift+len2]\n",
      "            m2new = m2[:]\n",
      "            m2rev = [t[::-1] for t in m2[::-1]][:]\n",
      "        elif len1 - shift < len2:\n",
      "            m1new = m1[shift:]\n",
      "            m2new = m2[:len1-shift]\n",
      "            m2rev = [t[::-1] for t in m2[::-1]][:len1-shift]\n",
      "        \n",
      "        ic1new = [IC(t) for t in m1new]\n",
      "        ic2new = [IC(t) for t in m2new]\n",
      "        ic2rev = [IC(t) for t in m2rev]\n",
      "        \n",
      "        # un-reverse\n",
      "        weight_overlap = sum([(t1 * t2) ** 0.5 for t1, t2 in zip(ic1new, ic2new)])\n",
      "        weight_nonoverlap = sum_IC(m1) + sum_IC(m2) - sum_IC(m1new) - sum_IC(m2new)\n",
      "        weighted_pcc = pcc_matrix_IC(m1new, m2new)\n",
      "        score = weighted_pcc / (weight_overlap + weight_nonoverlap)\n",
      "        if score > max_score:\n",
      "            max_score = score\n",
      "            shift_pos = shift\n",
      "            reverse = False\n",
      "            \n",
      "        # reverse\n",
      "        weight_overlap = sum([(t1 * t2) ** 0.5 for t1, t2 in zip(ic1new, ic2rev)])\n",
      "        weight_nonoverlap = sum_IC(m1) + sum_IC(m2) - sum_IC(m1new) - sum_IC(m2rev)\n",
      "        weighted_pcc = pcc_matrix_IC(m1new, m2rev)\n",
      "        score = weighted_pcc / (weight_overlap + weight_nonoverlap)\n",
      "        if score > max_score:\n",
      "            max_score = score\n",
      "            shift_pos = shift\n",
      "            reverse = True\n",
      "    \n",
      "    return max_score, shift_pos, reverse\n",
      "\n",
      "'''\n",
      "#test\n",
      "inf = open('test.distance')\n",
      "mm=[]\n",
      "ii=0\n",
      "for l in inf:\n",
      "    ii+=1\n",
      "    if ii%10000==0:\n",
      "        print ii\n",
      "    l = l.split('\\t')\n",
      "    id1 = l[0].split('_')[0]\n",
      "    id2 = l[1].split('_')[0]\n",
      "    score = float(l[2])\n",
      "    cc = similarity(p.motifs[id1]['pssm'][0], p.motifs[id2]['pssm'][0])\n",
      "    mm.append(cc[0]-score)\n",
      "    if abs(cc[0]-score) > 0.2:\n",
      "        print id1, id2, cc, score\n",
      "\n",
      "\n",
      "mmm=sorted(mm, key=lambda x:abs(x))\n",
      "mmm[0]\n",
      "mmm[-1]\n",
      "'''\n",
      "\n",
      "class Cluster:\n",
      "   def __init__(self):\n",
      "       self.motif = {}\n",
      "       self.nodes = []\n",
      "       self.nodescount = 1\n",
      "       self.score_for_node = 0.0\n",
      "\n",
      "def flat(cluster):\n",
      "    '''flat a Cluster class into a list.\n",
      "    '''\n",
      "    if not cluster.nodes:\n",
      "        return [cluster.motif]\n",
      "    else:\n",
      "        return flat(cluster.nodes[0]) + flat(cluster.nodes[1])\n",
      "\n",
      "def motif_hcluster(motif_list, cutoff):\n",
      "    \"\"\"Use complete distance, that mean get farest for each cluster.\n",
      "    \"\"\"\n",
      "    #from mdseqpos import pwmclus_motif_comp as pmc\n",
      "    #p = mp.MotifParser\n",
      "    #keys = p.motifs.keys()\n",
      "    #keys = keys[:20]\n",
      "    #print keys\n",
      "    clusters = [] # a list with clustered motifs.\n",
      "    cluster_score_mat = numpy.array([[None for t in range(len(motif_list))] for m in range(len(motif_list))]) # 2d matrix, order as keys.\n",
      "    \n",
      "    # Adding motifs from mp to clusters\n",
      "    #for k in keys:\n",
      "    for m in motif_list:\n",
      "        cl = Cluster()\n",
      "        cl.motif.update(m)\n",
      "        cl.motif['pssm'] = [[float(t1) for t1 in t] for t in m['pssm']]  #numpy.array(m['pssm'])\n",
      "        cl.motif['id'] = m['id']\n",
      "        clusters.append(cl)\n",
      "\n",
      "    #Calc each 2 pair of motifs and fill (score, position, strand) in matrix like below\n",
      "    # xxx\n",
      "    #  xx\n",
      "    #   x\n",
      "    #    \n",
      "    for i in range(len(clusters)-1):\n",
      "        for j in range(i+1, len(clusters)):\n",
      "            ts = similarity(clusters[i].motif['pssm'], clusters[j].motif['pssm']) # score, position, strand\n",
      "            cluster_score_mat[i][j] = ts[0] # 1-distance score\n",
      "\n",
      "    idcount = 0\n",
      "    mround = 0\n",
      "    \n",
      "    #find index of the max score\n",
      "    while 1:\n",
      "        max_score = cluster_score_mat.max()\n",
      "        mshape = cluster_score_mat.shape\n",
      "        max_index = (999, 999)\n",
      "        findit = False\n",
      "        for i in range(mshape[0]):\n",
      "            for j in range(i+1, mshape[1]):\n",
      "                if abs(max_score - cluster_score_mat[i][j]) < 1e-5:\n",
      "                    max_index = (i, j)\n",
      "                    findit = True\n",
      "                    break\n",
      "            if findit:\n",
      "                break\n",
      "        \n",
      "        # if the max is smaller than cutoff, end of clustering\n",
      "        if max_score < cutoff:\n",
      "            break\n",
      "        \n",
      "        # Build merged motif except the matrix, matrix will add later.\n",
      "        max2 = clusters.pop(max_index[1])\n",
      "        max1 = clusters.pop(max_index[0])\n",
      "        merged = Cluster()\n",
      "        merged.score_for_node = max_score\n",
      "        merged.nodescount = max1.nodescount + max2.nodescount\n",
      "        merged.nodes = [max1,max2]\n",
      "        merged.motif['id'] = 'MT%d'%idcount\n",
      "        \n",
      "        idcount += 1\n",
      "        \n",
      "        # Append merged motif to cluster\n",
      "        clusters.append(merged)\n",
      "        print 'Finish round', mround\n",
      "        mround += 1\n",
      "        \n",
      "        # Refine score matrix and list. Including cut 2 line and 2 col, and then add 1 line and 1 col.\n",
      "        i, j = max_index\n",
      "        score_y1 = numpy.append(cluster_score_mat[:,i][:i], cluster_score_mat[i][i:])\n",
      "        score_y2 = numpy.append(cluster_score_mat[:,j][:j], cluster_score_mat[j][j:])\n",
      "        score_ymin = []\n",
      "        for x1, x2 in zip(score_y1, score_y2):\n",
      "            if x1 is None or x2 is None:\n",
      "                pass\n",
      "            elif x1 > x2:\n",
      "                score_ymin.append(x2)\n",
      "            else:\n",
      "                score_ymin.append(x1)\n",
      "        cluster_score_mat = numpy.append(cluster_score_mat[:j], cluster_score_mat[j+1:],0)\n",
      "        cluster_score_mat = numpy.append(cluster_score_mat[:i], cluster_score_mat[i+1:],0)\n",
      "        cluster_score_mat = numpy.append(cluster_score_mat[:,:j], cluster_score_mat[:,j+1:], 1)\n",
      "        cluster_score_mat = numpy.append(cluster_score_mat[:,:i], cluster_score_mat[:,i+1:], 1)\n",
      "        x = cluster_score_mat.shape[0]\n",
      "        \n",
      "        if score_ymin:\n",
      "            cluster_score_mat = numpy.append(cluster_score_mat, [[t] for t in score_ymin], 1)\n",
      "            cluster_score_mat = numpy.append(cluster_score_mat, [[None for t in range(x+1)]], 0)\n",
      "        else:\n",
      "            break # all motif in it are 1 cluster.\n",
      "    \n",
      "    #print 'Cluster %d motifs into %d clusters' %(len(keys), len(clusters))\n",
      "    flat_clusters = [flat(t) for t in clusters]\n",
      "    return flat_clusters\n",
      "\n",
      "def motif_hcluster2(motif_list, cutoff):\n",
      "    \"\"\"Use complete distance, that mean get farest for each cluster.\n",
      "    \n",
      "    This one is for the MDSeqPos.py to use, input motif_list is list of Motif() obj.\n",
      "    \"\"\"\n",
      "    clusters = [] # a list with clustered motifs.\n",
      "    cluster_score_mat = numpy.array([[None for t in range(len(motif_list))] for m in range(len(motif_list))]) # 2d matrix, order as keys.\n",
      "    \n",
      "    # Adding motifs from mp to clusters\n",
      "    for m in motif_list:\n",
      "        cl = Cluster()\n",
      "        cl.motif = m\n",
      "        clusters.append(cl)\n",
      "\n",
      "    #Calc each 2 pair of motifs and fill (score, position, strand) in matrix like below\n",
      "    # xxx\n",
      "    #  xx\n",
      "    #   x\n",
      "    #    \n",
      "    count = 0\n",
      "    for i in range(len(clusters)-1):\n",
      "        count+=1\n",
      "        print count\n",
      "        for j in range(i+1, len(clusters)):\n",
      "            ts = similarity(clusters[i].motif.seqpos_results['pssm'], clusters[j].motif.seqpos_results['pssm']) # score, position, strand\n",
      "            cluster_score_mat[i][j] = ts[0] # 1-distance score\n",
      "\n",
      "    idcount = 0\n",
      "    mround = 0\n",
      "    \n",
      "    #find index of the max score\n",
      "    while 1:\n",
      "        if not cluster_score_mat.any():\n",
      "            break\n",
      "        max_score = cluster_score_mat.max()\n",
      "        mshape = cluster_score_mat.shape\n",
      "        max_index = (999, 999)\n",
      "        findit = False\n",
      "        for i in range(mshape[0]):\n",
      "            for j in range(i+1, mshape[1]):\n",
      "                if abs(max_score - cluster_score_mat[i][j]) < 1e-5:\n",
      "                    max_index = (i, j)\n",
      "                    findit = True\n",
      "                    break\n",
      "            if findit:\n",
      "                break\n",
      "        \n",
      "        # if the max is smaller than cutoff, end of clustering\n",
      "        if max_score < cutoff:\n",
      "            break\n",
      "        \n",
      "        # Build merged motif except the matrix, matrix will add later.\n",
      "        max2 = clusters.pop(max_index[1])\n",
      "        max1 = clusters.pop(max_index[0])\n",
      "        merged = Cluster()\n",
      "        merged.motif = mdseqpos.motif.Motif()\n",
      "        merged.score_for_node = max_score\n",
      "        merged.nodescount = max1.nodescount + max2.nodescount\n",
      "        merged.nodes = [max1,max2]\n",
      "        merged.motif.id = 'MT%d'%idcount\n",
      "        \n",
      "        idcount += 1\n",
      "        \n",
      "        # Append merged motif to cluster\n",
      "        clusters.append(merged)\n",
      "        print 'Clustering, finish round', mround\n",
      "        mround += 1\n",
      "        \n",
      "        # Refine score matrix and list. Including cut 2 line and 2 col, and then add 1 line and 1 col.\n",
      "        i, j = max_index\n",
      "        score_y1 = numpy.append(cluster_score_mat[:,i][:i], cluster_score_mat[i][i:])\n",
      "        score_y2 = numpy.append(cluster_score_mat[:,j][:j], cluster_score_mat[j][j:])\n",
      "        score_ymin = []\n",
      "        for x1, x2 in zip(score_y1, score_y2):\n",
      "            if x1 is None or x2 is None:\n",
      "                pass\n",
      "            elif x1 > x2:\n",
      "                score_ymin.append(x2)\n",
      "            else:\n",
      "                score_ymin.append(x1)\n",
      "        cluster_score_mat = numpy.append(cluster_score_mat[:j], cluster_score_mat[j+1:],0)\n",
      "        cluster_score_mat = numpy.append(cluster_score_mat[:i], cluster_score_mat[i+1:],0)\n",
      "        cluster_score_mat = numpy.append(cluster_score_mat[:,:j], cluster_score_mat[:,j+1:], 1)\n",
      "        cluster_score_mat = numpy.append(cluster_score_mat[:,:i], cluster_score_mat[:,i+1:], 1)\n",
      "        x = cluster_score_mat.shape[0]\n",
      "        \n",
      "        if score_ymin:\n",
      "            cluster_score_mat = numpy.append(cluster_score_mat, [[t] for t in score_ymin], 1)\n",
      "            cluster_score_mat = numpy.append(cluster_score_mat, [[None for t in range(x+1)]], 0)\n",
      "        else:\n",
      "            break # all motif in it are 1 cluster.\n",
      "    \n",
      "    #print 'Cluster %d motifs into %d clusters' %(len(keys), len(clusters))\n",
      "    flat_clusters = [flat(t) for t in clusters]\n",
      "    return flat_clusters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i += 1\n",
    "text = ds[i]\n",
    "print(i)\n",
    "print_ex(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1263,
   "id": "c83d465c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nicolair/maths-cours\n",
      "C2195.tex\n",
      "\\input{courspdf.tex}\n",
      "\\debutcours{Approximations des zéros d'une fonction}{alpha}\n",
      "\n",
      "L'approximation des zéros (ou racines) d'une fonction comporte deux temps : la séparation des racines et l'approximation proprement dite.\\newline\n",
      "La séparation des racines consiste à former des intervalles sur lesquels la restriction de la fonction a de bonnes propriétés et admet une seule racine. Les méthodes proposées ici ne portent que sur les manières de former des valeurs approchées de l'unique zéro dans l'intervalle considéré.\\newline\n",
      "Dans les trois cas, on supposera que la fonction est strictement croissante sur un intervalle $[a,b]$ avec $f(a)<0$ et $f(b)>0$.\n",
      "\n",
      "\\section{Dichotomie}\n",
      "La méthode de dichotomie repose sur le diagramme suivant et se met en oeuvre très facilement informatiquement. Il est à noter que l'on dispose automatiquement d'une majorations de l'erreur car après $n$ itérations, la racine est entre $a$ et $b$ avec \n",
      "\\begin{displaymath}\n",
      " 0<b-a=\\frac{b-a}{2^n}\n",
      "\\end{displaymath}\n",
      "\\begin{figure}[ht]\n",
      " \\centering\n",
      " \\includegraphics[width=12cm]{C2195_1.pdf}\n",
      " \\caption{Dichotomie}\n",
      "\\label{C2195_1}\n",
      "\\end{figure}\n",
      "\n",
      "\\section{Méthode de la sécante}\n",
      "\\begin{figure}[ht]\n",
      " \\centering\n",
      "\\input{C2195_3.pdf_t}\n",
      "\\caption{Méthode de la sécante}\n",
      "\\label{fig:C2195_3}\n",
      "\\end{figure} \n",
      "\\index{méthode de la sécante}\n",
      "\\index{Interpolation linéaire}\n",
      "\n",
      "\\section{Méthode de Newton}\n",
      "\\begin{figure}[ht]\n",
      " \\centering\n",
      "\\input{C2195_2.pdf_t}\n",
      "\\caption{Méthode de Newton}\n",
      "\\label{fig:C2195_2}\n",
      "\\end{figure} \n",
      "\\index{méthode de Newton}\n",
      "La séparation des racines a conduit à une fonction $f$ de classe $\\mathcal C^2([a,b])$ telle que $f(a)<0$, $f(b)>0$, strictement croissante et convexe. L'unique zéro de $f$ est notée $\\xi$.\\newline\n",
      "Le principe de la méthode de Newton est de considérer le point d'intersection de la tangente en $M_b$ (de coordonnées $(b,f(b))$ avec l'axe des abscisses. Son abscisse est notée $c$. On démontre alors les résultats suivants :\n",
      "\\begin{displaymath}\n",
      " c = b - \\frac{f(b)}{f'(b)} \\hspace{1cm} \\xi < c < b\n",
      "\\end{displaymath}\n",
      "En effet, un point de coordonnées $(x,y)$ est sur la tangente en $M_b$ si et seulement si\n",
      "\\begin{displaymath}\n",
      " y = f(b) +(x-b)f'(b)\n",
      "\\end{displaymath}\n",
      "On en tire\n",
      "\\begin{displaymath}\n",
      " 0 = b+ (c-b)f'(b) \\Rightarrow c = b - \\frac{f(b)}{f'(b)}\n",
      "\\end{displaymath}\n",
      "Comme $f(b)$ et $f'(b)$ sont strictement positifs, cela prouve aussi $c<b$. Pour l'autre inégalité, on considère l'accroissement entre $\\xi$ et $b$, on utilise ensuite le théorème des accroisements finis puis la  croissance de la dérivée:\n",
      "\\begin{displaymath}\n",
      " \\exists d\\in ]\\xi,b[ \\text{ tel que }\n",
      "\\frac{f(b)}{b-\\xi}=\\frac{f(b)-f(\\xi)}{b-\\xi}=f'(d)< f'(b)\n",
      "\\Rightarrow \\frac{f(b)}{f'(b)}<b-\\xi \\Rightarrow \\xi < c\n",
      "\\end{displaymath}\n",
      "On peut donc définir par récurrence une suite $\\left(x_n \\right)_{n\\in\\N}$ par :\n",
      "\\begin{displaymath}\n",
      " x_0=b\\hspace{1cm} x_{n+1} = x_n-\\frac{f(x_n)}{f'(x_n)}\n",
      "\\end{displaymath}\n",
      "D'après les résultats précédents appliqués à un intervalle $[a,x_n]$, cette suite est décroissante et minorée par $\\xi$ :\n",
      "\\begin{displaymath}\n",
      " \\forall n\\in \\N : \\xi < x_{n+1} < x_n\n",
      "\\end{displaymath}\n",
      "Considérons la fonction $\\varphi$ définie par \n",
      "\\begin{displaymath}\n",
      "\\forall x\\in [a,b] : \\varphi(x) = -\\frac{f(x)}{f'(x)} \n",
      "\\end{displaymath}\n",
      "Elle est évidemment continue et vérifie \n",
      "\\begin{displaymath}\n",
      " \\varphi(x)=x \\Leftrightarrow f(x)=0\n",
      "\\end{displaymath}\n",
      "On en déduit que la limite de la suite convergente $\\left(x_n \\right)_{n\\in\\N}$ est l'unique zéro $\\xi$.\\newline\n",
      "En fait cette convergence est très rapide. Cela tient au fait que $\\xi$ est un point \\og super-attractif \\fg de $\\varphi$. En effet :\n",
      "\\begin{displaymath}\n",
      " \\varphi'(x) = \\frac{f(x)f''(x)}{f'(x)^2} \\Rightarrow \\varphi'(\\xi)=0\n",
      "\\end{displaymath}\n",
      "Cela permet d'obtenir des \\hyperdef{prop}{major}{formules de majoration d'erreur} très intéressantes et commodes:\n",
      "\\begin{displaymath}\n",
      " \\left\\lbrace \n",
      "\\begin{aligned}\n",
      " 0< x_n -\\xi \\leq&\\frac{M_2}{2m_1}(x_{n-1}-x_n)^2\\\\\n",
      " 0< x_{n+1}-\\xi \\leq&\\frac{M_2}{2m_1}(\\xi-x_n)^2\n",
      "\\end{aligned}\n",
      "\\right. \n",
      "\\text{ avec } m_1 = \\min_{[a,b]}|f'| \\text{ et } M_2 = \\max_{[a,b]}f'' \n",
      "\\end{displaymath}\n",
      "\\begin{demo}\n",
      " On utilise la formule de Taylor avec reste de Lagrange à l'ordre 2 entre $x_{n-1}$ et $x_{n}$. Il existe $c\\in]x_n,x_{n-1}[$ tel que \n",
      "\\begin{displaymath}\n",
      "  f(x_{n})=f(x_{n-1})+(x_{n} -x_{n-1})f'(x_{n-1})+\\frac{(x_{n}-x_{n-1})^2}{2}f''(c)\n",
      "\\end{displaymath}\n",
      "Par construction :\n",
      "\\begin{displaymath}\n",
      " x_{n}=x_{n-1}-\\frac{f(x_{n-1})}{f'(x_{n-1})}\\Rightarrow f(x_{n-1)}+ (x_{n} -x_{n-1})f'(x_{n-1})=0\n",
      "\\Rightarrow f(x_{n+1})=\\frac{(x_{n+1}-x_{n})^2}{2}f''(c)\n",
      "\\end{displaymath}\n",
      "D'autre part, en utilisant le théorème des accroissements finis appliqué à $f$ entre $x_{n}$ et $\\xi$, il existe $d\\in ]\\xi,x_{n}[$ tel que \n",
      "\\begin{displaymath}\n",
      " 0=f(\\xi)=f(x_{n}) + (\\xi-x_n)f'(d)\n",
      "\\end{displaymath}\n",
      "On en déduit\n",
      "\\begin{displaymath}\n",
      " x_n -\\xi = -\\frac{f(x_n)}{f'(d)}= - \\frac{(x_{n}-x_{n-1})^2f''(c)}{2f'(d)}\\leq \\frac{M_2}{2m_1}(x_{n}-x_{n-1})^2\n",
      "\\end{displaymath}\n",
      "Utilisons maintenant la formule de Taylor avec reste de Lagrange à l'ordre $2$ entre $x_n$ et $\\xi$. Il existe $u\\in ]\\xi,x_n[$ tel que \n",
      "\\begin{displaymath}\n",
      "  0=f(\\xi)=f(x_{n})+(\\xi -x_{n})f'(x_{n})+\\frac{(\\xi-x_{n})^2}{2}f''(u)\n",
      "\\end{displaymath}\n",
      "Or\n",
      "\\begin{displaymath}\n",
      " x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}\\Rightarrow f(x_n)-x_nf'(x_n)=-x_{n+1}f'(x_n)\n",
      "\\Rightarrow 0= (\\xi -x_{n+1})f'(x_{n})+\\frac{(\\xi-x_{n})^2}{2}f''(u)\n",
      "\\end{displaymath}\n",
      "On obtient donc :\n",
      "\\begin{displaymath}\n",
      " x_{n+1}-\\xi = \\frac{(\\xi-x_{n})^2f''(u)}{2f'(x_n}\\leq \\frac{M_2}{2m_1}(\\xi-x_{n})^2\n",
      "\\end{displaymath}\n",
      "\n",
      "\\end{demo}\n",
      "\\end{document}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "j = 10\n",
    "print(ds[j][\"max_stars_repo_name\"])\n",
    "print(ds[j][\"max_stars_repo_path\"])\n",
    "print(ds[j][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1278,
   "id": "307735db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ds: \n",
    "    if x[\"ext\"]==\"ipynb\":\n",
    "        print_ex(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a49a576e",
   "metadata": {},
   "source": [
    "## Generic Filter Debugging Utilities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77875c55",
   "metadata": {},
   "source": [
    "We define a utility function to load the full dataset for a given language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acd33269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lang_dataset(lang):\n",
    "    ds = []\n",
    "    dir = os.path.join(\"stack-code\", lang)\n",
    "    files = sorted(os.listdir(dir))\n",
    "    for f in files:\n",
    "        f = os.path.join(dir, f)\n",
    "        print(f\"Loading: {f}.\")\n",
    "        with open(f) as f:\n",
    "            ds += ndjson.load(f)\n",
    "    return ds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "200fa2e8",
   "metadata": {},
   "source": [
    "We define some generic utilities to filter and visualize datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8ba153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_str(ex):\n",
    "    \"\"\"\n",
    "    A rendering of a data sample as a single Julia string.\n",
    "    \"\"\"\n",
    "    return \"\\n\\n\".join([\n",
    "        \"# \" + ex[\"max_stars_repo_name\"],\n",
    "        \"# \" + ex[\"max_stars_repo_path\"],\n",
    "        ex[\"content\"]])\n",
    "\n",
    "def filtered(filter, dataset):\n",
    "    return [d for d in dataset if filter(d)]\n",
    "\n",
    "def sorted_by_size(dataset):\n",
    "    return sorted(dataset, key=lambda x: x[\"size\"], reverse=True)\n",
    "\n",
    "def save_examples(examples, dir, ext=\"txt\", max_num=None):\n",
    "    dir = os.path.join(\"analysis\", dir)\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    for i, d in enumerate(examples):\n",
    "        print(example_str(d), file=open(os.path.join(dir, f\"{i}.{ext}\"), \"w\"))\n",
    "        if max_num is not None and i >= max_num:\n",
    "            break\n",
    "\n",
    "def total_size(ds):\n",
    "    return sum(d[\"size\"] for d in ds) / 1e9"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aadfcf72",
   "metadata": {},
   "source": [
    "## Designing the Julia Filter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37919171",
   "metadata": {},
   "source": [
    "We first load the full Julia dataset and plot a histogram of file size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0bc3554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: stack-code/julia/0000000.jsonl.\n",
      "Loading: stack-code/julia/0000001.jsonl.\n",
      "Loading: stack-code/julia/0000002.jsonl.\n",
      "Loading: stack-code/julia/0000003.jsonl.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "JULIA_DATASET = load_lang_dataset(\"julia\")\n",
    "plt.hist([math.log10(d[\"size\"]) for d in JULIA_DATASET], log=True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd4a35ac",
   "metadata": {},
   "source": [
    "We can now define the current Julia filter being proposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3b2b140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def julia_test_file(ex, ratio=0.1):\n",
    "    # Whether a file has some minimum ratio of @test statements\n",
    "    txt = ex[\"content\"]\n",
    "    kwd = \"@test\"\n",
    "    nlines = txt.count(\"\\n\") + 1\n",
    "    return kwd in txt and (txt.count(kwd) / nlines >= ratio)\n",
    "\n",
    "def julia_numerical_density(ex):\n",
    "    # The ratio of digit characters over non-digit characters in the file\n",
    "    txt = ex[\"content\"]\n",
    "    ntoks = sum(txt.count(c) for c in \"0123456789\")\n",
    "    return ntoks / len(txt)\n",
    "\n",
    "def generated_file(ex):\n",
    "    #This heuristic happens to be superfluous\n",
    "    return \"generated\" in ex[\"max_stars_repo_name\"] or ex[\"max_stars_repo_name\"][0] == \".\"\n",
    "\n",
    "def julia_filter(ex):\n",
    "    if ex[\"content\"][0] in [\"%\", \"{\", \"[\"]:\n",
    "        # Eliminates non-Julia files such as JSON lines (.jl) files \n",
    "        return False\n",
    "    elif ex[\"size\"] >= 1e5:\n",
    "        # Overly large files are often auto-generated boilerplate and/or mostly\n",
    "        # contain large arrays of numbers.Thus, we reject such large files unless\n",
    "        # unless they are test files with low numerical density.\n",
    "        return julia_test_file(ex) and julia_numerical_density(ex) <= 0.5\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b41d21ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of keywords that make a Julia file interesting\n",
    "julia_whitelist = [\n",
    "    # Popular packages for scientific computing\n",
    "    \"LinearAlgebra\",\n",
    "    \"DifferentialEquations\",\n",
    "    \"Symbolics\",\n",
    "    \"Distributions\",\n",
    "    \"DataFrames\",\n",
    "    \"DynamicalSystems\",\n",
    "    \"Turing\",\n",
    "    \"Gen\",\n",
    "    \"JuMP\",\n",
    "    # Standard mathematical functions\n",
    "    \"sqrt\",\n",
    "    \"abs\",\n",
    "    \"zeros\",\n",
    "    \"ones\",\n",
    "    \"sin\",\n",
    "    \"cos\",\n",
    "    \"tan\",\n",
    "    \"log\",\n",
    "    \"exp\",\n",
    "    \"integrate\",\n",
    "    \"likelihood\",\n",
    "    \"Matrix\",\n",
    "    \"π\",\n",
    "    \"pi\",\n",
    "    \"rand\",\n",
    "    \"grad\"\n",
    "]\n",
    "\n",
    "julia_whitelist_rexp = re.compile(\"|\".join(\"(\\\\W\" + kwd + \"\\\\W)\" for kwd in julia_whitelist))\n",
    "\n",
    "def julia_filter_strict(ex):\n",
    "    return julia_filter(ex) and julia_whitelist_rexp.search(ex[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a575b03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 1.50GB\n",
      "Filtered: 1.50GB\n"
     ]
    }
   ],
   "source": [
    "# Computing the strict filtered dataset is a bit slow\n",
    "# This should take about 5-10 minutes.\n",
    "\n",
    "JULIA_DATASET_FILTERED = filtered(julia_filter, JULIA_DATASET)\n",
    "JULIA_DATASET_FILTERED_STRICT = filtered(julia_filter_strict, JULIA_DATASET)\n",
    "\n",
    "print(f\"Total: {total_size(JULIA_DATASET):.2f}GB\")\n",
    "print(f\"Filtered: {total_size(JULIA_DATASET_FILTERED):.2f}GB\")\n",
    "print(f\"Filtered strict: {total_size(JULIA_DATASET_FILTERED_STRICT):.2f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6db083c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_julia_filtered_examples():\n",
    "    dataset_shuffled = JULIA_DATASET_FILTERED.copy()\n",
    "    random.shuffle(dataset_shuffled)\n",
    "    dataset_sorted = sorted_by_size(JULIA_DATASET_FILTERED)\n",
    "    save_examples(dataset_shuffled, \"shuffled\", max_num=100, ext=\"jl\")\n",
    "    save_examples(dataset_sorted, \"largest\", max_num=100, ext=\"jl\")\n",
    "    save_examples(JULIA_DATASET_FILTERED_STRICT, \"strict\", max_num=100, ext=\"jl\")\n",
    "\n",
    "save_julia_filtered_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391d7f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
