{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ndjson\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len:  100000\n"
     ]
    }
   ],
   "source": [
    "lang = \"julia\"\n",
    "with open(f\"stack-code/{lang}/0000000.jsonl\") as f: \n",
    "    ds = ndjson.load(f)\n",
    "\n",
    "print(\"len: \", len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ex(example): \n",
    "    print(example[\"max_stars_repo_name\"])\n",
    "    print(example[\"max_stars_repo_path\"] + \"\\n\" + \"#\"*40 + \"\\n\")\n",
    "    print(example[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING EXAMPLE  0\n",
      "lucpaoli/Clapeyron.jl\n",
      "src/Clapeyron.jl\n",
      "########################################\n",
      "\n",
      "module Clapeyron\n",
      "using StaticArrays\n",
      "using LinearAlgebra\n",
      "\n",
      "#for the assoc solver\n",
      "import PackedVectorsOfVectors\n",
      "const PackedVofV = PackedVectorsOfVectors.PackedVectorOfVectors\n",
      "\n",
      "#for non allocating vectors of zeros and ones\n",
      "using FillArrays: FillArrays\n",
      "\n",
      "using Roots: Roots\n",
      "using NLSolvers\n",
      "import Metaheuristics\n",
      "using DiffResults, ForwardDiff\n",
      "using Scratch \n",
      "include(\"solvers/Solvers.jl\")\n",
      "using .Solvers\n",
      "using .Solvers: log, sqrt\n",
      "using Unitful\n",
      "import LogExpFunctions\n",
      "include(\"constants.jl\")\n",
      "include(\"models/basetools.jl\") #type hierarchy\n",
      "include(\"database/ParamOptions.jl\") \n",
      "include(\"utils/vectors.jl\")\n",
      "include(\"utils/ClapeyronParam.jl\")\n",
      "\n",
      "\n",
      "include(\"utils/macros.jl\")\n",
      "using CSV, Tables\n",
      "include(\"database/database.jl\")\n",
      "include(\"utils/misc.jl\")\n",
      "\n",
      "\n",
      "include(\"models/combiningrules.jl\")\n",
      "\n",
      "include(\"models/eos.jl\")\n",
      "include(\"utils/visualisation.jl\")\n",
      "include(\"utils/split_model.jl\")\n",
      "include(\"database/UserReader.jl\")\n",
      "\n",
      "include(\"models/eos/ideal/BasicIdeal.jl\") #before macros, because its used there\n",
      "include(\"models/eos/ideal/MonomerIdeal.jl\")\n",
      "include(\"models/eos/ideal/ReidIdeal.jl\")\n",
      "include(\"models/eos/ideal/WalkerIdeal.jl\")\n",
      "include(\"models/eos/ideal/JobackIdeal.jl\")\n",
      "\n",
      "include(\"models/eos/SAFT/PCSAFT/PCSAFT.jl\")\n",
      "include(\"models/eos/SAFT/PCSAFT/variants/sPCSAFT.jl\")\n",
      "\n",
      "include(\"models/eos/SAFT/ogSAFT/ogSAFT.jl\")\n",
      "include(\"models/eos/SAFT/CPA/CPA.jl\")\n",
      "include(\"models/eos/SAFT/CPA/variants/sCPA.jl\")\n",
      "include(\"models/eos/SAFT/SAFTVRSW/SAFTVRSW.jl\")\n",
      "include(\"models/eos/SAFT/LJSAFT/LJSAFT.jl\")\n",
      "include(\"models/eos/SAFT/softSAFT/softSAFT.jl\")\n",
      "include(\"models/eos/SAFT/SAFTVRMie/SAFTVRMie.jl\")\n",
      "include(\"models/eos/SAFT/SAFTVRMie/variants/SAFTVRQMie.jl\")\n",
      "include(\"models/eos/SAFT/SAFTgammaMie/SAFTgammaMie.jl\")\n",
      "\n",
      "include(\"models/eos/SAFT/CKSAFT/CKSAFT.jl\")\n",
      "include(\"models/eos/SAFT/CKSAFT/variants/sCKSAFT.jl\")\n",
      "include(\"models/eos/SAFT/BACKSAFT/BACKSAFT.jl\")\n",
      "\n",
      "include(\"models/eos/SAFT/equations.jl\")\n",
      "\n",
      "include(\"models/eos/cubic/equations.jl\")\n",
      "include(\"models/eos/cubic/vdW.jl\")\n",
      "include(\"models/eos/cubic/RK/RK.jl\")\n",
      "include(\"models/eos/cubic/PR/PR.jl\")\n",
      "\n",
      "include(\"models/eos/Activity/Wilson/Wilson.jl\")\n",
      "include(\"models/eos/Activity/NRTL/NRTL.jl\")\n",
      "include(\"models/eos/Activity/UNIQUAC/UNIQUAC.jl\")\n",
      "include(\"models/eos/Activity/UNIFAC/UNIFAC.jl\")\n",
      "include(\"models/eos/Activity/UNIFAC/variants/ogUNIFAC.jl\")\n",
      "include(\"models/eos/Activity/UNIFAC/variants/PSRK.jl\")\n",
      "include(\"models/eos/Activity/UNIFAC/variants/VTPR.jl\")\n",
      "\n",
      "include(\"models/eos/Activity/COSMOSAC/utils.jl\")\n",
      "include(\"models/eos/Activity/COSMOSAC/COSMOSAC02.jl\")\n",
      "include(\"models/eos/Activity/COSMOSAC/COSMOSAC10.jl\")\n",
      "include(\"models/eos/Activity/COSMOSAC/COSMOSACdsp.jl\")\n",
      "\n",
      "include(\"models/eos/cubic/alphas/alphas.jl\")\n",
      "include(\"models/eos/cubic/mixing/mixing.jl\")\n",
      "include(\"models/eos/cubic/translation/translation.jl\")\n",
      "\n",
      "include(\"models/eos/cubic/RK/variants/SRK.jl\")\n",
      "include(\"models/eos/cubic/RK/variants/PSRK.jl\")\n",
      "include(\"models/eos/cubic/PR/variants/PR78.jl\")\n",
      "include(\"models/eos/cubic/PR/variants/VTPR.jl\")\n",
      "include(\"models/eos/cubic/PR/variants/UMRPR.jl\")\n",
      "\n",
      "include(\"models/eos/Activity/equations.jl\")\n",
      "\n",
      "include(\"models/eos/EmpiricHelmholtz/IAPWS95.jl\")\n",
      "include(\"models/eos/EmpiricHelmholtz/PropaneRef.jl\")\n",
      "include(\"models/eos/EmpiricHelmholtz/GERG2008/GERG2008.jl\")\n",
      "\n",
      "include(\"models/eos/LatticeFluid/SanchezLacombe/SanchezLacombe.jl\")\n",
      "\n",
      "include(\"models/eos/SPUNG/SPUNG.jl\")\n",
      "\n",
      "include(\"models/eos/cached/CachedEoS.jl\")\n",
      "\n",
      "include(\"methods/methods.jl\")\n",
      "\n",
      "end # module\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  1\n",
      "zhenwu0728/Oceananigans.jl\n",
      "src/Solvers/solver_utils.jl\n",
      "########################################\n",
      "\n",
      "\"\"\"\n",
      "    ω(M, k)\n",
      "\n",
      "Return the `M`th root of unity raised to the `k`th power.\n",
      "\"\"\"\n",
      "@inline ω(M, k) = exp(-2im*π*k/M)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  2\n",
      "UnofficialJuliaMirror/Celeste.jl-92f6eab1-61e3-5b29-aa81-669a19de860c\n",
      "src/mcmc/mcmc_infer.jl\n",
      "########################################\n",
      "\n",
      "# High level MCMC and AIS inference functions.  These functions\n",
      "# construct the star and galaxy log likelihood and prior functions, and\n",
      "# run either Slice-Sampling or Slice-Sampling-within-AIS\n",
      "\n",
      "\"\"\"\n",
      "Runs Annealed Importance Sampling on both the Star and Galaxy posteriors\n",
      "to estimate the marginal likelihood of each model and posterior samples\n",
      "simultaneously\n",
      "\"\"\"\n",
      "function run_ais(entry::CatalogEntry,\n",
      "                 imgs::Vector,\n",
      "                 patches::Array{ImagePatch, 2},\n",
      "                 background_images::Array{Array{Float64, 2}, 1},\n",
      "                 pos_delta::Array{Float64, 1}=[2., 2.];\n",
      "                 num_samples::Int=2,\n",
      "                 num_temperatures::Int=50,\n",
      "                 print_skip::Int=20,\n",
      "                 num_samples_per_chain::Int=25)\n",
      "    Log.info(\"\\nRunning AIS on with patch size $(imgs[1].H) x $(imgs[1].W)\")\n",
      "    Log.info(\"  catalog type: $(entry.is_star ? \"star\" : \"galaxy\")\")\n",
      "    Log.info(\"  num images  : $(length(imgs))\")\n",
      "    n_active = sum([sum(p.active_pixel_bitmap) for p in patches[1, :]]) / length(patches[1,:])\n",
      "    Log.info(\"  num active pixels per patch: $(n_active)\")\n",
      "    #imgs, pos_delta, num_samples, print_skip, num_temperatures, num_samples_per_chain = patch_images, [1., 1.], 3, 1, 10, 25\n",
      "\n",
      "    ###################\n",
      "    # run star MCMC   #\n",
      "    ###################\n",
      "    star_loglike, star_logprior, star_logpost, sample_star_prior, ra_lim, dec_lim, uniform_to_deg, deg_to_uniform =\n",
      "          MCMC.make_star_inference_functions(imgs, entry;\n",
      "                                        patches=patches[1, :],\n",
      "                                        background_images=background_images,\n",
      "                                        pos_delta=pos_delta)\n",
      "\n",
      "    th_cat = [log.(entry.star_fluxes)..., deg_to_uniform(entry.pos)...]\n",
      "    th_rand = sample_star_prior()\n",
      "    Log.info(\"star loglike at CATALOG vs PRIOR : \", star_loglike(th_cat), \", \", star_loglike(th_rand))\n",
      "    Log.info(\"star logprior at CATALOG vs PRIOR : \", star_logprior(th_cat), \", \", star_logprior(th_rand))\n",
      "    star_schedule = MCMC.sigmoid_schedule(num_temperatures; rad=4)\n",
      "    res_star = MCMC.ais_slicesample(star_logpost, star_logprior,\n",
      "                                    sample_star_prior;\n",
      "                                    schedule=star_schedule,\n",
      "                                    num_samps=num_samples,\n",
      "                                    num_samples_per_step=1)\n",
      "    star_chains, star_chain_lls = [], []\n",
      "    for i in 1:size(res_star[:zsamps], 2)\n",
      "        Log.info(\"    star chain \", i, \" of \", size(res_star[:zsamps], 2))\n",
      "        star_chain, star_lls = MCMC.slicesample_chain(star_logpost,\n",
      "            res_star[:zsamps][:,1], num_samples_per_chain;\n",
      "            print_skip=Int64(num_samples_per_chain/5), verbose=false)\n",
      "        push!(star_chains, star_chain)\n",
      "        push!(star_chain_lls, star_lls)\n",
      "    end\n",
      "    res_star[:zsamps]    = transpose(vcat(star_chains...))\n",
      "    res_star[:zsamp_lls] = vcat(star_chain_lls...)\n",
      "    lnZ  = res_star[:lnZ]\n",
      "    lnZs = res_star[:lnZ_bootstrap]\n",
      "    lo, hi = percentile(lnZs, 2.5), percentile(lnZs, 97.5)\n",
      "    Log.info(@sprintf \"STAR AIS estimate : %6.3f [%6.3f, %6.3f]\\n\" lnZ lo hi)\n",
      "    Log.info(@sprintf \"  CI width : %6.5f \\n\" (hi-lo))\n",
      "\n",
      "    ####################\n",
      "    # run galaxy AIS   #\n",
      "    ####################\n",
      "    gal_loglike, gal_logprior, gal_logpost, sample_gal_prior, ra_lim, dec_lim, uniform_to_deg, deg_to_uniform =\n",
      "          MCMC.make_gal_inference_functions(imgs, entry;\n",
      "                                        patches=patches[1, :],\n",
      "                                        background_images=background_images,\n",
      "                                        pos_delta=pos_delta)\n",
      "    th_cat = MCMC.parameters_from_catalog(entry; is_star=false)\n",
      "    th_rand = sample_gal_prior()\n",
      "    Log.info(\"gal loglike  at CATALOG vs PRIOR : \", gal_loglike(th_cat), \", \", gal_loglike(th_rand))\n",
      "    Log.info(\"gal logprior at CATALOG vs PRIOR : \", gal_logprior(th_cat), \", \", gal_logprior(th_rand))\n",
      "    gal_schedule = MCMC.sigmoid_schedule(num_temperatures; rad=4)\n",
      "    res_gal = MCMC.ais_slicesample(gal_logpost, gal_logprior,\n",
      "                                   sample_gal_prior;\n",
      "                                   schedule=gal_schedule,\n",
      "                                   num_samps=num_samples,\n",
      "                                   num_samples_per_step=1)\n",
      "    gal_chains, gal_chain_lls = [], []\n",
      "    for i in 1:size(res_gal[:zsamps], 2)\n",
      "        Log.info(\"    gal chain \", i, \" of \", size(res_gal[:zsamps], 2))\n",
      "        gal_chain, gal_lls = MCMC.slicesample_chain(gal_logpost,\n",
      "            res_gal[:zsamps][:,1], num_samples_per_chain;\n",
      "            print_skip=Int64(num_samples_per_chain/5), verbose=false)\n",
      "        push!(gal_chains, gal_chain)\n",
      "        push!(gal_chain_lls, gal_lls)\n",
      "    end\n",
      "    res_gal[:zsamps]    = transpose(vcat(gal_chains...))\n",
      "    res_gal[:zsamp_lls] = vcat(gal_chain_lls...)\n",
      "    lnZ = res_gal[:lnZ]\n",
      "    lnZs = res_gal[:lnZ_bootstrap]\n",
      "    lo, hi = percentile(lnZs, 2.5), percentile(lnZs, 97.5)\n",
      "    Log.info(@sprintf \"GAL AIS estimate : %6.3f [%6.3f, %6.3f]\\n\" lnZ lo hi)\n",
      "    Log.info(@sprintf \"  CI width : %6.5f \\n\" (hi-lo))\n",
      "\n",
      "    #########################################################\n",
      "    # Compute prob star vs gal based on marginal likelihood #\n",
      "    #########################################################\n",
      "    type_chain  = zeros(length(res_gal[:lnZ_bootstrap]))\n",
      "    # is_star = [.28, .72] vs [.999, .001] vs [.5, .5]\n",
      "    lnprob_a    = log(.28)\n",
      "    lnprob_nota = log(.72)\n",
      "    for n in 1:length(res_gal[:lnZ_bootstrap])\n",
      "        # normalizing constant is ln p(data | star)\n",
      "        # so p(star | data) \\propto p(data | star) p(star)\n",
      "        lnprob_star = res_star[:lnZ_bootstrap][n] + lnprob_a\n",
      "        lnprob_gal  = res_gal[:lnZ_bootstrap][n] + lnprob_nota\n",
      "        lnsum = Model.logsumexp([lnprob_star, lnprob_gal]) # normalize\n",
      "        type_chain[n] = lnprob_star - lnsum\n",
      "    end\n",
      "    ave_pstar = Model.logsumexp(type_chain) - log(length(type_chain))\n",
      "    Log.info(\"  source p-star = \", exp(ave_pstar))\n",
      "\n",
      "    ####################################################################\n",
      "    # convert positions to RA/Dec and organize chains into dataframes  #\n",
      "    ####################################################################\n",
      "    for n in 1:size(res_gal[:zsamps], 2)\n",
      "        res_gal[:zsamps][6:7,n]  = uniform_to_deg(res_gal[:zsamps][6:7,n])\n",
      "        res_star[:zsamps][6:7,n] = uniform_to_deg(res_star[:zsamps][6:7,n])\n",
      "    end\n",
      "    star_chain = MCMC.samples_to_dataframe(transpose(res_star[:zsamps]), is_star=true)\n",
      "    gal_chain  = MCMC.samples_to_dataframe(transpose(res_gal[:zsamps]), is_star=false)\n",
      "\n",
      "    # store objid (for concatenation)\n",
      "    mcmc_results = Dict(\"star_samples\" => star_chain,\n",
      "                        \"star_lls\"     => res_star[:zsamp_lls], #[res_star[:lnZsamps],\n",
      "                        \"star_bootstrap\"=> res_star[:lnZ_bootstrap],\n",
      "                        \"gal_samples\"  => gal_chain,\n",
      "                        \"gal_lls\"      => res_gal[:zsamp_lls], #res_gal[:lnZsamps],\n",
      "                        \"gal_bootstrap\" => res_gal[:lnZ_bootstrap],\n",
      "                        \"type_samples\" => type_chain,\n",
      "                        \"ave_pstar\"    => ave_pstar)\n",
      "    return mcmc_results\n",
      "end\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "Run single source MCMC chain\n",
      "\"\"\"\n",
      "function run_mcmc(entry::CatalogEntry,\n",
      "                  imgs::Vector,\n",
      "                  patches::Array{ImagePatch, 2},\n",
      "                  background_images::Array{Array{Float64, 2}, 1},\n",
      "                  pos_delta::Array{Float64, 1}=[1., 1.];\n",
      "                  num_samples::Int=500,\n",
      "                  print_skip::Int=20)\n",
      "    Log.info(\"\\nRunning mcmc on entry with patch size \",\n",
      "            imgs[1].H, \"x\", imgs[1].W)\n",
      "    Log.info(\"  catalog type: \", entry.is_star ? \"star\" : \"galaxy\")\n",
      "\n",
      "    # position log prior --- same for both star and galaxy (constrains to a\n",
      "    # small window around the existing catalog location\n",
      "    #imgs, pos_delta, num_samples, print_skip = patch_images, [1., 1.], 200, 20\n",
      "    pos_logprior, ra_lim, dec_lim = MCMC.make_location_prior(\n",
      "        imgs[1], entry.pos; pos_pixel_delta=[2., 2.])\n",
      "\n",
      "    ###################\n",
      "    # run star MCMC   #\n",
      "    ###################\n",
      "    star_loglike, constrain_pos, unconstrain_pos =\n",
      "        MCMC.make_star_loglike(imgs, entry.pos;\n",
      "                               patches=patches[1,:],\n",
      "                               background_images=background_images,\n",
      "                               pos_delta=pos_delta)\n",
      "\n",
      "    function star_logprior(th)\n",
      "        lnfluxes, pos = th[1:5], th[6:end]\n",
      "        return MCMC.logflux_logprior(lnfluxes; is_star=true) + pos_logprior(pos)\n",
      "    end\n",
      "\n",
      "    function star_logpost(th)\n",
      "        return star_loglike(th) + star_logprior(th)\n",
      "    end\n",
      "\n",
      "    # log likelihood at data generating parameters, and random prior\n",
      "    th_cat = [log.(entry.star_fluxes)..., entry.pos...]\n",
      "    #th_cat = MCMC.parameters_from_catalog(entry, unconstrain_pos; is_star=true)\n",
      "    #th_rand = [th_cat[1:5]..., [.001, .001]...]\n",
      "    th_rand = th_cat + .0001*randn(length(th_cat))\n",
      "    Log.info(\"loglike at true initial position: \", star_loglike(th_cat))\n",
      "    Log.info(\"loglike at random prior position: \", star_loglike(th_rand))\n",
      "    Log.info(\"logprior at true position:        \", star_logprior(th_cat))\n",
      "\n",
      "    # draw MCMC samples\n",
      "    star_chain, star_lls = MCMC.slicesample_chain(star_logpost, th_cat,\n",
      "        num_samples; print_skip=print_skip, verbose=false)\n",
      "    num_warmup = Int(round(.25 * num_samples))\n",
      "    star_chain = star_chain[num_warmup:end, :]\n",
      "    star_lls   = star_lls[num_warmup:end]\n",
      "\n",
      "    ####################\n",
      "    # run galaxy MCMC  #\n",
      "    ####################\n",
      "    gal_loglike, constrain_pos, unconstrain_pos =\n",
      "        MCMC.make_gal_loglike(imgs, entry.pos;\n",
      "                              patches=patches[1,:],\n",
      "                              background_images=background_images,\n",
      "                              pos_delta=pos_delta)\n",
      "    gal_logprior = MCMC.make_gal_logprior()\n",
      "\n",
      "    # test at catalog initialized position vs shifted --- eye test\n",
      "    th_cat = MCMC.parameters_from_catalog(entry; is_star=false)\n",
      "    th_rand = th_cat + .00001*randn(length(th_cat))\n",
      "    Log.info(\"gal ll at Catalog vs Shifted : \",\n",
      "        gal_loglike(th_cat), \" vs. \", gal_loglike(th_rand))\n",
      "    Log.info(\"gal lnprior at true initial pos:  \", gal_logprior(th_cat))\n",
      "    th_cat[1:5] = th_rand[1:5]\n",
      "\n",
      "    function gal_logpost(th)\n",
      "        # catch illegal values in the prior\n",
      "        llprior = gal_logprior(th)\n",
      "        if llprior < -1e100\n",
      "            return llprior\n",
      "        end\n",
      "        return gal_loglike(th; print_params=false) + llprior\n",
      "    end\n",
      "\n",
      "    # draw MCMC samples\n",
      "    gal_chain, gal_lls = MCMC.slicesample_chain(\n",
      "        gal_logpost, th_cat, num_samples; print_skip=print_skip, verbose=false)\n",
      "    gal_chain = gal_chain[num_warmup:end, :]\n",
      "    gal_lls   = gal_lls[num_warmup:end]\n",
      "\n",
      "    #############################################\n",
      "    # Compute prob star vs gal based on samples #\n",
      "    #############################################\n",
      "    type_chain  = zeros(length(gal_lls))\n",
      "    lnprob_a    = log(.5)\n",
      "    lnprob_nota = log(1.-.5)\n",
      "    for n in 1:length(gal_lls)\n",
      "        # a == 1 full joint prob ln p(pixels | theta^star, a=star) p(theta^star) p(theta^gal) p(a)\n",
      "        lnjoint_star = star_lls[n] + gal_logprior(gal_chain[n, :]) + lnprob_a\n",
      "\n",
      "        # a == 0 (galaxy) full joint\n",
      "        lnjoint_gal = gal_lls[n] + star_logprior(star_chain[n, :]) + lnprob_nota\n",
      "\n",
      "        # compute log prob of type = star (1)\n",
      "        lnsum = Model.logsumexp([lnjoint_star, lnjoint_gal])\n",
      "        type_chain[n] = lnjoint_star - lnsum\n",
      "    end\n",
      "    ave_pstar = Model.logsumexp(type_chain) - log(length(gal_lls))\n",
      "    Log.info(\"  source p-star = \", exp(ave_pstar))\n",
      "\n",
      "    ####################################################################\n",
      "    # convert positions to RA/Dec and organize chains into dataframes  #\n",
      "    ####################################################################\n",
      "    star_chain = MCMC.samples_to_dataframe(star_chain; is_star=true)\n",
      "    gal_chain = MCMC.samples_to_dataframe(gal_chain; is_star=false)\n",
      "\n",
      "    # store objid (for concatenation)\n",
      "    mcmc_results = Dict(\"star_samples\" => star_chain,\n",
      "                        \"star_lls\"     => star_lls,\n",
      "                        \"gal_samples\"  => gal_chain,\n",
      "                        \"gal_lls\"      => gal_lls,\n",
      "                        \"type_samples\" => type_chain)\n",
      "    return mcmc_results\n",
      "end\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "Turn MCMC results into a single dataframe row that summarizes the\n",
      "posterior distribution\n",
      "\"\"\"\n",
      "function summarize_samples(results_dict)\n",
      "    stardf   = results_dict[\"star_samples\"]\n",
      "    galdf    = results_dict[\"gal_samples\"]\n",
      "    star_row = samples_to_dataframe_row(stardf; is_star=true)\n",
      "    gal_row  = samples_to_dataframe_row(galdf; is_star=false)\n",
      "    return star_row, gal_row\n",
      "end\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "Consolidate samples into results dataframes (single entry per source)\n",
      "\"\"\"\n",
      "function consolidate_samples(reslist; objids=nothing)\n",
      "    # give each source a unique label\n",
      "    if objids==nothing\n",
      "        objids = [\"samp_$(i)\" for i in 1:length(reslist)]\n",
      "    end\n",
      "\n",
      "    # loop through each result sample list and summarize\n",
      "    joint_summary, star_summary, gal_summary = [], [], []\n",
      "    for i in 1:length(reslist)\n",
      "        r = reslist[i]\n",
      "\n",
      "        # compute star and gal summaries\n",
      "        star_row, gal_row = summarize_samples(r)\n",
      "        star_row[:objid], gal_row[:objid] = objids[i], objids[i]\n",
      "        push!(star_summary, star_row)\n",
      "        push!(gal_summary, gal_row)\n",
      "\n",
      "        # compute star average\n",
      "        pstar = exp(r[\"ave_pstar\"])\n",
      "        srow  = (pstar > .5) ? star_row : gal_row\n",
      "        srow[:, :is_star] = [pstar]\n",
      "        push!(joint_summary, srow)\n",
      "    end\n",
      "    joint_summary = vcat(joint_summary...)\n",
      "    star_summary  = vcat(star_summary...)\n",
      "    gal_summary   = vcat(gal_summary...)\n",
      "    return star_summary, gal_summary, joint_summary\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  3\n",
      "CPIMC/CPIMC.jl\n",
      "examples/run.jl\n",
      "########################################\n",
      "\n",
      "using StaticArrays\n",
      "using OnlineStats\n",
      "using DelimitedFiles\n",
      "using CPIMC\n",
      "using CPIMC.PlaneWaves\n",
      "using CPIMC.Estimators\n",
      "using CPIMC.UniformElectronGas\n",
      "using CPIMC.DefaultUpdates\n",
      "\n",
      "function main()\n",
      "    # MC options\n",
      "    NMC = 10^5\n",
      "    cyc = 50\n",
      "    NEquil = 2*10^4\n",
      "    # system parameters\n",
      "    θ = 0.125\n",
      "    rs = 2.0\n",
      "\n",
      "    # use 7 particles\n",
      "    S = sphere_with_same_spin(PlaneWave((0,0,0)),dk=1)\n",
      "    N = length(S)\n",
      "    ξ = fractional_spin_polarization(S)\n",
      "    c = Configuration(S)\n",
      "    d = dimension(c.occupations)\n",
      "\n",
      "    println(\"parameters:\")\n",
      "    println(\"θ: \", θ)\n",
      "    println(\"rs: \", rs)\n",
      "    println(\"N: \", N)\n",
      "    println(\"ξ: \", ξ)\n",
      "\n",
      "    e = CEnsemble(λ(N, rs, d), β(θ, N, ξ, d), N)\n",
      "    equilibrate_diagonal!(UEG(), e, c)\n",
      "\n",
      "    updates = [move_particle!, add_type_B!, remove_type_B!, add_type_C!, remove_type_C!, add_type_D!, remove_type_D!, add_type_E!, remove_type_E!, shuffle_indices!]\n",
      "\n",
      "    measurements = Dict(# TODO: type-specification in the construction of the statistic objects (use @code_warntype)\n",
      "      :sign => (Variance(), signum)\n",
      "    , :Ekin => (Variance(), Ekin)\n",
      "    , :W_diag => (Variance(), W_diag)\n",
      "    , :K => (Variance(), K)\n",
      "    , :K_fermion => (Variance(), K)\n",
      "    , :occs => (Group([Variance(Float64) for i in 1:100]), occupations)\n",
      "    )\n",
      "\n",
      "    println(\"Start MC process ... \")\n",
      "    rates = sweep!(UEG(), e, c, updates, measurements, NMC, cyc, NEquil)\n",
      "    println(\" finished.\")\n",
      "\n",
      "    println(\"parameters:\")\n",
      "    println(\"θ: \", θ)\n",
      "    println(\"rs: \", rs)\n",
      "    println(\"N: \", N)\n",
      "\n",
      "    print_rates(rates)\n",
      "\n",
      "    print_results(measurements, e)\n",
      "end\n",
      "\n",
      "main()\n",
      "#Juno.@run(main())\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  4\n",
      "meteorologytoday/IOM\n",
      "tools/misc/make_daily_time.jl\n",
      "########################################\n",
      "\n",
      "using ArgParse\n",
      "using JSON\n",
      "using DataStructures\n",
      "using NCDatasets\n",
      "\n",
      "function runOneCmd(cmd)\n",
      "    println(\">> \", string(cmd))\n",
      "    run(cmd)\n",
      "end\n",
      "\n",
      "function pleaseRun(cmd)\n",
      "    if isa(cmd, Array)\n",
      "        for i = 1:length(cmd)\n",
      "            runOneCmd(cmd[i])\n",
      "        end\n",
      "    else\n",
      "        runOneCmd(cmd)\n",
      "    end\n",
      "end\n",
      "\n",
      "println(\"\"\"\n",
      "This file produce an netcdf file with only `time` and `time_bound` variables\n",
      "for users to append variables to other files. \n",
      "\n",
      "Notice: This program uses no-leap calendar (365 days fixed)\n",
      "\n",
      "\"\"\")\n",
      "\n",
      "s = ArgParseSettings()\n",
      "@add_arg_table s begin\n",
      "\n",
      "    \"--output\"\n",
      "        help = \"The file you want to produce.\"\n",
      "        arg_type = String\n",
      "        required = true\n",
      "\n",
      "    \"--years\"\n",
      "        help = \"How many years?\"\n",
      "        arg_type = Int64\n",
      "        default = 1\n",
      "\n",
      "end\n",
      "\n",
      "parsed = DataStructures.OrderedDict(parse_args(ARGS, s))\n",
      "\n",
      "JSON.print(parsed, 4)\n",
      "\n",
      "\n",
      "doy = 365\n",
      "\n",
      "t    = zeros(Float64,    doy)\n",
      "bnds = zeros(Float64, 2, doy)\n",
      "\n",
      "for d=1:doy*parsed[\"years\"]\n",
      "    bnds[1, d] = d-1\n",
      "    bnds[2, d] = d\n",
      "    t[d] = (bnds[1, d] + bnds[2, d]) / 2.0\n",
      "end\n",
      "\n",
      "Dataset(parsed[\"output\"], \"c\") do ds\n",
      "\n",
      "    defDim(ds, \"time\", Inf)\n",
      "    defDim(ds, \"d2\", 2)\n",
      "\n",
      "    defVar(ds, \"time\", t, (\"time\", ), ; attrib = Dict(\n",
      "        \"long_name\" => \"time\",\n",
      "        \"bounds\"    => \"time_bound\",\n",
      "        \"calendar\"  =>  \"noleap\",\n",
      "        \"units\"     => \"days since 0001-01-01 00:00:00\",\n",
      "    ))\n",
      "\n",
      "    defVar(ds, \"time_bound\", bnds, (\"d2\", \"time\"), ; attrib = Dict(\n",
      "        \"long_name\" => \"boundaries for time-averaging interval\",\n",
      "        \"units\"     => \"days since 0001-01-01 00:00:00\",\n",
      "    ))\n",
      "\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  5\n",
      "JuliaBinaryWrappers/cohomCalg_jll.jl\n",
      "src/cohomCalg_jll.jl\n",
      "########################################\n",
      "\n",
      "# Use baremodule to shave off a few KB from the serialized `.ji` file\n",
      "baremodule cohomCalg_jll\n",
      "using Base\n",
      "using Base: UUID\n",
      "import JLLWrappers\n",
      "\n",
      "JLLWrappers.@generate_main_file_header(\"cohomCalg\")\n",
      "JLLWrappers.@generate_main_file(\"cohomCalg\", UUID(\"5558cf25-a90e-53b0-b813-cadaa3ae7ade\"))\n",
      "end  # module cohomCalg_jll\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  6\n",
      "JuliaReinforcementLearning/JuliaReinforcementLearning.github.io\n",
      "docs/experiments/experiments/Offline/JuliaRL_PLAS_Pendulum.jl\n",
      "########################################\n",
      "\n",
      "using ReinforcementLearning\n",
      "using StableRNGs\n",
      "using Flux\n",
      "using Flux.Losses\n",
      "\n",
      "function RL.Experiment(\n",
      "    ::Val{:JuliaRL},\n",
      "    ::Val{:PLAS},\n",
      "    ::Val{:Pendulum},\n",
      "    type::AbstractString;\n",
      "    save_dir = nothing,\n",
      "    seed = 123,\n",
      ")\n",
      "    rng = StableRNG(seed)\n",
      "    inner_env = PendulumEnv(T = Float32, rng = rng)\n",
      "    A = action_space(inner_env)\n",
      "    low = A.left\n",
      "    high = A.right\n",
      "    ns = length(state(inner_env))\n",
      "    na = 1\n",
      "    latent_dims = 2\n",
      "\n",
      "    trajectory_num = 10000\n",
      "    dataset_size = 10000\n",
      "    batch_size = 64\n",
      "\n",
      "    env = ActionTransformedEnv(\n",
      "        inner_env;\n",
      "        action_mapping = x -> low + (x[1] + 1) * 0.5 * (high - low),\n",
      "    )\n",
      "    init = glorot_uniform(rng)\n",
      "\n",
      "    create_policy_net() = NeuralNetworkApproximator(\n",
      "        model = Chain(\n",
      "            Dense(ns, 64, relu; init = glorot_uniform(rng)),\n",
      "            Dense(64, 64, relu; init = glorot_uniform(rng)),\n",
      "            Dense(64, latent_dims; init = glorot_uniform(rng))\n",
      "        ),\n",
      "        optimizer = ADAM(0.003),\n",
      "    )\n",
      "\n",
      "    create_q_net() = NeuralNetworkApproximator(\n",
      "        model = Chain(\n",
      "            Dense(ns + na, 64, relu; init = init),\n",
      "            Dense(64, 64, relu; init = init),\n",
      "            Dense(64, 1; init = init),\n",
      "        ),\n",
      "        optimizer = ADAM(0.003),\n",
      "    )\n",
      "\n",
      "    create_vae_net() = NeuralNetworkApproximator(\n",
      "        model = VAE(\n",
      "            encoder = GaussianNetwork(\n",
      "                pre = Chain(\n",
      "                    Dense(ns + na, 64, relu),\n",
      "                    Dense(64, 64, relu),\n",
      "                ),\n",
      "                μ = Chain(Dense(64, latent_dims, init = init)),\n",
      "                logσ = Chain(Dense(64, latent_dims, init = init)),\n",
      "            ),\n",
      "            decoder = Chain(\n",
      "                Dense(ns + latent_dims, 64, relu; init = init),\n",
      "                Dense(64, 64, relu; init = init),\n",
      "                Dense(64, na; init = init),\n",
      "            ),\n",
      "            latent_dims = latent_dims,\n",
      "        ),\n",
      "        optimizer = ADAM(0.003),\n",
      "    )\n",
      "\n",
      "    agent = Agent(\n",
      "        policy = OfflinePolicy(\n",
      "            learner = PLASLearner(\n",
      "                policy = create_policy_net() |> cpu,\n",
      "                target_policy = create_policy_net() |> cpu,\n",
      "                qnetwork1 = create_q_net() |> cpu,\n",
      "                qnetwork2 = create_q_net() |> cpu,\n",
      "                target_qnetwork1 = create_q_net() |> cpu,\n",
      "                target_qnetwork2 = create_q_net() |> cpu,\n",
      "                vae = create_vae_net() |> cpu,\n",
      "                batch_size = batch_size,\n",
      "                pretrain_step = 1500,\n",
      "                update_freq = 1,\n",
      "            ),\n",
      "            dataset = gen_JuliaRL_dataset(:SAC, :Pendulum, type; dataset_size = dataset_size),\n",
      "            continuous = true,\n",
      "            batch_size = batch_size,\n",
      "        ),\n",
      "        trajectory = CircularArraySARTTrajectory(\n",
      "            capacity = 1000,\n",
      "            state = Vector{Float32} => (ns,),\n",
      "            action = Vector{Float32} => (na,),\n",
      "        ),\n",
      "    )\n",
      "\n",
      "    stop_condition = StopAfterStep(trajectory_num, is_show_progress=!haskey(ENV, \"CI\"))\n",
      "    hook = TotalRewardPerEpisode()\n",
      "    Experiment(agent, env, stop_condition, hook, \"PLAS <-> Pendulum ($type dataset)\")\n",
      "end\n",
      "\n",
      "using Plots\n",
      "pyplot() #hide\n",
      "ex = E`JuliaRL_PLAS_Pendulum(medium)`\n",
      "run(ex)\n",
      "plot(ex.hook.rewards)\n",
      "savefig(\"assets/JuliaRL_PLAS_Pendulum_medium.png\") #hide\n",
      "\n",
      "# This file was generated using Literate.jl, https://github.com/fredrikekre/Literate.jl\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  7\n",
      "mpirke/MPFirst.jl\n",
      "test/runtests.jl\n",
      "########################################\n",
      "\n",
      "using MPFirst\n",
      "using Test\n",
      "\n",
      "@testset \"MPFirst.jl\" begin\n",
      "    # Write your tests here.\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  8\n",
      "fcard/GenPrintf.jl\n",
      "src/GenPrintf.jl\n",
      "########################################\n",
      "\n",
      "module GenPrintf\n",
      "export printf, @fmt_str\n",
      "\n",
      "abstract type FormatSpecifier end\n",
      "\n",
      "struct PrintArgument <: FormatSpecifier end\n",
      "struct PrintValue{V} <: FormatSpecifier end\n",
      "\n",
      "struct PrintBoth{A,B} <: FormatSpecifier\n",
      "  a::A\n",
      "  b::B\n",
      "end\n",
      "\n",
      "const ARGN_ERR =\n",
      "  \"wrong number of arguments sent to printf\"\n",
      "\n",
      "\n",
      "include(\"impl.jl\")\n",
      "include(\"meta.jl\")\n",
      "include(\"cons.jl\")\n",
      "include(\"list.jl\")\n",
      "\n",
      "\"\"\"\n",
      "Macro to create formatting strings.\n",
      "{} are where arguments will go.\n",
      "\n",
      "examples:\n",
      "  fmt\"ab cd\"\n",
      "  fmt\"hello, {}!\"\n",
      "\"\"\"\n",
      "macro fmt_str(s)\n",
      "  values = split(unescape_string(s), \"{}\")\n",
      "  print_list(values)\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "Prints formatted output. Use the fmt macro for it\n",
      "to generate code at compile time.\n",
      "\n",
      "examples:\n",
      "  printf(fmt\"ab cd\")\n",
      "  printf(fmt\"hello, {}!\", \"world\")\n",
      "  printf(\"ab{}{}\", \"c\", \"d\")\n",
      "\"\"\"\n",
      "@generated function printf(fmt::FormatSpecifier, args...)\n",
      "  printf_impl(fmt, length(args))\n",
      "end\n",
      "\n",
      "function printf(fmt::String, args...)\n",
      "  i = 1\n",
      "  values = split(fmt, \"{}\")\n",
      "  @assert length(values) == length(args)+1 ARGN_ERR\n",
      "\n",
      "  for value in values\n",
      "    print(value)\n",
      "    if i != length(args) + 1\n",
      "      print(args[i])\n",
      "      i += 1\n",
      "    end\n",
      "  end\n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  9\n",
      "SpinDoctorMRI/SpinDoctor.jl\n",
      "src/adc/solve_hadc.jl\n",
      "########################################\n",
      "\n",
      "\"\"\"\n",
      "    solve(problem::HADC, gradient::ScalarGradient, odesolver = QNDF();\n",
      "        abstol = 1e-6,\n",
      "        reltol = 1e-4,\n",
      "    )\n",
      "\n",
      "Compute the ADC using a homogenized ADC model (HADC). This is currently only implemented for\n",
      "scalar gradients.\n",
      "\"\"\"\n",
      "function solve(\n",
      "    problem::HADC,\n",
      "    gradient::ScalarGradient,\n",
      "    odesolver = QNDF(autodiff = false);\n",
      "    abstol = 1e-6,\n",
      "    reltol = 1e-4,\n",
      ")\n",
      "    (; model, matrices) = problem\n",
      "    (; mesh, D) = model\n",
      "    (; M_cmpts, S_cmpts, G, volumes) = matrices\n",
      "\n",
      "    f = gradient.profile\n",
      "    dir = gradient.dir\n",
      "    TE = echotime(f)\n",
      "\n",
      "    # Deduce sizes\n",
      "    ncompartment = length(D)\n",
      "\n",
      "    # Initial conditions\n",
      "    ω₀ = zeros.(size.(mesh.points, 2))\n",
      "\n",
      "    # Time dependent ODE function\n",
      "    function Mdω!(dω, ω, p, t)\n",
      "        # @show t\n",
      "        (; mS, f, surfint) = p\n",
      "        mul!(dω, mS, ω)\n",
      "        dω .+= integral(f, t) .* surfint\n",
      "    end\n",
      "\n",
      "    # Create ODE function and Jacobian from matrices\n",
      "    Jac!(J, _, p, t) = (J .= p.mS)\n",
      "\n",
      "    # Allocate output array\n",
      "    adc = zeros(ncompartment)\n",
      "\n",
      "    # Iterate over compartments and gradient sequences and directions\n",
      "    for icmpt = 1:ncompartment\n",
      "        # Free diffusivity in gradient direction\n",
      "        D₀ = dir' * D[icmpt] * dir\n",
      "\n",
      "        # Surface integrals in gradient direction\n",
      "        surfint = G[icmpt] * (D[icmpt] * dir)\n",
      "\n",
      "        p = (; mS = -S_cmpts[icmpt], f, surfint)\n",
      "\n",
      "        odefunction = ODEFunction(\n",
      "            Mdω!,\n",
      "            jac = Jac!,\n",
      "            jac_prototype = p.mS,\n",
      "            mass_matrix = M_cmpts[icmpt],\n",
      "        )\n",
      "        odeproblem = ODEProblem(odefunction, ω₀[icmpt], (0, TE), p, progress = false)\n",
      "\n",
      "        # Solve ODE, keep all time steps (for integral)\n",
      "        sol = OrdinaryDiffEq.solve(odeproblem, odesolver, reltol = reltol, abstol = abstol)\n",
      "\n",
      "        # Integral over compartment boundary\n",
      "        a, = quadgk(t -> integral(f, t) * (surfint' * sol(t)), 0, TE)\n",
      "\n",
      "        # HADC (free diffusivity minus correction)\n",
      "        adc[icmpt] = D₀ - a / volumes[icmpt] / int_F²(f)\n",
      "    end\n",
      "\n",
      "    adc\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  10\n",
      "YiqingZhouKelly/LinQu.jl\n",
      "src/inter_qstate_qgate/qstate_block_circuit.jl\n",
      "########################################\n",
      "\n",
      "\n",
      "function apply!(state::QState, block::QGateBlock, pos::Vector{Int}; kwargs...)\n",
      "\tfor j = 1: length(block)\n",
      "\t\tgateOrBlock = gates(block)[j]\n",
      "\t\tgateOrBlockPos = qubits(block)[j]\n",
      "\t\tapply!(state, gateOrBlock, [pos[i] for i ∈ gateOrBlockPos]; kwargs...)\n",
      "\tend\n",
      "end\n",
      "apply!(state::QState, block::QGateBlock, pos::Int; kwargs...) = apply!(state, block, [pos]; kwargs...)\n",
      "\n",
      "apply!(state::QState, circuit::QCircuit, pos::Vector{Int} = [1:circuit.N;]; kwargs...) = apply!(state, circuit.block, pos; kwargs...)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  11\n",
      "bertapedret/PETLION.jl\n",
      "src/set_variables.jl\n",
      "########################################\n",
      "\n",
      "@inline function set_vars!(sol::R1, p::R2, Y::R3, YP::R3, t::R4, run::R5, opts::R6, bounds::R7;\n",
      "    modify!::R8=set_var!,\n",
      "    init_all::Bool=false,\n",
      "    SOC::Number = (@inbounds sol.SOC[end])\n",
      "    ) where {\n",
      "        R1<:solution,\n",
      "        R2<:model,\n",
      "        R3<:Vector{Float64},\n",
      "        R4<:Float64,\n",
      "        R5<:AbstractRun,\n",
      "        R6<:options_simulation_immutable,\n",
      "        R7<:boundary_stop_conditions_immutable,\n",
      "        R8<:Function,\n",
      "        }\n",
      "    \"\"\"\n",
      "    Sets all the outputs for the sol. There are three kinds of variable outputs:\n",
      "    \n",
      "    1. `keep.x = true`: The variable is calculated and saved on every iteration\n",
      "    \n",
      "    2. `keep.x = false` WITHOUT the check `if keep.x ... end`: These variables  MUST be\n",
      "        calculated to ensure that `check_simulation_stop!` works properly (e.g., check if\n",
      "        `t > tf` or `SOC > SOC_max`), but they are not saved on every iteration\n",
      "    \n",
      "    3. `keep.x = false` WITH the check `if keep.x ... end`: These variables are not\n",
      "        evaluated at all and may not even be calculable (e.g., `T` if there is no\n",
      "        temperature enabled)\n",
      "    \"\"\"\n",
      "    keep = opts.var_keep\n",
      "\n",
      "    # these variables must be calculated, but they may not necessarily be kept\n",
      "    modify!(sol.SOC, isempty(sol.SOC) ? SOC : calc_SOC(SOC, Y, t + run.t0, sol, p), (keep.SOC || init_all))\n",
      "    modify!(sol.t,   t + run.t0, (keep.t || init_all))\n",
      "    \n",
      "    # these variables do not need to be calculated\n",
      "    if keep.YP      modify!(sol.YP,      copy(YP)           ) end\n",
      "    if keep.I       modify!(sol.I,       calc_I(Y, p)       ) end\n",
      "    if keep.V       modify!(sol.V,       calc_V(Y, p)       ) end\n",
      "    if keep.P       modify!(sol.P,       calc_P(Y, p)       ) end\n",
      "    if keep.c_e     modify!(sol.c_e,     calc_c_e(Y, p)     ) end\n",
      "    if keep.c_s_avg modify!(sol.c_s_avg, calc_c_s_avg(Y, p) ) end\n",
      "    if keep.j       modify!(sol.j,       calc_j(Y, p)       ) end\n",
      "    if keep.Φ_e     modify!(sol.Φ_e,     calc_Φ_e(Y, p)     ) end\n",
      "    if keep.Φ_s     modify!(sol.Φ_s,     calc_Φ_s(Y, p)     ) end\n",
      "    \n",
      "    # exist as an optional output if the sol uses them\n",
      "    if ( p.numerics.temperature == true           && keep.T    ) modify!(sol.T,    calc_T(Y,p)    ) end\n",
      "    if ( p.numerics.aging == :SEI                 && keep.film ) modify!(sol.film, calc_film(Y,p) ) end\n",
      "    if ( p.numerics.aging == :SEI                 && keep.SOH  ) modify!(sol.SOH,  calc_SOH(Y, p) ) end\n",
      "    if ( !(p.numerics.aging == false)             && keep.j_s  ) modify!(sol.j_s,  calc_j_s(Y,p)  ) end\n",
      "    if ( p.numerics.solid_diffusion == :quadratic && keep.Q    ) modify!(sol.Q,    calc_Q(Y,p)    ) end\n",
      "\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "@inline set_var!(x, x_val) = push!(x, x_val)\n",
      "@inline function set_var!(x::T1, x_val::T2, keep::Bool) where {T1<:Vector{Float64},T2<:Number}\n",
      "    keep ? push!(x, x_val) : (@inbounds x[1] = x_val)\n",
      "end\n",
      "@inline function set_var!(x::T1, x_val::T2, keep::Bool) where {T1<:VectorOfArray{Float64,2,Array{Array{Float64,1},1}},T2<:AbstractVector{Float64}}\n",
      "    keep ? push!(x, x_val) : (@inbounds x[1] .= x_val)\n",
      "end\n",
      "\n",
      "@inline function set_var_last!(x::T1, x_val::T2, keep=true) where {T1<:Vector{Float64},T2<:Number}\n",
      "    @inbounds x[end] = x_val\n",
      "end\n",
      "@inline function set_var_last!(x::T1, x_val::T2, keep=true) where {T1<:VectorOfArray{Float64,2,Array{Array{Float64,1},1}},T2<:AbstractVector{Float64}}\n",
      "    @inbounds x[end] .= x_val\n",
      "end\n",
      "\n",
      "@inline function (sol::solution)(tspan::Union{Number,AbstractVector}; interp_bc::Symbol=:interpolate, k::Int64=1,kw...)\n",
      "    if tspan isa UnitRange\n",
      "        t = collect(tspan)\n",
      "    elseif tspan isa Number\n",
      "        t = Float64[Float64(tspan)]\n",
      "    else\n",
      "        t = tspan\n",
      "    end\n",
      "\n",
      "    var_keep = @inbounds @views sol.results[end].opts.var_keep\n",
      "    function f(field)\n",
      "        x = getproperty(sol, field)\n",
      "        if field == :t\n",
      "            return t\n",
      "        elseif x isa AbstractArray{Float64} && getproperty(var_keep, field) && length(x) > 1\n",
      "            return interpolate_variable(x, sol, t, interp_bc; k=k, kw...)\n",
      "        else\n",
      "            return x\n",
      "        end\n",
      "    end\n",
      "    \n",
      "    states_tot = @inbounds (f(field) for field in fieldnames(solution))\n",
      "\n",
      "    sol = solution(states_tot...)\n",
      "\n",
      "    return sol\n",
      "end\n",
      "@inline interpolate_variable(x::Any,y...;kw...) = x\n",
      "@inline function interpolate_variable(x::R1, sol::R2, tspan::T1, interp_bc::Symbol;kw...) where {R1<:AbstractVector{Float64},R2<:solution,T1<:Union{Real,AbstractArray}}\n",
      "    spl = Spline1D(sol.t, x; bc = (interp_bc == :interpolate ? \"nearest\" : (interp_bc == :extrapolate ? \"extrapolate\" : error(\"Invalid interp_bc method.\"))),kw...)\n",
      "    out = spl(tspan)\n",
      "    \n",
      "    return out\n",
      "end\n",
      "@inline function interpolate_variable(x::R1,y...;kw...) where {R1<:Union{VectorOfArray{Float64,2,Array{Array{Float64,1},1}},Vector{Vector{Float64}}}}\n",
      "    out = @inbounds @views hcat([interpolate_variable(x[i,:],y...;kw...) for i in 1:size(x,1)]...)\n",
      "\n",
      "    return @inbounds VectorOfArray([out[i,:] for i in 1:size(out,1)])\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  12\n",
      "ranocha/LIKWID.jl\n",
      "src/topology.jl\n",
      "########################################\n",
      "\n",
      "\"Initialize LIKWIDs topology module.\"\n",
      "function init_topology()\n",
      "    ret = LibLikwid.topology_init()\n",
      "    if ret == 0\n",
      "        _cputopo[] = unsafe_load(LibLikwid.get_cpuTopology())\n",
      "        _cpuinfo[] = unsafe_load(LibLikwid.get_cpuInfo())\n",
      "        _build_jl_cputopo()\n",
      "        _build_jl_cpuinfo()\n",
      "        topo_initialized[] = true\n",
      "        return true\n",
      "    end\n",
      "    return false\n",
      "end\n",
      "\n",
      "function _build_jl_cputopo()\n",
      "    ct = _cputopo[]\n",
      "    ncachelvls = Int(ct.numCacheLevels)\n",
      "    nhwthreads = Int(ct.numHWThreads)\n",
      "    threadpools = unsafe_wrap(Array, ct.threadPool, nhwthreads)\n",
      "    threads = Vector{HWThread}(undef, nhwthreads)\n",
      "    for (i, tp) in enumerate(threadpools)\n",
      "        threads[i] = HWThread(\n",
      "            tp.threadId,\n",
      "            tp.coreId,\n",
      "            tp.packageId,\n",
      "            tp.apicId,\n",
      "            tp.dieId,\n",
      "            tp.inCpuSet,\n",
      "        )\n",
      "    end\n",
      "    cachelvls = unsafe_wrap(Array, ct.cacheLevels, ncachelvls)\n",
      "    caches = Vector{CacheLevel}(undef, ncachelvls)\n",
      "    for (i, clvl) in enumerate(cachelvls)\n",
      "        caches[i] = CacheLevel(\n",
      "            clvl.level,\n",
      "            clvl.type == LibLikwid.DATACACHE ? :data :\n",
      "                          clvl.type == LibLikwid.INSTRUCTIONCACHE ? :instruction :\n",
      "                          clvl.type == LibLikwid.UNIFIEDCACHE ? :unified :\n",
      "                          clvl.type == LibLikwid.ITLB ? :itlb :\n",
      "                          clvl.type == LibLikwid.DTLB ? :dtlb : :nocache,\n",
      "            clvl.associativity,\n",
      "            clvl.sets,\n",
      "            clvl.lineSize,\n",
      "            clvl.size,\n",
      "            clvl.threads,\n",
      "            clvl.inclusive,\n",
      "        )\n",
      "    end\n",
      "\n",
      "    cputopo[] = CpuTopology(\n",
      "        nhwthreads,\n",
      "        ct.activeHWThreads,\n",
      "        ct.numSockets,\n",
      "        ct.numDies,\n",
      "        ct.numCoresPerSocket,\n",
      "        ct.numThreadsPerCore,\n",
      "        ncachelvls,\n",
      "        threads,\n",
      "        caches,\n",
      "    )\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "\"Close and finalize LIKWIDs topology module.\"\n",
      "function finalize_topology()\n",
      "    LibLikwid.topology_finalize()\n",
      "    topo_initialized[] = false\n",
      "    _cputopo[] = nothing\n",
      "    _cpuinfo[] = nothing\n",
      "    cputopo[] = nothing\n",
      "    cpuinfo[] = nothing\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "function _build_jl_cpuinfo()\n",
      "    ci = _cpuinfo[]\n",
      "    cpuinfo[] = CpuInfo(\n",
      "        ci.family,\n",
      "        ci.model,\n",
      "        ci.stepping,\n",
      "        ci.vendor,\n",
      "        ci.part,\n",
      "        ci.clock,\n",
      "        ci.turbo,\n",
      "        unsafe_string(ci.osname),\n",
      "        unsafe_string(ci.name),\n",
      "        unsafe_string(ci.short_name),\n",
      "        unsafe_string(ci.features),\n",
      "        ci.isIntel,\n",
      "        join(Char(c) for c in ci.architecture if !iszero(c)),\n",
      "        ci.supportUncore,\n",
      "        ci.supportClientmem,\n",
      "        ci.featureFlags,\n",
      "        ci.perf_version,\n",
      "        ci.perf_num_ctr,\n",
      "        ci.perf_width_ctr,\n",
      "        ci.perf_num_fixed_ctr,\n",
      "    )\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    get_cpu_topology() -> CpuTopology\n",
      "Get the CPU topology of the machine.\n",
      "\n",
      "Automatically initializes the topology and NUMA modules,\n",
      "i.e. calls [`LIKWID.init_topology`](@ref) and [`LIKWID.init_numa`](@ref).\n",
      "\"\"\"\n",
      "function get_cpu_topology()\n",
      "    if !topo_initialized[]\n",
      "        init_topology() || error(\"Couldn't init topology.\")\n",
      "    end\n",
      "    if !numa_initialized[]\n",
      "        init_numa() || error(\"Couldn't init numa.\")\n",
      "    end\n",
      "    return cputopo[]\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    get_cpu_info() -> CpuInfo\n",
      "Get detailed information about the CPU.\n",
      "\n",
      "Automatically initializes the topology and NUMA modules,\n",
      "i.e. calls [`LIKWID.init_topology`](@ref) and [`LIKWID.init_numa`](@ref).\n",
      "\"\"\"\n",
      "function get_cpu_info()\n",
      "    if !topo_initialized[]\n",
      "        init_topology() || error(\"Couldn't init topology.\")\n",
      "    end\n",
      "    if !numa_initialized[]\n",
      "        init_numa() || error(\"Couldn't init numa.\")\n",
      "    end\n",
      "    return cpuinfo[]\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    print_supported_cpus(; cprint=true)\n",
      "Print a list of all supported CPUs.\n",
      "\n",
      "If `cprint=false`, LIKWID.jl\n",
      "will first capture the stdout and then `print` the list.\n",
      "\"\"\"\n",
      "function print_supported_cpus(; cprint=true)\n",
      "    if cprint\n",
      "        LibLikwid.print_supportedCPUs()\n",
      "    else\n",
      "        buf = IOBuffer()\n",
      "        capture_stdout!(LibLikwid.print_supportedCPUs, buf)\n",
      "        s = String(take!(buf))\n",
      "        print(s)\n",
      "    end\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "Graphical visualization of the CPU topology. Extracts the corresponding output of `likwid-topology -g`.\n",
      "\"\"\"\n",
      "function print_cpu_topology()\n",
      "    out = _execute(`likwid-topology -g`)\n",
      "    if out[:stderr] != \"\"\n",
      "        @warn out[:stderr]\n",
      "    end\n",
      "    stdout = out[:stdout]\n",
      "    idcs = findfirst(\"Graphical Topology\", stdout)\n",
      "    print(stdout[first(idcs):end])\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  13\n",
      "ZWoodstock/FrankWolfe.jl\n",
      "examples/blended_cg.jl\n",
      "########################################\n",
      "\n",
      "include(\"activate.jl\")\n",
      "\n",
      "using LinearAlgebra\n",
      "using Random\n",
      "using SparseArrays\n",
      "\n",
      "n = 1000\n",
      "k = 10000\n",
      "\n",
      "s = rand(1:100)\n",
      "@info \"Seed $s\"\n",
      "\n",
      "# this seed produces numerical issues with Float64 with the k-sparse 100 lmo / for testing\n",
      "s = 41\n",
      "Random.seed!(s)\n",
      "\n",
      "\n",
      "matrix = rand(n, n)\n",
      "hessian = transpose(matrix) * matrix\n",
      "linear = rand(n)\n",
      "f(x) = dot(linear, x) + 0.5 * transpose(x) * hessian * x\n",
      "function grad!(storage, x)\n",
      "    return storage .= linear + hessian * x\n",
      "end\n",
      "L = eigmax(hessian)\n",
      "\n",
      "#Run over the probability simplex and call LMO to get initial feasible point\n",
      "lmo = FrankWolfe.ProbabilitySimplexOracle(1.0);\n",
      "x00 = FrankWolfe.compute_extreme_point(lmo, zeros(n))\n",
      "\n",
      "target_tolerance = 1e-5\n",
      "\n",
      "x0 = deepcopy(x00)\n",
      "x, v, primal, dual_gap, trajectoryBCG_accel_simplex = FrankWolfe.blended_conditional_gradient(\n",
      "    f,\n",
      "    grad!,\n",
      "    lmo,\n",
      "    x0,\n",
      "    epsilon=target_tolerance,\n",
      "    max_iteration=k,\n",
      "    line_search=FrankWolfe.Adaptive(),\n",
      "    print_iter=k / 10,\n",
      "    hessian=hessian,\n",
      "    emphasis=FrankWolfe.memory,\n",
      "    L=L,\n",
      "    accelerated=true,\n",
      "    verbose=true,\n",
      "    trajectory=true,\n",
      "    K=1.00,\n",
      "    weight_purge_threshold=1e-10,\n",
      ")\n",
      "\n",
      "x0 = deepcopy(x00)\n",
      "x, v, primal, dual_gap, trajectoryBCG_simplex = FrankWolfe.blended_conditional_gradient(\n",
      "    f,\n",
      "    grad!,\n",
      "    lmo,\n",
      "    x0,\n",
      "    epsilon=target_tolerance,\n",
      "    max_iteration=k,\n",
      "    line_search=FrankWolfe.Adaptive(),\n",
      "    print_iter=k / 10,\n",
      "    hessian=hessian,\n",
      "    emphasis=FrankWolfe.memory,\n",
      "    L=L,\n",
      "    accelerated=false,\n",
      "    verbose=true,\n",
      "    trajectory=true,\n",
      "    K=1.00,\n",
      "    weight_purge_threshold=1e-10,\n",
      ")\n",
      "\n",
      "x0 = deepcopy(x00)\n",
      "x, v, primal, dual_gap, trajectoryBCG_convex = FrankWolfe.blended_conditional_gradient(\n",
      "    f,\n",
      "    grad!,\n",
      "    lmo,\n",
      "    x0,\n",
      "    epsilon=target_tolerance,\n",
      "    max_iteration=k,\n",
      "    line_search=FrankWolfe.Adaptive(),\n",
      "    print_iter=k / 10,\n",
      "    emphasis=FrankWolfe.memory,\n",
      "    L=L,\n",
      "    verbose=true,\n",
      "    trajectory=true,\n",
      "    K=1.00,\n",
      "    weight_purge_threshold=1e-10,\n",
      ")\n",
      "\n",
      "data = [trajectoryBCG_accel_simplex, trajectoryBCG_simplex, trajectoryBCG_convex]\n",
      "label = [\"BCG (accel simplex)\", \"BCG (simplex)\", \"BCG (convex)\"]\n",
      "FrankWolfe.plot_trajectories(data, label, xscalelog=true)\n",
      "\n",
      "\n",
      "\n",
      "matrix = rand(n, n)\n",
      "hessian = transpose(matrix) * matrix\n",
      "linear = rand(n)\n",
      "f(x) = dot(linear, x) + 0.5 * transpose(x) * hessian * x + 10\n",
      "function grad!(storage, x)\n",
      "    return storage .= linear + hessian * x\n",
      "end\n",
      "L = eigmax(hessian)\n",
      "\n",
      "#Run over the K-sparse polytope\n",
      "lmo = FrankWolfe.KSparseLMO(100, 100.0)\n",
      "x00 = FrankWolfe.compute_extreme_point(lmo, zeros(n))\n",
      "\n",
      "x0 = deepcopy(x00)\n",
      "x, v, primal, dual_gap, trajectoryBCG_accel_simplex = FrankWolfe.blended_conditional_gradient(\n",
      "    f,\n",
      "    grad!,\n",
      "    lmo,\n",
      "    x0,\n",
      "    epsilon=target_tolerance,\n",
      "    max_iteration=k,\n",
      "    line_search=FrankWolfe.Adaptive(),\n",
      "    print_iter=k / 10,\n",
      "    hessian=hessian,\n",
      "    emphasis=FrankWolfe.memory,\n",
      "    L=L,\n",
      "    accelerated=true,\n",
      "    verbose=true,\n",
      "    trajectory=true,\n",
      "    K=1.00,\n",
      "    weight_purge_threshold=1e-10,\n",
      ")\n",
      "\n",
      "x0 = deepcopy(x00)\n",
      "x, v, primal, dual_gap, trajectoryBCG_simplex = FrankWolfe.blended_conditional_gradient(\n",
      "    f,\n",
      "    grad!,\n",
      "    lmo,\n",
      "    x0,\n",
      "    epsilon=target_tolerance,\n",
      "    max_iteration=k,\n",
      "    line_search=FrankWolfe.Adaptive(),\n",
      "    print_iter=k / 10,\n",
      "    hessian=hessian,\n",
      "    emphasis=FrankWolfe.memory,\n",
      "    L=L,\n",
      "    accelerated=false,\n",
      "    verbose=true,\n",
      "    trajectory=true,\n",
      "    K=1.00,\n",
      "    weight_purge_threshold=1e-10,\n",
      ")\n",
      "\n",
      "x0 = deepcopy(x00)\n",
      "x, v, primal, dual_gap, trajectoryBCG_convex = FrankWolfe.blended_conditional_gradient(\n",
      "    f,\n",
      "    grad!,\n",
      "    lmo,\n",
      "    x0,\n",
      "    epsilon=target_tolerance,\n",
      "    max_iteration=k,\n",
      "    line_search=FrankWolfe.Adaptive(),\n",
      "    print_iter=k / 10,\n",
      "    emphasis=FrankWolfe.memory,\n",
      "    L=L,\n",
      "    verbose=true,\n",
      "    trajectory=true,\n",
      "    K=1.00,\n",
      "    weight_purge_threshold=1e-10,\n",
      ")\n",
      "\n",
      "x0 = deepcopy(x00)\n",
      "x, v, primal, dual_gap, trajectoryBPCG = FrankWolfe.blended_pairwise_conditional_gradient(\n",
      "    f,\n",
      "    grad!,\n",
      "    lmo,\n",
      "    x0,\n",
      "    epsilon=target_tolerance,\n",
      "    max_iteration=k,\n",
      "    line_search=FrankWolfe.Adaptive(),\n",
      "    print_iter=k / 10,\n",
      "    emphasis=FrankWolfe.memory,\n",
      "    L=L,\n",
      "    verbose=true,\n",
      "    trajectory=true,\n",
      ")\n",
      "\n",
      "data = [trajectoryBCG_accel_simplex, trajectoryBCG_simplex, trajectoryBCG_convex, trajectoryBPCG]\n",
      "label = [\"BCG (accel simplex)\", \"BCG (simplex)\", \"BCG (convex)\", \"BPCG\"]\n",
      "FrankWolfe.plot_trajectories(data, label, xscalelog=false)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  14\n",
      "KrisJensen/metaRL\n",
      "bandit_utils.jl\n",
      "########################################\n",
      "\n",
      "include(\"A2C_utils.jl\")\n",
      "using Flux, Statistics, Random, Distributions, StatsFuns, Zygote\n",
      "\n",
      "T = 100\n",
      "Nhidden = 50\n",
      "Nstates = 1\n",
      "Nstate_rep = 1\n",
      "Naction = 2\n",
      "Nin = Naction+1+1 #no state information for this agent, just actions, reward, time\n",
      "Nout = Naction+1\n",
      "βv = 0.05f0\n",
      "βe = 0.05f0\n",
      "γ = 0.9f0\n",
      "\n",
      "function forward(m, x)\n",
      "    #this just adds a softmax to the policy output\n",
      "    y = m(x)\n",
      "    logπ = y[1:2]\n",
      "    logπ = logπ .- StatsFuns.logsumexp(logπ) #softmax\n",
      "    return [logπ; y[3]]\n",
      "end\n",
      "\n",
      "function env(y, t, state, ps)\n",
      "    ### input the agent output; output action, reward, and new input\n",
      "    πt = exp.(y[1:2]) #probability of pulling arms\n",
      "    d = Binomial(1, Float64(πt[2])) #probability of second arm\n",
      "    a = (rand(d)+1) # 0 -> 1, 1 -> 2\n",
      "    rew = rand(Binomial(1, Float64(ps[a]))) #draw reward from corresponding arm\n",
      "    ahot = zeros(2)\n",
      "    ahot[a] = 1.\n",
      "    x = [ahot; rew; t] #input is action, reward, timestep\n",
      "    ps = ps #reward probabilities do not change\n",
      "    s_new = zeros(1) #state is empty\n",
      "    return Int(a), Float32(rew), Float32.(x), Float32.(ps), Float32.(s_new)\n",
      "end\n",
      "Zygote.@nograd env #don't take gradients of this\n",
      "\n",
      "function initialize(ps, state)\n",
      "    if maximum(ps) == 0 #if not provided\n",
      "        p = rand()*0.95+0.025\n",
      "        ps = [p; 1-p]\n",
      "    end\n",
      "    state = Float32.(zeros(1)) #no state\n",
      "    return Float32.(ps), Float32.(state)\n",
      "end\n",
      "Zygote.@nograd initialize #don't take gradients of this\n",
      "\n",
      "function model_eval()\n",
      "    #evaluation function; compute mean reward (random is 0.5; oracle is 0.745)\n",
      "    means = []\n",
      "    all_as = []\n",
      "    all_ps = [[i/50.; 1-i/50.] for i = 1:49]\n",
      "    for ps = all_ps\n",
      "        L, ys, rews, as, ps = run_episode(m, ps = ps, hidden = false)\n",
      "        means = [means; mean(rews)]\n",
      "        all_as = [all_as; mean(as)]\n",
      "    end\n",
      "    return mean(means), mean(all_as)\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  15\n",
      "thomasgibson/ClimateMachine.jl\n",
      "test/Ocean/HydrostaticBoussinesqModel/test_hydrostatic_boussinesq_model.jl\n",
      "########################################\n",
      "\n",
      "using ClimateMachine\n",
      "\n",
      "ClimateMachine.init()\n",
      "\n",
      "using ClimateMachine.CartesianDomains\n",
      "\n",
      "using CLIMAParameters: AbstractEarthParameterSet\n",
      "struct DefaultParameters <: AbstractEarthParameterSet end\n",
      "\n",
      "using ClimateMachine.Ocean:\n",
      "    HydrostaticBoussinesqSuperModel, current_time, current_step, Δt\n",
      "\n",
      "@testset \"$(@__FILE__)\" begin\n",
      "\n",
      "    domain = RectangularDomain(\n",
      "        Ne = (1, 1, 1),\n",
      "        Np = 4,\n",
      "        x = (-1, 1),\n",
      "        y = (-1, 1),\n",
      "        z = (-1, 0),\n",
      "    )\n",
      "\n",
      "    model = HydrostaticBoussinesqSuperModel(\n",
      "        domain = domain,\n",
      "        time_step = 0.1,\n",
      "        parameters = DefaultParameters(),\n",
      "    )\n",
      "\n",
      "    @test model isa HydrostaticBoussinesqSuperModel\n",
      "    @test Δt(model) == 0.1\n",
      "    @test current_step(model) == 0\n",
      "    @test current_time(model) == 0.0\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  16\n",
      "mlelarge/MiniGNN.jl\n",
      "gcn_test.jl\n",
      "########################################\n",
      "\n",
      "using MiniGNN\n",
      "using JLD, HDF5\n",
      "# Beware! https://github.com/JuliaIO/JLD.jl/issues/234\n",
      "using Flux.Data: DataLoader\n",
      "using CUDA\n",
      "using MiniFastai\n",
      "using Flux: logitcrossentropy, onehotbatch, Descent, Dense, Dropout, relu, Chain\n",
      "using SparseArrays\n",
      "using MiniGNN: create_batch\n",
      "\n",
      "@load \"train_data.jld\" train_data\n",
      "#size Nsamples x V\n",
      "@load \"train_labels.jld\" train_labels\n",
      "@load \"test_data.jld\" test_data\n",
      "@load \"test_labels.jld\" test_labels\n",
      "\n",
      "#small = 1000\n",
      "#train_data = train_data[1:small,:]\n",
      "#train_labels = train_labels[1:small]\n",
      "train_labels = onehotbatch(train_labels, 0:9)\n",
      "#size Nlabels x Nsamples\n",
      "test_labels = onehotbatch(test_labels,0:9)\n",
      "d = load(\"List_graphs.jld\")\n",
      "L_g = d[\"L_g\"]\n",
      "sizes = d[\"sizes\"]\n",
      "\n",
      "bs = 100\n",
      "\n",
      "train_loader = DataLoader((permutedims(train_data),train_labels), batchsize=bs, shuffle=true)\n",
      "val_loader = DataLoader((permutedims(test_data),test_labels), batchsize=bs, shuffle=false)\n",
      "databunch = Databunch(train_loader,val_loader)\n",
      "\n",
      "batch, labels = create_batch(100,train_loader)\n",
      "input = convert(Array{Float32,3},process_data(batch))\n",
      "\n",
      "p=0.5\n",
      "mat1 = MiniGNN.make_rescaled_mat(L_g[1])\n",
      "layer1 = MiniGNN.GraphConv(mat1,1=>32,5)\n",
      "mp = MiniGNN.GraphMaxPool(4)\n",
      "mat2 = MiniGNN.make_rescaled_mat(L_g[3])\n",
      "layer2 = MiniGNN.GraphConv(mat2,32=>64,5)\n",
      "dim_fc = Int(64*size(mat2)[1]/4)\n",
      "model = Chain(layer1 , mp, layer2, mp, MiniGNN.graphflatten, Dense(dim_fc,512, relu), Dropout(p), Dense(512,10)) \n",
      "\n",
      "learning_rate = 0.05\n",
      "SGD = Descent(learning_rate)\n",
      "loss(pred,y) = logitcrossentropy(pred,y)\n",
      "\n",
      "learner_gnn = Learner(model,SGD,loss,databunch,cbs=(AvgStatsCallback(),))\n",
      "transform = x -> convert(Array{Float32,3},process_data(x))\n",
      "fit!(learner_gnn,30,transform)\n",
      "\n",
      "model(input)\n",
      "#one batch\n",
      "using Flux\n",
      "using Zygote: pullback, update!\n",
      "ps = params(model)\n",
      "            #source https://fluxml.ai/Flux.jl/stable/training/training/\n",
      "            # https://fluxml.ai/Zygote.jl/latest/adjoints/#Pullbacks-1\n",
      "y_pred, back_net = pullback(() -> model(input), ps)\n",
      "current_loss, back_loss = pullback(y -> loss(y,labels),y_pred)\n",
      "            #current_loss, back = pullback(() -> los_f(mod(xb),yb), ps)\n",
      "gs = back_net(back_loss(1)[1])#back(one(current_loss))\n",
      "update!(SGD,ps,gs)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  17\n",
      "genkuroki/public\n",
      "0016/Makie/CairoMakie LaTeXStrings example.jl\n",
      "########################################\n",
      "\n",
      "# -*- coding: utf-8 -*-\n",
      "# ---\n",
      "# jupyter:\n",
      "#   jupytext:\n",
      "#     formats: ipynb,jl:hydrogen\n",
      "#     text_representation:\n",
      "#       extension: .jl\n",
      "#       format_name: hydrogen\n",
      "#       format_version: '1.3'\n",
      "#       jupytext_version: 1.11.2\n",
      "#   kernelspec:\n",
      "#     display_name: Julia 1.6.2\n",
      "#     language: julia\n",
      "#     name: julia-1.6\n",
      "# ---\n",
      "\n",
      "# %%\n",
      "]activate .\n",
      "\n",
      "# %%\n",
      "]st\n",
      "\n",
      "# %%\n",
      "]add CairoMakie LaTeXStrings\n",
      "\n",
      "# %%\n",
      "]st\n",
      "\n",
      "# %%\n",
      "using CairoMakie, LaTeXStrings\n",
      "\n",
      "xs = 0.0:0.01:2.0\n",
      "lines(xs, sin.(π.*xs), axis=(title=L\"\\sin{x}\",))\n",
      "\n",
      "# %%\n",
      "using Pkg\n",
      "println(\"Julia v\", VERSION)\n",
      "Pkg.status(\"CairoMakie\")\n",
      "Pkg.status(\"Makie\"; mode=PKGMODE_MANIFEST)\n",
      "Pkg.status(\"LaTeXStrings\")\n",
      "\n",
      "# %%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  18\n",
      "limmyforget/feffery-antd-components\n",
      "src/jl/'feffery'_antdcheckboxgroup.jl\n",
      "########################################\n",
      "\n",
      "# AUTO GENERATED FILE - DO NOT EDIT\n",
      "\n",
      "export 'feffery'_antdcheckboxgroup\n",
      "\n",
      "\"\"\"\n",
      "    'feffery'_antdcheckboxgroup(;kwargs...)\n",
      "\n",
      "An AntdCheckboxGroup component.\n",
      "\n",
      "Keyword arguments:\n",
      "- `id` (String; optional)\n",
      "- `className` (String; optional)\n",
      "- `disabled` (Bool; optional)\n",
      "- `loading_state` (optional): . loading_state has the following type: lists containing elements 'is_loading', 'prop_name', 'component_name'.\n",
      "Those elements have the following types:\n",
      "  - `is_loading` (Bool; optional): Determines if the component is loading or not\n",
      "  - `prop_name` (String; optional): Holds which property is loading\n",
      "  - `component_name` (String; optional): Holds the name of the component that is loading\n",
      "- `options` (optional): . options has the following type: Array of lists containing elements 'label', 'value', 'disabled'.\n",
      "Those elements have the following types:\n",
      "  - `label` (String; optional)\n",
      "  - `value` (String; optional)\n",
      "  - `disabled` (Bool; optional)s\n",
      "- `style` (Dict; optional)\n",
      "- `value` (Array of Strings; optional)\n",
      "\"\"\"\n",
      "function 'feffery'_antdcheckboxgroup(; kwargs...)\n",
      "        available_props = Symbol[:id, :className, :disabled, :loading_state, :options, :style, :value]\n",
      "        wild_props = Symbol[]\n",
      "        return Component(\"'feffery'_antdcheckboxgroup\", \"AntdCheckboxGroup\", \"feffery_antd_components\", available_props, wild_props; kwargs...)\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  19\n",
      "JuliaActors/QuickActors.jl\n",
      "test/runtests.jl\n",
      "########################################\n",
      "\n",
      "include(\"actorinterfacestests.jl\")\n",
      "include(\"stack.jl\")\n",
      "include(\"basics.jl\")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  20\n",
      "clintonTE/CCA\n",
      "Interconnect/reference/CTModDONOTUSE.jl\n",
      "########################################\n",
      "\n",
      "module CTModCopy\n",
      "\n",
      "using  DataFrames, Distributions, StatsBase, GLM#, Base.BLAS, Base.LinAlg, RData\n",
      "\n",
      "const DEBUG_CTMOD = false\n",
      "const DEFAULT_STAR_LEGEND = \"*p < 0.1, **p < 0.05, ***p < 0.01 s.t. p=Pr(>|T|)\"\n",
      "\n",
      "export CTLM, CT2SLS, project!, getResid!, getHomoskedΣ!, getModWhiteΣ!,\n",
      "  pullModelMatrix, getCoeff!, getModWhiteΣSlow, getHomoskedΣSlow,\n",
      "  dropNullsFromDF, CTExpr, CTSym, texTable, writeTables2File, CTQR,\n",
      "  get1stStage, getTerm, getR\n",
      "\n",
      "#this alias is useful when parsing inputs to formula objects\n",
      "const CTExpr = Union{Symbol,Expr,Void}\n",
      "const CTSym = Union{Symbol,Void}\n",
      "\n",
      "abstract type CTModel end\n",
      "\n",
      "##################Utility Functions ###############################\n",
      "\n",
      "#helper function  to get the model matrix from a dataframe given a formula\n",
      "#IN: A dataframe and formula object\n",
      "#OUT: the model matrix\n",
      "function getModelMatrix(df::T, f::Formula)::Matrix{Float64} where\n",
      "  T <: AbstractDataFrame\n",
      "  return ModelMatrix(ModelFrame(f, df)).m\n",
      "end\n",
      "\n",
      "#Same as above but allows for an expression\n",
      "function getModelMatrix(df::T, exp::V)::Matrix{Float64} where\n",
      "  {T <: AbstractDataFrame, V <: CTExpr}\n",
      "\n",
      "  #special case which crashes Formula\n",
      "  if exp == Symbol(\"\")\n",
      "    return ones(Float64,size(df,1),1)\n",
      "  end\n",
      "\n",
      "  return getModelMatrix(df, get1SidedFormula(exp))\n",
      "end\n",
      "\n",
      "#helper function  to get the list of symbols in an expression\n",
      "#IN: A dataframe and a string object, typically representing a formula\n",
      "#OUT: a vector of symbols in the string object\n",
      "function getSymbolsFromExpr(exp::V)::Vector{Symbol} where {V <: CTExpr}\n",
      "  symStrings::Vector{String} = split(string(exp),\n",
      "    ['|','=','~',' ','+','*','&',')','(','-'], keep=false)\n",
      "\n",
      "  filter!(s::String->typeof(parse(s))≠Int,symStrings)\n",
      "\n",
      "  #convert the strings to symbols\n",
      "  return Symbol.(symStrings)\n",
      "end\n",
      "\n",
      "\n",
      "#helper function to create a one-sided formula given an expression\n",
      "#IN: an expression and dataframe\n",
      "#OUT: A one-sided formula object\n",
      "function get1SidedFormula(RHS::T)::Formula where\n",
      "  {T <: CTExpr}\n",
      "\n",
      "  return Formula(nothing, RHS)\n",
      "end\n",
      "\n",
      "#drops nulls  from dataframe given a list of symbols\n",
      "#IN: a data frame and symbols\n",
      "#OUT: dataframe less the null entires as dictated by the symbol list\n",
      "dropNullsFromDF(df::DataFrame, syms::Vector{Symbol})::DataFrame =\n",
      "  df[completecases(df[:,syms]),:]\n",
      "\n",
      "#drops nulls  from dataframe given a list of symbols\n",
      "#IN: a sub-dataframe and symbols, #OUT: subdataframe less the null entries\n",
      "dropNullsFromDF(dfSub::SubDataFrame, syms::Vector{Symbol})::SubDataFrame =\n",
      "    view(dfSub,completecases(dfSub[:,syms]))\n",
      "\n",
      "#helper function for the above, takes in a single symbol\n",
      "#IN: a subdataframe and symbol #OUT: subdataframe less the null entries\n",
      "function dropNullsFromDF(df::T, s::Symbol)::T  where {T<:AbstractDataFrame}\n",
      "\n",
      "  return dropNullsFromDF(df, collect([s]))\n",
      "end\n",
      "\n",
      "#helper function for the above, de-nulls entire dataframe\n",
      "#IN: a subdataframe #OUT: subdataframe less the null entries\n",
      "function dropNullsFromDF(df::T)::T where {T<:AbstractDataFrame}\n",
      "  return dropNullsFromDF(df, names(df))::T\n",
      "end\n",
      "\n",
      "#####################CTQR Type###########################\n",
      "#=This is a storage object specific to the QR optimizations\n",
      "meant to hold the QR factorization and a handle for X\n",
      "Values: X matrix that is decomposed, Q matrix, and R matrix\n",
      "The X matrix has dimensions of NxK. R is the inverse, stored\n",
      "for computational efficiency.=#\n",
      "\n",
      "struct CTQR\n",
      "  X::Matrix{Float64}\n",
      "  Q::Matrix{Float64}\n",
      "  R::Matrix{Float64}\n",
      "\n",
      "  N::Int\n",
      "  K::Int\n",
      "  RInv::Matrix{Float64}\n",
      "end\n",
      "\n",
      "#helper method which takes the inverse of the R matrix (which is used in a lot)\n",
      "#IN: X matrix and its Q R decomposition in matrix form\n",
      "#OUT: CTQR Object\n",
      "CTQR(X::Matrix{Float64},Q::Matrix{Float64},R::Matrix{Float64};keepX=true)::CTQR =\n",
      "  CTQR(keepX?X:Matrix{Float64}(),Q,R,size(X,1),size(X,2),(R)\\eye(size(X,2)))\n",
      "\n",
      "#main constructor for the CTQR object\n",
      "#IN: X Matrix\n",
      "#OUT: CTQR object\n",
      "function CTQR(X::Matrix{Float64}; keepX = true)::CTQR\n",
      "  Q::Matrix{Float64},R::Matrix{Float64} = qr(X)\n",
      "  return CTQR(X,Q,R)\n",
      "end\n",
      "\n",
      "#default constructor to clear memory\n",
      "CTQR() = CTQR(Matrix{Float64}(),Matrix{Float64}(),Matrix{Float64}(),\n",
      "    0,0,Matrix{Float64}())::CTQR\n",
      "\n",
      "\n",
      "#####################CTLM Model Type#########################\n",
      "#This is designed to hold the minimal info for a linear model\n",
      "#Plus the associated CTQR object\n",
      " mutable struct CTLM <: CTModel\n",
      "  xqr::CTQR #handle to the xqr object\n",
      "  X::Matrix{Float64} #the data and x matrix (handle)\n",
      "  Y::Vector{Float64} #Y data\n",
      "\n",
      "  N::Int #Number of data points (rows)\n",
      "  K::Int #Number of data columns\n",
      "  β::Vector{Float64} #beta coefficient\n",
      "  ε::Vector{Float64} #residuals\n",
      "\n",
      "  XNames::Vector{Symbol} #names of the X variables\n",
      "  YName::Symbol #names of the Y variables\n",
      "  #rowLabels::Vector{Date}\n",
      "\n",
      "\n",
      "end\n",
      "\n",
      "#this function calculates the Pearson correlation coefficient of the predicted values\n",
      "#relative to the realized values\n",
      "getR(lin::CTLM)::Float64 = cor(lin.Y, lin.Y .- lin.ε)\n",
      "\n",
      "\n",
      "#convenience function, calls CTQR constructor\n",
      "#Standard constructor to be called from outside\n",
      "#IN: X matrix of independent vars, Y vector for dependent var\n",
      "#OUT: CTLM Object\n",
      "function CTLM(xqr::Matrix{Float64}, Y::Vector{Float64};\n",
      "    XNames::Vector{Symbol} = Symbol.(:X, 1:size(X,2)),\n",
      "    YName::Symbol = :Y)::CTLM\n",
      "\n",
      "    #showall(X[1:100,1:2])\n",
      "    xqr::CTQR = CTQR(X, keepX=false)\n",
      "    β::Vector{Float64} = Vector{Float64}(xqr.K)\n",
      "    getCoeff!(xqr,Y,β)\n",
      "\n",
      "    ε::Vector{Float64} = Vector{Float64}(xqr.N)\n",
      "    getResid!(X,Y,β,ε)\n",
      "\n",
      "    return CTLM(xqr, X, Y, xqr.N, xqr.K, β, ε, XNames, YName)\n",
      "end\n",
      "\n",
      "#convenience function, calls CTQR constructor\n",
      "#Standard constructor to be called from outside\n",
      "#IN: X matrix of independent vars, Y vector for dependent var\n",
      "#OUT: CTLM Object\n",
      "function CTLM(X::Matrix{Float64}, Y::Vector{Float64};\n",
      "    XNames::Vector{Symbol} = Symbol.(:X, 1:size(X,2)),\n",
      "    YName::Symbol = :Y)::CTLM\n",
      "\n",
      "    #showall(X[1:100,1:2])\n",
      "    xqr::CTQR = CTQR(X, keepX=false)\n",
      "    β::Vector{Float64} = Vector{Float64}(xqr.K)\n",
      "    getCoeff!(xqr,Y,β)\n",
      "\n",
      "    ε::Vector{Float64} = Vector{Float64}(xqr.N)\n",
      "    getResid!(X,Y,β,ε)\n",
      "\n",
      "    return CTLM(xqr, X, Y, xqr.N, xqr.K, β, ε, XNames, YName)\n",
      "end\n",
      "\n",
      "#=Constructor and helper method which gets required info from DataFrame\n",
      "IN: The source dataframe, a formula expression for the RHS,\n",
      "    the dependent variable as a symbol, optionally names for X columns,\n",
      "    Y and a switch to elliminate null values\n",
      "OUT: A CTLM object\n",
      "NOTE: RHS expression must be ordered with factors last, otherwise\n",
      "    the factor names will be incorrect =#\n",
      "function CTLM(df::DataFrame,  XExpr::T, YSym::Symbol;\n",
      "    XNames::Vector{Symbol}=[Symbol(:Intercept)], YName::Symbol=:Y,\n",
      "    eliminateNulls=true, fixedEffectsSym::V = nothing)::CTLM  where {T <: CTExpr, V<:Union{Symbol,Void}}\n",
      "\n",
      "    #get the list of symbols from the expression for X\n",
      "    XSym::Vector{Symbol} = getSymbolsFromExpr(XExpr)\n",
      "\n",
      "    #make a view so if we drop nulls it doesn't affect the original\n",
      "    if fixedEffectsSym == nothing || fixedEffectsSym ∈ [XSym; YSym]\n",
      "        dfSub::SubDataFrame = view(df[:,[XSym; YSym]],1:size(df,1))\n",
      "    else\n",
      "        dfSub = view(df[:,[XSym; YSym; fixedEffectsSym]],1:size(df,1))\n",
      "    end\n",
      "\n",
      "    if eliminateNulls     # if we are going to drop nulls\n",
      "        dfSub = dropNullsFromDF(dfSub)\n",
      "    end\n",
      "\n",
      "    #get the factor expanded model matrix (Adds the dummies)\n",
      "    XModelMatrix::Matrix{Float64} = getModelMatrix(dfSub, XExpr)\n",
      "\n",
      "    #this is a check to make sure the factor expansion follows other columns\n",
      "    if length(XSym) > 1\n",
      "        for i ∈ 2:length(XSym) #all types\n",
      "            if typeof(dfSub[:,XSym[i-1]])<:PooledDataVector &&\n",
      "                !(typeof(dfSub[:,XSym[i]])<:PooledDataVector)\n",
      "                warn(\"Type of $(typeof(dfSub[:,i])) is preceeded by type of\n",
      "                    factor. Column names are likely MISALIGNED. Put factors\n",
      "                    after numerical variables in RHS expressions.\")\n",
      "            end\n",
      "        end\n",
      "    end\n",
      "\n",
      "    #Now assign the names as appropriate\n",
      "    XNamesFull::Vector{Symbol} = Vector{Symbol}(size(XModelMatrix,2))\n",
      "    for i ∈ 1:length(XNamesFull)\n",
      "        XNamesFull[i] = i≤length(XNames)?XNames[i]:Symbol(:X,i)\n",
      "    end\n",
      "\n",
      "    #get the appropriate matrices and construct the CTLM object\n",
      "\n",
      "    if fixedEffectsSym != nothing\n",
      "            #println(typeof(Vector(dfSub[:,fixedEffectsSym])))\n",
      "        return CTLM(XModelMatrix, Vector{Float64}(dfSub[:,YSym]), Vector(dfSub[:,fixedEffectsSym]),\n",
      "            XNames=XNamesFull, YName=YName)\n",
      "    else\n",
      "        return CTLM(XModelMatrix,\n",
      "            Vector{Float64}(dfSub[:,YSym]),\n",
      "            XNames=XNamesFull, YName=YName)\n",
      "    end\n",
      "end\n",
      "\n",
      "#One-way clustered SEs\n",
      "function CTLM(X::Matrix{Float64}, Y::Vector{Float64}, fixedEffects::Vector{V};\n",
      "    XNames::Vector{Symbol} = Symbol.(:X, 1:size(X,2)),\n",
      "    YName::Symbol = :Y)::CTLM where V<:Union{Float64,Int,Date,Symbol}\n",
      "\n",
      "    #we get the unique values and make a two way table\n",
      "    #tVars::Vector{T} = unique(tFI)\n",
      "    iVars::Vector{V} = unique(fixedEffects)\n",
      "    iN::Int = length(iVars)\n",
      "    iTable::Dict = Dict(iVars[i] => i for i::Int ∈ 1:iN)\n",
      "\n",
      "    K::Int = size(X,2)\n",
      "    N::Int = size(X,1)\n",
      "\n",
      "    #now create the codified versions\n",
      "    #Xi::Matrix{Float64} = Matrix{Float64}(length(iVars),size(X,2))\n",
      "    fixedEffectsCode::Vector{Int} = ((x::V)->iTable[x]).(fixedEffects)\n",
      "\n",
      "    meanXY::Matrix{Float64} = zeros(iN,K+1)\n",
      "    NXY::Vector{Int} = zeros(iN)\n",
      "\n",
      "    #println(\"$N,$K,$iN,$(size(NXY))\")\n",
      "    @fastmath @inbounds for r ∈ 1:N\n",
      "        meanXY[fixedEffectsCode[r],K+1] += Y[r]\n",
      "        NXY[fixedEffectsCode[r]] += 1.0\n",
      "    end\n",
      "\n",
      "    @fastmath @inbounds for c ∈2:K, r ∈1:N\n",
      "            meanXY[fixedEffectsCode[r],c] += X[r,c]\n",
      "    end\n",
      "\n",
      "    meanXY ./= NXY\n",
      "\n",
      "    @fastmath @inbounds for c ∈2:K, r ∈1:N\n",
      "            X[r,c] -= meanXY[fixedEffectsCode[r],c]\n",
      "    end\n",
      "\n",
      "    @fastmath @inbounds for r ∈ 1:N\n",
      "         Y[r] -= meanXY[fixedEffectsCode[r],K+1]\n",
      "    end\n",
      "\n",
      "\n",
      "    #=@fastmath Threads.@threads for i ∈ 1:iN\n",
      "        cluster::Vector{Int} = find((x::Int)->x==i,fixedEffectsCode)\n",
      "\n",
      "        meanY::Float64 = mean(Y[cluster])\n",
      "        #print(i<10?\"$meanY\\n\":\"\")\n",
      "        Y[cluster] .-= meanY\n",
      "\n",
      "        #We get a dramatic benefit from the parallelization\n",
      "        for j::Int ∈ 1:K\n",
      "            if XNames[j] != :intercept\n",
      "                meanX::Float64 = mean(X[cluster,j])\n",
      "                X[cluster, j] .-= meanX\n",
      "            end\n",
      "        end\n",
      "    end=#\n",
      "\n",
      "    return CTLM(X, Y, XNames=XNames, YName=YName)\n",
      "end\n",
      "\n",
      "#blank default constructor for memory management\n",
      "CTLM() = CTLM(CTQR(), Matrix{Float64}(), Vector{Float64}(), 0, 0,\n",
      "        Vector{Float64}(), Vector{Float64}(), Vector{Symbol}(), Symbol())::CTLM\n",
      "\n",
      "#fucntion for getting regression coefficients\n",
      "getTerm(lm::CTLM, s::Symbol) = (lm.β[findfirst(lm.XNames, s)])::Float64\n",
      "\n",
      "######2SLS constructor\n",
      "#Holds the modelling componenets for a 2SLS model (except errors)\n",
      "#Variable descriptions are in the struct\n",
      "# Runs standard 2SLS using QR optimization\n",
      "mutable struct CT2SLS <: CTModel\n",
      "    zaqr::CTQR #QR decomposition of Za (Z|W)\n",
      "    xaqr::CTQR #QR decomposition of fitted 1st stage values (X̃|W)\n",
      "\n",
      "    X::Matrix{Float64} #Endogeneous covariates\n",
      "    W::Matrix{Float64} #Exogeneous covariates\n",
      "    Y::Vector{Float64} #Dependent var\n",
      "    Z::Matrix{Float64} #IV data\n",
      "\n",
      "    N::Int #number of data points\n",
      "    K::Int # of endogeneous covariates\n",
      "    L::Int # of instrumental variables\n",
      "    KW::Int # of exogeneous covariates\n",
      "\n",
      "    Π1::Matrix{Float64} #first stage results\n",
      "    Ξ1::Matrix{Float64} #first stage residuals\n",
      "\n",
      "    δ2::Vector{Float64} #2SLS coefficients\n",
      "    ξ2::Vector{Float64} #2SLS residuals\n",
      "\n",
      "    XNames::Vector{Symbol} #names of the X variables\n",
      "    WNames::Vector{Symbol} #names of the W variables\n",
      "    YName::Symbol #names of the Y variables\n",
      "    ZNames::Vector{Symbol} #names of the Z variables\n",
      "\n",
      "    #CT2SLS()\n",
      "end\n",
      "\n",
      "\n",
      "#= Convenience constructor for CT2SLS that allocates a 0 element array for the\n",
      "case of no exogeneous covariates. NOTE: no exog covariates implies no intercept,\n",
      "so there probably should be  some exogeneous covariates\n",
      "#IN: X Matrix, Y Vector, and the Z matrix of Instrumental variables\n",
      "#OUT: CT2SLS object=#\n",
      "CT2SLS(X::Matrix{Float64},Y::Vector{Float64},Z::Matrix{Float64};\n",
      "    XNames::Vector{Symbol} = Symbol.(:X, 1:size(X,2)),\n",
      "    YName::Symbol = :Y,\n",
      "    ZNames::Vector{Symbol} = Symbol.(:Z, 1:size(Z,2)))::CT2SLS =\n",
      "        CT2SLS(X,Matrix{Float64}(Size(X,1),0),Y,Z)\n",
      "\n",
      "#=Main constructor for CT2SLS object\n",
      "IN: Endogeneous matrix X, Exogeneous matrix W, Dependent vector Y,\n",
      "instrumental zariable matrix Z\n",
      "OUT: A 2SLS object\n",
      "=#\n",
      "function CT2SLS(X::Matrix{Float64}, W::Matrix{Float64},\n",
      "  Y::Vector{Float64},Z::Matrix{Float64};\n",
      "  XNames::Vector{Symbol} = Symbol.(:X, 1:size(X,2)),\n",
      "  WNames::Vector{Symbol} = Symbol.(:W, 1:size(W,2)),\n",
      "  YName::Symbol = :Y,\n",
      "  ZNames::Vector{Symbol} = Symbol.(:Z, 1:size(Z,2)))::CT2SLS\n",
      "\n",
      "  #memory pre-allocaiton\n",
      "  N::Int = size(X,1) #number of data points\n",
      "  K::Int = size(X,2) # of endogeneous variables\n",
      "  L::Int = size(Z,2) # of instrumental variables\n",
      "  KW::Int = size(W,2)# of exogeneous covariates\n",
      "\n",
      "  Π1::Matrix{Float64} = Matrix{Float64}(L+KW,K)\n",
      "  X̂::Matrix{Float64} = Matrix{Float64}(N,K) #holds fitted first stage values\n",
      "  Ξ1::Matrix{Float64} = similar(X̂) #holds first stage residuals\n",
      "  δ2::Vector{Float64} = Vector{Float64}(K+KW)\n",
      "  ξ2::Vector{Float64} = similar(Y)\n",
      "  #Xa::Matrix{Float64} = Matrix{Float64}(N,K+KW) #fitted 1st stage plus exog covariates\n",
      "\n",
      "  #start with setting up and running the first stage\n",
      "  ZW::Matrix{Float64} = [Z W]\n",
      "  zaqr::CTQR = CTQR(ZW, keepX=false) #augment the matrices to ZW and get the QR\n",
      "  getCoeff!(zaqr, X, Π1) #get the first stage coefficients\n",
      "  BLAS.gemm!('N','N',1.0,ZW,Π1,0.0,X̂) #get the fitted first stage values\n",
      "  getResid!(ZW, X, Π1, Ξ1) #get the residuals\n",
      "\n",
      "  #now run the second stage\n",
      "  xaqr::CTQR = CTQR([X̂ W], keepX = false) #augment X̂W and get the QR\n",
      "  getCoeff!(xaqr, Y, δ2) #get the 2SLS coefficients\n",
      "  getResid!([X W], Y, δ2, ξ2) #get the 2SLS residuals\n",
      "\n",
      "  #Finally, return the constructed model\n",
      "  return CT2SLS(zaqr, xaqr, X, W, Y, Z, N, K, L, KW, Π1, Ξ1, δ2, ξ2,\n",
      "    XNames, WNames, YName, ZNames)\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#Constructor and helper method which gets required info from DataFrame\n",
      "#IN: The source dataframe, a formula expression/symbol for X, W, Y, and Z\n",
      "# the dependent variable as a symbol\n",
      "#OUT: A CTLM object\n",
      "function CT2SLS(df::DataFrame, XExpr::T, WExpr::U, YSym::Symbol, ZExpr::V;\n",
      "    XNames::Vector{Symbol} = Vector{Symbol}(),\n",
      "    WNames::Vector{Symbol} = Vector{Symbol}([:Intercept]),\n",
      "    YName::Symbol = :Y,\n",
      "    ZNames::Vector{Symbol} = Vector{Symbol}(),\n",
      "    eliminateNulls=true)::CT2SLS where {T <: CTExpr, U <: CTExpr, V <: CTExpr}\n",
      "\n",
      "    #get the list of symbols for X, W and Z\n",
      "    XSym::Vector{Symbol} = getSymbolsFromExpr(XExpr)\n",
      "    WSym::Vector{Symbol} = getSymbolsFromExpr(WExpr)\n",
      "    ZSym::Vector{Symbol} = getSymbolsFromExpr(ZExpr)\n",
      "\n",
      "    #make a view so if we drop nulls it doesn't affect the original\n",
      "    dfSub::SubDataFrame = view(df[:, [XSym; WSym; YSym; ZSym]],1:size(df,1))\n",
      "\n",
      "    # if we are going to drop nulls\n",
      "    if eliminateNulls\n",
      "        dfSub = dropNullsFromDF(dfSub)\n",
      "    end\n",
      "\n",
      "    #get the model matrices, which will expand all factors\n",
      "    XModelMatrix::Matrix{Float64} = getModelMatrix(dfSub, XExpr)\n",
      "    WModelMatrix::Matrix{Float64} = getModelMatrix(dfSub, WExpr)\n",
      "    ZModelMatrix::Matrix{Float64} = getModelMatrix(dfSub, ZExpr)\n",
      "\n",
      "    #this is a check to make sure the factor expansion follows other columns\n",
      "    #We must repeat the check on each variable matrix\n",
      "    for symVec::Vector{Symbol} ∈ [XSym, WSym, ZSym]\n",
      "        if length(symVec) > 1\n",
      "            for i ∈ 2:length(symVec) #all types\n",
      "                if typeof(dfSub[:,symVec[i-1]])<:PooledDataVector &&\n",
      "                    !(typeof(dfSub[:,symVec[i]])<:PooledDataVector)\n",
      "                    warn(\"Type of $(typeof(dfSub[:,i])) is preceeded by type of\n",
      "                        factor. Column names are likely MISALIGNED. Put factors\n",
      "                        after numerical variables in RHS expressions.\")\n",
      "                end\n",
      "            end\n",
      "        end\n",
      "    end\n",
      "\n",
      "    #now create the namesfor the expanded matrix\n",
      "    XNamesFull::Vector{Symbol} = Vector{Symbol}(size(XModelMatrix,2))\n",
      "    for i ∈ 1:length(XNamesFull)\n",
      "        XNamesFull[i] = i≤length(XNames)?XNames[i]:Symbol(:X,i)\n",
      "    end\n",
      "\n",
      "    WNamesFull::Vector{Symbol} = Vector{Symbol}(size(WModelMatrix,2))\n",
      "    for i ∈ 1:length(WNamesFull)\n",
      "        WNamesFull[i] = i≤length(WNames)?WNames[i]:Symbol(:W,i)\n",
      "    end\n",
      "\n",
      "    ZNamesFull::Vector{Symbol} = Vector{Symbol}(size(ZModelMatrix,2))\n",
      "    for i ∈ 1:length(ZNamesFull)\n",
      "        ZNamesFull[i] = i≤length(ZNames)?ZNames[i]:Symbol(:Z,i)\n",
      "    end\n",
      "\n",
      "    #get the appropriate matrices and construct the CT2SLS object\n",
      "    return CT2SLS(XModelMatrix, WModelMatrix, Vector{Float64}(dfSub[:,YSym]),\n",
      "        ZModelMatrix, XNames=XNamesFull, WNames=WNamesFull,\n",
      "        YName=YName, ZNames=ZNamesFull)\n",
      "\n",
      "end\n",
      "\n",
      "#default constructor to help with memory management\n",
      "CT2SLS() = CT2SLS(CTQR(), CTQR(), Matrix{Float64}(), Matrix{Float64}(),\n",
      "    Vector{Float64}(), Matrix{Float64}(), 0, 0, 0, 0, Matrix{Float64}(),\n",
      "    Matrix{Float64}(), Vector{Float64}(), Vector{Float64}(),\n",
      "    Vector{Symbol}(), Vector{Symbol}(), Symbol(), Vector{Symbol}())::CT2SLS\n",
      "\n",
      "#=function get1stStage\n",
      "#The purpose is to get the first stage of the IV as a linear model\n",
      "#Unfortunately, we need to copy some of the data, so this can be expensive,\n",
      "#although Z and W should only be copied once\n",
      "#IN: an IV object\n",
      "#OUT: a vector of CTLM objects, one for each focal (X) variable in the\n",
      "#initial regression=#\n",
      "function get1stStage(iv::CT2SLS)::Vector{CTLM}\n",
      "    ZW::Matrix{Float64} =  [iv.Z iv.W]\n",
      "    iv1st::Vector = Vector{CTLM}()\n",
      "\n",
      "    for i ∈ 1:length(iv.XNames)\n",
      "        push!(iv1st, CTLM(iv.zaqr, [iv.Z iv.W], iv.X[:,i],\n",
      "            iv.zaqr.N, iv.zaqr.K, iv.Π1[:,i], iv.Ξ1[:,i],\n",
      "            [iv.ZNames; iv.WNames], iv.XNames[i]))\n",
      "    end\n",
      "\n",
      "    return iv1st\n",
      "end\n",
      "\n",
      "\n",
      "#########################Project!##############################\n",
      "#=gets the projection matrix\n",
      "\n",
      "IN: THe CTQR decomposition and the memory for  the projection matrix\n",
      "OUT: Writes and returns the projection matrix\n",
      "NOTE: This method will allocate the projection matrix if no second\n",
      "argument is supplied. =#\n",
      "function project!(xqr::CTQR, P::Matrix{Float64}=Matrix{Float64}(xqr.N, xqr.N)\n",
      "  )::Matrix{Float64}\n",
      "\n",
      "  #use the BLAS library for fast matrix algebra\n",
      "  return BLAS.gemm!('N','T',1.0,xqr.Q,xqr.Q,0.0,P)\n",
      "\n",
      "end\n",
      "\n",
      "#=This version gets only the diagonal of the projection matrix\n",
      "IN: THe CTQR decomposition and the memory for  the projection diagonal\n",
      "OUT: Writes and returns the projection matrix=#\n",
      "function project!(xqr::CTQR, P::Vector{Float64})::Vector{Float64}\n",
      "  #get the diagonal quickly\n",
      "  #equivlenet to diag(Q*Q')\n",
      "  P .= 0.0\n",
      "  @fastmath for j::Int ∈ 1:xqr.K, i::Int ∈ 1:xqr.N\n",
      "    P[i] += xqr.Q[i,j] * xqr.Q[i,j]\n",
      "  end\n",
      "\n",
      "  return P\n",
      "\n",
      "end\n",
      "\n",
      "#=This version runs either of the above methods after generating\n",
      "the xqr object given an independent variable matrix\n",
      "IN: Independent variable X matrix and the memory for  the projection matrix\n",
      "or vector for the diagonal\n",
      "OUT: Writes and returns the projection matrix=#\n",
      "function project!(X::Matrix{Float64},\n",
      "  P::Array{Float64}=Matrix{Float64}(size(X,1),size(X,1)))::Array{Float64}\n",
      "\n",
      "  return project!(CTQR(X),P)\n",
      "end\n",
      "\n",
      "#=simple test function to verify the projection optimizations\n",
      "output should be identical to the matrix function above\n",
      "IN: Independent variable X matrix, memory for the projection matrix\n",
      "OUT: Writes and returns teh projection matrix=#\n",
      "function projectSlow!(X::Matrix{Float64},P::Matrix{Float64})\n",
      "  P .= (X * ((X' * X)\\eye(size(X,2))) * X')\n",
      "  return P\n",
      "end\n",
      "\n",
      "#########################getResid!#########################\n",
      "#=gets the residuals in the 2SLS framework\n",
      "\n",
      "Note this is a wrapper function which can accept multiple independent\n",
      "and multiple dependent variables. NOTE the change in the naming convention\n",
      "relative to other verisons of this method (due to the 2SLS context)\n",
      "IN: QR decomposition of the RHS variables, LHS dependent variable matrix,\n",
      "a coefficient matrix, optionally the memory for the residual matrix\n",
      "OUT: Writes and returns the residual matrix=#\n",
      "function getResid!(ZW::Matrix{Float64}, X::Matrix{Float64}, Π1::Matrix{Float64},\n",
      "  Ξ1::Matrix{Float64}=similar(X))::Matrix{Float64}\n",
      "\n",
      "  #get the residuals by reference\n",
      "  for i ∈ 1:size(X,2) #get the vector of reisduals multiple times\n",
      "    getResid!(ZW, view(X,:,i), view(Π1,:,i), view(Ξ1,:,i))\n",
      "  end\n",
      "  return Ξ1\n",
      "end\n",
      "\n",
      "#=Main method to get residuals\n",
      "IN: X matrix the RHS variables, LHS dependent variable,\n",
      "a coefficient vector, optionally the memory for the residual vector\n",
      "OUT: Writes and returns the residual vector=#\n",
      "function getResid!(X::Matrix{Float64}, Y::T,\n",
      "  β::T, ε::T=similar(Y))::T where T<:StridedVector{Float64}\n",
      "\n",
      "  return BLAS.axpy!(1.0, Y, BLAS.gemv!('N',-1.0, X, β,0.0,ε)) #ε=Y-Xβ\n",
      "end\n",
      "\n",
      "#########################getCoef!###########################\n",
      "# Gets the coefficients in a regression\n",
      "\n",
      "#=This is a wrapper function which gets a matrix of coefficients for use in\n",
      "# the first stage of 2SLS. NOTE the change in the naming convention\n",
      "relative to other verisons of this method (due to the 2SLS context)\n",
      "IN: QR decomposition of the RHS variables, LHS dependent variable matrix,\n",
      "optionally the memory for the coefficient matrix\n",
      "OUT: Writes and returns the coefficient matrix=#\n",
      "function getCoeff!(zaqr::CTQR, X::Matrix{Float64},\n",
      "  Π1::Matrix{Float64} = Matrix{Float64}(zaqr.K, size(X,2)))::Matrix{Float64}\n",
      "\n",
      "  for i ∈ 1:size(X,2) # for each dependent variable vector\n",
      "    getCoeff!(zaqr, view(X,:,i), view(Π1,:,i)) #run the regression as needed\n",
      "  end\n",
      "\n",
      "  return Π1\n",
      "end\n",
      "\n",
      "#=Main method to get the regression coefficients\n",
      "IN: QR decomposition of X matrix the RHS variables, LHS dependent variable,\n",
      "optionally the memory for the coefficient vector\n",
      "OUT: Writes and returns the coefficient vector=#\n",
      "function getCoeff!(xqr::CTQR, Y::T,\n",
      "  β::T = Vector{Float64}(xqr.K))::T where  T<:StridedVector{Float64}\n",
      "\n",
      "  return  BLAS.gemv!('N',1.0,BLAS.gemm('N', 'T', xqr.RInv, xqr.Q),Y,0.0,β)\n",
      "end\n",
      "\n",
      "#=Convenience method to get the regression coefficients\n",
      "IN: X matrix the RHS variables, LHS dependent variable,\n",
      "optionally the memory for the coefficient vector\n",
      "OUT: Writes and returns the coefficeint vector=#\n",
      "getCoeff!(X::Vector{Float64}, Y::Vector{Float64}) =\n",
      "  getCoeff!(CTQR(X), Y, Vector{Float64}(size(X,2)))::Vector{Float64}\n",
      "\n",
      "\n",
      "###################getHomosked!#######################\n",
      "#Gets the covariance matrix under Homoskedastic assumptions σ^2[X'X]^-1\n",
      "\n",
      "#main method to get the covariance matrix\n",
      "#IN: The QR decomposition from the regression, a vector of residuals,\n",
      "#optionally memory for the covariance matrix\n",
      "#OUT: Writes and returns the covariance matrix\n",
      "function getHomoskedΣ!(xqr::CTQR, ε::Vector{Float64},\n",
      "  Σ::Matrix{Float64} = Matrix{Float64}(lin.K, lin.K))::Matrix{Float64}\n",
      "\n",
      "  return BLAS.gemm!('N','T',(ε⋅ε)/(xqr.N-xqr.K),xqr.RInv,xqr.RInv,0.0,Σ) #[X'X]^-1*σ2\n",
      "end\n",
      "\n",
      "#=helper method for the above function which extracts the QR decomposition\n",
      "from a linear model\n",
      "IN: A linear model, optionally memory for the covariance matrix\n",
      "OUT: WRites and returns the covariance matrix=#\n",
      "function getHomoskedΣ!(lin::CTLM,\n",
      "  Σ::Matrix{Float64}=Matrix{Float64}(lin.K, lin.K))::Matrix{Float64}\n",
      "\n",
      "  return getHomoskedΣ!(lin.xqr, lin.ε, Σ)\n",
      "end\n",
      "\n",
      "#=helper method for the above function which extracts the QR decomposition\n",
      "from a CT2SLS object\n",
      "IN: A linear model, optionally memory for the covariance matrix\n",
      "OUT: WRites and returns the covariance matrix=#\n",
      "function getHomoskedΣ!(iv::CT2SLS,\n",
      "  Σ::Matrix{Float64}=Matrix{Float64}(iv.xaqr.K, iv.xaqr.K))::Matrix{Float64}\n",
      "\n",
      "  return getHomoskedΣ!(iv.xaqr, iv.ξ2, Σ)\n",
      "end\n",
      "\n",
      "#=Simple test function to verify the QR-related optimizations\n",
      "Output should be identical to the standard methods\n",
      "IN: Independent variable X matrix\n",
      "OUT: Returns the covariance matrix=#\n",
      "getHomoskedΣSlow(X::Matrix{Float64}, ε::Vector{Float64})::Matrix{Float64} =\n",
      "  (X.'*X)\\eye(size(X,2))*(ε⋅ε)/(size(X,1)-size(X,2))\n",
      "\n",
      "#Convenience method for above: IN: A linear model #OUT: A covariance matrix\n",
      "getHomoskedΣSlow(lin::CTLM)::Matrix{Float64} =\n",
      "  getHomoskedΣSlow(lin.X, lin.Y.-lin.X * lin.β)\n",
      "\n",
      "#Convenience method for above: IN: A CT2SLS object #OUT: A covariance matrix\n",
      "getHomoskedΣSlow(iv::CT2SLS)::Matrix{Float64} =\n",
      "  getHomoskedΣSlow([[iv.Z iv.W]*iv.Π1 iv.W], iv.Y.-[iv.X iv.W] * iv.δ2)\n",
      "\n",
      "###################getMWErrors!##############################\n",
      "#Main method to get the modified white SEs Does #[X'X]^-1X'ΛX[X'X]^-1\n",
      "\n",
      "#=Main method to calculate the modified white SEs\n",
      "IN: A CTQR decomposition object, a residuals vector,\n",
      "optional memory for a covariance matrix\n",
      "OUT: Writes and returns the covariance matrix=#\n",
      "function getModWhiteΣ!(xqr::CTQR, ε::Vector{Float64},\n",
      "  Σ::Matrix{Float64} = Matrix{Float64}(lin.K, lin.K))::Matrix{Float64}\n",
      "\n",
      "  Λ::Vector{Float64} = similar(ε)\n",
      "\n",
      "  project!(xqr,Λ) #get the projection diagonal\n",
      "  Λ .= (ε./(1.0.-Λ)).^2.0\n",
      "\n",
      "  QRtInv::Matrix{Float64} = BLAS.gemm('N','T',xqr.Q,xqr.RInv) #Q(R')^-1\n",
      "  RInvQΛ::Matrix{Float64} = QRtInv.'\n",
      "\n",
      "  #loop to scale the matrix by Λ (modified part of modified white)\n",
      "  @fastmath for j ∈ 1:xqr.N, i∈1:xqr.K\n",
      "    RInvQΛ[i,j] *= Λ[j]\n",
      "  end\n",
      "\n",
      "  #final multiplicaiton and assignment\n",
      "  return BLAS.gemm!('N','N',1.0,RInvQΛ, QRtInv,0.0,Σ) #R^-1Q'ΛQ(R')^-1\n",
      "end\n",
      "\n",
      "#=helper method which extracts the required components from a linear model\n",
      "IN: A linear model, optionally memory for the covariance matrix\n",
      "OUT: Writes and allocates the covariance matrix=#\n",
      "function getModWhiteΣ!(lin::CTLM,\n",
      "  Σ::Matrix{Float64} = Matrix{Float64}(lin.K, lin.K))::Matrix{Float64}\n",
      "\n",
      "  return getModWhiteΣ!(lin.xqr, lin.ε, Σ)\n",
      "end\n",
      "\n",
      "#=helper method which extracts the required components from a 2SLS model\n",
      "IN: A 2SLS model, optionally memory for the covariance matrix\n",
      "OUT: Writes and allocates the covariance matrix=#\n",
      "function getModWhiteΣ!(iv::CT2SLS,\n",
      "  Σ::Matrix{Float64}=Matrix{Float64}(iv.xaqr.K, iv.xaqr.K))::Matrix{Float64}\n",
      "\n",
      "  return getModWhiteΣ!(iv.xaqr, iv.ξ2, Σ)\n",
      "end\n",
      "\n",
      "#=Simple test function to verify the QR-related optimizations\n",
      "Output should be identical to the standard methods\n",
      "IN: Independent variable X matrix\n",
      "OUT: Returns the covariance matrix=#\n",
      "function getModWhiteΣSlow(X::Matrix{Float64}, ε::Vector{Float64})\n",
      "  XXInv::Matrix{Float64} = (X.' * X)\\eye(size(X,2))\n",
      "\n",
      "  P::Matrix{Float64} = X * (XXInv) * X.'\n",
      "  return XXInv * X.' * diagm(ε  ./ (1.0 .- diag(P))) .^ 2.0 * X * XXInv\n",
      "\n",
      "end\n",
      "\n",
      "#Convenience method for above: IN: A linear model #OUT: A covariance matrix\n",
      "getModWhiteΣSlow(lin::CTLM) = getModWhiteΣSlow(lin.X, lin.Y.-lin.X * lin.β)\n",
      "\n",
      "#Convenience method for above: IN: A 2SLS object #OUT: A covariance matrix\n",
      "getModWhiteΣSlow(iv::CT2SLS)::Matrix{Float64} =\n",
      "  getModWhiteΣSlow([[iv.Z iv.W]*iv.Π1 iv.W], iv.Y.-[iv.X iv.W] * iv.δ2)\n",
      "\n",
      "\n",
      "\n",
      "######################IO################\n",
      "\n",
      "\n",
      "#texTable\n",
      "#=    Creates a well-formed Latex table from string components\n",
      "  The content matrix consists of an array of matrices, which are overlayed\n",
      "  via a one line offset. For example, the first matrix might be the values,\n",
      "  the second matrix the errors. Observational rows can be put in\n",
      "  descContent, which is a vector of rows. Similarly, colNames is a vector\n",
      "  of rows. So that column headers can span multiple columns, the widthColNames\n",
      "  and widthDescContent provides the option to specify dimentions\n",
      "  IN: caption (title), colNames, rowNames, content, descContent (rows of\n",
      "      descriptive data), notes, optionally widthColNames and widthDescConent\n",
      "      (which are the width of each entry in columns)\n",
      "  OUT: The tex table as a string=#\n",
      "\n",
      "function texTable(titleCaption::String,\n",
      "  caption::String,\n",
      "  colNames::Vector{Vector{String}},\n",
      "  contentRowNames::Vector{String},\n",
      "  content::Vector{Matrix{String}},\n",
      "  descRowNames::Vector{String},\n",
      "  descContent::Vector{Vector{String}},\n",
      "  notes::Vector{String};\n",
      "  arrayStretch::Float64 = 1.5,\n",
      "  lineSpacer::String = \"\\\\\\\\\",\n",
      "  summaryMathMode::Bool = true,\n",
      "  widthColNames::Vector{Vector{Int}} = #contains the number of columns for each entry\n",
      "    broadcast((i::Int)->ones(Int,length(colNames[i])),1:length(colNames)),\n",
      "  alignmentColNames::Vector{Vector{String}} = #contains the number of columns for each entry\n",
      "    broadcast((i::Int)->[\"r\" for i ∈ 1:length(colNames[i])],1:length(colNames)),\n",
      "  widthDescContent::Vector{Vector{Int}} = #contains the number of columns for each entry\n",
      "    broadcast((i::Int)->ones(Int,length(descContent[i])),1:length(descContent)),\n",
      "  columnSepPt::Int = 0,\n",
      "  colHeaderName::Vector{String} = [\"\" for i ∈ 1:length(colNames)])\n",
      "\n",
      "  #size parameters for content\n",
      "  numContentRows::Int = length(contentRowNames)\n",
      "\n",
      "  numContentCols::Int = sum(widthColNames[1])\n",
      "\n",
      "  numContentSubRows::Int = length(content)\n",
      "\n",
      "      #intiate the stream\n",
      "  b::IOBuffer = IOBuffer()\n",
      "  write(b, \"\"\"\n",
      "      %This table was programatically generated\n",
      "\n",
      "      \\\\begin{table} \\\\caption{$titleCaption} \\\\label{} \\\\centering\n",
      "      $(length(caption)>0?\"\\\\textit{$caption\\\\\\\\}\":\"\")\n",
      "      \\\\renewcommand{\\\\arraystretch}{$arrayStretch}\n",
      "      \\\\begin{tabular}{l | \"\"\")\n",
      "\n",
      "    for i ∈ 1:(numContentCols) #set the dimensions in tex\n",
      "      write(b,\"r\")\n",
      "    end\n",
      "    #write(b, \"{\\\\textwidth}{Xccccccc}\")\n",
      "    write(b,\"}\\n \\\\toprule\")#filler tex\n",
      "\n",
      "  for r::Int ∈ 1:length(colNames) #for each row of column headings\n",
      "      #write(b,\"\\n\\\\\\\\[-1.8ex]\") #use this if the below doesn't work\n",
      "    write(b, colHeaderName[r])\n",
      "    if length(colNames[r]) ≠ numContentCols\n",
      "      for c::Int ∈ 1:length(colNames[r]) #for each column heading\n",
      "          write(b,\"\\t&\\t\\\\multicolumn{$(widthColNames[r][c])}{$(alignmentColNames[r][c])}{$(colNames[r][c])}\")\n",
      "      end\n",
      "    else\n",
      "      for c::Int ∈ 1:length(colNames[r]) #for each column heading\n",
      "        write(b,\"\\t&\\t$(colNames[r][c])\")\n",
      "      end\n",
      "    end\n",
      "      write(b,\"\\n\\\\\\\\\")\n",
      "  end\n",
      "  write(b, \" \\\\midrule\\n \")\n",
      "\n",
      "  #now write out the table content\n",
      "    if numContentRows > 0\n",
      "        write(b,\" \\t \\t \")\n",
      "        for r::Int ∈ 1:numContentRows\n",
      "          write(b, \"$(contentRowNames[r])\") #the row label\n",
      "          for s::Int ∈ 1:numContentSubRows #print the sub-rows for each row\n",
      "            for c::Int ∈ 1:numContentCols #print the columns for each sub-row\n",
      "              #write(b,\"\\t&\\t\\\\multicolumn{1}{r}{\\$$((content[s])[r, c])\\$}\")\n",
      "              write(b,\"\\t&\\t$((content[s])[r, c])\")\n",
      "            end\n",
      "            write(b,\"\\n $(lineSpacer) \\t\\t\") #line-break stylistic formatting\n",
      "          end\n",
      "        end\n",
      "        write(b, \"\\n \\\\midrule\\n\")\n",
      "    end\n",
      "    sumMathFlag::String = summaryMathMode?\"\\$\":\"\"\n",
      "\n",
      "    if length(descContent)>0\n",
      "        for r::Int ∈ 1:length(descContent) #for each description row\n",
      "          write(b, \"$(descRowNames[r])\") #the row label\n",
      "          if length(widthDescContent[r]) ≠ numContentCols\n",
      "            for c::Int ∈ 1:length(descContent[r]) #for each descriptive row\n",
      "              if length(descContent[r][c]) ≥ 1\n",
      "                write(b,\"\\t&\\t\\\\multicolumn{$(widthDescContent[r][c])}{r}{$(sumMathFlag)$(descContent[r][c])$(sumMathFlag)}\")\n",
      "              else\n",
      "                write(b,\"\\t&\\t\\\\multicolumn{$(widthDescContent[r][c])}{r}{}\")\n",
      "              end\n",
      "            end\n",
      "          else\n",
      "            for c::Int ∈ 1:length(descContent[r]) #for each descriptive row\n",
      "              if length(descContent[r][c]) ≥ 1\n",
      "                write(b,\"\\t&\\t$(sumMathFlag)$(descContent[r][c])$(sumMathFlag)\")\n",
      "              else\n",
      "                write(b,\"\\t&\\t\")\n",
      "              end\n",
      "            end\n",
      "          end\n",
      "            write(b,\"\\n $(lineSpacer) \\t\\t\") #line-break stylistic formatting\n",
      "        end\n",
      "    end\n",
      "\n",
      "      write(b,\"\"\" \\\\bottomrule\"\"\")\n",
      "  #if we have footnotes\n",
      "  if length(notes) > 0\n",
      "      write(b,\"\"\"\\n \\\\\\\\[-1.0ex] \\\\textit{Notes:} \\t \"\"\")\n",
      "      for r ∈ length(notes)\n",
      "          write(b, \"\\t&\\t \\\\multicolumn{$numContentCols}{l}{$(notes[r])}\\n \\\\\\\\\")\n",
      "      end\n",
      "  end\n",
      "  write(b, \"\\t \\\\end{tabular}\\n \\\\\\\\ \\\\end{table}\")\n",
      "  return String(b)\n",
      "end\n",
      "\n",
      "\n",
      "#=this version formats a table from a set of linear models\n",
      "While customizable, the idea here is to have sensible default arguments\n",
      "where possible.\n",
      "IN: A collection of models, the rows to capture (returns an empty string in\n",
      "the table if a row is not present, optionally column names, their width,\n",
      "names of the rows, names of the descriptive rows, descriptive content,\n",
      "a boolean switch for including signficance stars, signficance levels for the stars,\n",
      "a scaling factor, the number of digits in values, and customizable\n",
      "notes\n",
      "OUT: A latex table string\n",
      "=#\n",
      "function texTable(models::Vector{CTLM}, getΣ::Function, rows::Vector{Symbol};\n",
      "    titleCaption::String = \"\",\n",
      "    caption::String = \"\",\n",
      "    colNames::Vector{Vector{String}} = [[\"C$i\" for i ∈ 1:length(models)]],\n",
      "    contentRowNames::Vector{String} = String.(rows),\n",
      "    descRowNames::Vector{String}=Vector{String}(),\n",
      "    descContent::Vector{Vector{String}}=Vector{Vector{String}}(),\n",
      "    notes::Vector{String} = Vector{String}(),\n",
      "    arrayStretch::Float64 = 1.5,\n",
      "    lineSpacer::String = \"\\\\\\\\\",\n",
      "    summaryMathMode::Bool = true,\n",
      "    widthColNames::Vector{Vector{Int}} =\n",
      "        broadcast((i::Int)->ones(Int,length(colNames[i])),1:length(colNames)),\n",
      "    alignmentColNames::Vector{Vector{String}} = #contains the number of columns for each entry\n",
      "      broadcast((i::Int)->[\"r\" for i ∈ 1:length(colNames[i])],1:length(colNames)),\n",
      "    widthDescContent::Vector{Vector{Int}} =\n",
      "        broadcast((i::Int)->ones(Int,length(descContent[i])),1:length(descContent)),\n",
      "    stars::Bool=true,\n",
      "    starLvls::Vector{Float64} = [.9, .95, .99],\n",
      "    starLegend::String = stars?DEFAULT_STAR_LEGEND:\"\",\n",
      "    starStrings::Vector{String} =\n",
      "      [\"\\\\ensuremath{^\\\\text{*}}\",\"\\\\ensuremath{^\\\\text{**}}\",\"\\\\ensuremath{^\\\\text{***}}\"],\n",
      "    scaling::Vector{Float64}=ones(length(rows)),\n",
      "    decimalDigits::Int = 2,\n",
      "    columnSepPt::Int = 25-length(models)*5,\n",
      "    colHeaderName::Vector{String} = [\"\" for i::Int ∈ 1:length(colNames)],\n",
      "    clearMem=false)\n",
      "\n",
      "  numCols = length(models)\n",
      "  numContentRows = length(rows)\n",
      "\n",
      "  #initialize a vector of content matrices\n",
      "  content::Vector{Matrix{String}} = [fill(\"\",numContentRows,numCols) for i::Int ∈ 1:2]\n",
      "\n",
      "  #Pre-allocate the vector of SE errors\n",
      "  modelsσ::Vector{Vector{Float64}} =\n",
      "      [Vector{Float64}(models[i].K) for i∈1:numCols]\n",
      "\n",
      "  #pull out the β coefficients and N\n",
      "  modelsβ::Vector{Vector{Float64}} = [models[i].β for i::Int ∈ 1:numCols]\n",
      "  modelsN::Vector{Int} = [models[i].N for i ∈ 1:numCols]\n",
      "  modelsXNames::Vector{Vector{Symbol}} = [models[i].XNames for i::Int ∈ 1:numCols]\n",
      "\n",
      "  #get the standard errors\n",
      "  for c ∈ 1:numCols\n",
      "      modelsσ[c] .= sqrt.(diag(getΣ(models[c])))\n",
      "      if clearMem #clears the memory of a model no longer used. Hurts performance.\n",
      "          models[c] .= CTLM()\n",
      "          gc()\n",
      "      end\n",
      "  end\n",
      "\n",
      "  if length(starLegend) > 0\n",
      "      notes = [starLegend; notes]\n",
      "  end\n",
      "\n",
      "  #get the content matrices\n",
      "  getContentMatrices!( modelsβ, modelsσ, modelsXNames, modelsN, rows, content,\n",
      "      stars=stars, starLvls=starLvls, scaling=scaling,\n",
      "      decimalDigits=decimalDigits, starStrings=starStrings)\n",
      "\n",
      "  return texTable(titleCaption,caption, colNames, contentRowNames, content, descRowNames,\n",
      "      descContent, notes, arrayStretch=arrayStretch, lineSpacer=lineSpacer, summaryMathMode=summaryMathMode, widthColNames=widthColNames,\n",
      "      widthDescContent=widthDescContent, columnSepPt=columnSepPt, colHeaderName=colHeaderName,\n",
      "      alignmentColNames=alignmentColNames)\n",
      "end\n",
      "\n",
      "function texTable(models::Vector{CT2SLS}, getΣ::Function, rows::Vector{Symbol};\n",
      "    titleCaption::String = \"\",\n",
      "    caption::String = \"\",\n",
      "    colNames::Vector{Vector{String}} = [[\"C$i\" for i ∈ 1:length(models)]],\n",
      "    contentRowNames::Vector{String} = String.(rows),\n",
      "    descRowNames::Vector{String}=Vector{String}(),\n",
      "    descContent::Vector{Vector{String}}=Vector{Vector{String}}(),\n",
      "    notes::Vector{String} = Vector{String}(),\n",
      "    arrayStretch::Float64 = 1.5,\n",
      "    lineSpacer::String = \"\\\\\\\\\",\n",
      "    summaryMathMode::Bool = true,\n",
      "    widthColNames::Vector{Vector{Int}} =\n",
      "        broadcast((i::Int)->ones(Int,length(colNames[i])),1:length(colNames)),\n",
      "    alignmentColNames::Vector{Vector{String}} = #contains the number of columns for each entry\n",
      "      broadcast((i::Int)->[\"r\" for i ∈ 1:length(colNames[i])],1:length(colNames)),\n",
      "    widthDescContent::Vector{Vector{Int}} =\n",
      "        broadcast((i::Int)->ones(Int,length(descContent[i])),1:length(descContent)),\n",
      "    stars::Bool=true,\n",
      "    starLvls::Vector{Float64} = [.9, .95, .99],\n",
      "    starLegend::String = stars?DEFAULT_STAR_LEGEND:\"\",\n",
      "    starStrings::Vector{String} =\n",
      "      [\"\\\\ensuremath{^\\\\text{*}}\",\"\\\\ensuremath{^\\\\text{**}}\",\"\\\\ensuremath{^\\\\text{***}}\"],\n",
      "    scaling::Vector{Float64}=ones(length(rows)),\n",
      "    decimalDigits::Int = 2,\n",
      "    columnSepPt::Int = 25-length(models)*5,\n",
      "    colHeaderName::Vector{String} = [\"\" for i ∈ 1:length(colNames)],\n",
      "    clearMem = false)\n",
      "\n",
      "    numCols = length(models)\n",
      "    numContentRows = length(rows)\n",
      "\n",
      "    #initialize a vector of content matrices\n",
      "    content::Vector{Matrix{String}} = [fill(\"\",numContentRows,numCols) for i ∈ 1:2]\n",
      "\n",
      "    #Pre-allocate the vector of SE errors\n",
      "    modelsσ::Vector{Vector{Float64}} =\n",
      "    [Vector{Float64}(models[i].K+models[i].KW) for i∈1:numCols]\n",
      "\n",
      "\n",
      "    #pull out the β coefficients and N\n",
      "    modelsβ::Vector{Vector{Float64}} = [models[i].δ2 for i ∈ 1:numCols]\n",
      "    modelsN::Vector{Int} = [models[i].N for i ∈ 1:numCols]\n",
      "    modelsXWNames::Vector{Vector{Symbol}} = [[models[i].XNames; models[i].WNames]  for i ∈ 1:numCols]\n",
      "\n",
      "    #get the standard errors\n",
      "    for c ∈ 1:numCols\n",
      "        modelsσ[c] .= sqrt.(diag(getΣ(models[c])))\n",
      "        if clearMem #clears the memory of a model no longer used. Hurts performance.\n",
      "            models[c] .= CT2SLS()\n",
      "            gc()\n",
      "        end\n",
      "    end\n",
      "\n",
      "    if length(starLegend) > 0\n",
      "        notes = [starLegend; notes]\n",
      "    end\n",
      "\n",
      "    #get the content matrices\n",
      "    getContentMatrices!( modelsβ, modelsσ, modelsXWNames, modelsN, rows, content,\n",
      "        stars=stars, starLvls=starLvls, scaling=scaling,\n",
      "        decimalDigits=decimalDigits, starStrings=starStrings)\n",
      "\n",
      "    return texTable(titleCaption, caption, colNames, contentRowNames, content, descRowNames,\n",
      "        descContent, notes, arrayStretch=arrayStretch, lineSpacer=lineSpacer, summaryMathMode=summaryMathMode, widthColNames=widthColNames,\n",
      "        widthDescContent=widthDescContent, columnSepPt=columnSepPt, alignmentColNames=alignmentColNames)\n",
      "end\n",
      "\n",
      "#=getContentMatrices!\n",
      "this is a bit of utiltiy code for making tex tables. It is not model specific\n",
      "hence why it was extracted into its own function\n",
      "#IN: a vector of βs, σs, names, rows (coefficeints selected). Optional parameters\n",
      "include a pre-allcoation of the string matrix, a switch for the inclusion of\n",
      "stars, a scaling factor, and the number of digits (rounding level)=#\n",
      "#OUT: Writes to and returns the content matrix\n",
      "function getContentMatrices!(modelsβ::Vector{Vector{Float64}},\n",
      "    modelsσ::Vector{Vector{Float64}},\n",
      "    modelsXNames::Vector{Vector{Symbol}},\n",
      "    modelsN::Vector{Int},\n",
      "    rows::Vector{Symbol},\n",
      "    content::Vector{Matrix{String}} = #will hold the coefficients and errors\n",
      "        [fill(\"\",length(rows),length(modelsCoef)) for i ∈ 1:2];\n",
      "    stars::Bool=true, #whether to display signficance stars\n",
      "    starLvls::Vector{Float64} = [.9, .95, .99],  #cutoffs for signficance (must be sorted)\n",
      "    starStrings::Vector{String} =\n",
      "      [\"\\\\ensuremath{^\\\\text{*}}\",\"\\\\ensuremath{^\\\\text{**}}\",\"\\\\ensuremath{^\\\\text{***}}\"],\n",
      "    scaling::Vector{Float64}=ones(length(rows)), # an optional scaling factor\n",
      "    decimalDigits::Int = 2) #number of decimal digits\n",
      "\n",
      "\n",
      "\n",
      "    #iterate through the models\n",
      "    for c ∈ 1:length(modelsβ)\n",
      "\n",
      "        #build a dictionary of the names\n",
      "        XNameTbl::Dict = Dict(modelsXNames[c][i] => i for i::Int ∈ 1:length(modelsβ[c]))\n",
      "\n",
      "        for r ∈ 1:length(rows)\n",
      "            if haskey(XNameTbl, rows[r]) #need to check if it exists\n",
      "                ind::Int = XNameTbl[rows[r]]\n",
      "                p::Float64 =\n",
      "                    cdf(TDist(modelsN[c]), modelsβ[c][ind]/modelsσ[c][ind]) #get CDF from T distribution\n",
      "                p = p > .5 ? 1-(1.0 - p)*2.0 : 1.0 - p*2.0 #calc 2-tailed p value\n",
      "                sigLevel::Int = sum(p.>starLvls)\n",
      "                if sigLevel > 0 && stars\n",
      "                    starString::String = starStrings[sum(p.>starLvls)]\n",
      "                else\n",
      "                    starString = \"\"\n",
      "                end\n",
      "\n",
      "                #scale, round and write the β coefficeint and σ into the string matrices\n",
      "                content[1][r,c] =\n",
      "                  #\"$(round(scaling[r]*modelsβ[c][ind],decimalDigits))^{$starString}\"\n",
      "                  \"\\$$(round(scaling[r]*modelsβ[c][ind],decimalDigits))\\$$starString\"\n",
      "                content[2][r,c] =\n",
      "                  #\"($(round(scaling[r]*modelsσ[c][ind],decimalDigits)))\"\n",
      "                  \"(\\$$(round(scaling[r]*modelsσ[c][ind],decimalDigits))\\$)\"\n",
      "            end\n",
      "        end\n",
      "    end\n",
      "\n",
      "  return content\n",
      "end\n",
      "\n",
      "#=Writes the fully formed string to the file\n",
      "  IN: A string with the output, optionally a path to the file, and the\n",
      "  output name\n",
      "  OUT: Writes the string to a file=#\n",
      "function writeTables2File(tablesString::String;\n",
      "    path::String=pwd(),\n",
      "    outName::String = \"$path\\\\results$(Dates.format(now(),\"yymmdd_THMS\")).tex\")\n",
      "\n",
      "    oStream::IOStream = open(\"$path\\\\$outName\",\"w+\")\n",
      "    write(oStream, tablesString)\n",
      "    close(oStream)\n",
      "end\n",
      "\n",
      "#=Writes the table strings to a file\n",
      "  Convenience method which takes an array of table strings and optionally\n",
      "  header and footer strings and writes the table to a tex file\n",
      "  IN: A string array of table strings, optionally a header string, a footer\n",
      "  string, a path to the file, the output name\n",
      "  OUT: Writes the tables to a file=#\n",
      "function writeTables2File(tables::Vector{String};\n",
      "    header::String = \"\\n\", footer::String = \"\",\n",
      "    path::String=pwd(),\n",
      "    outName::String = \"$path\\\\results$(Dates.format(now(),\"yymmdd_THMS\")).tex\")\n",
      "\n",
      "    b::IOBuffer = IOBuffer() #make an IO buffer\n",
      "    write(b,\"\\n$header\\n\\n\")\n",
      "    for t ∈ tables\n",
      "        write(b,\"$t\\n\\n\\n\") #write each table\n",
      "    end\n",
      "    write(b,footer) #write the footer\n",
      "\n",
      "    #write the output via another instance\n",
      "    writeTables2File(String(b), path=path, outName = outName)\n",
      "end\n",
      "\n",
      "#=Writes the table strings to a file\n",
      "Convenience method which takes an array of table strings and the locations of\n",
      "header and footer files.\n",
      "IN: A string array of table strings, the name of a header file, the name of a\n",
      "a footer file, optionally a path to the file, the output name\n",
      "OUT: Writes the tables to a file=#\n",
      "function writeTables2File(tables::Vector{String}, headerName::String,\n",
      "  footerName::String;\n",
      "  path::String=pwd(),\n",
      "  outName::String = \"$path\\\\results$(Dates.format(now(),\"yymmdd_THMS\")).tex\")\n",
      "\n",
      "  iStream::IOStream = open(\"$path\\\\$headerName\")\n",
      "  header::String = readstring(iStream)\n",
      "  close(iStream)\n",
      "\n",
      "  iStream = open(\"$path\\\\$footerName\")\n",
      "  footer::String = readstring(iStream)\n",
      "  close(iStream)\n",
      "\n",
      "  #write the output via another instance\n",
      "  writeTables2File(tables, path=path, outName = outName, header=header,\n",
      "      footer=footer)\n",
      "end\n",
      "\n",
      "#array2String\n",
      "  #=takes content of an array, formats each cell into a string, appends a\n",
      "  prefix and suffix, and sends back an array of strings with the same\n",
      "  dimension as the input\n",
      "  IN: A general array, optionally a prefix, suffix, scaling factor, and\n",
      "   set number of decimal digits\n",
      "  OUT: An array of strings with the same dimensions as the input=#\n",
      "function array2String(m::Array{Float64}; prefix::String = \"\",\n",
      "  suffix::String = \"\", scaling::Float64 = 1.0,\n",
      "  decimalDigits::Int = 2)::Array{String}\n",
      "\n",
      "  #broadcast the prefix, value in m, and suffix and concatenate respectively\n",
      "  stringMat::Array{String} =\n",
      "      ((x::Float64)->(prefix*\"$(round(x,decimalDigits))\"*suffix)).(m)\n",
      "\n",
      "  return stringMat\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "function IOTest()\n",
      "  #test parameters\n",
      "  nrowsContent = 8\n",
      "  ncols = 4\n",
      "  nsecs = ncols ÷ 2\n",
      "  nrowsDesc = 2\n",
      "  nsubRows = 2\n",
      "\n",
      "  path = pwd() * \"\\\\results\"\n",
      "  outName = \"test.tex\"\n",
      "  footerName = \"footer.tex\"\n",
      "  headerName = \"header.tex\"\n",
      "\n",
      "  #test table\n",
      "  caption = \"test table\"\n",
      "  colNames::Vector{Vector{String}} =\n",
      "      [broadcast(i->\"secs$i\",1:nsecs),broadcast(i->\"ncols$i\",1:ncols)]\n",
      "  contentRowNames::Vector{String} = [\"nrows$i\" for i ∈ 1:nrowsContent]\n",
      "  content::Vector{Matrix{String}} =\n",
      "      array2String.(broadcast((i::Int)->i .* ones(nrowsContent,ncols), 1:nsubRows))\n",
      "  descRowNames::Vector{String} = [\"Desc. row $i\" for i ∈ 1:nrowsDesc]\n",
      "  descContent::Vector{Vector{String}} =\n",
      "      [broadcast(i->\"desc-r1c$i\",1:ncols),broadcast(i->\"desc-r1c$i\",1:ncols)]\n",
      "  notes::Vector{String} = [\"a note\"]\n",
      "  widthColNames::Vector{Vector{Int}} =\n",
      "      [broadcast(i->(ncols ÷ nsecs), 1:nsecs),broadcast(i->1, 1:ncols)]\n",
      "\n",
      "  s=texTable(caption, colNames,  contentRowNames, content, descRowNames,\n",
      "      descContent, notes, widthColNames=widthColNames)\n",
      "\n",
      "  writeTables2File([s,s], headerName, footerName, path=path, outName = outName)\n",
      "\n",
      "  #println(array2String(fill(.45/π,3,3,4),decimalDigits=4))\n",
      "\n",
      "print(s)\n",
      "end\n",
      "\n",
      "#################testing methods for this module\n",
      "function LMtest()\n",
      "\n",
      "  #Number of Observations\n",
      "  N::Int = 200\n",
      "  K::Int = 2\n",
      "\n",
      "  #Allocate\n",
      "  X::Matrix{Float64} = Matrix{Float64}(N,K)\n",
      "  Y::Vector{Float64} = Vector{Float64}(N)\n",
      "  ε::Vector{Float64} = similar(Y)\n",
      "\n",
      "  #parameters for the simulation\n",
      "  σ2::Vector{Float64} = [2.0^2.0 for i::Int ∈ 1:N]\n",
      "  σ2[1:ceil(Int, N/2)] .= 0.5^2.0\n",
      "  β::Vector{Float64} = [(1.0 * i) for i::Int ∈ 1:K]\n",
      "  #println(\"β: \", β)\n",
      "  #println(\"σ2: $σ2\")\n",
      "\n",
      "  #this will hold the sampled beta\n",
      "  e::Vector{Float64} = similar(ε)\n",
      "\n",
      "  #run the simulation\n",
      "  X[:,1] .= 1.0 #intercept\n",
      "  for i ∈ 2:K\n",
      "    X[:,i] .= rand(Uniform(),N)\n",
      "  end\n",
      "\n",
      "  ε .= map((s2::Float64)->rand(Normal(0.0,s2^0.5)),σ2)\n",
      "  Y .=  X*β .+ ε\n",
      "\n",
      "  #get the linear model\n",
      "  lin::CTLM = CTLM(X, Y)\n",
      "\n",
      "  #get the homoskedastic SEs\n",
      "  ΣHomosked::Matrix{Float64} = getHomoskedΣ!(lin)\n",
      "  ΣHomoskedSlow::Matrix{Float64} = getHomoskedΣSlow(lin)\n",
      "\n",
      "  #print the coefficients\n",
      "  println(\"Coefficients: \",lin.β)\n",
      "  println(\"Homoskedastic Errors: \", diag(ΣHomosked).^.5)\n",
      "  println(\"Check: \", diag(ΣHomoskedSlow).^.5)\n",
      "\n",
      "  #get the modified white SEs\n",
      "  ΣWhite::Matrix{Float64} = similar(ΣHomosked)\n",
      "  getModWhiteΣ!(lin, ΣWhite)\n",
      "  ΣWhiteSlow::Matrix{Float64} = getModWhiteΣSlow(lin)\n",
      "\n",
      "  #print the coefficients\n",
      "  println(\"Modified White Errors: \",diag(ΣWhite).^.5)\n",
      "  println(\"Check: \", diag(ΣWhiteSlow).^.5)\n",
      "\n",
      "    #=Π1::Matrix{Float64} = Matrix{Float64}(K,2)\n",
      "  getCoeff!(lin.xqr, [Y 2.*Y], Π1)\n",
      "  println(\"1st stage Z: $(lin.X)\")\n",
      "  println(\"1st Stage X: $([Y 2.*Y])\" )\n",
      "  println(\"1st Stage Test Coef: $Π1\" )\n",
      "  Ξ::Matrix{Float64} = getResid!(lin.xqr, [Y 2.*Y], Π1)\n",
      "  println(\"1st Stage Resid: $Ξ\" )=#\n",
      "\n",
      "\n",
      "  #test the project routines\n",
      "  Pa::Vector{Float64} = Vector{Float64}(N)\n",
      "  PM::Matrix{Float64} = Matrix{Float64}(N,N)\n",
      "  PS::Matrix{Float64} = Matrix{Float64}(N,N)\n",
      "\n",
      "  project!(X,PM)\n",
      "  project!(X,Pa)\n",
      "\n",
      "  projectSlow!(X,PS)\n",
      "  println(\"P: \", Pa[1:5])\n",
      "  println(\"P (from full matrix): \", PM[1:3,1:3])\n",
      "  println(\"P Slow: \", diag(PS)[1:10])\n",
      "end\n",
      "\n",
      "function IVTest()\n",
      "\n",
      "  srand(11)\n",
      "\n",
      "  N::Int = 200 #Number of Observations\n",
      "  K::Int = 3 # of endogneous covariates\n",
      "  L::Int = 4 # of instruments\n",
      "  KW::Int = 5# of exog covariates\n",
      "\n",
      "  #Allocate\n",
      "  X::Matrix{Float64} = Matrix{Float64}(N,K)\n",
      "  Z::Matrix{Float64} = Matrix{Float64}(N,L)\n",
      "  W::Matrix{Float64} = Matrix{Float64}(N,KW)\n",
      "  Y::Vector{Float64} = Vector{Float64}(N)\n",
      "  A::Vector{Float64} = Vector{Float64}(N)\n",
      "\n",
      "  Π1::Matrix{Float64} = Matrix{Float64}(L+KW,K)\n",
      "  π2::Vector{Float64} = Vector{Float64}(L+KW)\n",
      "  Ξ1::Matrix{Float64} = similar(X)\n",
      "  e2::Vector{Float64} = similar(Y)\n",
      "\n",
      "  #parameters for the simulation\n",
      "  σ2::Vector{Float64} = [2.0^2 for i::Int ∈ 1:N]\n",
      "  σ2[1:ceil(Int, N/2)] .= 0.5^2.0\n",
      "\n",
      "  #generate π2 coefficients (pattern is 1 times the index, ie 1 2 3 ...)\n",
      "  π2 .= [(10*i) for i::Int ∈ 1:(L+KW)]\n",
      "  π2[L+1] .= 1.0 #intercept term\n",
      "  #println(\"π2: \",π2)\n",
      "\n",
      "  #generate Π1, pattern is δ2 times 1/10 the index, ie ie .1δ2 .2δ2 .3δ2 ...)\n",
      "  for i ∈ 1:(L+KW), j∈1:K\n",
      "    Π1[i,j] .= i + j^2\n",
      "  end\n",
      "  Π1[L+1,:] .= 1.0 #set the intercept term\n",
      "  #display(Π1)\n",
      "\n",
      "  #generate the exogeneous variables\n",
      "  for i ∈ 2:KW\n",
      "    W[:,i] .= rand(Uniform(-10,10),N)\n",
      "  end\n",
      "  W[:,1] .= 1.0 #intercept\n",
      "\n",
      "  #generate the instrumental variables\n",
      "  for i ∈ 1:L\n",
      "    Z[:,i] .= rand(Uniform(-10,10),N)\n",
      "  end\n",
      "\n",
      "  #map((s2::Float64)->rand(Normal(0.0,s2^0.5)),σ2)\n",
      "  #generate the errors\n",
      "  for i ∈ 1:N\n",
      "    for j ∈ 1:K\n",
      "      Ξ1[i,j] = rand(Normal(0.0,σ2[i]^0.5))\n",
      "    end\n",
      "    e2[i] = rand(Normal(0.0,σ2[i]^0.5))\n",
      "  end\n",
      "\n",
      "  #println(Ξ1)\n",
      "  #populate Y and X\n",
      "  X .= [Z W]*Π1 .+ Ξ1\n",
      "  Y .= [Z W]*π2 .+ e2\n",
      "\n",
      "  #add some endogeneity\n",
      "  for i ∈ 1:K\n",
      "    A .= rand(Uniform(-i,i),N)\n",
      "    X[:,i] .+= A\n",
      "    Y .+= A .* 10\n",
      "  end\n",
      "\n",
      "\n",
      "  #probably is a more graceful way to do this\n",
      "  XNames::Vector{Symbol} = [Symbol(\"X$i\") for i = 1:K]\n",
      "  WNames::Vector{Symbol} = [Symbol(\"W$i\") for i = 1:KW]\n",
      "  ZNames::Vector{Symbol} = [Symbol(\"Z$i\") for i = 1:L]\n",
      "\n",
      "\n",
      "  iv::CT2SLS = CT2SLS(X,W,Y,Z, XNames=XNames, YName=:Y, WNames=WNames, ZNames=ZNames)\n",
      "  println(\"coefficients: \\n\", [XNames; WNames] ,\"\\n\", iv.δ2)\n",
      "\n",
      "  #get the homoskedastic SEs\n",
      "  ΣHomosked::Matrix{Float64} = getHomoskedΣ!(iv)\n",
      "  ΣHomoskedSlow::Matrix{Float64} = getHomoskedΣSlow(iv)\n",
      "\n",
      "  #print the coefficients\n",
      "  println(\"Homoskedastic Errors: \", diag(ΣHomosked).^.5)\n",
      "  println(\"Check: \", diag(ΣHomoskedSlow).^.5)\n",
      "\n",
      "  #get the modified white SEs\n",
      "  ΣWhite::Matrix{Float64} = getModWhiteΣ!(iv)\n",
      "  ΣWhiteSlow::Matrix{Float64} = getModWhiteΣSlow(iv)\n",
      "\n",
      "  #print the coefficients\n",
      "  println(\"Modified White Errors: \",diag(ΣWhite).^.5)\n",
      "  println(\"Check: \", diag(ΣWhiteSlow).^.5)\n",
      "\n",
      "  iv1st::Vector{CTLM} = get1stStage(iv)\n",
      "  println(\"1st Stage results: \\n $(iv1st[1].XNames)\")\n",
      "  for iv1 ∈ iv1st\n",
      "      println(\"coefficients $(iv1.YName):  $(iv1.β )\")\n",
      "      println(\"Error (Homosked $(iv1.YName)): $(diag(getHomoskedΣ!(iv1)).^.5)\")\n",
      "  end\n",
      "\n",
      "\n",
      "\n",
      "  oStream::IOStream = open(\n",
      "    \"C:\\\\Users\\\\Clinton\\\\Dropbox\\\\Projects\\\\Summer17RTester\\\\Summer17RTester\\\\IVTestOut.csv\",\"w+\")\n",
      "\n",
      "\n",
      "  write(oStream, [string.(iv.XNames); string.(iv.WNames)]::Vector{String})\n",
      "  writecsv(oStream, [X W Y Z])\n",
      "  close(oStream)\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "if DEBUG_CTMOD\n",
      "  #LMtest()\n",
      "  IVTest()\n",
      "  #IOTest()\n",
      "  #print(perfTestStr(10^6))\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "#end module\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  21\n",
      "joshday/Penalties.jl\n",
      "src/common.jl\n",
      "########################################\n",
      "\n",
      "value(p::ElementPenalty, θ::Number, s::Number)       = s * value(p, θ)\n",
      "value(p::ElementPenalty, θ::AbstractArray{<:Number})            = sum(x -> value(p, x), θ)\n",
      "value(p::ElementPenalty, θ::AbstractArray{<:Number}, s::Number) = sum(x -> value(p, x, s), θ)\n",
      "function value(p::ElementPenalty, θ::AbstractArray{T}, s::AbstractArray{S}) where {T <: Number, S <: Number}\n",
      "    size(θ) == size(s) || error(\"lengths of parameter/weights do not match\")\n",
      "    result = zero(value(p, first(θ), first(s)))\n",
      "    @inbounds for i in eachindex(θ, s)\n",
      "        result += value(p, θ[i], s[i])\n",
      "    end\n",
      "    result\n",
      "end\n",
      "\n",
      "prox!(p::ProxableElementPenalty, θ::AbstractArray{<:Number}, s::Number) = map!(θj -> prox(p, θj, s), θ, θ)\n",
      "function prox!(p::ProxableElementPenalty, θ::AbstractArray{<:Number}, s::AbstractArray{<:Number})\n",
      "    @assert size(θ) == size(s)\n",
      "    @inbounds for i in eachindex(θ, s)\n",
      "        θ[i] = prox(p, θ[i], s[i])\n",
      "    end\n",
      "    θ\n",
      "end\n",
      "prox(p::ProxableElementPenalty, θ::AbstractArray{<:Number}, s::Number)       = prox!(p, copy(θ), s)\n",
      "prox(p::ProxableElementPenalty, θ::AbstractArray{<:Number}, s::AbstractArray{<:Number}) = prox!(p, copy(θ), s)\n",
      "\n",
      "deriv(p::ElementPenalty, θ::Number, s::Number) = s * deriv(p, θ)\n",
      "grad(p::ElementPenalty, θ::AbstractArray{<:Number}) = grad!(similar(θ), p, θ)\n",
      "function grad(p::ElementPenalty, θ::AbstractArray{T}, s::S) where {T<:Number, S<:Number}\n",
      "    grad!(similar(θ, float(promote_type(T, S))), p, θ, s)\n",
      "end\n",
      "function grad(p::ElementPenalty, θ::AbstractArray{T}, s::AbstractArray{S}) where {T<:Number, S<:Number}\n",
      "    grad!(similar(θ, float(promote_type(T, S))), p, θ, s)\n",
      "end\n",
      "function grad!(storage::AbstractArray{<:Number}, p::ElementPenalty, θ::AbstractArray{<:Number})\n",
      "    map!(x -> deriv(p, x), storage, θ)\n",
      "end\n",
      "function grad!(storage::AbstractArray{<:Number}, p::ElementPenalty, θ::AbstractArray{<:Number}, s::Number)\n",
      "    map!(x -> deriv(p, x, s), storage, θ)\n",
      "end\n",
      "function grad!(storage::AbstractArray{<:Number}, p::ElementPenalty, θ::AbstractArray{<:Number}, s::AbstractArray{<:Number})\n",
      "    @assert size(storage) == size(θ) == size(s)\n",
      "    @inbounds for j in eachindex(θ, s)\n",
      "        storage[j] = deriv(p, θ[j], s[j])\n",
      "    end\n",
      "    storage\n",
      "end\n",
      "\n",
      "addgrad(∇j::Number, p::ElementPenalty, θj::Number) = ∇j + deriv(p, θj)\n",
      "addgrad(∇j::Number, p::ElementPenalty, θj::Number, s::Number) = ∇j + s * deriv(p, θj)\n",
      "function addgrad!(∇::AbstractArray{<:Number}, p::ElementPenalty, θ::AbstractArray{<:Number})\n",
      "    @assert size(∇) == size(θ)\n",
      "    @inbounds for j in eachindex(∇, θ)\n",
      "        ∇[j] = addgrad(∇[j], p, θ[j])\n",
      "    end\n",
      "    ∇\n",
      "end\n",
      "function addgrad!(∇::AbstractArray{<:Number}, p::ElementPenalty, θ::AbstractArray{<:Number}, s::Number)\n",
      "    @assert size(∇) == size(θ)\n",
      "    @inbounds for j in eachindex(∇, θ)\n",
      "        ∇[j] = addgrad(∇[j], p, θ[j], s)\n",
      "    end\n",
      "    ∇\n",
      "end\n",
      "function addgrad!(∇::AbstractArray{<:Number}, p::ElementPenalty, θ::AbstractArray{<:Number}, s::AbstractArray{<:Number})\n",
      "    @assert size(∇) == size(θ) == size(s)\n",
      "    @inbounds for j in eachindex(∇, θ, s)\n",
      "        ∇[j] = addgrad(∇[j], p, θ[j], s[j])\n",
      "    end\n",
      "    ∇\n",
      "end\n",
      "\n",
      "value(p::ArrayPenalty, A::AbstractArray{<:Number}, λ::Number) = λ * value(p, A)\n",
      "\n",
      "# --------------------\n",
      "# AVAILABLE PENALTIES\n",
      "# --------------------\n",
      "include(\"penalties/elementwise.jl\")\n",
      "include(\"penalties/arraywise.jl\")\n",
      "\n",
      "# common functions\n",
      "soft_thresh(x::Number, λ::Number) = sign(x) * max(zero(x), abs(x) - λ)\n",
      "\n",
      "function soft_thresh!(x::AbstractArray{<:Number}, λ::Number)\n",
      "    for i in eachindex(x)\n",
      "        @inbounds x[i] = soft_thresh(x[i], λ)\n",
      "    end\n",
      "    x\n",
      "end\n",
      "\n",
      "# make penalties callable\n",
      "for T in filter(!isabstracttype, union(subtypes(ElementPenalty), \n",
      "                                      subtypes(ProxableElementPenalty), \n",
      "                                      subtypes(ArrayPenalty)))\n",
      "    @eval (pen::$T)(args...) = value(pen, args...)\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  22\n",
      "matbesancon/ConstraintSolver.jl\n",
      "test/sudoku_tests.jl\n",
      "########################################\n",
      "\n",
      "@testset \"Sudoku\" begin\n",
      "\n",
      "@testset \"Sudoku from opensourc.es\" begin\n",
      "    grid = [0 2 1 0 7 9 0 8 5;\n",
      "            0 4 5 3 1 0 0 0 9;\n",
      "            0 7 0 0 4 0 0 1 0;\n",
      "            0 0 0 1 0 8 0 3 6;\n",
      "            0 6 0 0 0 0 2 0 8;\n",
      "            0 0 0 0 0 3 0 0 4;\n",
      "            6 0 8 0 0 0 0 0 0;\n",
      "            0 9 4 0 0 7 8 0 0;\n",
      "            2 0 0 5 0 0 0 4 0]\n",
      "\n",
      "    m = Model(with_optimizer(CS.Optimizer))\n",
      "    @variable(m, 1 <= x[1:9,1:9] <= 9, Int)\n",
      "    # set variables\n",
      "    for r=1:9, c=1:9\n",
      "        if grid[r,c] != 0\n",
      "            @constraint(m, x[r,c] == grid[r,c])\n",
      "        end\n",
      "    end\n",
      "    # sudoku constraints\n",
      "    jump_add_sudoku_constr!(m, x)\n",
      "\n",
      "    optimize!(m)\n",
      "    @test JuMP.termination_status(m) == MOI.OPTIMAL\n",
      "    @test jump_fulfills_sudoku_constr(JuMP.value.(x))\n",
      "end\n",
      "\n",
      "\n",
      "@testset \"Hard sudoku\" begin\n",
      "    com = CS.init()\n",
      "\n",
      "    grid = zeros(Int,(9,9))\n",
      "    grid[1,:] = [0 0 0 5 4 6 0 0 9]\n",
      "    grid[2,:] = [0 2 0 0 0 0 0 0 7]\n",
      "    grid[3,:] = [0 0 3 9 0 0 0 0 4]\n",
      "    grid[4,:] = [9 0 5 0 0 0 0 7 0]\n",
      "    grid[5,:] = [7 0 0 0 0 0 0 2 0]\n",
      "    grid[6,:] = [0 0 0 0 9 3 0 0 0]\n",
      "    grid[7,:] = [0 5 6 0 0 8 0 0 0]\n",
      "    grid[8,:] = [0 1 0 0 3 9 0 0 0]\n",
      "    grid[9,:] = [0 0 0 0 0 0 8 0 6]\n",
      "\n",
      "    com_grid = create_sudoku_grid!(com, grid)\n",
      "    add_sudoku_constr!(com, com_grid)\n",
      "\n",
      "    @test CS.solve!(com, CS.get_default_options()) == :Solved\n",
      "    @test fulfills_sudoku_constr(com_grid)\n",
      "end\n",
      "\n",
      "@testset \"Hard sudoku infeasible\" begin\n",
      "    grid = [0 0 0 5 4 6 0 0 9;\n",
      "            0 2 0 0 0 0 0 0 7;\n",
      "            0 0 3 9 0 0 0 0 4;\n",
      "            9 0 5 0 0 0 0 7 3;\n",
      "            7 0 0 0 0 0 0 2 0;\n",
      "            0 0 0 0 9 3 0 0 0;\n",
      "            0 5 6 0 0 8 0 0 0;\n",
      "            0 1 0 0 3 9 0 0 0;\n",
      "            0 0 0 0 0 0 8 0 6]\n",
      "\n",
      "    m = Model(with_optimizer(CS.Optimizer))\n",
      "    @variable(m, 1 <= x[1:9,1:9] <= 9, Int)\n",
      "    # set variables\n",
      "    for r=1:9, c=1:9\n",
      "        if grid[r,c] != 0\n",
      "            @constraint(m, x[r,c] == grid[r,c])\n",
      "        end\n",
      "    end\n",
      "    # sudoku constraints\n",
      "    jump_add_sudoku_constr!(m, x)\n",
      "\n",
      "    optimize!(m)\n",
      "    @test JuMP.termination_status(m) == MOI.INFEASIBLE\n",
      "    @test !jump_fulfills_sudoku_constr(JuMP.value.(x))\n",
      "end\n",
      "\n",
      "\n",
      "@testset \"Hard fsudoku repo\" begin\n",
      "    com = CS.init()\n",
      "\n",
      "    grid = zeros(Int,(9,9))\n",
      "    grid[1,:] = [0 0 0 0 0 0 0 0 0]\n",
      "    grid[2,:] = [0 1 0 6 2 0 0 9 0]\n",
      "    grid[3,:] = [0 0 2 0 0 9 3 1 0]\n",
      "    grid[4,:] = [0 0 4 0 0 6 0 8 0]\n",
      "    grid[5,:] = [0 0 8 7 0 2 1 0 0]\n",
      "    grid[6,:] = [0 3 0 8 0 0 5 0 0]\n",
      "    grid[7,:] = [0 6 9 1 0 0 4 0 0]\n",
      "    grid[8,:] = [0 8 0 0 7 3 0 5 0]\n",
      "    grid[9,:] = [0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "    m = Model(with_optimizer(CS.Optimizer))\n",
      "    @variable(m, 1 <= x[1:9,1:9] <= 9, Int)\n",
      "    # set variables\n",
      "    nvars_set = 0\n",
      "    for r=1:9, c=1:9\n",
      "        if grid[r,c] != 0\n",
      "            @constraint(m, x[r,c] == grid[r,c])\n",
      "            nvars_set += 1\n",
      "        end\n",
      "    end\n",
      "\n",
      "    @test nvars_set == length(filter(n -> n != 0, grid))\n",
      "\n",
      "    # sudoku constraints\n",
      "    jump_add_sudoku_constr!(m, x)\n",
      "\n",
      "    optimize!(m)\n",
      "\n",
      "    @test JuMP.termination_status(m) == MOI.OPTIMAL\n",
      "\n",
      "    # check that it actually solves the given sudoku\n",
      "    for r=1:9, c=1:9\n",
      "        if grid[r,c] != 0\n",
      "            @test JuMP.value(x[r,c]) == grid[r,c]\n",
      "        end\n",
      "    end\n",
      "\n",
      "    @test jump_fulfills_sudoku_constr(JuMP.value.(x))\n",
      "end\n",
      "\n",
      "@testset \"Hard fsudoku repo 0-8\" begin\n",
      "    com = CS.init()\n",
      "\n",
      "    grid = zeros(Int,(9,9))\n",
      "    grid[1,:] = [0 0 0 0 0 0 0 0 0]\n",
      "    grid[2,:] = [0 1 0 6 2 0 0 9 0]\n",
      "    grid[3,:] = [0 0 2 0 0 9 3 1 0]\n",
      "    grid[4,:] = [0 0 4 0 0 6 0 8 0]\n",
      "    grid[5,:] = [0 0 8 7 0 2 1 0 0]\n",
      "    grid[6,:] = [0 3 0 8 0 0 5 0 0]\n",
      "    grid[7,:] = [0 6 9 1 0 0 4 0 0]\n",
      "    grid[8,:] = [0 8 0 0 7 3 0 5 0]\n",
      "    grid[9,:] = [0 0 0 0 0 0 0 0 0]\n",
      "    grid .-= 1\n",
      "\n",
      "    com_grid = Array{CS.Variable, 2}(undef, 9, 9)\n",
      "    for (ind,val) in enumerate(grid)\n",
      "        if val == -1\n",
      "            if ind == 81 # bottom right\n",
      "                # some other values are possible there\n",
      "                com_grid[ind] = CS.add_var!(com, 9, 11)\n",
      "            elseif ind == 80 # one above (will be 9 in the end)\n",
      "                com_grid[ind] = CS.add_var!(com, 7, 11)\n",
      "            else\n",
      "                com_grid[ind] = CS.add_var!(com, 0, 8)\n",
      "            end\n",
      "        else\n",
      "            com_grid[ind] = CS.add_var!(com, 0, 8; fix=val)\n",
      "        end\n",
      "    end\n",
      "    \n",
      "    add_sudoku_constr!(com, com_grid)\n",
      "\n",
      "    @test CS.solve!(com, CS.get_default_options()) == :Solved\n",
      "    @test fulfills_sudoku_constr(com_grid)\n",
      "end\n",
      "\n",
      "@testset \"top95 some use backtracking\" begin\n",
      "    grids = sudokus_from_file(\"data/top95\")\n",
      "    c = 0\n",
      "    for grid in grids\n",
      "        m = Model(with_optimizer(CS.Optimizer))\n",
      "\n",
      "        @variable(m, 1 <= x[1:9,1:9] <= 9, Int)\n",
      "        # set variables\n",
      "        for r=1:9, c=1:9\n",
      "            if grid[r,c] != 0\n",
      "                @constraint(m, x[r,c] == grid[r,c])\n",
      "            end\n",
      "        end\n",
      "\n",
      "        # sudoku constraints\n",
      "        jump_add_sudoku_constr!(m, x)\n",
      "\n",
      "        optimize!(m)\n",
      "\n",
      "        @test JuMP.termination_status(m) == MOI.OPTIMAL\n",
      "        @test jump_fulfills_sudoku_constr(JuMP.value.(x))\n",
      "        c += 1\n",
      "    end\n",
      "    # check that actually all 95 problems were tested\n",
      "    @test c == 95\n",
      "end\n",
      "\n",
      "\n",
      "@testset \"Number 7 in top95.txt w/o backtracking\" begin\n",
      "    m = Model(with_optimizer(CS.Optimizer, backtrack=false))\n",
      "\n",
      "    grid = Int[6,0,2,0,5,0,0,0,0,0,0,0,0,0,3,0,4,0,0,0,0,0,0,0,0,0,0,4,3,0,0,0,8,0,\n",
      "              0,0,0,1,0,0,0,0,2,0,0,0,0,0,0,0,0,7,0,0,5,0,0,2,7,0,0,0,0,0,0,0,0,0,\n",
      "              0,0,8,1,0,0,0,6,0,0,0,0,0]\n",
      "    grid = transpose(reshape(grid, (9,9)))\n",
      "\n",
      "    @variable(m, 1 <= x[1:9,1:9] <= 9, Int)\n",
      "    # set variables\n",
      "    for r=1:9, c=1:9\n",
      "        if grid[r,c] != 0\n",
      "            @constraint(m, x[r,c] == grid[r,c])\n",
      "        end\n",
      "    end\n",
      "\n",
      "    # sudoku constraints\n",
      "    jump_add_sudoku_constr!(m, x)\n",
      "\n",
      "    optimize!(m)\n",
      "\n",
      "    com = JuMP.backend(m).optimizer.model.inner\n",
      "    @test JuMP.termination_status(m) == MOI.OTHER_LIMIT\n",
      "\n",
      "    @test !com.info.backtracked\n",
      "    @test com.info.backtrack_fixes == 0\n",
      "    @test com.info.in_backtrack_calls == 0\n",
      "    @show com.info\n",
      "end\n",
      "\n",
      "\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  23\n",
      "UnofficialJuliaMirror/EmpiricalRiskMinimization.jl-9b2d3710-960f-59cf-86c2-f38aa34c807a\n",
      "misc/old-src/embeddings.jl\n",
      "########################################\n",
      "\n",
      "\n",
      "\n",
      "##############################################################################\n",
      "\n",
      "abstract type Embedding end\n",
      "\n",
      "##############################################################################\n",
      "# Embeddings\n",
      "\n",
      "\n",
      "mutable struct Standardize<:Embedding\n",
      "    mean\n",
      "    std\n",
      "    used::Bool\n",
      "end\n",
      "\n",
      "##############################################################################\n",
      "# generic embedding\n",
      "\n",
      "mutable struct FunctionEmbedding <: Embedding\n",
      "    f\n",
      "end\n",
      "\n",
      "function embed(e::FunctionEmbedding, u::Array{Float64,1})\n",
      "    x = u\n",
      "end\n",
      "\n",
      "\n",
      "##############################################################################\n",
      "# standardize\n",
      "\n",
      "function Standardize()\n",
      "    return Standardize(0,0,false)\n",
      "end\n",
      "\n",
      "#\n",
      "# embeddings operate on matrices 1 row at a time\n",
      "# (for some embeddings, like standardize, the results depend\n",
      "#  on all the entries)\n",
      "#\n",
      "function embed(e::Standardize, u::Array{Float64,1})\n",
      "    if !e.used\n",
      "        error(\"cannot standardize single data point\")\n",
      "    end\n",
      "    x = (u - e.mean[:])./(e.std[:])\n",
      "end\n",
      "\n",
      "function unembed(e::Standardize, x::Array{Float64,1})\n",
      "    if !e.used\n",
      "        error(\"cannot standardize single data point\")\n",
      "    end\n",
      "    return  x.*e.std + e.mean\n",
      "end\n",
      "\n",
      "function embed(e::Standardize, U::Array{Float64,2})\n",
      "    n = size(U,1)\n",
      "    if !e.used\n",
      "        e.mean = mean(U,1)\n",
      "        e.std = std(U,1)\n",
      "        e.used = true\n",
      "    end\n",
      "    return rowwise(u->embed(e,u), U)\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "##############################################################################\n",
      "\n",
      "struct IdentityEmbed<:Embedding end\n",
      "embed(e::IdentityEmbed, u::Array{Float64,1}) = u\n",
      "unembed(e::IdentityEmbed, u::Array{Float64,1}) = u\n",
      "\n",
      "##############################################################################\n",
      "# polyembed\n",
      "\n",
      "\n",
      "\n",
      "mutable struct PolyEmbed<:Embedding\n",
      "    degree\n",
      "end\n",
      "\n",
      "function embed(e::PolyEmbed, u::Array{Float64,1})\n",
      "    d = length(u)\n",
      "    if d != 1\n",
      "        println(\"Error: PolyEmbed only operates on scalars\")\n",
      "    end\n",
      "    x = zeros(e.degree+1)\n",
      "    for j=0:e.degree\n",
      "        x[j+1] = u[1]^j\n",
      "    end\n",
      "    return x\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "mutable struct PiecewiseEmbed<:Embedding\n",
      "    knot\n",
      "end\n",
      "\n",
      "# this is a neat trick for allowing many knots\n",
      "# we embed by appending a new feature\n",
      "# TODO: we need a better API for this\n",
      "#\n",
      "# embeddings can be pointwise or not\n",
      "# can take inputs which are x or u\n",
      "# can append their output to the input or replace the input\n",
      "#\n",
      "function embed(e::PiecewiseEmbed, u::Array{Float64,1})\n",
      "    n = length(u)\n",
      "    x = zeros(n+1)\n",
      "    x[1:n] = u\n",
      "    x[n+1] = max(u[1]-e.knot,0)\n",
      "    return x\n",
      "end\n",
      "\n",
      "##############################################################################\n",
      "type AppendOneEmbed<:Embedding end\n",
      "\n",
      "function embed(e::AppendOneEmbed, x::Array{Float64,1})\n",
      "    return matrix([1 x'])\n",
      "end\n",
      "\n",
      "\n",
      "##############################################################################\n",
      "# apply embeddings\n",
      "\n",
      "# allow embeddings to be defined either on the whole dataset\n",
      "# or per-record\n",
      "# preferentially apply whole dataset embedding if available\n",
      "function oneembedding(e, U::Array{Float64,2})\n",
      "    # if there is a method embedding the whole dataset\n",
      "    if method_exists(embed, (typeof(e), Array{Float64,2}))\n",
      "        return embed(e, U)\n",
      "    end\n",
      "    # otherwise do one row at a time\n",
      "    return rowwise(u->embed(e, u), U)\n",
      "end\n",
      "\n",
      "oneembedding(e, u::Array{Float64,1}) = embed(e,u)\n",
      "\n",
      "# apply list of embeddings from right to left\n",
      "function embed(E::Array, z)\n",
      "    ne = length(E)\n",
      "    for i=ne:-1:1\n",
      "        z = oneembedding(E[i], z)\n",
      "    end\n",
      "    return z\n",
      "end\n",
      "\n",
      "##############################################################################\n",
      "# apply unembeddings\n",
      "\n",
      "function oneunembedding(e, U::Array{Float64,2})\n",
      "    # if there is a method embedding the whole dataset\n",
      "    if method_exists(unembed, (typeof(e), Array{Float64,2}))\n",
      "        return unembed(e, U)\n",
      "    end\n",
      "    # otherwise do one row at a time\n",
      "    return rowwise(u->unembed(e, u), U)\n",
      "end\n",
      "\n",
      "oneunembedding(e, u::Array{Float64,1}) = unembed(e,u)\n",
      "\n",
      "function unembed(E::Array, z)\n",
      "    ne = length(E)\n",
      "    for i=1:ne\n",
      "        z = oneunembedding(E[i], z)\n",
      "    end\n",
      "    return z\n",
      "end\n",
      "\n",
      "##############################################################################\n",
      "# interface\n",
      "\n",
      "\n",
      "##############################################################################\n",
      "\n",
      "mutable struct SimpleSource<:DataSource\n",
      "    U\n",
      "    V\n",
      "    Xembed\n",
      "    Yembed\n",
      "\n",
      "    function SimpleSource(U, V, Xembed, Yembed)\n",
      "        if Xembed == false\n",
      "            Xembed = [AppendOneEmbed(), Standardize()]\n",
      "        end\n",
      "        if Yembed == false\n",
      "        Yembed = [Standardize()]\n",
      "        end\n",
      "        return new(matrix(U), matrix(V), Xembed, Yembed)\n",
      "    end\n",
      "end\n",
      "\n",
      "\n",
      "function getXY(S::SimpleSource)\n",
      "    hasconstfeature = false\n",
      "    if isa(S.Xembed[1], AppendOneEmbed)\n",
      "        hasconstfeature = true\n",
      "    end\n",
      "    Y = embed(S.Yembed, S.V)\n",
      "    X = embed(S.Xembed, S.U)\n",
      "    return X, Y, hasconstfeature\n",
      "end\n",
      "\n",
      "getU(S::SimpleSource) = S.U\n",
      "getV(S::SimpleSource) = S.V\n",
      "\n",
      "# embed one data record\n",
      "embedU(S::SimpleSource, u::Array{Float64,1}) = embed(S.Xembed, u)\n",
      "\n",
      "# unembed one or many targets\n",
      "unembedY(S::SimpleSource, y) = unembed(S.Yembed, y)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  24\n",
      "cscherrer/BayesianLinearRegression.jl\n",
      "src/example2.jl\n",
      "########################################\n",
      "\n",
      "using BayesianLinearRegression\n",
      "\n",
      "X = randn(100, 80);\n",
      "β = randn(50);\n",
      "y = X[:,1:50] * β + randn(100);\n",
      "\n",
      "\n",
      "@time m = BayesianLinReg(X,y);\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "@time fit!(m);\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "logEvidence(m)\n",
      "\n",
      "effectiveNumParameters(m)\n",
      "\n",
      "priorScale(m)\n",
      "noiseScale(m)\n",
      "\n",
      "posteriorWeights(m)\n",
      "posteriorVariance(m)\n",
      "\n",
      "predict(m,X[:,m.active])\n",
      "\n",
      "function getpath!(m)\n",
      "    path = Pair{Int, Float64}[]\n",
      "    while length(m.active) > 1\n",
      "        bestj = 0\n",
      "        bestlogEv = -Inf\n",
      "        activebase = m.active\n",
      "        for j in activebase\n",
      "            m.active = setdiff(activebase, j)\n",
      "            update!(m)\n",
      "            fit!(m)\n",
      "\n",
      "            thislogEv = logEvidence(m)\n",
      "            if thislogEv > bestlogEv\n",
      "                bestj = j\n",
      "                bestlogEv = thislogEv\n",
      "            end\n",
      "        end\n",
      "\n",
      "        push!(path, bestj => bestlogEv)\n",
      "        println(\"removing \", bestj)\n",
      "        m.active = setdiff(activebase, bestj)\n",
      "    end\n",
      "    return path\n",
      "end\n",
      "\n",
      "path = getpath!(m)\n",
      "\n",
      "logEvs = [getproperty(p,:second) for p in path]\n",
      "\n",
      "plot(logEvs)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "effectiveNumParameters(m)\n",
      "\n",
      "priorScale(m)\n",
      "noiseScale(m)\n",
      "\n",
      "posteriorWeights(m)\n",
      "posteriorVariance(m)\n",
      "\n",
      "predict(m,view(m.X, :, m.active))\n",
      "\n",
      "\n",
      "function f(n)\n",
      "    m = BayesianLinReg(X[:,1:n],y)\n",
      "    fit!(m; callback=stopAtIteration(10))\n",
      "    return m\n",
      "end;\n",
      "\n",
      "ms = f.(1:100);\n",
      "\n",
      "argmax(logEvidence.(ms))\n",
      "m = ms[49];\n",
      "\n",
      "\n",
      "effectiveNumParameters(m)\n",
      "\n",
      "priorScale(m)\n",
      "noiseScale(m)\n",
      "\n",
      "posteriorWeights(m)\n",
      "posteriorVariance(m)\n",
      "\n",
      "predict(m,m.X)\n",
      "\n",
      "using Plots\n",
      "using Statistics\n",
      "\n",
      "logevs = logEvidence.(ms)\n",
      "\n",
      "plot(3:100,logevs[3:100], legend=false)\n",
      "xlabel!(\"Number of features used\")\n",
      "ylabel!(\"Log Evidence\")\n",
      "\n",
      "m = BayesianLinReg(X[:,1:50],y)\n",
      "fit!(m; callback=stopAtIteration(10))\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  25\n",
      "JuliaTagBot/ParticleScattering.jl\n",
      "test/minimum_N_P_test.jl\n",
      "########################################\n",
      "\n",
      "#compare to precomputed values\n",
      "k0 = 0.3\n",
      "kin = 0.5k0\n",
      "tols = [1e-9;\n",
      "        1e-7;\n",
      "        1e-5]\n",
      "N_res = [250;\n",
      "         100;\n",
      "         313]\n",
      "\n",
      "@testset \"minimum N\" begin\n",
      "    shape_funs =   [N -> squircle(1, N);\n",
      "                    N -> rounded_star(0.08, 0.02, 3, N);\n",
      "                    N -> rounded_star(25, 5, 5, N)]\n",
      "\n",
      "    for (i,f) in enumerate(shape_funs)\n",
      "        N, err = minimumN(k0, kin, f; tol = tols[i], N_points = 20_000,\n",
      "                    N_start = 250, N_min = 100, N_max = 400)\n",
      "        @test N == N_res[i] && err <= tols[i]\n",
      "    end\n",
      "end\n",
      "\n",
      "P_res = [13;\n",
      "         9;\n",
      "         34]\n",
      "dists = [2.0;\n",
      "    \t 2.0;\n",
      "         1.0]\n",
      "@testset \"minimum P\" begin\n",
      "    shapes = [squircle(1, N_res[1]);\n",
      "                rounded_star(0.08, 0.02, 3, N_res[2]);\n",
      "                rounded_star(25, 5, 5, N_res[3])]\n",
      "\n",
      "    for i in eachindex(shapes)\n",
      "        P, err = minimumP(k0, kin, shapes[i]; tol = tols[i], N_points = 20_000,\n",
      "                    P_min = 1, P_max = 60, dist = dists[i])\n",
      "        @test P == P_res[i] && err <= tols[i]\n",
      "    end\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  26\n",
      "noob-data-analaysis/LeetCode.jl\n",
      "src/unresolved/1530.number-of-good-leaf-nodes-pairs.jl\n",
      "########################################\n",
      "\n",
      "# ---\n",
      "# title: 1530. Number of Good Leaf Nodes Pairs\n",
      "# id: problem1530\n",
      "# author: Tian Jun\n",
      "# date: 2020-10-31\n",
      "# difficulty: Medium\n",
      "# categories: Tree, Depth-first Search\n",
      "# link: <https://leetcode.com/problems/number-of-good-leaf-nodes-pairs/description/>\n",
      "# hidden: true\n",
      "# ---\n",
      "# \n",
      "# Given the `root` of a binary tree and an integer `distance`. A pair of two\n",
      "# different **leaf** nodes of a binary tree is said to be good if the length of\n",
      "# **the shortest path** between them is less than or equal to `distance`.\n",
      "# \n",
      "# Return _the number of good leaf node pairs_ in the tree.\n",
      "# \n",
      "# \n",
      "# \n",
      "# **Example 1:**\n",
      "# \n",
      "# ![](https://assets.leetcode.com/uploads/2020/07/09/e1.jpg)\n",
      "# \n",
      "#     \n",
      "#     \n",
      "#     Input: root = [1,2,3,null,4], distance = 3\n",
      "#     Output: 1\n",
      "#     Explanation: The leaf nodes of the tree are 3 and 4 and the length of the shortest path between them is 3. This is the only good pair.\n",
      "#     \n",
      "# \n",
      "# **Example 2:**\n",
      "# \n",
      "# ![](https://assets.leetcode.com/uploads/2020/07/09/e2.jpg)\n",
      "# \n",
      "#     \n",
      "#     \n",
      "#     Input: root = [1,2,3,4,5,6,7], distance = 3\n",
      "#     Output: 2\n",
      "#     Explanation: The good pairs are [4,5] and [6,7] with shortest path = 2. The pair [4,6] is not good because the length of ther shortest path between them is 4.\n",
      "#     \n",
      "# \n",
      "# **Example 3:**\n",
      "# \n",
      "#     \n",
      "#     \n",
      "#     Input: root = [7,1,4,6,null,5,3,null,null,null,null,null,2], distance = 3\n",
      "#     Output: 1\n",
      "#     Explanation: The only good pair is [2,5].\n",
      "#     \n",
      "# \n",
      "# **Example 4:**\n",
      "# \n",
      "#     \n",
      "#     \n",
      "#     Input: root = [100], distance = 1\n",
      "#     Output: 0\n",
      "#     \n",
      "# \n",
      "# **Example 5:**\n",
      "# \n",
      "#     \n",
      "#     \n",
      "#     Input: root = [1,1,1], distance = 2\n",
      "#     Output: 1\n",
      "#     \n",
      "# \n",
      "# \n",
      "# \n",
      "# **Constraints:**\n",
      "# \n",
      "#   * The number of nodes in the `tree` is in the range `[1, 2^10].`\n",
      "#   * Each node's value is between `[1, 100]`.\n",
      "#   * `1 <= distance <= 10`\n",
      "# \n",
      "# \n",
      "## @lc code=start\n",
      "using LeetCode\n",
      "\n",
      "## add your code here:\n",
      "## @lc code=end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  27\n",
      "djsegal/Boot.jl\n",
      "test/packages/DocumentedCode/src/organized_folder/j_func.jl\n",
      "########################################\n",
      "\n",
      "\"\"\"\n",
      "    j_func()\n",
      "\n",
      "Lorem ipsum dolor sit amet.\n",
      "\"\"\"\n",
      "function j_func()\n",
      "  \"R\"\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    j_func(cur_obj::AType)\n",
      "\n",
      "Lorem ipsum dolor sit amet.\n",
      "\"\"\"\n",
      "function j_func(cur_obj::AType)\n",
      "  \"G\"\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    j_func(cur_obj::MType)\n",
      "\n",
      "Lorem ipsum dolor sit amet.\n",
      "\"\"\"\n",
      "function j_func(cur_obj::MType)\n",
      "  \"B\"\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  28\n",
      "patrickboehnke/ProductizeBayes.jl\n",
      "src/ProductizeBayes.jl\n",
      "########################################\n",
      "\n",
      "module ProductizeBayes\n",
      "\n",
      "import SHA\n",
      "import StanSample\n",
      "\n",
      "include(\"versionmodels/VersionedModel.jl\")\n",
      "include(\"versionmodels/VersionedFile.jl\")\n",
      "\n",
      "\n",
      "export VersionedModel,\n",
      "        stan_sample,\n",
      "        read_samples,\n",
      "        read_summary,\n",
      "        stan_summary,\n",
      "        stan_generate_quantities,\n",
      "        read_generated_quantities,\n",
      "        diagnose\n",
      "end # module\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  29\n",
      "mossr/POMDPGym.jl\n",
      "src/extra/sequence_mdp.jl\n",
      "########################################\n",
      "\n",
      "@with_kw mutable struct SequenceMDP{S, A} <: MDP{S,A}\n",
      "    mdps::Array{MDP{S,A}, 1} # Sequence of mdps to play\n",
      "    Ns::Array{Int} # Number of experience samples for each mdp before switching to the next one\n",
      "    count::Int = 0 # current count of the gen function\n",
      "end\n",
      "\n",
      "function get_index(Ns, count)\n",
      "    Nsum = cumsum(Ns)\n",
      "    loc = count % Nsum[end]\n",
      "    i = findfirst(loc .< Nsum)\n",
      "end\n",
      "\n",
      "function curr(mdps::SequenceMDP)\n",
      "    mdps.mdps[get_index(mdps.Ns, mdps.count)]\n",
      "end\n",
      "\n",
      "POMDPs.initialstate(mdp::SequenceMDP) = initialstate(curr(mdp))\n",
      "POMDPs.isterminal(mdp::SequenceMDP, s) = isterminal(curr(mdp), s)\n",
      "POMDPs.discount(mdp::SequenceMDP) = discount(curr(mdp))\n",
      "function POMDPs.gen(mdp::SequenceMDP, s, a, args...; kwargs...)\n",
      "    mdp.count += 1\n",
      "    gen(curr(mdp), s, a, args...; kwargs...)\n",
      "end\n",
      "render(mdp::SequenceMDP, args...; kwargs...) = render(curr(mdp), args...; kwargs...)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  30\n",
      "mkualquiera/huepl\n",
      "code/solvers/greedy.jl\n",
      "########################################\n",
      "\n",
      "\n",
      "include(\"../psmsdst.jl\")\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "    solvegreedy(problem)\n",
      "\n",
      "Solves the given PSMSDST problem using a greedy heuristic: for every pair (j,m)\n",
      "of available jobs and machines, the pair that produces the lowest increment \n",
      "in the objective function is programmed, until a complete solution is reached.\n",
      "\"\"\"\n",
      "function solvegreedy(problem::PSMSDSTProblem)::Vector{Vector{Int}}\n",
      "\n",
      "    machines = 1:problem.nummachines\n",
      "    \n",
      "    # Create resulting vector for the solution\n",
      "    solution = [ Vector{Int}() for machineid in machines ] \n",
      "\n",
      "    # Create a set for the jobs that have not been programmed yet\n",
      "    availablejobs = Set{Int}(1:problem.numjobs)\n",
      "\n",
      "    # Create a vector for the finish times of each machine\n",
      "    machinefinishtimes = [ 0 for machineid in machines ]\n",
      "\n",
      "    # Variable that holds the current objective function\n",
      "    currentmaxfinishtime = maximum(machinefinishtimes)\n",
      "\n",
      "    # Matrix that contains how the machine finish time would increase when\n",
      "    # a job is programmed on it.\n",
      "    delays = [ problem.durations[job] for job in 1:problem.numjobs, \n",
      "                machine in machines ]\n",
      "\n",
      "    # Matrix that indicates if programming a job on a machine would invalidate\n",
      "    # the pre-calculated delay.\n",
      "    createsdelayupdate = [ true for job in 1:problem.numjobs, \n",
      "        machine in machines ]\n",
      "\n",
      "    # The id of the machine that will be updated because the cached delays\n",
      "    # where invalidated.\n",
      "    updatedelays = 0\n",
      "\n",
      "    # Program jobs until a complete solution is reached\n",
      "    while !isempty(availablejobs)\n",
      "\n",
      "        # Cartesian product, (j,m) pairs of jobs and machines.\n",
      "        options = Iterators.product(availablejobs,machines)\n",
      "\n",
      "        if updatedelays > 0\n",
      "            # The delays of a machine need to be recalculated.\n",
      "            machine = updatedelays\n",
      "            for job in availablejobs\n",
      "\n",
      "                # The initial delay is just the duration of the job\n",
      "                delay = problem.durations[job]\n",
      "\n",
      "                if length(solution[machine]) > 0\n",
      "                    lastjob = solution[machine][end]\n",
      "                    lastfamily = problem.families[lastjob]\n",
      "                    thisfamily = problem.families[job]\n",
      "\n",
      "                    # If the family of the next job is different to the\n",
      "                    # family of this job, this means that all the delays are\n",
      "                    # invalidated because the setup times will change. \n",
      "                    createsdelayupdate[job,machine] = thisfamily != lastfamily\n",
      "\n",
      "                    # Add the setup time to the delay\n",
      "                    delay += problem.setuptimes[lastfamily,thisfamily]\n",
      "                end\n",
      "\n",
      "                delays[job,machine] = delay\n",
      "            end    \n",
      "        end\n",
      "\n",
      "        # Look for the best option\n",
      "        bestoption = nothing\n",
      "        bestcost = typemax(Int64)\n",
      "\n",
      "        for (job,machine) in options\n",
      "            # Finish time of the machine if the job was programmed on it.\n",
      "            virtualmachinefinish = (machinefinishtimes[machine]\n",
      "                +delays[job,machine])\n",
      "            \n",
      "            # Objective function if the job was programmed on it.\n",
      "            cost = max(currentmaxfinishtime,virtualmachinefinish)\n",
      "\n",
      "            if cost < bestcost\n",
      "                bestoption = (job,machine,virtualmachinefinish,\n",
      "                    createsdelayupdate[job,machine])\n",
      "                bestcost = cost\n",
      "            end\n",
      "        end\n",
      "\n",
      "        job,machine,finishtime,createsupdate = bestoption\n",
      "\n",
      "        # If the job creates an update in the delays, they have to be \n",
      "        # re-calculated in the next iteration.\n",
      "        if createsupdate\n",
      "            updatedelays = machine\n",
      "        else\n",
      "            updatedelays = 0 \n",
      "        end\n",
      "\n",
      "        machinefinishtimes[machine] = finishtime\n",
      "\n",
      "        currentmaxfinishtime = maximum(machinefinishtimes)\n",
      "        push!(solution[machine],job)\n",
      "        delete!(availablejobs,job)\n",
      "    end\n",
      "\n",
      "    return solution\n",
      "end\n",
      "\n",
      "#\n",
      "#    getsolver()\n",
      "#\n",
      "#Returns a pair containing the name of the solver, and a pre-parameterized \n",
      "#function that only takes the problem as argument. \n",
      "#\n",
      "#Internally it also solves a small problem using the solver, ensuring that\n",
      "#the code for the solver is compiled ahead of time and there is no reduced\n",
      "#performance during evaluation.\n",
      "#\n",
      "## Examples\n",
      "#```julia-repl\n",
      "#julia> include(\"solvers/solver.jl\")(param1=42.0,param2=64.0)\n",
      "#\"Solver param1=42 param2=64\"=>#1 (generic function with 1 method)\n",
      "#```\n",
      "\n",
      "function getsolver()::Pair{String,Function}\n",
      "    solver = problem -> solvegreedy(problem)\n",
      "\n",
      "    presolve(solver)\n",
      "\n",
      "    return \"Greedy\"=>solver\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  31\n",
      "jagot/AtomicLevels.jl\n",
      "test/jj_terms.jl\n",
      "########################################\n",
      "\n",
      "@testset \"JJ terms\" begin\n",
      "    @testset \"_terms_jw\" begin\n",
      "        function terms_reference(j::HalfInteger, w::Integer)\n",
      "            w <= 2j+1 || throw(ArgumentError(\"w=$w too large for $orb orbital\"))\n",
      "\n",
      "            2w ≥ 2j+1 && (w = convert(Int, 2j) + 1 - w)\n",
      "            w == 0 && return [zero(HalfInt)]\n",
      "            w == 1 && return [j]\n",
      "\n",
      "            # Forms full Cartesian product of all mⱼ, not necessarily the most\n",
      "            # performant method.\n",
      "            mⱼs = filter(allunique, collect(AtomicLevels.allchoices([-j:j for i = 1:w])))\n",
      "            MJs = map(x -> reduce(+, x), mⱼs) # TODO: make map(sum, mⱼs) work\n",
      "\n",
      "            Js = HalfInt[]\n",
      "\n",
      "            while !isempty(MJs)\n",
      "                # Identify the maximum MJ and associate it with J.\n",
      "                MJmax = maximum(MJs)\n",
      "                N = count(isequal(MJmax), MJs)\n",
      "                append!(Js, repeat([MJmax], N))\n",
      "                # Remove the -MJ:MJ series, N times.\n",
      "                for MJ = -MJmax:MJmax\n",
      "                    deleteat!(MJs, findall(isequal(MJ), MJs)[1:N])\n",
      "                end\n",
      "            end\n",
      "\n",
      "            # Do we really want unique here?\n",
      "            sort(unique(Js))\n",
      "        end\n",
      "\n",
      "        for twoj = 0:10, w = 1:twoj+1\n",
      "            j = HalfInteger(twoj//2)\n",
      "            ts = AtomicLevels._terms_jw(j, w)\n",
      "\n",
      "            @test issorted(ts, rev=true) # make sure that the array is sorted in descending order\n",
      "            @test terms_reference(j, w) == sort(unique(ts))\n",
      "            # Check particle-hole symmetry\n",
      "            if w != twoj + 1\n",
      "                @test AtomicLevels._terms_jw(j, twoj+1-w) == ts\n",
      "            end\n",
      "        end\n",
      "    end\n",
      "\n",
      "    @testset \"jj coupling of equivalent electrons\" begin\n",
      "        @test terms(ro\"1s\", 0) == [0]\n",
      "        @test terms(ro\"1s\", 1) == [1//2]\n",
      "        @test terms(ro\"1s\", 2) == [0]\n",
      "\n",
      "        @test terms(ro\"3d-\", 0) == [0]\n",
      "        @test terms(ro\"3d-\", 1) == [3//2]\n",
      "        @test terms(ro\"3d-\", 4) == [0]\n",
      "\n",
      "        @test terms(ro\"Xd\", 0) == [0]\n",
      "        @test terms(ro\"Xd\", 1) == [5//2]\n",
      "        @test terms(ro\"Xd\", 6) == [0]\n",
      "\n",
      "        # Table 4.5, Cowan 1981\n",
      "        foreach([\n",
      "            (ro\"1s\",ro\"2p-\") => [(0,2) => 0, 1 => 1//2],\n",
      "            (ro\"2p\",ro\"3d-\") => [(0,4) => 0, (1,3) => 3//2, 2 => [0,2]],\n",
      "            (ro\"3d\",ro\"4f-\") => [(0,6) => 0, (1,5) => 5//2, (2,4) => [0,2,4],\n",
      "                                 3 => [3//2,5//2,9//2]],\n",
      "            (ro\"4f\",ro\"5g-\") => [(0,8) => 0, (1,7) => 7//2, (2,6) => [0,2,4,6],\n",
      "                                 (3,5) => [3//2,5//2,7//2,9//2,11/2,15//2],\n",
      "                                 4 => [0,2,2,4,4,5,6,8]],\n",
      "            (ro\"5g\",ro\"6h-\") => [(0,10) => 0, (1,9) => 9//2, (2,8) => [0,2,4,6,8],\n",
      "                                 (3,7) => [3//2,5//2,7//2,9//2,9//2,11//2,13//2,15//2,17//2,21//2],\n",
      "                                 (4,6) => [0,0,2,2,3,4,4,4,5,6,6,6,7,8,8,9,10,12],\n",
      "                                 5 => [1//2,3//2,5//2,5//2,7//2,7//2,9//2,9//2,9//2,11//2,11//2,13//2,13//2,15//2,15//2,17//2,17//2,19//2,21//2,25//2]]\n",
      "        ]) do (orbs,wsj)\n",
      "            foreach(orbs) do orb\n",
      "                foreach(wsj) do (ws,j)\n",
      "                    js = map(HalfInteger, isa(j, Number) ? [j] : j)\n",
      "                    foreach(ws) do w\n",
      "                        @test terms(orb,w) == js\n",
      "                    end\n",
      "                end\n",
      "            end\n",
      "        end\n",
      "    end\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  32\n",
      "tmcgrath325/GOGMA.jl\n",
      "src/transformation.jl\n",
      "########################################\n",
      "\n",
      "# Extend rotation and transformation methods from Rotations and CoordinateTransformations\n",
      "\n",
      "function Rotations.AngleAxis(rx, ry, rz) \n",
      "    # Note: promoting with Float64 here in order to avoid strange behavior when passing AngleAxis{Int} to AffineMap()\n",
      "    #       I don't think this is a big deal, since the only time a RotMatrix{Int} will be valid is for the identity matrix\n",
      "    t = promote_type(typeof(rx), typeof(ry), typeof(rz), Float64)\n",
      "    theta = √(rx^2+ry^2+rz^2)\n",
      "    return theta == 0 ? AngleAxis(zero(t),one(t),zero(t),zero(t)) : AngleAxis(theta, rx, ry, rz)\n",
      "end\n",
      "\n",
      "function rot_to_axis(R)\n",
      "    aa = AngleAxis(R)\n",
      "    return aa.theta.*(aa.axis_x, aa.axis_y, aa.axis_z)\n",
      "end\n",
      "\n",
      "function affinemap_to_params(tform::AffineMap)\n",
      "    return (rot_to_axis(tform.linear)..., tform.translation)\n",
      "end\n",
      "\n",
      "CoordinateTransformations.LinearMap(rx,ry,rz) = CoordinateTransformations.LinearMap(AngleAxis(rx,ry,rz))\n",
      "CoordinateTransformations.AffineMap(rx,ry,rz,tx,ty,tz) = CoordinateTransformations.AffineMap(AngleAxis(rx,ry,rz), SVector(tx,ty,tz))\n",
      "\n",
      "# There is some concern about the inferability of the functions below. Using Test.@inferred did not throw any errors\n",
      "\n",
      "function (tform::AffineMap)(x::AbstractIsotropicGaussian)\n",
      "    T = typeof(x)\n",
      "    otherfields = [getfield(x,fname) for fname in fieldnames(typeof(x))][5:end] # first 3 fields must be `μ`, `σ`, `ϕ`, and `dirs`\n",
      "    return T.name.wrapper(tform(x.μ), x.σ, x.ϕ, [tform.linear*dir for dir in x.dirs], otherfields...)\n",
      "end\n",
      "\n",
      "function (tform::AffineMap)(x::AbstractIsotropicGMM)\n",
      "    T = typeof(x)\n",
      "    otherfields = [getfield(x,fname) for fname in fieldnames(typeof(x))][2:end] # first field must be `gaussians`\n",
      "    return T.name.wrapper([tform(g) for g in x.gaussians], otherfields...)\n",
      "end\n",
      "\n",
      "function (tform::AffineMap)(x::AbstractIsotropicMultiGMM)\n",
      "    T = typeof(x)\n",
      "    otherfields = [getfield(x,fname) for fname in fieldnames(typeof(x))][2:end] # first field must be `gmms`\n",
      "    tformgmms = [tform(x.gmms[key]) for key in keys(x.gmms)]\n",
      "    gmmdict = Dict{eltype(keys(x.gmms)),eltype(tformgmms)}()\n",
      "    for (i,key) in enumerate(keys(x.gmms))\n",
      "        push!(gmmdict, key=>tformgmms[i])\n",
      "    end\n",
      "    return T.name.wrapper(gmmdict, otherfields...)\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  33\n",
      "proteanblank/model-zoo\n",
      "other/housing/housing.jl\n",
      "########################################\n",
      "\n",
      "# # Housing data\n",
      "\n",
      "# In this example, we create a linear regression model that predicts housing data. \n",
      "# It replicates the housing data example from the [Knet.jl readme](https://github.com/denizyuret/Knet.jl). \n",
      "# Although we could have reused more of Flux (see the MNIST example), the library's abstractions are very \n",
      "# lightweight and don't force you into any particular strategy.\n",
      "\n",
      "# A linear model can be created as a neural network with a single layer. \n",
      "# The number of inputs is the same as the features that the data has. \n",
      "# Each input is connected to a single output with no activation function. \n",
      "# Then, the output of the model is a linear function that predicts unseen data. \n",
      "\n",
      "# ![singleneuron](img/singleneuron.svg)\n",
      "\n",
      "# Source: [Dive into Deep Learning](http://d2l.ai/chapter_linear-networks/linear-regression.html#from-linear-regression-to-deep-networks)\n",
      "\n",
      "# To run this example, we need the following packages:\n",
      "\n",
      "using Flux\n",
      "using Flux: gradient\n",
      "using Flux.Optimise: update!\n",
      "using DelimitedFiles, Statistics\n",
      "using Parameters: @with_kw\n",
      "\n",
      "\n",
      "# We set default values for the learning rate (for the training routine) and the percentage of \n",
      "# the data that we use when testing the model:\n",
      "\n",
      "@with_kw mutable struct Hyperparams\n",
      "    ## Learning rate\n",
      "    lr::Float64 = 0.1 \n",
      "    ## Train Test split ratio, define percentage of data to be used as Test data\n",
      "    split_ratio::Float64 = 0.1 \n",
      "end\n",
      "\n",
      "\n",
      "# ## Data \n",
      "\n",
      "# We create the function `get_processed_data` to load the housing data, normalize it, \n",
      "# and finally split it into train and test datasets:\n",
      "\n",
      "\n",
      "function get_processed_data(args)\n",
      "    isfile(\"housing.data\") ||\n",
      "        download(\"https://raw.githubusercontent.com/MikeInnes/notebooks/master/housing.data\",\n",
      "            \"housing.data\")\n",
      "\n",
      "    rawdata = readdlm(\"housing.data\")'\n",
      "\n",
      "    ## The last feature is our target -- the price of the house.\n",
      "    split_ratio = args.split_ratio ## For the train test split\n",
      "\n",
      "    x = rawdata[1:13,:]\n",
      "    y = rawdata[14:14,:]\n",
      "\n",
      "    ## Normalise the data\n",
      "    x = (x .- mean(x, dims = 2)) ./ std(x, dims = 2)\n",
      "\n",
      "    ## Split into train and test sets\n",
      "    split_index = floor(Int,size(x,2)*split_ratio)\n",
      "    x_train = x[:,1:split_index]\n",
      "    y_train = y[:,1:split_index]\n",
      "    x_test = x[:,split_index+1:size(x,2)]\n",
      "    y_test = y[:,split_index+1:size(x,2)]\n",
      "\n",
      "    train_data = (x_train, y_train)\n",
      "    test_data = (x_test, y_test)\n",
      "\n",
      "    return train_data,test_data\n",
      "end\n",
      "\n",
      "# This function performs the following tasks:\n",
      "\n",
      "# 1. Downloads the housing data. The original size of the data is 505 rows and 14 columns.\n",
      "# 2. Loads the data as a 14x505 matrix. This is the shape that Flux expects.\n",
      "# 3. Splits the data into features and a target. Notice that the 14th row corresponds to the target for each example.\n",
      "# 4. Normalizes the data. For more information on normalizing data, see [How to Use StandardScaler and MinMaxScaler Transforms in Python](https://machinelearningmastery.com/standardscaler-and-minmaxscaler-transforms-in-python/).  \n",
      "# 5. Splits the data into train and test datasets.\n",
      "    \n",
      "\n",
      "# ## Model\n",
      "# We use a struct to define the model’s parameters. \n",
      "# It contains an array for holding the weights *W* and a vector for the bias term *b*:\n",
      "\n",
      "mutable struct model\n",
      "    W::AbstractArray\n",
      "    b::AbstractVector\n",
      "end\n",
      "\n",
      "# Also, we create the function `predict` to compute the model’s output:\n",
      "\n",
      "predict(x, m) = m.W*x .+ m.b\n",
      "\n",
      "# Notice that the function `predict` takes as an argument the model struct we defined above.\n",
      "\n",
      "# ## Loss function\n",
      "\n",
      "# The most commonly used loss function for Linear Regression is Mean Squared Error (MSE). \n",
      "# We define the MSE function as:\n",
      "\n",
      "meansquarederror(ŷ, y) = sum((ŷ .- y).^2)/size(y, 2)\n",
      "\n",
      "# **Note:** An implementation of the MSE function is also available in \n",
      "# [Flux](https://fluxml.ai/Flux.jl/stable/models/losses/#Flux.Losses.mse).\n",
      "\n",
      "# ## Train function\n",
      "# Finally, we define the `train` function so that the model learns the best parameters (*W* and *b*):\n",
      "\n",
      "\n",
      "function train(; kws...)\n",
      "    ## Initialize the Hyperparamters\n",
      "    args = Hyperparams(; kws...)\n",
      "    \n",
      "    ## Load the data\n",
      "    (x_train,y_train),(x_test,y_test) = get_processed_data(args)\n",
      "    \n",
      "    ## The model\n",
      "    m = model((randn(1,13)),[0.])\n",
      "    \n",
      "    loss(x, y) = meansquarederror(predict(x, m), y) \n",
      "\n",
      "    ## Training\n",
      "    η = args.lr\n",
      "    θ = params(m.W, m.b)\n",
      "\n",
      "    for i = 1:500\n",
      "        g = gradient(() -> loss(x_train, y_train), θ)\n",
      "        for x in θ\n",
      "            update!(x, g[x]*η)\n",
      "        end\n",
      "        if i%100==0\n",
      "            @show loss(x_train, y_train)\n",
      "        end\n",
      "    end\n",
      "    \n",
      "    ## Predict the RMSE on the test set\n",
      "    err = meansquarederror(predict(x_test, m),y_test)\n",
      "    println(err)\n",
      "end\n",
      "\n",
      "# The function above initializes the model’s parameters *W* and *b* randomly. \n",
      "# Then, it sets the learning rate η and θ as a \n",
      "# [params object](https://fluxml.ai/Flux.jl/stable/training/training/#Flux.params) \n",
      "# that points to  W and b. Also, it sets a \n",
      "# [custom training loop](https://fluxml.ai/Flux.jl/stable/training/training/#Custom-Training-loops) \n",
      "# which is the [Gradient descent algorithm](https://en.wikipedia.org/wiki/Gradient_descent). \n",
      "# Finally, it computes the MSE for the test set.\n",
      "\n",
      "# ## Run the example \n",
      "# We call the `train` function to run the Housing data example:\n",
      "\n",
      "cd(@__DIR__)\n",
      "train()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  34\n",
      "ali-ramadhan/Atmosfoolery.jl\n",
      "verification/dry_rising_thermal_bubble/dry_rising_thermal_bubble.jl\n",
      "########################################\n",
      "\n",
      "using Logging\n",
      "using Printf\n",
      "using Statistics\n",
      "using NCDatasets\n",
      "using CUDA\n",
      "\n",
      "using Oceananigans\n",
      "using Oceananigans.Grids\n",
      "using Oceananigans.Advection\n",
      "using Oceananigans.OutputWriters\n",
      "using Oceananigans.Utils\n",
      "using JULES\n",
      "\n",
      "using Oceananigans.Fields: cpudata\n",
      "\n",
      "Logging.global_logger(OceananigansLogger())\n",
      "\n",
      "const km = kilometers\n",
      "const hPa = 100.0\n",
      "\n",
      "function simulate_dry_rising_thermal_bubble(; architecture=CPU(), thermodynamic_variable, end_time=1000.0)\n",
      "    tvar = thermodynamic_variable\n",
      "\n",
      "    Lx = 20km\n",
      "    Lz = 10km\n",
      "    Δ  = 200meters\n",
      "\n",
      "    Nx = Int(Lx/Δ)\n",
      "    Ny = 1\n",
      "    Nz = Int(Lz/Δ)\n",
      "\n",
      "    topo = (Periodic, Periodic, Bounded)\n",
      "    domain = (x=(-Lx/2, Lx/2), y=(-Lx/2, Lx/2), z=(0, Lz))\n",
      "    grid = RegularCartesianGrid(topology=topo, size=(Nx, Ny, Nz), halo=(3, 3, 3); domain...)\n",
      "\n",
      "    model = CompressibleModel(\n",
      "                  architecture = architecture,\n",
      "                          grid = grid,\n",
      "                         gases = DryEarth(),\n",
      "        thermodynamic_variable = tvar,\n",
      "                       closure = IsotropicDiffusivity(ν=75.0, κ=75.0)\n",
      "    )\n",
      "\n",
      "    gas = model.gases.ρ\n",
      "    R, cₚ, cᵥ = gas.R, gas.cₚ, gas.cᵥ\n",
      "    g  = model.gravity\n",
      "    pₛ = 1000hPa\n",
      "    Tₛ = 300.0\n",
      "\n",
      "    # Define an approximately hydrostatic background state\n",
      "    θ₀(x, y, z) = Tₛ\n",
      "    p₀(x, y, z) = pₛ * (1 - g*z / (cₚ*Tₛ))^(cₚ/R)\n",
      "    T₀(x, y, z) = Tₛ * (p₀(x, y, z)/pₛ)^(R/cₚ)\n",
      "    ρ₀(x, y, z) = p₀(x, y, z) / (R*T₀(x, y, z))\n",
      "\n",
      "    # Define both energy and entropy\n",
      "    uᵣ, Tᵣ, ρᵣ, sᵣ = gas.u₀, gas.T₀, gas.ρ₀, gas.s₀  # Reference values\n",
      "    ρe₀(x, y, z) = ρ₀(x, y, z) * (uᵣ + cᵥ * (T₀(x, y, z) - Tᵣ) + g*z)\n",
      "    ρs₀(x, y, z) = ρ₀(x, y, z) * (sᵣ + cᵥ * log(T₀(x, y, z)/Tᵣ) - R * log(ρ₀(x, y, z)/ρᵣ))\n",
      "\n",
      "    # Define the initial density perturbation\n",
      "    θᶜ′ = 2.0\n",
      "    xᶜ, zᶜ = 0km, 2km\n",
      "    xʳ, zʳ = 2km, 2km\n",
      "\n",
      "    L(x, y, z) = sqrt(((x - xᶜ)/xʳ)^2 + ((z - zᶜ)/zʳ)^2)\n",
      "    θ′(x, y, z) = (L(x, y, z) <= 1) * θᶜ′ * cos(π/2 * L(x, y, z))^2\n",
      "    ρ′(x, y, z) = -ρ₀(x, y, z) * θ′(x, y, z) / θ₀(x, y, z)\n",
      "\n",
      "    # Define initial state\n",
      "    ρᵢ(x, y, z) = ρ₀(x, y, z) + ρ′(x, y, z)\n",
      "    pᵢ(x, y, z) = p₀(x, y, z)\n",
      "    Tᵢ(x, y, z) = pᵢ(x, y, z) / (R * ρᵢ(x, y, z))\n",
      "\n",
      "    ρeᵢ(x, y, z) = ρᵢ(x, y, z) * (uᵣ + cᵥ * (Tᵢ(x, y, z) - Tᵣ) + g*z)\n",
      "    ρsᵢ(x, y, z) = ρᵢ(x, y, z) * (sᵣ + cᵥ * log(Tᵢ(x, y, z)/Tᵣ) - R * log(ρᵢ(x, y, z)/ρᵣ))\n",
      "\n",
      "    # Set initial state\n",
      "    set!(model.tracers.ρ, ρᵢ)\n",
      "    tvar isa Energy  && set!(model.tracers.ρe, ρeᵢ)\n",
      "    tvar isa Entropy && set!(model.tracers.ρs, ρsᵢ)\n",
      "    update_total_density!(model)\n",
      "\n",
      "    simulation = Simulation(model, Δt=0.1, stop_time=end_time, iteration_interval=50,\n",
      "                            progress=print_progress, parameters=(ρᵢ, ρeᵢ, ρsᵢ))\n",
      "\n",
      "    fields = Dict(\n",
      "        \"ρ\"  => model.total_density,\n",
      "        \"ρu\" => model.momenta.ρu,\n",
      "        \"ρw\" => model.momenta.ρw\n",
      "    )\n",
      "\n",
      "    tvar isa Energy  && push!(fields, \"ρe\" => model.tracers.ρe)\n",
      "    tvar isa Entropy && push!(fields, \"ρs\" => model.tracers.ρs)\n",
      "    \n",
      "    simulation.output_writers[:fields] =\n",
      "        NetCDFOutputWriter(model, fields, filepath=\"dry_rising_thermal_bubble_$(typeof(tvar)).nc\",\n",
      "                           time_interval=10seconds)\n",
      "\n",
      "\n",
      "    # Save base state to NetCDF.\n",
      "    ds = simulation.output_writers[:fields].dataset\n",
      "    ds_ρ = defVar(ds, \"ρ₀\", Float32, (\"xC\", \"yC\", \"zC\"))\n",
      "    ds_ρe = defVar(ds, \"ρe₀\", Float32, (\"xC\", \"yC\", \"zC\"))\n",
      "\n",
      "    x, y, z = nodes((Cell, Cell, Cell), grid, reshape=true)\n",
      "    ds_ρ[:, :, :] = ρ₀.(x, y, z)\n",
      "    ds_ρe[:, :, :] = ρe₀.(x, y, z)\n",
      "\n",
      "    run!(simulation)\n",
      "\n",
      "    return simulation\n",
      "end\n",
      "\n",
      "function print_progress(simulation)\n",
      "    model, Δt = simulation.model, simulation.Δt\n",
      "    tvar = model.thermodynamic_variable\n",
      "    ρᵢ, ρeᵢ, ρsᵢ = simulation.parameters\n",
      "\n",
      "    zC = znodes(Cell, model.grid)\n",
      "    ρ̄ᵢ = mean(ρᵢ.(0, 0, zC))\n",
      "    ρ̄ = mean(cpudata(model.total_density))\n",
      "\n",
      "    progress = 100 * model.clock.time / simulation.stop_time\n",
      "    message = @sprintf(\"[%05.2f%%] iteration = %d, time = %s, CFL = %.4e, acoustic CFL = %.4e, ρ̄ = %.4e (relΔ = %.4e)\",\n",
      "                       progress, model.clock.iteration, prettytime(model.clock.time), cfl(model, Δt),\n",
      "                       acoustic_cfl(model, Δt), ρ̄, (ρ̄ - ρ̄ᵢ) / ρ̄)\n",
      "\n",
      "    if tvar isa Energy\n",
      "        ρ̄ēᵢ = mean(ρeᵢ.(0, 0, zC))\n",
      "        ρ̄ē = mean(cpudata(model.tracers.ρe))\n",
      "        message *= @sprintf(\", ρ̄ē = %.4e (relΔ = %.4e)\", ρ̄ē, (ρ̄ē - ρ̄ēᵢ)/ρ̄ē)\n",
      "    elseif tvar isa Entropy\n",
      "        ρ̄s̄ᵢ = mean(ρsᵢ.(0, 0, zC))\n",
      "        ρ̄s̄ = mean(cpudata(model.tracers.ρs))\n",
      "        message *= @sprintf(\", ρ̄s̄ = %.4e (relΔ = %.4e)\", ρ̄s̄, (ρ̄s̄ - ρ̄s̄ᵢ)/ρ̄s̄)\n",
      "    end\n",
      "\n",
      "    @info message\n",
      "\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  35\n",
      "glwagner/OceanLES.jl\n",
      "src/Fields/show_fields.jl\n",
      "########################################\n",
      "\n",
      "show_location(X, Y, Z) = string(\"(\", string(typeof(X())), \", \",\n",
      "                                     string(typeof(Y())), \", \",\n",
      "                                     string(typeof(Z())), \")\")\n",
      "\n",
      "show_location(field::AbstractLocatedField{X, Y, Z}) where {X, Y, Z} = show_location(X, Y, Z)\n",
      "\n",
      "short_show(a) = string(typeof(a))\n",
      "shortname(a::Array) = string(typeof(a).name.wrapper)\n",
      "\n",
      "show(io::IO, field::Field) =\n",
      "    print(io,\n",
      "          short_show(field), '\\n',\n",
      "          \"├── data: \", typeof(field.data), '\\n',\n",
      "          \"└── grid: \", typeof(field.grid), '\\n',\n",
      "          \"    ├── size: \", size(field.grid), '\\n',\n",
      "          \"    └── domain: \", show_domain(field.grid), '\\n')\n",
      "\n",
      "short_show(field::AbstractLocatedField) = string(\"Field at \", show_location(field))\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  36\n",
      "hustf/Spotify.jl\n",
      "src/util/request.jl\n",
      "########################################\n",
      "\n",
      "\n",
      "# Use the access token to access the Spotify Web API\n",
      "# https://developer.spotify.com/documentation/general/guides/authorization-guide/#client-credentials-flow\n",
      "\n",
      "\"Access the Spotify Web API\"\n",
      "function spotify_request(url_ext::String, method::String= \"GET\"; scope = \"client-credentials\")\n",
      "    # Not so cool, but this is how we get rid of spaces in vectors of strings:\n",
      "    url_ext = replace(url_ext, ' ' => \"\")\n",
      "    url = \"https://api.spotify.com/v1/$url_ext\"\n",
      "    headers = header_maker(;scope)\n",
      "    isnothing(headers) && return()\n",
      "    resp = HTTP.Messages.Response()\n",
      "    try\n",
      "        resp = HTTP.request(method, url, headers)\n",
      "    catch e\n",
      "        knowntype = e isa HTTP.ExceptionRequest.StatusError && e.status == 401\n",
      "        if knowntype\n",
      "            response_body = e.response.body |> String\n",
      "            @error response_body\n",
      "            return nothing\n",
      "        else\n",
      "            @warn \"HTTP.request call: method = $method\\n headers = $headers \\n $url_ext\"\n",
      "            @error e\n",
      "            return nothing\n",
      "        end\n",
      "    end\n",
      "    response_body = resp.body |> String\n",
      "    response_body |> JSON3.read\n",
      "end\n",
      "\n",
      "#=\n",
      "\"\"\"\n",
      "Access the Spotify web api through the 'Implicit grant flow'.\n",
      "Implicit grant flow is for clients that are implemented entirely \n",
      "using JavaScript and running in the resource owner’s browser.\n",
      "Julia: No prob.!\n",
      "..but we do launch a browser for login..\n",
      "\"\"\"\n",
      "function other_request()\n",
      "    error(\"ouch - not used\")\n",
      "    url = OAUTH_AUTHORIZE_URL\n",
      "    headers = header_maker(\"Bearer\")\n",
      "    resp = HTTP.Messages.Response()\n",
      "    method = \"GET\"\n",
      "    try\n",
      "        resp = HTTP.request(method, url, headers)\n",
      "    catch e\n",
      "        request = \"HTTP.request call: method = $method\\n  url = $url\\n  headers = $headers \\n\"\n",
      "        @error request\n",
      "        @error e\n",
      "        return nothing\n",
      "    end\n",
      "    response_body = resp.body |> String\n",
      "    response_body |> JSON3.read\n",
      "end\n",
      "=#\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  37\n",
      "bgctw/Lognormals.jl\n",
      "test/semcor_benchmark.jl\n",
      "########################################\n",
      "\n",
      "using LogNormals\n",
      "using Test, Distributions, LinearAlgebra, StatsBase, Missings, Random\n",
      "using OffsetArrays, RecursiveArrayTools\n",
      "\n",
      "function boot_sem_cor()\n",
      "    #using FillArrays\n",
      "    ##using BandedMatrices\n",
      "    ##using Bootstrap\n",
      "    nsum = 100\n",
      "    probgap = 0.6\n",
      "    acf0 = [1,0.4,0.1]\n",
      "    Sigma = cormatrix_for_acf(nsum, acf0);\n",
      "    dmn = MvNormal(ones(nsum), Symmetric(Sigma));\n",
      "    #always use the same gaps\n",
      "    igap = sample(1:nsum,trunc(Int,nsum*probgap), replace=false)\n",
      "    b = allowmissing(rand(dmn));\n",
      "    b[igap] .= missing;\n",
      "    sem_cor(b, acf0, ExactMissing())\n",
      "    nboot = 10_000\n",
      "    resboot = map(1:nboot) do iboot\n",
      "        b = allowmissing(rand(dmn));\n",
      "        b[igap] .= missing\n",
      "        sum(skipmissing(b)), mean(skipmissing(b)), sem_cor(b, acf0, ExactMissing())\n",
      "    end;\n",
      "    sums_boot, means_boot, semcor_boot = vectuptotupvec(resboot);\n",
      "    mean(sums_boot), std(sums_boot)\n",
      "    mean(means_boot), std(means_boot)\n",
      "    dvn = SimpleDistributionVector(Fill(Normal(1,1), nsum)...);\n",
      "    dvn[ismissing.(b)] .= missing;\n",
      "    dsum = sum(dvn, AutoCorrelationFunction(acf0), SkipMissing())\n",
      "    dmean = mean(dvn, AutoCorrelationFunction(acf0), SkipMissing())\n",
      "    @test dmean.σ ≈ std(means_boot) atol=0.01\n",
      "    # mean over Normals with missings works\n",
      "    function sem_cor_benchmark(x, acfe, ms::MissingStrategy=ExactMissing())\n",
      "        n = length(x)\n",
      "        n <= 1 && return(std(x))\n",
      "        nmiss = count(ismissing.(x))\n",
      "        nfin = n - nmiss\n",
      "        neff = effective_n_cor(x, acfe)\n",
      "        σ2uncorr = var(skipmissing(x))\n",
      "        # BLUE Var(x) for correlated: Zieba11 eq.(1) \n",
      "        σ2 = σ2uncorr*(nfin-1)*neff/(nfin*(neff-1))\n",
      "        if ms === ExactMissing() && (nmiss != 0)\n",
      "            σ = Fill(√σ2, n)\n",
      "            dv = ParamDistributionVector(Normal{nonmissingtype(eltype(x))}, x, σ)\n",
      "            acfes = n < length(acfe) ? view(acfe,1:n) : acfe\n",
      "            dm = mean(dv, AutoCorrelationFunction(acfes), SkipMissing())\n",
      "            #@show acfes, dm, length(dv), count(ismissing,dv), count(ismissing,x)\n",
      "            return(dm.σ)\n",
      "        else\n",
      "            return(√(σ2/neff))\n",
      "        end\n",
      "    end\n",
      "    res_sem_cor = sem_cor(b, acf0)\n",
      "    @test res_sem_cor ≈ std(means_boot) atol=0.02\n",
      "    res_sem_cor2a = sem_cor_benchmark(b, acf0, ms=ExactMissing())\n",
      "    @test res_sem_cor2a ≈ std(means_boot) atol=0.02\n",
      "    res_sem_cor2b = sem_cor_benchmark(b, acf0, ms=SkipMissing())\n",
      "    @test res_sem_cor2b ≈ std(means_boot) atol=0.02\n",
      "    #using BenchmarkTools: @btime\n",
      "    @btime sem_cor_benchmark($b, $acf0, ms=ExactMissing())\n",
      "    @btime sem_cor_benchmark($b, $acf0, ms=SkipMissing())\n",
      "    # neff based method much faster\n",
      "    function tmpf()\n",
      "        #using StatsPlots\n",
      "        plot(density(means_boot))\n",
      "        vline!([mean(means_boot), quantile(means_boot,[0.025,0.975])...])\n",
      "        #\n",
      "        # plot(density(means_boot), label = \"density mean\")\n",
      "        # vline!([mean(means_boot), quantile(means_boot,[0.025,0.975])...], label = \"stats mean\")\n",
      "        density(semcor_boot, label = \"density sem_cor\")\n",
      "        vline!([mean(semcor_boot), quantile(semcor_boot,[0.025,0.975])...], label = \"stats sem_cor\")\n",
      "        vline!([std(means_boot)], label = \"std(means_bootstrap)\") # true mu and sigma\n",
      "        vline!([dmean.σ], label = \"sum_normals - true distribs\") # true mu and sigma\n",
      "    end\n",
      "end\n",
      "\n",
      "function inspect_lags_autocorrelation()\n",
      "    nsum = 1_000\n",
      "    acf0 = [1,0.4,0.1]\n",
      "    Sigma = cormatrix_for_acf(nsum, acf0);\n",
      "    dmn = MvNormal(ones(nsum), Symmetric(Sigma));\n",
      "    a = rand(dmn);\n",
      "    probgap = 0.4\n",
      "    clustersize = 2\n",
      "    #clustersize = 50\n",
      "    nboot = 1_000\n",
      "    resboot = map(1:nboot) do iboot\n",
      "        igap0 = sample(0:(nsum-clustersize),trunc(Int,nsum*probgap/clustersize), replace=true);\n",
      "        b = allowmissing(a);\n",
      "        # outer product see https://stackoverflow.com/a/44592419\n",
      "        #igap0.+Base.OneTo(clustersize)' \n",
      "        b[igap0.+Base.OneTo(clustersize)'] .= missing;\n",
      "        ae = autocor(b, 1:2, ms=ExactMissing())\n",
      "        af = autocor(b, 1:2, ms=SkipMissing())\n",
      "        (ae, af)\n",
      "    end;\n",
      "    ae, af = VectorOfArray.(vectuptotupvec(resboot));\n",
      "    mean(ae; dims=2)\n",
      "    mean(af; dims=2)\n",
      "    autocor(a, 1:2)\n",
      "\n",
      "end\n",
      "\n",
      "function benchmark_count_forlags()\n",
      "    #using BenchmarkTools: @btime\n",
      "    function count_forlags_slower(pred, x,lags)\n",
      "        cnt = zeros(size(lags))\n",
      "        ax = OffsetArrays.no_offset_view(axes(x,1))\n",
      "        lx = length(x)\n",
      "        for i in 1:lx\n",
      "            for (ik,k) in enumerate(lags)\n",
      "                i > lx-k && continue\n",
      "                if (pred(x[ax[i]])::Bool || pred(x[ax[i+k]])::Bool); cnt[ik] += 1; end\n",
      "            end\n",
      "        end\n",
      "        cnt\n",
      "    end\n",
      "    x = repeat([1,2,missing,missing,5], 500)\n",
      "    lags = 0:4\n",
      "    @btime count_forlags($ismissing, $x, $lags)\n",
      "    @btime count_forlags_slower($ismissing, $x, $lags)\n",
      "    # the version with calling subfunction is faster\n",
      "    @code_warntype count_forlags(ismissing, x, lags)\n",
      "    @code_warntype LogNormals.count_forlags2(ismissing, x, lags)\n",
      "    @code_warntype LogNormals.count_forlag(ismissing, x, 2)\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  38\n",
      "garborg/DataArrays.jl\n",
      "src/datavector.jl\n",
      "########################################\n",
      "\n",
      "# dv[SingleItemIndex, SingleItemIndex)\n",
      "function Base.getindex(d::DataVector,\n",
      "                       i::SingleIndex,\n",
      "                       j::SingleIndex)\n",
      "    if j != 1\n",
      "        throw(ArgumentError(\"Second index must be 1\"))\n",
      "    end\n",
      "    if d.na[i]\n",
      "        return NA\n",
      "    else\n",
      "        return d.data[i]\n",
      "    end\n",
      "end\n",
      "\n",
      "head(dv::AbstractDataVector) = dv[1:min(6, length(dv))]\n",
      "tail(dv::AbstractDataVector) = dv[max(length(dv) - 6, 1):length(dv)]\n",
      "\n",
      "# Container operations\n",
      "\n",
      "# TODO: Macroize these definitions\n",
      "\n",
      "function Base.push!{T}(dv::DataVector{T}, v::NAtype)\n",
      "    push!(dv.data, baseval(T))\n",
      "    push!(dv.na, true)\n",
      "    return v\n",
      "end\n",
      "\n",
      "function Base.push!{S, T}(dv::DataVector{S}, v::T)\n",
      "    push!(dv.data, v)\n",
      "    push!(dv.na, false)\n",
      "    return v\n",
      "end\n",
      "\n",
      "function Base.pop!(dv::DataVector)\n",
      "    d, m = pop!(dv.data), pop!(dv.na)\n",
      "    if m\n",
      "        return NA\n",
      "    else\n",
      "        return d\n",
      "    end\n",
      "end\n",
      "\n",
      "function Base.unshift!{T}(dv::DataVector{T}, v::NAtype)\n",
      "    unshift!(dv.data, baseval(T))\n",
      "    unshift!(dv.na, true)\n",
      "    return v\n",
      "end\n",
      "\n",
      "function Base.unshift!{S, T}(dv::DataVector{S}, v::T)\n",
      "    unshift!(dv.data, v)\n",
      "    unshift!(dv.na, false)\n",
      "    return v\n",
      "end\n",
      "\n",
      "function Base.shift!{T}(dv::DataVector{T})\n",
      "    d, m = shift!(dv.data), shift!(dv.na)\n",
      "    if m\n",
      "        return NA\n",
      "    else\n",
      "        return d\n",
      "    end\n",
      "end\n",
      "\n",
      "# TODO: should this be an AbstractDataVector, so it works with PDV's?\n",
      "function Base.map(f::Function, dv::DataVector)\n",
      "    n = length(dv)\n",
      "    res = DataArray(Any, n)\n",
      "    for i in 1:n\n",
      "        res[i] = f(dv[i])\n",
      "    end\n",
      "    return res\n",
      "end\n",
      "\n",
      "function Base.push!{T,R}(pdv::PooledDataVector{T,R}, v::NAtype)\n",
      "    push!(pdv.refs, zero(R))\n",
      "    return v\n",
      "end\n",
      "\n",
      "function Base.push!{S,R,T}(pdv::PooledDataVector{S,R}, v::T)\n",
      "    v = convert(S,v)\n",
      "    push!(pdv.refs, getpoolidx(pdv, v))\n",
      "    return v\n",
      "end\n",
      "\n",
      "Base.pop!(pdv::PooledDataVector) = pdv.pool[pop!(pdv.refs)]\n",
      "\n",
      "function Base.unshift!{T,R}(pdv::PooledDataVector{T,R}, v::NAtype)\n",
      "    unshift!(pdv.refs, zero(R))\n",
      "    return v\n",
      "end\n",
      "\n",
      "function Base.unshift!{S,R,T}(pdv::PooledDataVector{S,R}, v::T)\n",
      "    v = convert(S,v)\n",
      "    unshift!(pdv.refs, getpoolidx(pdv, v))\n",
      "    return v\n",
      "end\n",
      "\n",
      "Base.shift!(pdv::PooledDataVector) = pdv.pool[shift!(pdv.refs)]\n",
      "\n",
      "Base.reverse(x::AbstractDataVector) = x[end:-1:1]\n",
      "\n",
      "# Pad a vector with NA's\n",
      "\n",
      "function padNA(dv::AbstractDataVector,\n",
      "               front::Integer,\n",
      "               back::Integer)\n",
      "    n = length(dv)\n",
      "    res = similar(dv, front + n + back)\n",
      "    for i in 1:n\n",
      "        res[i + front] = dv[i]\n",
      "    end\n",
      "    return res\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  39\n",
      "ranocha/StochasticDiffEq.jl\n",
      "src/caches/basic_method_caches.jl\n",
      "########################################\n",
      "\n",
      "struct EMConstantCache <: StochasticDiffEqConstantCache end\n",
      "@cache struct EMCache{uType,rateType,rateNoiseType} <: StochasticDiffEqMutableCache\n",
      "  u::uType\n",
      "  uprev::uType\n",
      "  tmp::uType\n",
      "  rtmp1::rateType\n",
      "  rtmp2::rateNoiseType\n",
      "end\n",
      "\n",
      "alg_cache(alg::EM,prob,u,ΔW,ΔZ,p,rate_prototype,noise_rate_prototype,uEltypeNoUnits,uBottomEltypeNoUnits,tTypeNoUnits,uprev,f,t,::Type{Val{false}}) = EMConstantCache()\n",
      "\n",
      "function alg_cache(alg::EM,prob,u,ΔW,ΔZ,p,rate_prototype,noise_rate_prototype,uEltypeNoUnits,uBottomEltypeNoUnits,tTypeNoUnits,uprev,f,t,::Type{Val{true}})\n",
      "  tmp = zero(u); rtmp1 = zero(rate_prototype);\n",
      "  rtmp2 = zero(noise_rate_prototype)\n",
      "  EMCache(u,uprev,tmp,rtmp1,rtmp2)\n",
      "end\n",
      "\n",
      "struct SplitEMConstantCache <: StochasticDiffEqConstantCache end\n",
      "@cache struct SplitEMCache{uType,rateType,rateNoiseType} <: StochasticDiffEqMutableCache\n",
      "  u::uType\n",
      "  uprev::uType\n",
      "  tmp::uType\n",
      "  rtmp1::rateType\n",
      "  rtmp2::rateNoiseType\n",
      "end\n",
      "\n",
      "alg_cache(alg::SplitEM,prob,u,ΔW,ΔZ,p,rate_prototype,noise_rate_prototype,uEltypeNoUnits,uBottomEltypeNoUnits,tTypeNoUnits,uprev,f,t,::Type{Val{false}}) = SplitEMConstantCache()\n",
      "\n",
      "function alg_cache(alg::SplitEM,prob,u,ΔW,ΔZ,p,rate_prototype,noise_rate_prototype,uEltypeNoUnits,uBottomEltypeNoUnits,tTypeNoUnits,uprev,f,t,::Type{Val{true}})\n",
      "  tmp = zero(u); rtmp1 = zero(rate_prototype);\n",
      "  rtmp2 = zero(noise_rate_prototype)\n",
      "  SplitEMCache(u,uprev,tmp,rtmp1,rtmp2)\n",
      "end\n",
      "\n",
      "struct EulerHeunConstantCache <: StochasticDiffEqConstantCache end\n",
      "@cache struct EulerHeunCache{uType,rateType,rateNoiseType,rateNoiseCollectionType} <: StochasticDiffEqMutableCache\n",
      "  u::uType\n",
      "  uprev::uType\n",
      "  tmp::uType\n",
      "  ftmp1::rateType\n",
      "  ftmp2::rateType\n",
      "  nrtmp::rateNoiseCollectionType\n",
      "  gtmp1::rateNoiseType\n",
      "  gtmp2::rateNoiseType\n",
      "end\n",
      "\n",
      "alg_cache(alg::EulerHeun,prob,u,ΔW,ΔZ,p,rate_prototype,noise_rate_prototype,uEltypeNoUnits,uBottomEltypeNoUnits,tTypeNoUnits,uprev,f,t,::Type{Val{false}}) = EulerHeunConstantCache()\n",
      "\n",
      "function alg_cache(alg::EulerHeun,prob,u,ΔW,ΔZ,p,rate_prototype,noise_rate_prototype,uEltypeNoUnits,uBottomEltypeNoUnits,tTypeNoUnits,uprev,f,t,::Type{Val{true}})\n",
      "  tmp = zero(u); ftmp1 = zero(rate_prototype); ftmp2 = zero(rate_prototype)\n",
      "  nrtmp = zero(rate_prototype)\n",
      "  gtmp1 = zero(noise_rate_prototype); gtmp2 = zero(noise_rate_prototype)\n",
      "  EulerHeunCache(u,uprev,tmp,ftmp1,ftmp2,nrtmp,gtmp1,gtmp2)\n",
      "end\n",
      "\n",
      "struct RandomEMConstantCache <: StochasticDiffEqConstantCache end\n",
      "@cache struct RandomEMCache{uType,rateType} <: StochasticDiffEqMutableCache\n",
      "  u::uType\n",
      "  uprev::uType\n",
      "  tmp::uType\n",
      "  rtmp::rateType\n",
      "end\n",
      "\n",
      "alg_cache(alg::RandomEM,prob,u,ΔW,ΔZ,p,rate_prototype,noise_rate_prototype,uEltypeNoUnits,uBottomEltypeNoUnits,tTypeNoUnits,uprev,f,t,::Type{Val{false}}) = RandomEMConstantCache()\n",
      "\n",
      "function alg_cache(alg::RandomEM,prob,u,ΔW,ΔZ,p,rate_prototype,noise_rate_prototype,uEltypeNoUnits,uBottomEltypeNoUnits,tTypeNoUnits,uprev,f,t,::Type{Val{true}})\n",
      "  tmp = zero(u); rtmp = zero(rate_prototype)\n",
      "  RandomEMCache(u,uprev,tmp,rtmp)\n",
      "end\n",
      "\n",
      "struct RKMilConstantCache <: StochasticDiffEqConstantCache end\n",
      "@cache struct RKMilCache{uType,rateType} <: StochasticDiffEqMutableCache\n",
      "  u::uType\n",
      "  uprev::uType\n",
      "  du1::rateType\n",
      "  du2::rateType\n",
      "  K::rateType\n",
      "  tmp::uType\n",
      "  L::rateType\n",
      "end\n",
      "\n",
      "alg_cache(alg::RKMil,prob,u,ΔW,ΔZ,p,rate_prototype,noise_rate_prototype,uEltypeNoUnits,uBottomEltypeNoUnits,tTypeNoUnits,uprev,f,t,::Type{Val{false}}) = RKMilConstantCache()\n",
      "\n",
      "function alg_cache(alg::RKMil,prob,u,ΔW,ΔZ,p,rate_prototype,noise_rate_prototype,uEltypeNoUnits,uBottomEltypeNoUnits,tTypeNoUnits,uprev,f,t,::Type{Val{true}})\n",
      "  du1 = zero(rate_prototype); du2 = zero(rate_prototype)\n",
      "  K = zero(rate_prototype); tmp = zero(u); L = zero(rate_prototype)\n",
      "  RKMilCache(u,uprev,du1,du2,K,tmp,L)\n",
      "end\n",
      "\n",
      "struct RKMilCommuteConstantCache <: StochasticDiffEqConstantCache end\n",
      "@cache struct RKMilCommuteCache{uType,rateType,rateNoiseType,WikType} <: StochasticDiffEqMutableCache\n",
      "  u::uType\n",
      "  uprev::uType\n",
      "  du1::rateType\n",
      "  du2::rateType\n",
      "  K::rateType\n",
      "  gtmp::rateNoiseType\n",
      "  L::rateNoiseType\n",
      "  I::WikType\n",
      "  Dg::WikType\n",
      "  mil_correction::rateType\n",
      "  Kj::uType\n",
      "  Dgj::rateNoiseType\n",
      "  tmp::uType\n",
      "end\n",
      "\n",
      "alg_cache(alg::RKMilCommute,prob,u,ΔW,ΔZ,p,rate_prototype,noise_rate_prototype,uEltypeNoUnits,uBottomEltypeNoUnits,tTypeNoUnits,uprev,f,t,::Type{Val{false}}) = RKMilCommuteConstantCache()\n",
      "\n",
      "function alg_cache(alg::RKMilCommute,prob,u,ΔW,ΔZ,p,rate_prototype,noise_rate_prototype,uEltypeNoUnits,uBottomEltypeNoUnits,tTypeNoUnits,uprev,f,t,::Type{Val{true}})\n",
      "  du1 = zero(rate_prototype); du2 = zero(rate_prototype)\n",
      "  K = zero(rate_prototype); gtmp = zero(noise_rate_prototype);\n",
      "  L = zero(noise_rate_prototype); tmp = zero(rate_prototype)\n",
      "  I = zeros(length(ΔW),length(ΔW));\n",
      "  Dg = zeros(length(ΔW),length(ΔW)); mil_correction = zero(rate_prototype)\n",
      "  Kj = zero(u); Dgj = zero(noise_rate_prototype)\n",
      "  RKMilCommuteCache(u,uprev,du1,du2,K,gtmp,L,I,Dg,mil_correction,Kj,Dgj,tmp)\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  40\n",
      "JuliaPackageMirrors/Bukdu.jl\n",
      "test/renderers/html.jl\n",
      "########################################\n",
      "\n",
      "importall Bukdu\n",
      "\n",
      "type HTMLController <: ApplicationController\n",
      "end\n",
      "\n",
      "index(::HTMLController) = render(HTML, \"<p>hello</p>\")\n",
      "\n",
      "Router() do\n",
      "    get(\"/\", HTMLController, index)\n",
      "end\n",
      "\n",
      "\n",
      "using Base.Test\n",
      "conn = (Router)(get, \"/\")\n",
      "@test 200 == conn.status\n",
      "@test \"<p>hello</p>\" == conn.resp_body\n",
      "\n",
      "logs = []\n",
      "before(render, HTML) do t\n",
      "    push!(logs, \"b $t\")\n",
      "end\n",
      "after(render, HTML) do t\n",
      "    push!(logs, \"a $t\")\n",
      "end\n",
      "\n",
      "conn = (Router)(get, \"/\")\n",
      "@test [\"b <p>hello</p>\", \"a <p>hello</p>\"] == logs\n",
      "\n",
      "layout(::Layout, body) = \"\"\"<div>$body</div>\"\"\"\n",
      "show(::HTMLController) = render(HTML/Layout, \"<p>hello</p>\")\n",
      "Router() do\n",
      "    get(\"/say\", HTMLController, show)\n",
      "end\n",
      "\n",
      "before(render, HTML/Layout) do t\n",
      "    push!(logs, \"bl $t\")\n",
      "end\n",
      "after(render, HTML/Layout) do t\n",
      "    push!(logs, \"al $t\")\n",
      "end\n",
      "\n",
      "empty!(logs)\n",
      "\n",
      "conn = (Router)(get, \"/say\")\n",
      "@test 200 == conn.status\n",
      "@test \"<div><p>hello</p></div>\" == conn.resp_body\n",
      "\n",
      "@test [\"bl <p>hello</p>\",\"b <p>hello</p>\",\"a <p>hello</p>\",\"al <p>hello</p>\"] == logs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  41\n",
      "karajan9/statisticalrethinking\n",
      "exercises/ch02/2H1-4.jl\n",
      "########################################\n",
      "\n",
      "using DrWatson\n",
      "@quickactivate \"StatReth\"\n",
      "\n",
      "# %%\n",
      "\"\"\"2H1\n",
      "Pr(twins|speciesA) = 0.1\n",
      "Pr(twins|speciesB) = 0.2\n",
      "Pr(speciesA) = Pr(speciesB) = 0.5\n",
      "Pr(twins) = Pr(twins|speciesA) * Pr(speciesA) + Pr(twins|speciesB) * Pr(speciesB)\n",
      "          = 0.1 * 0.5 + 0.2 * 0.5 = 0.15\n",
      "\n",
      "Now births twins.\n",
      "\n",
      "Bayes:\n",
      "Pr(species|twins) = Pr(twins|species) * Pr(species) / Pr(twins)\n",
      "Pr(panda = speciesA|twins) = 0.1 * 0.5 / 0.15 = 1/3\n",
      "Pr(panda = speciesB|twins) = 0.2 * 0.5 / 0.15 = 2/3\n",
      "\n",
      "\n",
      "Pr(twin|panda) = Pr(twins|speciesA) * Pr(panda = speciesA) +\n",
      "                 Pr(twins|speciesB) * Pr(panda = speciesB)\n",
      "               = 0.1 * 1/3 + 0.2 * 2/3 = 0.167\n",
      "\n",
      "\"\"\"\n",
      "# %%\n",
      "\"\"\"2H2\n",
      "Pr(twins|speciesA) = 0.1\n",
      "Pr(twins|speciesB) = 0.2\n",
      "Pr(speciesA) = Pr(speciesB) = 0.5\n",
      "Pr(twins) = Pr(twins|speciesA) * Pr(speciesA) + Pr(twins|speciesB) * Pr(speciesB)\n",
      "          = 0.1 * 0.5 + 0.2 * 0.5 = 0.15\n",
      "\n",
      "Now births twins.\n",
      "\n",
      "Bayes:\n",
      "Pr(species|twins) = Pr(twins|species) * Pr(species) / Pr(twins)\n",
      "Pr(panda = speciesA|twins) = 0.1 * 0.5 / 0.15 = 1/3\n",
      "\"\"\"\n",
      "# %%\n",
      "\"\"\"2H3\n",
      "Pr(twins|speciesA) = 0.1  |  Pr(singleinfant|speciesA) = 0.9\n",
      "Pr(twins|speciesB) = 0.2  |  Pr(singleinfant|speciesB) = 0.8\n",
      "\n",
      "Now:\n",
      "Pr(speciesA) = 1/3\n",
      "Pr(speciesB) = 2/3\n",
      "Pr(twin|panda) = 0.167\n",
      "\n",
      "Pr(singleinfant) = Pr(singleinfant|speciesA) * Pr(speciesA) +\n",
      "                   Pr(singleinfant|speciesB) * Pr(speciesB)\n",
      "                 = 0.9 * 1/3 + 0.8 * 2/3 = 0.833\n",
      "\n",
      "Now births single infant.\n",
      "\n",
      "Bayes:\n",
      "Pr(species|singleinfant) = Pr(singleinfant|species) * Pr(species) / Pr(singleinfant)\n",
      "Pr(panda = speciesA|singleinfant) = 0.9 * 1/3 / 0.833 = 0.36\n",
      "\"\"\"\n",
      "# %%\n",
      "\"\"\"2H4\n",
      "I understood the test like this:\n",
      "\n",
      "                          panda is:\n",
      "                    speciesA    speciesB\n",
      "test    speciesA      0.8         0.35\n",
      "says:   speciesB      0.2         0.65\n",
      "\n",
      "Now the test comes back as speciesA.\n",
      "\n",
      "We would like to know Pr(panda = speciesA | test = speciesA).\n",
      "\n",
      "Bayes:\n",
      "Pr(test = A | panda = A) = 0.8\n",
      "Pr(panda = A) = Pr(panda = B) = 0.5\n",
      "Pr(test = A) = 0.8 * 0.5 + 0.35 * 0.5 = 0.575\n",
      "Pr(test = B) = 0.2 * 0.5 + 0.65 * 0.5 = 0.425\n",
      "\n",
      "Pr(panda = A | test = A)\n",
      "            = Pr(test = A | panda = A) * Pr(panda = A) / Pr(test = A)\n",
      "            = 0.8 * 0.5 / 0.575 = 0.696\n",
      "Pr(panda = B | test = A)\n",
      "            = Pr(test = A | panda = B) * Pr(panda = B) / Pr(test = A)\n",
      "            = 0.35 * 0.5 / 0.425 = 0.304\n",
      "\n",
      "This will be our new prior:\n",
      "=> Pr(speciesA) = 0.696\n",
      "=> Pr(speciesB) = 0.304\n",
      "\n",
      "\n",
      "Now births twins:\n",
      "We want to know: Pr(speciesA|twins)\n",
      "\n",
      "Pr(twins|speciesA) = 0.1  |  Pr(singleinfant|speciesA) = 0.9\n",
      "Pr(twins|speciesB) = 0.2  |  Pr(singleinfant|speciesB) = 0.8\n",
      "\n",
      "Bayes:\n",
      "Pr(speciesA|twins) = Pr(twins|speciesA) * Pr(speciesA) / Pr(twins)\n",
      "Pr(twins|speciesA) = 0.1\n",
      "Pr(speciesA) = 0.696\n",
      "Pr(twins) = 0.1 * 0.696 + 0.2 * 0.304 = 0.130\n",
      "=> Pr(speciesA|twins) = 0.1 * 0.696 / 0.130 = 0.535\n",
      "=> Pr(speciesB|twins) = 0.2 * 0.304 / 0.130 = 0.468\n",
      "(including some rounding errors)\n",
      "\n",
      "New priors:\n",
      "=> Pr(speciesA) = 0.535\n",
      "=> Pr(speciesB) = 0.468\n",
      "\n",
      "\n",
      "Now births twins:\n",
      "We want to know: Pr(speciesA|singleinfant)\n",
      "\n",
      "Bayes:\n",
      "Pr(speciesA|singleinfant) = Pr(singleinfant|speciesA) * Pr(speciesA) / Pr(singleinfant)\n",
      "Pr(singleinfant|speciesA) = 0.9\n",
      "Pr(speciesA) = 0.535\n",
      "Pr(singleinfant) = 0.9 * 0.535 + 0.8 * 0.468 = 0.856\n",
      "=> Pr(speciesA|twins) = 0.9 * 0.535 / 0.856 = 0.563\n",
      "=> Pr(speciesB|twins) = 0.8 * 0.468 / 0.856 = 0.437\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# %%\n",
      "using Statistics\n",
      "using BenchmarkTools\n",
      "\n",
      "function genetest(p)\n",
      "    if p == true  # panda is A\n",
      "        return rand() < 0.8\n",
      "    else          # panda is B\n",
      "        return rand() > 0.65\n",
      "    end\n",
      "end\n",
      "\n",
      "function twinbirth(p)\n",
      "    if p == true  # panda is A\n",
      "        return rand() < 0.1\n",
      "    else          # panda is B\n",
      "        return rand() < 0.2\n",
      "    end\n",
      "end\n",
      "\n",
      "function singleinfant(p)\n",
      "    if p == true  # panda is A\n",
      "        return rand() < 0.9\n",
      "    else          # panda is B\n",
      "        return rand() < 0.8\n",
      "    end\n",
      "end\n",
      "\n",
      "\n",
      "f(p) = mean(p[@. genetest(p) & twinbirth(p) & singleinfant(p)])\n",
      "\n",
      "function g(p)\n",
      "    countA = count(p) do p\n",
      "        genetest(p) && twinbirth(p) && singleinfant(p) && p\n",
      "    end\n",
      "    countB = count(p) do p\n",
      "        genetest(p) && twinbirth(p) && singleinfant(p) && !p\n",
      "    end\n",
      "    countA / (countA + countB)\n",
      "end\n",
      "\n",
      "function h(pandasA)\n",
      "    countA = 0\n",
      "    countB = 0\n",
      "    for p in pandasA\n",
      "        if genetest(p) && twinbirth(p) && singleinfant(p)\n",
      "            if p\n",
      "                countA += 1\n",
      "            else\n",
      "                countB += 1\n",
      "            end\n",
      "        end\n",
      "    end\n",
      "    countA / (countA + countB)\n",
      "end\n",
      "\n",
      "\n",
      "n = 10000000\n",
      "pandasA = rand(Bool, n)\n",
      "\n",
      "f(pandasA)\n",
      "g(pandasA)\n",
      "h(pandasA)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  42\n",
      "RalphAS/SLICOTMath.jl\n",
      "test/mb05md_test.jl\n",
      "########################################\n",
      "\n",
      "# Portions translated from SLICOT-Reference distribution\n",
      "# Copyright (c) 2002-2020 NICONET e.V.\n",
      "function run_mb05md(datfile, io=stdout)\n",
      "    NIN = 5\n",
      "    NOUT = 6\n",
      "    NMAX = 20\n",
      "    LDA = NMAX\n",
      "    LDV = NMAX\n",
      "    LDY = NMAX\n",
      "    LDWORK = 4*NMAX\n",
      "    A = Array{Float64,2}(undef, LDA,NMAX)\n",
      "    V = Array{Float64,2}(undef, LDV,NMAX)\n",
      "    Y = Array{Float64,2}(undef, LDY,NMAX)\n",
      "    VALR = Array{Float64,1}(undef, NMAX)\n",
      "    VALI = Array{Float64,1}(undef, NMAX)\n",
      "    DWORK = Array{Float64,1}(undef, LDWORK)\n",
      "    IWORK = Array{BlasInt,1}(undef, NMAX)\n",
      "    f = open(datfile,\"r\")\n",
      "    readline(f)\n",
      "    BALANC = 'N'\n",
      "    vs = split(readline(f))\n",
      "    N = parse(BlasInt, vs[1])\n",
      "    DELTA = parse(Float64, replace(vs[2],'D'=>'E'))\n",
      "    if ( N<=0 || N>NMAX )\n",
      "        @error \"Illegal N=$N\"\n",
      "    end\n",
      "\n",
      "    vs = String[]\n",
      "    _isz,_jsz = (N,N)\n",
      "    while length(vs) < _isz*_jsz\n",
      "        append!(vs, replace.(split(readline(f)),'D'=>'E'))\n",
      "    end\n",
      "    for i in 1:_isz\n",
      "       _i0 = (i-1)*_jsz\n",
      "       A[i,1:_jsz] .= parsex.(Float64, vs[_i0+1:_i0+_jsz])\n",
      "    end\n",
      "    close(f)\n",
      "    # interp call 1\n",
      "\n",
      "    INFO = SLICOT.mb05md!(BALANC, N, DELTA, A, V, Y, VALR, VALI, LDWORK)\n",
      "    @test INFO == 0\n",
      "    INFO == 0 || return\n",
      "\n",
      "# interp output 1\n",
      "    println(io, \"A:\")\n",
      "    _nc = N\n",
      "    _nr = N\n",
      "    show(io, \"text/plain\", A[1:_nr,1:_nc])\n",
      "    println(io)\n",
      "\n",
      "# unable to translate write loop:\n",
      "#  write (I), VALI(I), I = 1,N \n",
      "# interp output 2\n",
      "    println(io, \"eigvals:\")\n",
      "    show(io, \"text/plain\", VALR[1:N]+im*VALI[1:N])\n",
      "    println(io)\n",
      "\n",
      "# interp output 3\n",
      "    println(io, \"V:\")\n",
      "    _nc = N\n",
      "    _nr = N\n",
      "    show(io, \"text/plain\", V[1:_nr,1:_nc])\n",
      "    println(io)\n",
      "\n",
      "# interp output 4\n",
      "    println(io, \"Y:\")\n",
      "    _nc = N\n",
      "    _nr = N\n",
      "    show(io, \"text/plain\", Y[1:_nr,1:_nc])\n",
      "    println(io)\n",
      "\n",
      "end # run_mb05md()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  43\n",
      "JuliaAlgebra/MultivariateMoments.jl\n",
      "test/hermitian_poly.jl\n",
      "########################################\n",
      "\n",
      "using Test\n",
      "using MultivariateMoments\n",
      "\n",
      "# In SumOfSquares, we want the hermitian to be able to hold MOI variables for which\n",
      "# im * MOI.VariableIndex(i) is not a Complex{MOI.VariableIndex}\n",
      "# We test this with polynomials as it behaves similarly.\n",
      "\n",
      "@testset \"VectorizedHermitianMatrix with polynomial\" begin\n",
      "    Mod.@polyvar x y\n",
      "    function _tests(Q)\n",
      "        for i in 1:2, j in 1:2\n",
      "            @test (@inferred Q[i, j]) isa eltype(Q)\n",
      "        end\n",
      "        @test x == @inferred Q[1, 1]\n",
      "        @test x + im * y == @inferred Q[1, 2]\n",
      "        @test x - im * y == @inferred Q[2, 1]\n",
      "        @test x == @inferred Q[2, 2]\n",
      "    end\n",
      "    q = [x, x, x, y]\n",
      "    Q = VectorizedHermitianMatrix(q, 2)\n",
      "    @test eltype(Q) == polynomialtype(x * y, Complex{Int})\n",
      "    _tests(Q)\n",
      "    R = VectorizedHermitianMatrix{eltype(q), Float64}(q, 2)\n",
      "    @test eltype(R) == polynomialtype(x * y, Complex{Float64})\n",
      "    _tests(R)\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  44\n",
      "aliddell/HomotopyContinuation.jl\n",
      "test/extensive/extensive_test.jl\n",
      "########################################\n",
      "\n",
      "@testset \"Extensive tests\" begin\n",
      "    @testset \"Lines on a quintic surface in 3-space\" begin\n",
      "        sys, q₀, gamma = fano_quintic()\n",
      "        @time res = solve(\n",
      "            sys;\n",
      "            gamma = gamma,\n",
      "            target_parameters = q₀,\n",
      "            start_system = :total_degree,\n",
      "            show_progress = true,\n",
      "        )\n",
      "        @test nsolutions(res) == 2875\n",
      "        @test ndistinct_certified(certify(sys, res, q₀)) == 2875\n",
      "\n",
      "        @time poly_res = solve(sys; target_parameters = q₀, start_system = :polyhedral)\n",
      "        @test nsolutions(poly_res) == 2875\n",
      "    end\n",
      "\n",
      "    @testset \"3264\" begin\n",
      "        F = steiner()\n",
      "        p = randn(ComplexF64, 30)\n",
      "        res = solve(F; target_parameters = p)\n",
      "        @test nresults(res; only_nonsingular = true) == 3264\n",
      "        @test ndistinct_certified(certify(F, res, p)) == 3264\n",
      "\n",
      "        real_conics = [\n",
      "            10124547 // 662488724,\n",
      "            8554609 // 755781377,\n",
      "            5860508 // 2798943247,\n",
      "            -251402893 // 1016797750,\n",
      "            -25443962 // 277938473,\n",
      "            1 // 1,\n",
      "            520811 // 1788018449,\n",
      "            2183697 // 542440933,\n",
      "            9030222 // 652429049,\n",
      "            -12680955 // 370629407,\n",
      "            -24872323 // 105706890,\n",
      "            1 // 1,\n",
      "            6537193 // 241535591,\n",
      "            -7424602 // 363844915,\n",
      "            6264373 // 1630169777,\n",
      "            13097677 // 39806827,\n",
      "            -29825861 // 240478169,\n",
      "            1 // 1,\n",
      "            13173269 // 2284890206,\n",
      "            4510030 // 483147459,\n",
      "            2224435 // 588965799,\n",
      "            33318719 // 219393000,\n",
      "            92891037 // 755709662,\n",
      "            1 // 1,\n",
      "            8275097 // 452566634,\n",
      "            -19174153 // 408565940,\n",
      "            5184916 // 172253855,\n",
      "            -23713234 // 87670601,\n",
      "            28246737 // 81404569,\n",
      "            1 // 1,\n",
      "        ]\n",
      "\n",
      "        real_res = solve(\n",
      "            F,\n",
      "            solutions(res);\n",
      "            start_parameters = p,\n",
      "            target_parameters = real_conics,\n",
      "            tracker_options = (parameters = :conservative,),\n",
      "        )\n",
      "\n",
      "        @test nsolutions(real_res) == 3264\n",
      "        real_cert = certify(F, real_res, real_conics)\n",
      "        @test ndistinct_certified(real_cert) == 3264\n",
      "        @test ndistinct_real_certified(real_cert) == 3264\n",
      "\n",
      "        direct_real_res = solve(F; target_parameters = real_conics)\n",
      "        @test nresults(direct_real_res; only_nonsingular = true) == 3264\n",
      "    end\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  45\n",
      "bgctw/MTKHelpers\n",
      "src/util.jl\n",
      "########################################\n",
      "\n",
      "\"\"\"\n",
      "    cm2inch(x)\n",
      "\n",
      "Convert length in cm to inch units: 1 inch = 2.54 cm.\n",
      "\"\"\"\n",
      "cm2inch(x) = x/2.54\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "    embed_system(m;name)\n",
      "\n",
      "Embeds system `m` as the single component of a larger system.\n",
      "This helps to match the naming of the states, parameters, observables to \n",
      "the namespace of the system. \n",
      "\n",
      "```jldocstest; output=false\n",
      "using ModelingToolkit, DifferentialEquations\n",
      "using MTKHelpers\n",
      "function samplesystem(;name) \n",
      "    @variables t \n",
      "    D = Differential(t) \n",
      "    sts = @variables x(t) RHS(t)  # RHS is observed\n",
      "    ps = @parameters τ       # parameters\n",
      "    ODESystem([ RHS  ~ (1 - x)/τ, D(x) ~ RHS ], t, sts, ps; name)\n",
      "end                     \n",
      "@named m = samplesystem()\n",
      "@named sys = embed_system(m)\n",
      "\n",
      "# note that keys are `m.x`,`m.τ` or `m.RHS`.\n",
      "# Hence only m needs to be defined rather than all the states, parameters, \n",
      "# and observables of the system.\n",
      "prob = ODEProblem(sys, [m.x => 0.0], (0.0,10.0), [m.τ => 3.0])\n",
      "sol = solve(prob);\n",
      "dx1 = sol[m.RHS][1:3] \n",
      "dx2 = sol[getproperty(m,:RHS)][1:3]  # access by symbols\n",
      "\n",
      "# using Plots\n",
      "# plot(sol, vars=[m.x,m.RHS])    \n",
      "# plot(sol, vars=getproperty.(Ref(m),[:x, :RHS])) # access by symbols\n",
      "length(dx2) == 3\n",
      "# output\n",
      "true\n",
      "```\n",
      "\"\"\"\n",
      "function embed_system(m;name)\n",
      "    @named _sys_embed = ODESystem(Equation[], ModelingToolkit.get_iv(m))               \n",
      "    sys = compose(_sys_embed, [m]; name)\n",
      "    structural_simplify(sys)\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    symbol(t)\n",
      "\n",
      "Extract the inner symbol from a Term or Num object.\n",
      "\"\"\"\n",
      "function symbol(t::Term); symbol(t.f); end\n",
      "symbol(num::Num) = symbol(num.val)\n",
      "symbol(s) = Symbol(s)\n",
      "\n",
      "\"\"\"\n",
      "    strip_namespace(s)\n",
      "    \n",
      "Omit the part before the first dot.\n",
      "\"\"\"    \n",
      "function strip_namespace(s::String); match(r\"[^.₊]+$\",s).match; end\n",
      "function strip_namespace(s::Symbol); Symbol(strip_namespace(string(s))); end\n",
      "\n",
      "\"\"\"\n",
      "    statesyms(sys::ODYSystem)\n",
      "    parsyms(sys::ODYSystem)\n",
      "\n",
      "Extract the basic symbols without namespace of system states and system parameters.\n",
      "\"\"\"\n",
      "function statesyms(sys::ODESystem); symbol.(states(sys)); end\n",
      "parsyms(sys::ODESystem) = symbol.(parameters(sys))\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  46\n",
      "JuliaComputing/Azure.jl\n",
      "src/DataLakeStore/DataLakeStoreAccountManagementClient/model_CreateOrUpdateTrustedIdProviderProperties.jl\n",
      "########################################\n",
      "\n",
      "# This file was generated by the Julia Swagger Code Generator\n",
      "# Do not modify this file directly. Modify the swagger specification instead.\n",
      "\n",
      "\n",
      "mutable struct CreateOrUpdateTrustedIdProviderProperties <: SwaggerModel\n",
      "    idProvider::Any # spec type: Union{ Nothing, String } # spec name: idProvider\n",
      "\n",
      "    function CreateOrUpdateTrustedIdProviderProperties(;idProvider=nothing)\n",
      "        o = new()\n",
      "        validate_property(CreateOrUpdateTrustedIdProviderProperties, Symbol(\"idProvider\"), idProvider)\n",
      "        setfield!(o, Symbol(\"idProvider\"), idProvider)\n",
      "        o\n",
      "    end\n",
      "end # type CreateOrUpdateTrustedIdProviderProperties\n",
      "\n",
      "const _property_map_CreateOrUpdateTrustedIdProviderProperties = Dict{Symbol,Symbol}(Symbol(\"idProvider\")=>Symbol(\"idProvider\"))\n",
      "const _property_types_CreateOrUpdateTrustedIdProviderProperties = Dict{Symbol,String}(Symbol(\"idProvider\")=>\"String\")\n",
      "Base.propertynames(::Type{ CreateOrUpdateTrustedIdProviderProperties }) = collect(keys(_property_map_CreateOrUpdateTrustedIdProviderProperties))\n",
      "Swagger.property_type(::Type{ CreateOrUpdateTrustedIdProviderProperties }, name::Symbol) = Union{Nothing,eval(Base.Meta.parse(_property_types_CreateOrUpdateTrustedIdProviderProperties[name]))}\n",
      "Swagger.field_name(::Type{ CreateOrUpdateTrustedIdProviderProperties }, property_name::Symbol) =  _property_map_CreateOrUpdateTrustedIdProviderProperties[property_name]\n",
      "\n",
      "function check_required(o::CreateOrUpdateTrustedIdProviderProperties)\n",
      "    (getproperty(o, Symbol(\"idProvider\")) === nothing) && (return false)\n",
      "    true\n",
      "end\n",
      "\n",
      "function validate_property(::Type{ CreateOrUpdateTrustedIdProviderProperties }, name::Symbol, val)\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  47\n",
      "JuliaBinaryWrappers/DASKR_jll.jl\n",
      "src/wrappers/x86_64-apple-darwin-libgfortran5.jl\n",
      "########################################\n",
      "\n",
      "# Autogenerated wrapper script for DASKR_jll for x86_64-apple-darwin-libgfortran5\n",
      "export libdaskr\n",
      "\n",
      "using CompilerSupportLibraries_jll\n",
      "JLLWrappers.@generate_wrapper_header(\"DASKR\")\n",
      "JLLWrappers.@declare_library_product(libdaskr, \"@rpath/libdaskr.dylib\")\n",
      "function __init__()\n",
      "    JLLWrappers.@generate_init_header(CompilerSupportLibraries_jll)\n",
      "    JLLWrappers.@init_library_product(\n",
      "        libdaskr,\n",
      "        \"lib/libdaskr.dylib\",\n",
      "        RTLD_LAZY | RTLD_DEEPBIND,\n",
      "    )\n",
      "\n",
      "    JLLWrappers.@generate_init_footer()\n",
      "end  # __init__()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  48\n",
      "LidkeLab/BAMF.jl\n",
      "examples/matlab_old.jl\n",
      "########################################\n",
      "\n",
      "## Testing the matlab interface\n",
      "out=BAMF.matlab_DD_FlatBG(data.data,\"gauss\",1.3f0,θ_start,θ_step,len,mypdf,Int32(burnin),Int32(iterations),xystd,istd,split_std,bndpixels)\n",
      "\n",
      "# mex interface\n",
      "\n",
      "args=[MATLAB.mxarray(data.data),\n",
      "MATLAB.mxarray(\"gauss\"),MATLAB.mxarray(1.3f0),MATLAB.mxarray(θ_start),MATLAB.mxarray(θ_step),\n",
      "MATLAB.mxarray(len),MATLAB.mxarray(mypdf),MATLAB.mxarray(Int32(burnin)),MATLAB.mxarray(Int32(iterations)),\n",
      "MATLAB.mxarray(xystd),MATLAB.mxarray(istd),MATLAB.mxarray(split_std),MATLAB.mxarray(bndpixels)\n",
      "]\n",
      "\n",
      "BAMF.mextypes(args)\n",
      "BAMF.mextest(args)\n",
      "\n",
      "mapn=BAMF.matlab_DD_FlatBG_mex(args)\n",
      "\n",
      "@time mapn=BAMF.matlab_DD_FlatBG_mex_lite(args);\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  49\n",
      "JuliaTagBot/spatial_self_construction\n",
      "cl/smulCL.jl\n",
      "########################################\n",
      "\n",
      "function getSMulKernel{T <: FloatingPoint}(::Type{T})\n",
      "    nType = T == Float64 ? \"double\" : \"float\"\n",
      "\n",
      "    return \"\n",
      "        #if defined(cl_khr_fp64)  // Khronos extension available?\n",
      "        #pragma OPENCL EXTENSION cl_khr_fp64 : enable\n",
      "        #elif defined(cl_amd_fp64)  // AMD extension available?\n",
      "        #pragma OPENCL EXTENSION cl_amd_fp64 : enable\n",
      "        #endif\n",
      "\n",
      "        #define number $nType\n",
      "\n",
      "        __kernel void smul(\n",
      "                      const number s,\n",
      "                      __global const number *a,\n",
      "                      __global number *out) {\n",
      "\n",
      "        int i = get_global_id(0);\n",
      "\n",
      "        out[i] = s * a[i];\n",
      "    }\n",
      "\"\n",
      "end\n",
      "\n",
      "function smulCL!{T <: FloatingPoint}(\n",
      "    s :: Real, a_buff,\n",
      "    out_buff,\n",
      "    d1 :: Int64, d2 :: Int64,\n",
      "    ctx, queue, program, :: Type{T})\n",
      "\n",
      "    k = Kernel(program, \"smul\")\n",
      "\n",
      "    call(queue, k, d1 * d2, nothing, convert(T, s), a_buff, out_buff)\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  50\n",
      "FredericWantiez/AdvancedPS.jl\n",
      "test/resampling.jl\n",
      "########################################\n",
      "\n",
      "@testset \"resampling.jl\" begin\n",
      "    D = [0.3, 0.4, 0.3]\n",
      "    num_samples = Int(1e6)\n",
      "    rng = Random.GLOBAL_RNG\n",
      "\n",
      "    resSystematic = AdvancedPS.resample_systematic(rng, D, num_samples)\n",
      "    resStratified = AdvancedPS.resample_stratified(rng, D, num_samples)\n",
      "    resMultinomial = AdvancedPS.resample_multinomial(rng, D, num_samples)\n",
      "    resResidual = AdvancedPS.resample_residual(rng, D, num_samples)\n",
      "    AdvancedPS.resample_systematic(rng, D)\n",
      "\n",
      "    @test sum(resSystematic .== 2) ≈ (num_samples * 0.4) atol = 1e-3 * num_samples\n",
      "    @test sum(resStratified .== 2) ≈ (num_samples * 0.4) atol = 1e-3 * num_samples\n",
      "    @test sum(resMultinomial .== 2) ≈ (num_samples * 0.4) atol = 1e-2 * num_samples\n",
      "    @test sum(resResidual .== 2) ≈ (num_samples * 0.4) atol = 1e-2 * num_samples\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  51\n",
      "Mechachleopteryx/Augmentor.jl\n",
      "src/operations/flip.jl\n",
      "########################################\n",
      "\n",
      "# TODO: implement methods for n-dim arrays\n",
      "\n",
      "\"\"\"\n",
      "    FlipX <: Augmentor.AffineOperation\n",
      "\n",
      "Description\n",
      "--------------\n",
      "\n",
      "Reverses the x-order of each pixel row. Another way of describing\n",
      "it would be that it mirrors the image on the y-axis, or that it\n",
      "mirrors the image horizontally.\n",
      "\n",
      "If created using the parameter `p`, the operation will be lifted\n",
      "into `Either(p=>FlipX(), 1-p=>NoOp())`, where `p` denotes the\n",
      "probability of applying `FlipX` and `1-p` the probability for\n",
      "applying [`NoOp`](@ref). See the documentation of\n",
      "[`Either`](@ref) for more information.\n",
      "\n",
      "Usage\n",
      "--------------\n",
      "\n",
      "    FlipX()\n",
      "\n",
      "    FlipX(p)\n",
      "\n",
      "Arguments\n",
      "--------------\n",
      "\n",
      "- **`p::Number`** : Optional. Probability of applying the\n",
      "    operation. Must be in the interval [0,1].\n",
      "\n",
      "See also\n",
      "--------------\n",
      "\n",
      "[`FlipY`](@ref), [`Either`](@ref), [`augment`](@ref)\n",
      "\n",
      "Examples\n",
      "--------------\n",
      "\n",
      "```jldoctest\n",
      "julia> using Augmentor\n",
      "\n",
      "julia> img = [200 150; 50 1]\n",
      "2×2 Matrix{Int64}:\n",
      " 200  150\n",
      "  50    1\n",
      "\n",
      "julia> img_new = augment(img, FlipX())\n",
      "2×2 Matrix{Int64}:\n",
      " 150  200\n",
      "   1   50\n",
      "```\n",
      "\"\"\"\n",
      "struct FlipX <: AffineOperation end\n",
      "FlipX(p::Number) = Either(FlipX(), p)\n",
      "\n",
      "@inline supports_stepview(::Type{FlipX}) = true\n",
      "\n",
      "toaffinemap(::FlipX, img::AbstractMatrix) = recenter(@SMatrix([1. 0; 0 -1.]), center(img))\n",
      "applyeager(::FlipX, img::Array, param) = plain_array(reverse(img; dims=2))\n",
      "applyeager(op::FlipX, img::AbstractArray, param) = plain_array(applystepview(op, img, param))\n",
      "applylazy_fallback(op::FlipX, img::AbstractMatrix, param) = applystepview(op, img, param)\n",
      "\n",
      "function applystepview(::FlipX, img::AbstractMatrix, param)\n",
      "    idx = map(i->1:1:length(i), axes(img))\n",
      "    indirect_view(img, (idx[1], reverse(idx[2])))\n",
      "end\n",
      "\n",
      "function showconstruction(io::IO, op::FlipX)\n",
      "    print(io, typeof(op).name.name, \"()\")\n",
      "end\n",
      "\n",
      "function Base.show(io::IO, op::FlipX)\n",
      "    if get(io, :compact, false)\n",
      "        print(io, \"Flip the X axis\")\n",
      "    else\n",
      "        print(io, \"Augmentor.\")\n",
      "        showconstruction(io, op)\n",
      "    end\n",
      "end\n",
      "\n",
      "# --------------------------------------------------------------------\n",
      "\n",
      "\"\"\"\n",
      "    FlipY <: Augmentor.AffineOperation\n",
      "\n",
      "Description\n",
      "--------------\n",
      "\n",
      "Reverses the y-order of each pixel column. Another way of\n",
      "describing it would be that it mirrors the image on the x-axis,\n",
      "or that it mirrors the image vertically.\n",
      "\n",
      "If created using the parameter `p`, the operation will be lifted\n",
      "into `Either(p=>FlipY(), 1-p=>NoOp())`, where `p` denotes the\n",
      "probability of applying `FlipY` and `1-p` the probability for\n",
      "applying [`NoOp`](@ref). See the documentation of\n",
      "[`Either`](@ref) for more information.\n",
      "\n",
      "Usage\n",
      "--------------\n",
      "\n",
      "    FlipY()\n",
      "\n",
      "    FlipY(p)\n",
      "\n",
      "Arguments\n",
      "--------------\n",
      "\n",
      "- **`p::Number`** : Optional. Probability of applying the\n",
      "    operation. Must be in the interval [0,1].\n",
      "\n",
      "See also\n",
      "--------------\n",
      "\n",
      "[`FlipX`](@ref), [`Either`](@ref), [`augment`](@ref)\n",
      "\n",
      "Examples\n",
      "--------------\n",
      "\n",
      "```jldoctest\n",
      "julia> using Augmentor\n",
      "\n",
      "julia> img = [200 150; 50 1]\n",
      "2×2 Matrix{Int64}:\n",
      " 200  150\n",
      "  50    1\n",
      "\n",
      "julia> img_new = augment(img, FlipY())\n",
      "2×2 Matrix{Int64}:\n",
      "  50    1\n",
      " 200  150\n",
      "```\n",
      "\"\"\"\n",
      "struct FlipY <: AffineOperation end\n",
      "FlipY(p::Number) = Either(FlipY(), p)\n",
      "\n",
      "@inline supports_stepview(::Type{FlipY}) = true\n",
      "\n",
      "toaffinemap(::FlipY, img::AbstractMatrix) = recenter(@SMatrix([-1. 0; 0 1.]), center(img))\n",
      "applyeager(::FlipY, img::Array, param) = plain_array(reverse(img; dims=1))\n",
      "applyeager(op::FlipY, img::AbstractArray, param) = plain_array(applystepview(op, img, param))\n",
      "applylazy_fallback(op::FlipY, img::AbstractMatrix, param) = applystepview(op, img, param)\n",
      "\n",
      "function applystepview(::FlipY, img::AbstractMatrix, param)\n",
      "    idx = map(i->1:1:length(i), axes(img))\n",
      "    indirect_view(img, (reverse(idx[1]), idx[2]))\n",
      "end\n",
      "\n",
      "function showconstruction(io::IO, op::FlipY)\n",
      "    print(io, typeof(op).name.name, \"()\")\n",
      "end\n",
      "\n",
      "function Base.show(io::IO, op::FlipY)\n",
      "    if get(io, :compact, false)\n",
      "        print(io, \"Flip the Y axis\")\n",
      "    else\n",
      "        print(io, \"Augmentor.\")\n",
      "        showconstruction(io, op)\n",
      "    end\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  52\n",
      "Gilga/GLMakie.jl\n",
      "src/GLVisualize/visualize/image_like.jl\n",
      "########################################\n",
      "\n",
      "\"\"\"\n",
      "A matrix of colors is interpreted as an image\n",
      "\"\"\"\n",
      "_default(::Node{Array{RGBA{N0f8}, 2}}, ::Style{:default}, ::Dict{Symbol,Any})\n",
      "\n",
      "\n",
      "function _default(main::MatTypes{T}, ::Style, data::Dict) where T <: Colorant\n",
      "    @gen_defaults! data begin\n",
      "        spatialorder = \"yx\"\n",
      "    end\n",
      "    if !(spatialorder in (\"xy\", \"yx\"))\n",
      "        error(\"Spatial order only accepts \\\"xy\\\" or \\\"yz\\\" as a value. Found: $spatialorder\")\n",
      "    end\n",
      "    ranges = get(data, :ranges) do\n",
      "        const_lift(main, spatialorder) do m, s\n",
      "            (0:size(m, s == \"xy\" ? 1 : 2), 0:size(m, s == \"xy\" ? 2 : 1))\n",
      "        end\n",
      "    end\n",
      "    delete!(data, :ranges)\n",
      "    @gen_defaults! data begin\n",
      "        image = main => (Texture, \"image, can be a Texture or Array of colors\")\n",
      "        primitive = const_lift(ranges) do r\n",
      "            x, y = minimum(r[1]), minimum(r[2])\n",
      "            xmax, ymax = maximum(r[1]), maximum(r[2])\n",
      "            return FRect2D(x, y, xmax - x, ymax - y)\n",
      "        end => to_uvmesh\n",
      "        preferred_camera = :orthographic_pixel\n",
      "        fxaa = false\n",
      "        shader = GLVisualizeShader(\"fragment_output.frag\", \"uv_vert.vert\", \"texture.frag\",\n",
      "            view = Dict(\"uv_swizzle\" => \"o_uv.$(spatialorder)\"))\n",
      "    end\n",
      "end\n",
      "\n",
      "function to_uvmesh(geom)\n",
      "    return NativeMesh(const_lift(GeometryBasics.uv_mesh, geom))\n",
      "end\n",
      "\n",
      "function to_plainmesh(geom)\n",
      "    return NativeMesh(const_lift(GeometryBasics.triangle_mesh, geom))\n",
      "end\n",
      "\n",
      "function to_uvwmesh3d(geom)\n",
      "    return NativeMesh(const_lift(GeometryBasics.uvw_triangle_mesh, geom))\n",
      "end\n",
      "\n",
      "function _default(main::VectorTypes{T}, ::Style, data::Dict) where T <: Colorant\n",
      "    @gen_defaults! data begin\n",
      "        image = main => Texture\n",
      "        primitive = FRect2D(0f0, 0f0, length(to_value(main)), 50f0) => to_uvmesh\n",
      "        fxaa = false\n",
      "        shader = GLVisualizeShader(\n",
      "            \"fragment_output.frag\", \"uv_vert.vert\", \"texture.frag\",\n",
      "            view = Dict(\"uv_swizzle\" => \"o_uv.xy\")\n",
      "        )\n",
      "    end\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "A matrix of Intensities will result in a contourf kind of plot\n",
      "\"\"\"\n",
      "function gl_heatmap(main::MatTypes{T}, data::Dict) where T <: AbstractFloat\n",
      "    main_v = to_value(main)\n",
      "    @gen_defaults! data begin\n",
      "        ranges = (0:size(main_v, 1), 0:size(main_v, 2))\n",
      "    end\n",
      "    prim = const_lift(data[:ranges]) do ranges\n",
      "        x, y, xw, yh = minimum(ranges[1]), minimum(ranges[2]), maximum(ranges[1]), maximum(ranges[2])\n",
      "        return FRect2D(x, y, xw-x, yh-y)\n",
      "    end\n",
      "    delete!(data, :ranges)\n",
      "    @gen_defaults! data begin\n",
      "        intensity = main => Texture\n",
      "        color_map = default(Vector{RGBA{N0f8}},s) => Texture\n",
      "        primitive = prim => to_uvmesh\n",
      "        nan_color = RGBAf0(1, 0, 0, 1)\n",
      "        color_norm = const_lift(extrema2f0, main)\n",
      "        stroke_width::Float32 = 0.05f0\n",
      "        levels::Float32 = 5f0\n",
      "        stroke_color = RGBA{Float32}(1,1,1,1)\n",
      "        shader = GLVisualizeShader(\"fragment_output.frag\", \"uv_vert.vert\", \"intensity.frag\")\n",
      "        fxaa = false\n",
      "    end\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "Float matrix with the style distancefield will be interpreted as a distancefield.\n",
      "A distancefield is describing a shape, with positive values denoting the inside\n",
      "of the shape, negative values the outside and 0 the border\n",
      "\"\"\"\n",
      "function _default(main::MatTypes{T}, s::style\"distancefield\", data::Dict) where T <: AbstractFloat\n",
      "    @gen_defaults! data begin\n",
      "        distancefield = main => Texture\n",
      "        shape = DISTANCEFIELD\n",
      "        fxaa = false\n",
      "    end\n",
      "    rect = FRect2D(0f0,0f0, size(to_value(main))...)\n",
      "    _default((rect, Point2f0[0]), s, data)\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "Takes a shader as a parametric function. The shader should contain a function stubb\n",
      "like this:\n",
      "```GLSL\n",
      "uniform float arg1; // you can add arbitrary uniforms and supply them via the keyword args\n",
      "float function(float x) {\n",
      " return arg1*sin(1/tan(x));\n",
      "}\n",
      "```\n",
      "\"\"\"\n",
      "_default(func::String, s::Style{:shader}, data::Dict) = @gen_defaults! data begin\n",
      "    color = default(RGBA, s) => Texture\n",
      "    dimensions = (120f0, 120f0)\n",
      "    primitive = FRect2D(0f0,0f0, dimensions...) => to_uvmesh\n",
      "    fxaa = false\n",
      "    shader = GLVisualizeShader(\n",
      "        \"fragment_output.frag\", \"parametric.vert\", \"parametric.frag\",\n",
      "        view = Dict(\"function\" => func)\n",
      "    )\n",
      "end\n",
      "\n",
      "#Volumes\n",
      "const VolumeElTypes = Union{Gray, AbstractFloat}\n",
      "\n",
      "const default_style = Style{:default}()\n",
      "\n",
      "function _default(a::VolumeTypes{T}, s::Style{:iso}, data::Dict) where T <: VolumeElTypes\n",
      "    data = @gen_defaults! data begin\n",
      "        isovalue  = 0.5f0\n",
      "        algorithm = IsoValue\n",
      "    end\n",
      "     _default(a, default_style, data)\n",
      "end\n",
      "\n",
      "function _default(a::VolumeTypes{T}, s::Style{:absorption}, data::Dict) where T<:VolumeElTypes\n",
      "    data = @gen_defaults! data begin\n",
      "        absorption = 1f0\n",
      "        algorithm  = Absorption\n",
      "    end\n",
      "    _default(a, default_style, data)\n",
      "end\n",
      "\n",
      "function _default(a::VolumeTypes{T}, s::Style{:absorption}, data::Dict) where T<:RGBA\n",
      "    data = @gen_defaults! data begin\n",
      "        algorithm  = AbsorptionRGBA\n",
      "    end\n",
      "    _default(a, default_style, data)\n",
      "end\n",
      "\n",
      "using .GLAbstraction: StandardPrerender\n",
      "\n",
      "struct VolumePrerender\n",
      "    sp::StandardPrerender\n",
      "end\n",
      "VolumePrerender(a, b) = VolumePrerender(StandardPrerender(a, b))\n",
      "\n",
      "function (x::VolumePrerender)()\n",
      "    x.sp()\n",
      "    glEnable(GL_CULL_FACE)\n",
      "    glCullFace(GL_FRONT)\n",
      "end\n",
      "\n",
      "function _default(main::VolumeTypes{T}, s::Style, data::Dict) where T <: VolumeElTypes\n",
      "    @gen_defaults! data begin\n",
      "        volumedata = main => Texture\n",
      "        hull = FRect3D(Vec3f0(0), Vec3f0(1)) => to_plainmesh\n",
      "        model = Mat4f0(I)\n",
      "        modelinv = const_lift(inv, model)\n",
      "        color_map = default(Vector{RGBA}, s) => Texture\n",
      "        color_norm = color_map == nothing ? nothing : const_lift(extrema2f0, main)\n",
      "        color = color_map == nothing ? default(RGBA, s) : nothing\n",
      "\n",
      "        algorithm = MaximumIntensityProjection\n",
      "        absorption = 1f0\n",
      "        isovalue = 0.5f0\n",
      "        isorange = 0.01f0\n",
      "        shader = GLVisualizeShader(\"fragment_output.frag\", \"util.vert\", \"volume.vert\", \"volume.frag\")\n",
      "        prerender = VolumePrerender(data[:transparency], data[:overdraw])\n",
      "        postrender = () -> glDisable(GL_CULL_FACE)\n",
      "    end\n",
      "    return data\n",
      "end\n",
      "\n",
      "function _default(main::VolumeTypes{T}, s::Style, data::Dict) where T <: RGBA\n",
      "    @gen_defaults! data begin\n",
      "        volumedata = main => Texture\n",
      "        hull = FRect3D(Vec3f0(0), Vec3f0(1)) => to_plainmesh\n",
      "        model = Mat4f0(I)\n",
      "        modelinv = const_lift(inv, model)\n",
      "        # These don't do anything but are needed for type specification in the frag shader\n",
      "        color_map = nothing => Texture\n",
      "        color_norm = nothing\n",
      "        color = color_map == nothing ? default(RGBA, s) : nothing\n",
      "\n",
      "        algorithm = AbsorptionRGBA\n",
      "        shader = GLVisualizeShader(\"fragment_output.frag\", \"util.vert\", \"volume.vert\", \"volume.frag\")\n",
      "        prerender = VolumePrerender(data[:transparency], data[:overdraw])\n",
      "        postrender = () -> glDisable(GL_CULL_FACE)\n",
      "    end\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  53\n",
      "cscherrer/ReactiveMP.jl\n",
      "test/test_rule.jl\n",
      "########################################\n",
      "\n",
      "module ReactiveMPRuleTest\n",
      "\n",
      "using Test\n",
      "using ReactiveMP \n",
      "using MacroTools\n",
      "\n",
      "import ReactiveMP: rule_macro_parse_on_tag, rule_macro_parse_fn_args, call_rule_macro_parse_fn_args\n",
      "\n",
      "@testset \"rule\" begin\n",
      "\n",
      "    @testset \"rule_macro_parse_on_tag(expression)\" begin\n",
      "        @test rule_macro_parse_on_tag(:(:out)) == (:(Type{ Val{ :out } }), nothing, nothing)\n",
      "        @test rule_macro_parse_on_tag(:(:mean)) == (:(Type{ Val{ :mean } }), nothing, nothing)\n",
      "        @test rule_macro_parse_on_tag(:(:mean, k)) == (:(Tuple{ Val{ :mean }, Int }), :k, :(k = on[2]))\n",
      "        @test rule_macro_parse_on_tag(:(:precision, r)) == (:(Tuple{ Val{ :precision }, Int }), :r, :(r = on[2]))\n",
      "\n",
      "        @test_throws ErrorException rule_macro_parse_on_tag(:(out))\n",
      "        @test_throws ErrorException rule_macro_parse_on_tag(:(123))\n",
      "        @test_throws ErrorException rule_macro_parse_on_tag(:(:mean, 1))\n",
      "        @test_throws ErrorException rule_macro_parse_on_tag(:(precision, r))\n",
      "    end\n",
      "\n",
      "    @testset \"rule_macro_parse_fn_args(inputs; specname, prefix, proxy)\" begin\n",
      "        names, types, init = rule_macro_parse_fn_args([ (:m_out, :PointMass), (:m_mean, :NormalMeanPrecision) ]; specname = :messages, prefix = :m_, proxy = :(ReactiveMP.Message))\n",
      "\n",
      "        @test names == :(Type{ Val{ (:out, :mean) } })\n",
      "        @test types == :(Tuple{ ReactiveMP.Message{ <: PointMass }, ReactiveMP.Message{ <: NormalMeanPrecision } })\n",
      "        @test init == Expr[:(m_out = getdata(messages[1])), :(m_mean = getdata(messages[2]))]\n",
      "\n",
      "        names, types, init = rule_macro_parse_fn_args([ (:m_out, :PointMass), (:m_mean, :NormalMeanPrecision) ]; specname = :marginals, prefix = :q_, proxy = :(ReactiveMP.Marginal))\n",
      "\n",
      "        @test names == :Nothing\n",
      "        @test types == :Nothing\n",
      "        @test init == Expr[]\n",
      "\n",
      "        names, types, init = rule_macro_parse_fn_args([ (:m_out, :PointMass), (:q_mean, :NormalMeanPrecision) ]; specname = :marginals, prefix = :q_, proxy = :(ReactiveMP.Marginal))\n",
      "\n",
      "        @test names == :(Type{ Val{ (:mean, ) } })\n",
      "        @test types == :(Tuple{ ReactiveMP.Marginal{ <: NormalMeanPrecision }, })\n",
      "        @test init == Expr[ :(q_mean = getdata(marginals[1])) ]\n",
      "    end\n",
      "\n",
      "    @testset \"call_rule_macro_parse_fn_args(inputs; specname, prefix, proxy)\" begin\n",
      "        names, values = call_rule_macro_parse_fn_args([ (:m_out, :(PointMass(1.0))), (:m_mean, :(NormalMeanPrecision(0.0, 1.0))) ]; specname = :messages, prefix = :m_, proxy = :(ReactiveMP.Message))\n",
      "\n",
      "        @test names == :(Val{ (:out, :mean) })\n",
      "        @test values == :(ReactiveMP.Message(PointMass(1.0), false, false), ReactiveMP.Message(NormalMeanPrecision(0.0, 1.0), false, false))\n",
      "\n",
      "        names, values = call_rule_macro_parse_fn_args([ (:m_out, :(PointMass(1.0))), (:m_mean, :(NormalMeanPrecision(0.0, 1.0))) ]; specname = :marginals, prefix = :q_, proxy = :(ReactiveMP.Marginal))\n",
      "\n",
      "        @test names == :nothing\n",
      "        @test values == :nothing\n",
      "\n",
      "        names, values = call_rule_macro_parse_fn_args([ (:m_out, :(PointMass(1.0))), (:q_mean, :(NormalMeanPrecision(0.0, 1.0))) ]; specname = :marginals, prefix = :q_, proxy = :(ReactiveMP.Marginal))\n",
      "\n",
      "        @test names == :(Val{ (:mean, ) })\n",
      "        @test values == :((ReactiveMP.Marginal(NormalMeanPrecision(0.0, 1.0), false, false),))\n",
      "    end\n",
      "    \n",
      "end\n",
      "\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  54\n",
      "atiyo/Diffractor.jl\n",
      "docs/terminology/setindex.jl\n",
      "########################################\n",
      "\n",
      "SetIndex(idx) = Optic(\n",
      "    obj->(obj, getindex(obj, idx)),\n",
      "    (obj, update)->setindex(obj, update, idx)\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  55\n",
      "philtomson/HopfieldNets.jl\n",
      "src/HopfieldNets.jl\n",
      "########################################\n",
      "\n",
      "module HopfieldNets\n",
      "    export HopfieldNet, DiscreteHopfieldNet, ContinuousHopfieldNet\n",
      "    export update!, energy, settle!, train!, associate!, storkeytrain!\n",
      "\n",
      "    include(\"generic.jl\")\n",
      "    include(\"discrete.jl\")\n",
      "    include(\"continuous.jl\")\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  56\n",
      "Betristor/LTESOM\n",
      "src/write_outputs/write_emissions.jl\n",
      "########################################\n",
      "\n",
      "\"\"\"\n",
      "GenX: An Configurable Capacity Expansion Model\n",
      "Copyright (C) 2021,  Massachusetts Institute of Technology\n",
      "This program is free software; you can redistribute it and/or modify\n",
      "it under the terms of the GNU General Public License as published by\n",
      "the Free Software Foundation; either version 2 of the License, or\n",
      "(at your option) any later version.\n",
      "This program is distributed in the hope that it will be useful,\n",
      "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
      "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
      "GNU General Public License for more details.\n",
      "A complete copy of the GNU General Public License v2 (GPLv2) is available\n",
      "in LICENSE.txt.  Users uncompressing this from an archive may not have\n",
      "received this license file.  If not, see <http://www.gnu.org/licenses/>.\n",
      "\"\"\"\n",
      "\n",
      "@doc raw\"\"\"\n",
      "\twrite_emissions(path::AbstractString, inputs::Dict, setup::Dict, EP::Model)\n",
      "\n",
      "Function for reporting time-dependent CO$_2$ emissions by zone.\n",
      "\n",
      "\"\"\"\n",
      "function write_emissions(path::AbstractString, inputs::Dict, setup::Dict, EP::Model)\n",
      "\tdfGen = inputs[\"dfGen\"]\n",
      "\tG = inputs[\"G\"]     # Number of resources (generators, storage, DR, and DERs)\n",
      "\tT = inputs[\"T\"]     # Number of time steps (hours)\n",
      "\tZ = inputs[\"Z\"]     # Number of zones\n",
      "\tL = inputs[\"L\"]     # Number of transmission lines\n",
      "\tW = inputs[\"REP_PERIOD\"]     # Number of subperiods\n",
      "    SEG = inputs[\"SEG\"] # Number of load curtailment segments\n",
      "\n",
      "\n",
      "\tif (setup[\"WriteShadowPrices\"]==1 || setup[\"UCommit\"]==0 || (setup[\"UCommit\"]==2 && (setup[\"Reserves\"]==0 || (setup[\"Reserves\"]>0 && inputs[\"pDynamic_Contingency\"]==0)))) # fully linear model\n",
      "\t\t# CO2 emissions by zone\n",
      "\n",
      "\t\tif setup[\"CO2Cap\"]>=1\n",
      "\t\t\t# Dual variable of CO2 constraint = shadow price of CO2\n",
      "\t\t\ttempCO2Price = zeros(Z,inputs[\"NCO2Cap\"])\n",
      "\t\t\tif has_duals(EP) == 1\n",
      "\t\t\t\tfor cap in 1:inputs[\"NCO2Cap\"]\n",
      "\t\t\t\t\tfor z in findall(x->x==1, inputs[\"dfCO2CapZones\"][:,cap])\n",
      "\t\t\t\t\t\ttempCO2Price[z,cap] = dual.(EP[:cCO2Emissions_systemwide])[cap]\n",
      "\t\t\t\t\t\t# when scaled, The objective function is in unit of Million US$/kton, thus k$/ton, to get $/ton, multiply 1000\n",
      "\t\t\t\t\t\tif setup[\"ParameterScale\"] ==1\n",
      "\t\t\t\t\t\t\ttempCO2Price[z,cap] = tempCO2Price[z,cap]* ModelScalingFactor\n",
      "\t\t\t\t\t\tend\n",
      "\t\t\t\t\tend\n",
      "\t\t\t\tend\n",
      "\t\t\tend\n",
      "\t\t\tdfEmissions = hcat(DataFrame(Zone = 1:Z), DataFrame(tempCO2Price, :auto), DataFrame(AnnualSum = Array{Union{Missing,Float64}}(undef, Z)))\n",
      "\t\t\tauxNew_Names=[Symbol(\"Zone\"); [Symbol(\"CO2_Price_$cap\") for cap in 1:inputs[\"NCO2Cap\"]]; Symbol(\"AnnualSum\")]\n",
      "\t\t\trename!(dfEmissions,auxNew_Names)\n",
      "\t\telse\n",
      "\t\t\tdfEmissions = DataFrame(Zone = 1:Z, AnnualSum = Array{Union{Missing,Float32}}(undef, Z))\n",
      "\t\tend\n",
      "\n",
      "\t\tfor i in 1:Z\n",
      "\t\t\tif setup[\"ParameterScale\"]==1\n",
      "\t\t\t\tdfEmissions[!,:AnnualSum][i] = sum(inputs[\"omega\"].*value.(EP[:eEmissionsByZone])[i,:])*ModelScalingFactor\n",
      "\t\t\telse\n",
      "\t\t\t\tdfEmissions[!,:AnnualSum][i] = sum(inputs[\"omega\"].*value.(EP[:eEmissionsByZone])[i,:])/ModelScalingFactor\n",
      "\t\t\tend\n",
      "\t\tend\n",
      "\n",
      "\t\tif setup[\"ParameterScale\"]==1\n",
      "\t\t\tdfEmissions = hcat(dfEmissions, DataFrame(value.(EP[:eEmissionsByZone])*ModelScalingFactor, :auto))\n",
      "\t\telse\n",
      "\t\t\tdfEmissions = hcat(dfEmissions, DataFrame(value.(EP[:eEmissionsByZone])/ModelScalingFactor, :auto))\n",
      "\t\tend\n",
      "\n",
      "\n",
      "\t\tif setup[\"CO2Cap\"]>=1\n",
      "\t\t\tauxNew_Names=[Symbol(\"Zone\");[Symbol(\"CO2_Price_$cap\") for cap in 1:inputs[\"NCO2Cap\"]];Symbol(\"AnnualSum\");[Symbol(\"t$t\") for t in 1:T]]\n",
      "\t\t\trename!(dfEmissions,auxNew_Names)\n",
      "\t\t\ttotal = DataFrame([\"Total\" zeros(1,inputs[\"NCO2Cap\"]) sum(dfEmissions[!,:AnnualSum]) fill(0.0, (1,T))], :auto)\n",
      "\t\t\tfor t in 1:T\n",
      "\t\t\t\ttotal[:,t+inputs[\"NCO2Cap\"]+2] .= sum(dfEmissions[:,Symbol(\"t$t\")][1:Z])\n",
      "\t\t\tend\n",
      "\t\t\trename!(total,auxNew_Names)\n",
      "\t\t\tdfEmissions = vcat(dfEmissions, total)\n",
      "\t\telse\n",
      "\t\t\tauxNew_Names=[Symbol(\"Zone\"); Symbol(\"AnnualSum\"); [Symbol(\"t$t\") for t in 1:T]]\n",
      "\t\t\trename!(dfEmissions,auxNew_Names)\n",
      "\t\t\ttotal = DataFrame([\"Total\" sum(dfEmissions[!,:AnnualSum]) fill(0.0, (1,T))], :auto)\n",
      "\t\t\tfor t in 1:T\n",
      "\t\t\t\ttotal[:,t+2] .= sum(dfEmissions[:,Symbol(\"t$t\")][1:Z])\n",
      "\t\t\tend\n",
      "\t\t\trename!(total,auxNew_Names)\n",
      "\t\t\tdfEmissions = vcat(dfEmissions, total)\n",
      "\t\tend\n",
      "\n",
      "\n",
      "## Aaron - Combined elseif setup[\"Dual_MIP\"]==1 block with the first block since they were identical. Why do we have this third case? What is different about it?\n",
      "\telse\n",
      "\t\t# CO2 emissions by zone\n",
      "\t\tdfEmissions = hcat(DataFrame(Zone = 1:Z), DataFrame(AnnualSum = Array{Union{Missing,Float64}}(undef, Z)))\n",
      "\t\tfor i in 1:Z\n",
      "\t\t\tif setup[\"ParameterScale\"]==1\n",
      "\t\t\t\tdfEmissions[!,:AnnualSum][i] = sum(inputs[\"omega\"].*value.(EP[:eEmissionsByZone])[i,:]) *ModelScalingFactor\n",
      "\t\t\telse\n",
      "\t\t\t\tdfEmissions[!,:AnnualSum][i] = sum(inputs[\"omega\"].*value.(EP[:eEmissionsByZone])[i,:])/ModelScalingFactor\n",
      "\t\t\tend\n",
      "\t\tend\n",
      "\t\tif setup[\"ParameterScale\"]==1\n",
      "\t\t\tdfEmissions = hcat(dfEmissions, DataFrame(value.(EP[:eEmissionsByZone])*ModelScalingFactor, :auto))\n",
      "\t\telse\n",
      "\t\t\tdfEmissions = hcat(dfEmissions, DataFrame(value.(EP[:eEmissionsByZone])/ModelScalingFactor, :auto))\n",
      "\t\tend\n",
      "\t\tauxNew_Names=[Symbol(\"Zone\");Symbol(\"AnnualSum\");[Symbol(\"t$t\") for t in 1:T]]\n",
      "\t\trename!(dfEmissions,auxNew_Names)\n",
      "\t\ttotal = DataFrame([\"Total\" sum(dfEmissions[!,:AnnualSum]) fill(0.0, (1,T))], :auto)\n",
      "\t\tfor t in 1:T\n",
      "\t\t\ttotal[:,t+2] .= sum(dfEmissions[:,Symbol(\"t$t\")][1:Z])\n",
      "\t\tend\n",
      "\t\trename!(total,auxNew_Names)\n",
      "\t\tdfEmissions = vcat(dfEmissions, total)\n",
      "\tend\n",
      "\tCSV.write(joinpath(path, \"emissions.csv\"), dftranspose(dfEmissions, false), writeheader=false)\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  57\n",
      "manuel-rhdt/GaussianMcmc.jl\n",
      "scripts/test_cooperative_chemotaxis.jl\n",
      "########################################\n",
      "\n",
      "import PWS\n",
      "using PWS: cooperative_chemotaxis_system, TrajectoryCallback, SMCEstimate, DirectMCEstimate, marginal_configuration, MarginalEnsemble, ConditionalEnsemble, gene_expression_system, generate_configuration, logpdf\n",
      "using StaticArrays\n",
      "import Catalyst\n",
      "using DiffEqBase\n",
      "using DiffEqJump\n",
      "import ModelingToolkit\n",
      "\n",
      "system_fn = () -> PWS.cooperative_chemotaxis_system(delta_e=0, delta_f=-1, lmax=3, mmax=9, γ=1/5)\n",
      "\n",
      "sol = begin\n",
      "system = system_fn()\n",
      "step_s = PWS.Trajectory([100.0, 200, 300.0], [SA[15.0], SA[50.0], SA[15.0]], [0])\n",
      "joint = merge(merge(system.sn, system.rn), system.xn)\n",
      "rx = merge(system.rn, system.xn)\n",
      "r_idxs = PWS.species_indices(joint, Catalyst.species(system.rn))\n",
      "u0 = system.u0\n",
      "u0[1] = step_s.u[1][1]\n",
      "dprob = DiscreteProblem(rx, u0, (0.0, 100.0), vcat(system.pr, system.px))\n",
      "jprob = JumpProblem(rx, dprob, Direct(), save_positions=(false, false))\n",
      "\n",
      "cb = TrajectoryCallback(step_s)\n",
      "cb = DiscreteCallback(cb, cb, save_positions=(false, false))\n",
      "\n",
      "sol = solve(jprob, SSAStepper(), callback=cb, tstops=step_s.t, saveat=1.0)\n",
      "end\n",
      "\n",
      "using Plots\n",
      "\n",
      "function active_indices(rs, firstletter = \"A\")\n",
      "    smap = Catalyst.speciesmap(rs)\n",
      "    result = Int[]\n",
      "    for (species, index) in smap\n",
      "        sname = String(ModelingToolkit.operation(species).name)\n",
      "        if startswith(sname, firstletter)\n",
      "            push!(result, index)\n",
      "        end\n",
      "    end\n",
      "    result\n",
      "end\n",
      "\n",
      "using Transducers\n",
      "function receptor_states(rs)\n",
      "    smap = Catalyst.speciesmap(rs)\n",
      "    xf = KeepSomething() do (species, index) \n",
      "        sname = String(ModelingToolkit.operation(species).name)\n",
      "        mtch = match(r\"([A-Z])_(\\d+)_(\\d+)\", sname)\n",
      "        if mtch !== nothing\n",
      "            a = mtch.captures[1] == \"A\"\n",
      "            l = parse(Int, mtch.captures[2])\n",
      "            m = parse(Int, mtch.captures[3])\n",
      "            (a, l, m) => index\n",
      "        else\n",
      "            nothing\n",
      "        end\n",
      "    end\n",
      "    smap |> xf |> collect\n",
      "end\n",
      "\n",
      "function bound_ligands(sol, rs)\n",
      "    rstates = receptor_states(rs)\n",
      "    rstates |> Map(((a, l, m), i)::Pair -> l .* sol[i,:]) |> sum\n",
      "end\n",
      "\n",
      "function bound_methyl(sol, rs)\n",
      "    rstates = receptor_states(rs)\n",
      "    rstates |> Map(((a, l, m), i)::Pair -> m .* sol[i,:]) |> sum\n",
      "end\n",
      "\n",
      "function active_receptors(sol, rs)\n",
      "    rstates = receptor_states(rs)\n",
      "    rstates |> Map(((a, l, m), i)::Pair -> a .* sol[i,:]) |> sum\n",
      "end\n",
      "\n",
      "begin\n",
      "t = sol.t\n",
      "plot(t, vec(sol[1,:]) ./ 100, label=\"ligand concentration\")\n",
      "plot!(t, active_receptors(sol, joint) ./ 100, label=\"active fraction\")\n",
      "plot!(t, vec(sol[end-1,:]) ./ 10000, label=\"Yp / (Y+Yp)\")\n",
      "plot!(t, bound_ligands(sol, joint) ./ 300, label=\"bound receptor fraction\")\n",
      "plot!(t, bound_methyl(sol, joint) ./ (8*3*100), label=\"methylated fraction\", legend=:topleft)\n",
      "end\n",
      "\n",
      "\n",
      "savefig(plot!(dpi=144), \"~/Downloads/plot2.png\")\n",
      "\n",
      "\n",
      "# FROM JuliaMarkdown File\n",
      "\n",
      "lmax = 3\n",
      "mmax = 9\n",
      "K_a = 500\n",
      "K_i = 25\n",
      "δg = log(K_a/K_i) # ≈ 3\n",
      "\n",
      "E0 = 2.0\n",
      "δf = -2.0\n",
      "\n",
      "n_clusters = 800\n",
      "\n",
      "p_bind = 0.05\n",
      "\n",
      "γ = 1/0.5 # 1 / (adaptation time scale)\n",
      "γ_B = γ / (mmax * abs(δf))\n",
      "γ_R = γ_B / 2\n",
      "\n",
      "params = [\n",
      "    E0,\n",
      "    0.1, # in/activation timescale\n",
      "    δg,\n",
      "    δf,\n",
      "    p_bind, # ligand binding to active receptor\n",
      "    p_bind, # ligand binding to inactive receptor\n",
      "    p_bind * K_a, # ligand dissociation from active receptor\n",
      "    p_bind * K_i, # ligand dissociation from inactive receptor\n",
      "    γ_B, # demethylation of active receptor\n",
      "    γ_R  # methylation of inactive receptor\n",
      "]\n",
      "\n",
      "system = cooperative_chemotaxis_system()\n",
      "Catalyst.numreactions(system.rn) + Catalyst.numreactions(system.xn)\n",
      "\n",
      "system = cooperative_chemotaxis_system(lmax=lmax, mmax=mmax, n_clusters=n_clusters, mean_l=100)\n",
      "\n",
      "conf = generate_configuration(system)\n",
      "\n",
      "plot(conf.x_traj)\n",
      "\n",
      "cens = ConditionalEnsemble(system)\n",
      "mens = MarginalEnsemble(system)\n",
      "mconf = marginal_configuration(conf)\n",
      "\n",
      "smc = SMCEstimate(128)\n",
      "cr = PWS.simulate(smc, conf, cens)\n",
      "mr = PWS.simulate(smc, mconf, mens)\n",
      "plot(PWS.log_marginal(cr) - PWS.log_marginal(mr))\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  58\n",
      "JuliaBinaryWrappers/Ninja_jll.jl\n",
      "src/wrappers/aarch64-linux-musl-cxx11.jl\n",
      "########################################\n",
      "\n",
      "# Autogenerated wrapper script for Ninja_jll for aarch64-linux-musl-cxx11\n",
      "export ninja\n",
      "\n",
      "JLLWrappers.@generate_wrapper_header(\"Ninja\")\n",
      "JLLWrappers.@declare_executable_product(ninja)\n",
      "function __init__()\n",
      "    JLLWrappers.@generate_init_header()\n",
      "    JLLWrappers.@init_executable_product(\n",
      "        ninja,\n",
      "        \"bin/ninja\",\n",
      "    )\n",
      "\n",
      "    JLLWrappers.@generate_init_footer()\n",
      "end  # __init__()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  59\n",
      "evildmp/Mimi.jl\n",
      "src/core/connections.jl\n",
      "########################################\n",
      "\n",
      "using LightGraphs\n",
      "using MetaGraphs\n",
      "\n",
      "\"\"\"\n",
      "    disconnect_param!(obj::AbstractCompositeComponentDef, comp_def::AbstractComponentDef, param_name::Symbol)\n",
      "\n",
      "Remove any parameter connections for a given parameter `param_name` in a given component\n",
      "`comp_def` which must be a direct subcomponent of composite `obj`.\n",
      "\"\"\"\n",
      "function disconnect_param!(obj::AbstractCompositeComponentDef, comp_def::AbstractComponentDef, param_name::Symbol)\n",
      "    # If the path isn't set yet, we look for a comp in the eventual location\n",
      "    path = @or(comp_def.comp_path, ComponentPath(obj, comp_def.name))\n",
      "\n",
      "    # @info \"disconnect_param!($(obj.comp_path), $path, :$param_name)\"\n",
      "\n",
      "    if is_descendant(obj, comp_def) === nothing\n",
      "        error(\"Cannot disconnect a component ($path) that is not within the given composite ($(obj.comp_path))\")\n",
      "    end\n",
      "\n",
      "    filter!(x -> !(x.dst_comp_path == path && x.dst_par_name == param_name), obj.internal_param_conns)\n",
      "\n",
      "    if obj isa ModelDef\n",
      "        filter!(x -> !(x.comp_path == path && x.param_name == param_name), obj.external_param_conns)\n",
      "    end\n",
      "    dirty!(obj)\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    disconnect_param!(obj::AbstractCompositeComponentDef, comp_name::Symbol, param_name::Symbol)\n",
      "\n",
      "Remove any parameter connections for a given parameter `param_name` in a given component\n",
      "`comp_def` which must be a direct subcomponent of composite `obj`.\n",
      "\"\"\"\n",
      "function disconnect_param!(obj::AbstractCompositeComponentDef, comp_name::Symbol, param_name::Symbol)\n",
      "    comp = compdef(obj, comp_name)\n",
      "    comp === nothing && error(\"Did not find $comp_name in composite $(printable(obj.comp_path))\")\n",
      "    disconnect_param!(obj, comp, param_name)\n",
      "end\n",
      "\n",
      "# Default string, string unit check function\n",
      "verify_units(unit1::AbstractString, unit2::AbstractString) = (unit1 == unit2)\n",
      "\n",
      "function _check_labels(obj::AbstractCompositeComponentDef,\n",
      "                       comp_def::AbstractComponentDef, param_name::Symbol, ext_param::ArrayModelParameter)\n",
      "    param_def = parameter(comp_def, param_name)\n",
      "\n",
      "    t1 = eltype(ext_param.values)\n",
      "    t2 = eltype(param_def.datatype)\n",
      "    if !(t1 <: Union{Missing, t2})\n",
      "        error(\"Mismatched datatype of parameter connection: Component: $(comp_def.comp_id) ($t1), Parameter: $param_name ($t2)\")\n",
      "    end\n",
      "\n",
      "    comp_dims  = dim_names(param_def)\n",
      "    param_dims = dim_names(ext_param)\n",
      "\n",
      "    if ! isempty(param_dims) && size(param_dims) != size(comp_dims)\n",
      "        d1 = size(comp_dims)\n",
      "        d2 = size(param_dims)\n",
      "        error(\"Mismatched dimensions of parameter connection: Component: $(comp_def.comp_id) ($d1), Parameter: $param_name ($d2)\")\n",
      "    end\n",
      "\n",
      "    # Don't check sizes for ConnectorComps since they won't match.\n",
      "    if nameof(comp_def) in (:ConnectorCompVector, :ConnectorCompMatrix)\n",
      "        return nothing\n",
      "    end\n",
      "\n",
      "    # index_values = indexvalues(obj)\n",
      "\n",
      "    for (i, dim) in enumerate(comp_dims)\n",
      "        if isa(dim, Symbol)\n",
      "            param_length = size(ext_param.values)[i]\n",
      "            comp_length = dim_count(obj, dim)\n",
      "            if param_length != comp_length\n",
      "                error(\"Mismatched data size for a parameter connection: dimension :$dim in $(comp_def.comp_id) has $comp_length elements; external parameter :$param_name has $param_length elements.\")\n",
      "            end\n",
      "        end\n",
      "    end\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    connect_param!(obj::AbstractCompositeComponentDef, comp_name::Symbol, param_name::Symbol, ext_param_name::Symbol;\n",
      "                   check_labels::Bool=true)\n",
      "\n",
      "Connect a parameter `param_name` in the component `comp_name` of composite `obj` to\n",
      "the external parameter `ext_param_name`.\n",
      "\"\"\"\n",
      "function connect_param!(obj::AbstractCompositeComponentDef, comp_name::Symbol,\n",
      "                        param_name::Symbol, ext_param_name::Symbol;\n",
      "                        check_labels::Bool=true)\n",
      "    comp_def = compdef(obj, comp_name)\n",
      "    connect_param!(obj, comp_def, param_name, ext_param_name, check_labels=check_labels)\n",
      "end\n",
      "\n",
      "function connect_param!(obj::AbstractCompositeComponentDef, comp_def::AbstractComponentDef,\n",
      "                        param_name::Symbol, ext_param_name::Symbol; check_labels::Bool=true)\n",
      "    ext_param = external_param(obj, ext_param_name)\n",
      "\n",
      "    if ext_param isa ArrayModelParameter && check_labels\n",
      "        _check_labels(obj, comp_def, param_name, ext_param)\n",
      "    end\n",
      "\n",
      "    disconnect_param!(obj, comp_def, param_name)    # calls dirty!()\n",
      "\n",
      "    comp_path = @or(comp_def.comp_path, ComponentPath(obj.comp_path, comp_def.name))\n",
      "    conn = ExternalParameterConnection(comp_path, param_name, ext_param_name)\n",
      "    add_external_param_conn!(obj, conn)\n",
      "\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    _connect_param!(obj::AbstractCompositeComponentDef,\n",
      "        dst_comp_path::ComponentPath, dst_par_name::Symbol,\n",
      "        src_comp_path::ComponentPath, src_var_name::Symbol,\n",
      "        backup::Union{Nothing, Array}=nothing;\n",
      "        ignoreunits::Bool=false, backup_offset::Int=0)\n",
      "\n",
      "Bind the parameter `dst_par_name` of one component `dst_comp_path` of composite `obj` to a\n",
      "variable `src_var_name` in another component `src_comp_path` of the same model using\n",
      "`backup` to provide default values and the `ignoreunits` flag to indicate the need to\n",
      "check match units between the two.  The `backup_offset` argument, which is only valid \n",
      "when `backup` data has been set, indicates that the backup data should be used for\n",
      "a specified number of timesteps after the source component begins. ie. the value would be \n",
      "`1` if the destination componentm parameter should only use the source component \n",
      "data for the second timestep and beyond.\n",
      "\"\"\"\n",
      "function _connect_param!(obj::AbstractCompositeComponentDef,\n",
      "                        dst_comp_path::ComponentPath, dst_par_name::Symbol,\n",
      "                        src_comp_path::ComponentPath, src_var_name::Symbol,\n",
      "                        backup::Union{Nothing, Array}=nothing;\n",
      "                        ignoreunits::Bool=false, backup_offset::Union{Nothing, Int}=nothing)\n",
      "\n",
      "    dst_comp_def = compdef(obj, dst_comp_path)\n",
      "    src_comp_def = compdef(obj, src_comp_path)\n",
      "\n",
      "    # remove any existing connections for this dst parameter\n",
      "    disconnect_param!(obj, dst_comp_def, dst_par_name)  # calls dirty!()\n",
      "\n",
      "    # @info \"dst_comp_def: $dst_comp_def\"\n",
      "    # @info \"src_comp_def: $src_comp_def\"\n",
      "\n",
      "    if backup !== nothing\n",
      "        # If value is a NamedArray, we can check if the labels match\n",
      "        if isa(backup, NamedArray)\n",
      "            dims = dimnames(backup)\n",
      "            check_parameter_dimensions(obj, backup, dims, dst_par_name)\n",
      "        else\n",
      "            dims = nothing\n",
      "        end\n",
      "\n",
      "        # Check that the backup data is the right size\n",
      "        if size(backup) != datum_size(obj, dst_comp_def, dst_par_name)\n",
      "            error(\"Cannot connect parameter; the provided backup data is the wrong size. \",\n",
      "                  \"Expected size $(datum_size(obj, dst_comp_def, dst_par_name)) but got $(size(backup)).\")\n",
      "        end\n",
      "\n",
      "        # convert number type and, if it's a NamedArray, convert to Array\n",
      "        backup = convert(Array{Union{Missing, number_type(obj)}}, backup)\n",
      "\n",
      "        dst_param = parameter(dst_comp_def, dst_par_name)\n",
      "        dst_dims  = dim_names(dst_param)\n",
      "        dim_count = length(dst_dims)\n",
      "\n",
      "        ti = get_time_index_position(dst_param)\n",
      "\n",
      "        if ti === nothing # not time dimension\n",
      "            values = backup\n",
      "        else # handle time dimension\n",
      "\n",
      "            # get first and last of the ModelDef, NOT the ComponentDef\n",
      "            first = first_period(obj)\n",
      "            last = last_period(obj) \n",
      "\n",
      "            T = eltype(backup)\n",
      "\n",
      "            if isuniform(obj)\n",
      "                stepsize = step_size(obj)\n",
      "                values = TimestepArray{FixedTimestep{first, stepsize, last}, T, dim_count, ti}(backup)\n",
      "            else\n",
      "                times = time_labels(obj)\n",
      "                values = TimestepArray{VariableTimestep{(times...,)}, T, dim_count, ti}(backup)\n",
      "            end\n",
      "\n",
      "        end\n",
      "\n",
      "        set_external_array_param!(obj, dst_par_name, values, dst_dims)\n",
      "        backup_param_name = dst_par_name\n",
      "\n",
      "    else\n",
      "        # cannot use backup_offset keyword argument if there is no backup\n",
      "        if backup_offset !== nothing\n",
      "            error(\"Cannot set `backup_offset` keyword argument if `backup` data is not explicitly provided\")\n",
      "        end\n",
      "\n",
      "        # If backup not provided, make sure the source component covers the span of the destination component\n",
      "        src_first, src_last = first_and_last(src_comp_def)\n",
      "        dst_first, dst_last = first_and_last(dst_comp_def)\n",
      "        if (dst_first !== nothing && src_first !== nothing && dst_first < src_first) ||\n",
      "            (dst_last  !== nothing && src_last  !== nothing && dst_last  > src_last)\n",
      "            src_first = printable(src_first)\n",
      "            src_last  = printable(src_last)\n",
      "            dst_first = printable(dst_first)\n",
      "            dst_last  = printable(dst_last)\n",
      "            error(\"\"\"Cannot connect parameter: $src_comp_path runs only from $src_first to $src_last,\n",
      "whereas $dst_comp_path runs from $dst_first to $dst_last. Backup data must be provided for missing years.\n",
      "Try calling:\n",
      "    `connect_param!(m, comp_name, par_name, comp_name, var_name, backup_data)`\"\"\")\n",
      "        end\n",
      "\n",
      "        backup_param_name = nothing\n",
      "    end\n",
      "\n",
      "    # Check the units, if provided\n",
      "    if ! ignoreunits && ! verify_units(variable_unit(src_comp_def, src_var_name),\n",
      "                                       parameter_unit(dst_comp_def, dst_par_name))\n",
      "        error(\"Units of $src_comp_path:$src_var_name do not match $dst_comp_path:$dst_par_name.\")\n",
      "    end\n",
      "\n",
      "    conn = InternalParameterConnection(src_comp_path, src_var_name, dst_comp_path, dst_par_name,\n",
      "                                       ignoreunits, backup_param_name, backup_offset=backup_offset)\n",
      "    add_internal_param_conn!(obj, conn)\n",
      "\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "function connect_param!(obj::AbstractCompositeComponentDef,\n",
      "                        dst_comp_name::Symbol, dst_par_name::Symbol,\n",
      "                        src_comp_name::Symbol, src_var_name::Symbol,\n",
      "                        backup::Union{Nothing, Array}=nothing; ignoreunits::Bool=false, \n",
      "                        backup_offset::Union{Nothing, Int} = nothing)\n",
      "    _connect_param!(obj, ComponentPath(obj, dst_comp_name), dst_par_name,\n",
      "                        ComponentPath(obj, src_comp_name), src_var_name,\n",
      "                        backup; ignoreunits=ignoreunits, backup_offset=backup_offset)\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    connect_param!(obj::AbstractCompositeComponentDef,\n",
      "        dst::Pair{Symbol, Symbol}, src::Pair{Symbol, Symbol},\n",
      "        backup::Union{Nothing, Array}=nothing;\n",
      "        ignoreunits::Bool=false, backup_offset::Union{Nothing, Int} = nothing)\n",
      "\n",
      "Bind the parameter `dst[2]` of one component `dst[1]` of composite `obj`\n",
      "to a variable `src[2]` in another component `src[1]` of the same composite\n",
      "using `backup` to provide default values and the `ignoreunits` flag to indicate the need\n",
      "to check match units between the two.  The `backup_offset` argument, which is only valid \n",
      "when `backup` data has been set, indicates that the backup data should be used for\n",
      "a specified number of timesteps after the source component begins. ie. the value would be \n",
      "`1` if the destination componentm parameter should only use the source component \n",
      "data for the second timestep and beyond.\n",
      "\"\"\"\n",
      "function connect_param!(obj::AbstractCompositeComponentDef,\n",
      "                        dst::Pair{Symbol, Symbol}, src::Pair{Symbol, Symbol},\n",
      "                        backup::Union{Nothing, Array}=nothing; ignoreunits::Bool=false, \n",
      "                        backup_offset::Union{Nothing, Int} = nothing)\n",
      "    connect_param!(obj, dst[1], dst[2], src[1], src[2], backup; ignoreunits=ignoreunits, backup_offset=backup_offset)\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    split_datum_path(obj::AbstractCompositeComponentDef, s::AbstractString)\n",
      "\n",
      "Split a string of the form \"/path/to/component:datum_name\" into the component path,\n",
      "`ComponentPath(:path, :to, :component)` and name `:datum_name`.\n",
      "\"\"\"\n",
      "function split_datum_path(obj::AbstractCompositeComponentDef, s::AbstractString)\n",
      "    elts = split(s, \":\")\n",
      "    length(elts) != 2 && error(\"Cannot split datum path '$s' into ComponentPath and datum name\")\n",
      "    return (ComponentPath(obj, elts[1]), Symbol(elts[2]))\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    connection_refs(obj::AbstractCompositeComponentDef)\n",
      "\n",
      "Return a vector of UnnamedReference's to parameters from subcomponents that are either found in\n",
      "internal connections or that have been already imported in a parameter definition.\n",
      "\"\"\"\n",
      "function connection_refs(obj::AbstractCompositeComponentDef)\n",
      "    refs = UnnamedReference[]\n",
      "\n",
      "    for conn in obj.internal_param_conns\n",
      "        push!(refs, UnnamedReference(conn.dst_comp_path.names[end], conn.dst_par_name))\n",
      "    end\n",
      "\n",
      "    for item in values(obj.namespace)\n",
      "        if item isa CompositeParameterDef\n",
      "            for ref in item.refs\n",
      "                push!(refs, ref)\n",
      "            end\n",
      "        end\n",
      "    end\n",
      "\n",
      "    return refs\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    connection_refs(obj::ModelDef)\n",
      "\n",
      "Return a vector of UnnamedReference's to parameters from subcomponents that are either found in\n",
      "internal connections or that have been already connected to external parameter values.\n",
      "\"\"\"\n",
      "function connection_refs(obj::ModelDef)\n",
      "    refs = UnnamedReference[]\n",
      "\n",
      "    for conn in obj.internal_param_conns\n",
      "        push!(refs, UnnamedReference(conn.dst_comp_path.names[end], conn.dst_par_name))\n",
      "    end\n",
      "\n",
      "    for conn in obj.external_param_conns\n",
      "        push!(refs, UnnamedReference(conn.comp_path.names[end], conn.param_name))\n",
      "    end\n",
      "\n",
      "    return refs\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    unconnected_params(obj::AbstractCompositeComponentDef)\n",
      "\n",
      "Return a list of UnnamedReference's to parameters that have not been connected\n",
      "to a value.\n",
      "\"\"\"\n",
      "function unconnected_params(obj::AbstractCompositeComponentDef)\n",
      "    return setdiff(subcomp_params(obj), connection_refs(obj))\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    set_leftover_params!(m::Model, parameters::Dict)\n",
      "\n",
      "Set all of the parameters in model `m` that don't have a value and are not connected\n",
      "to some other component to a value from a dictionary `parameters`. This method assumes\n",
      "the dictionary keys are strings that match the names of unset parameters in the model.\n",
      "\"\"\"\n",
      "function set_leftover_params!(md::ModelDef, parameters::Dict{T, Any}) where T\n",
      "    for param_ref in unconnected_params(md)\n",
      "        param_name = param_ref.datum_name\n",
      "        comp_name = param_ref.comp_name\n",
      "        comp_def = find_comp(md, comp_name)\n",
      "        param_def = comp_def[param_name]\n",
      "\n",
      "        # Only set the unconnected parameter if it doesn't have a default\n",
      "        if param_def.default === nothing\n",
      "            # check whether we need to create the external parameter\n",
      "            if external_param(md, param_name, missing_ok=true) === nothing\n",
      "                if haskey(parameters, string(param_name))  \n",
      "                    value = parameters[string(param_name)]\n",
      "                    param_dims = parameter_dimensions(md, comp_name, param_name)\n",
      "\n",
      "                    set_external_param!(md, param_name, value; param_dims = param_dims)\n",
      "                else\n",
      "                    error(\"Cannot set parameter :$param_name, not found in provided dictionary and no default value detected.\")\n",
      "                end\n",
      "            end\n",
      "            connect_param!(md, comp_name, param_name, param_name)\n",
      "        end\n",
      "    end\n",
      "    nothing\n",
      "end\n",
      "\n",
      "# Find internal param conns to a given destination component\n",
      "function internal_param_conns(obj::AbstractCompositeComponentDef, dst_comp_path::ComponentPath)\n",
      "    return filter(x->x.dst_comp_path == dst_comp_path, internal_param_conns(obj))\n",
      "end\n",
      "\n",
      "function internal_param_conns(obj::AbstractCompositeComponentDef, comp_name::Symbol)\n",
      "    return internal_param_conns(obj, ComponentPath(obj.comp_path, comp_name))\n",
      "end\n",
      "\n",
      "function add_internal_param_conn!(obj::AbstractCompositeComponentDef, conn::InternalParameterConnection)\n",
      "    push!(obj.internal_param_conns, conn)\n",
      "    dirty!(obj)\n",
      "end\n",
      "\n",
      "#\n",
      "# These should all take ModelDef instead of AbstractCompositeComponentDef as 1st argument\n",
      "#\n",
      "\n",
      "# Find external param conns for a given comp\n",
      "function external_param_conns(obj::ModelDef, comp_path::ComponentPath)\n",
      "    return filter(x -> x.comp_path == comp_path, external_param_conns(obj))\n",
      "end\n",
      "\n",
      "function external_param_conns(obj::ModelDef, comp_name::Symbol)\n",
      "    return external_param_conns(obj, ComponentPath(obj.comp_path, comp_name))\n",
      "end\n",
      "\n",
      "function external_param(obj::ModelDef, name::Symbol; missing_ok=false)\n",
      "    haskey(obj.external_params, name) && return obj.external_params[name]\n",
      "\n",
      "    missing_ok && return nothing\n",
      "\n",
      "    error(\"$name not found in external parameter list\")\n",
      "end\n",
      "\n",
      "function add_external_param_conn!(obj::ModelDef, conn::ExternalParameterConnection)\n",
      "    push!(obj.external_param_conns, conn)\n",
      "    dirty!(obj)\n",
      "end\n",
      "\n",
      "function set_external_param!(obj::ModelDef, name::Symbol, value::ModelParameter)\n",
      "    # if haskey(obj.external_params, name)\n",
      "    #     @warn \"Redefining external param :$name in $(obj.comp_path) from $(obj.external_params[name]) to $value\"\n",
      "    # end\n",
      "    obj.external_params[name] = value\n",
      "    dirty!(obj)\n",
      "    return value\n",
      "end\n",
      "\n",
      "function set_external_param!(obj::ModelDef, name::Symbol, value::Number;\n",
      "                             param_dims::Union{Nothing,Array{Symbol}} = nothing)\n",
      "    set_external_scalar_param!(obj, name, value)\n",
      "end\n",
      "\n",
      "function set_external_param!(obj::ModelDef, name::Symbol,\n",
      "                             value::Union{AbstractArray, AbstractRange, Tuple};\n",
      "                             param_dims::Union{Nothing,Array{Symbol}} = nothing)\n",
      "    ti = get_time_index_position(param_dims)\n",
      "    if ti != nothing\n",
      "        value = convert(Array{number_type(obj)}, value)\n",
      "        num_dims = length(param_dims)\n",
      "        values = get_timestep_array(obj, eltype(value), num_dims, ti, value)\n",
      "    else\n",
      "        values = value\n",
      "    end\n",
      "\n",
      "    set_external_array_param!(obj, name, values, param_dims)\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    set_external_array_param!(obj::ModelDef,\n",
      "                              name::Symbol, value::TimestepVector, dims)\n",
      "\n",
      "Add a one dimensional time-indexed array parameter indicated by `name` and\n",
      "`value` to the composite `obj`.  In this case `dims` must be `[:time]`.\n",
      "\"\"\"\n",
      "function set_external_array_param!(obj::ModelDef,\n",
      "                                   name::Symbol, value::TimestepVector, dims)\n",
      "    param = ArrayModelParameter(value, [:time])  # must be :time\n",
      "    set_external_param!(obj, name, param)\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    set_external_array_param!(obj::ModelDef,\n",
      "                              name::Symbol, value::TimestepMatrix, dims)\n",
      "\n",
      "Add a multi-dimensional time-indexed array parameter `name` with value\n",
      "`value` to the composite `obj`.  In this case `dims` must be `[:time]`.\n",
      "\"\"\"\n",
      "function set_external_array_param!(obj::ModelDef,\n",
      "                                   name::Symbol, value::TimestepArray, dims)\n",
      "    param = ArrayModelParameter(value, dims === nothing ? Vector{Symbol}() : dims)\n",
      "    set_external_param!(obj, name, param)\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    set_external_array_param!(obj::ModelDef,\n",
      "                              name::Symbol, value::AbstractArray, dims)\n",
      "\n",
      "Add an array type parameter `name` with value `value` and `dims` dimensions to the composite `obj`.\n",
      "\"\"\"\n",
      "function set_external_array_param!(obj::ModelDef,\n",
      "                                   name::Symbol, value::AbstractArray, dims)\n",
      "    param = ArrayModelParameter(value, dims === nothing ? Vector{Symbol}() : dims)\n",
      "    set_external_param!(obj, name, param)\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    set_external_scalar_param!(obj::ModelDef, name::Symbol, value::Any)\n",
      "\n",
      "Add a scalar type parameter `name` with the value `value` to the composite `obj`.\n",
      "\"\"\"\n",
      "function set_external_scalar_param!(obj::ModelDef, name::Symbol, value::Any)\n",
      "    param = ScalarModelParameter(value)\n",
      "    set_external_param!(obj, name, param)\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    update_param!(obj::AbstractCompositeComponentDef, name::Symbol, value; update_timesteps = nothing)\n",
      "\n",
      "Update the `value` of an external model parameter in composite `obj`, referenced\n",
      "by `name`. The update_timesteps keyword argument is deprecated, we keep it here \n",
      "just to provide warnings.\n",
      "\"\"\"\n",
      "function update_param!(obj::AbstractCompositeComponentDef, name::Symbol, value; update_timesteps = nothing)\n",
      "    !isnothing(update_timesteps) ? @warn(\"Use of the `update_timesteps` keyword argument is no longer supported or needed, time labels will be adjusted automatically if necessary.\") : nothing\n",
      "    _update_param!(obj::AbstractCompositeComponentDef, name, value)\n",
      "end\n",
      "\n",
      "function update_param!(mi::ModelInstance, name::Symbol, value)\n",
      "    param = mi.md.external_params[name]\n",
      "\n",
      "    if param isa ScalarModelParameter\n",
      "        param.value = value\n",
      "    elseif param.values isa TimestepArray\n",
      "        copyto!(param.values.data, value)\n",
      "    else\n",
      "        copyto!(param.values, value)\n",
      "    end\n",
      "\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "function _update_param!(obj::AbstractCompositeComponentDef,\n",
      "                        name::Symbol, value)\n",
      "    param = external_param(obj, name, missing_ok=true)\n",
      "    if param === nothing\n",
      "        error(\"Cannot update parameter; $name not found in composite's external parameters.\")\n",
      "    end\n",
      "\n",
      "    if param isa ScalarModelParameter\n",
      "        _update_scalar_param!(param, name, value)\n",
      "    else\n",
      "        _update_array_param!(obj, name, value)\n",
      "    end\n",
      "\n",
      "    dirty!(obj)\n",
      "end\n",
      "\n",
      "function _update_scalar_param!(param::ScalarModelParameter, name, value)\n",
      "    if ! (value isa typeof(param.value))\n",
      "        try\n",
      "            value = convert(typeof(param.value), value)\n",
      "        catch e\n",
      "            error(\"Cannot update parameter $name; expected type $(typeof(param.value)) but got $(typeof(value)).\")\n",
      "        end\n",
      "    end\n",
      "    param.value = value\n",
      "    nothing\n",
      "end\n",
      "\n",
      "function _update_array_param!(obj::AbstractCompositeComponentDef, name, value)\n",
      "   \n",
      "    # Get original parameter\n",
      "    param = external_param(obj, name)\n",
      "\n",
      "    # Check type of provided parameter\n",
      "    if !(typeof(value) <: AbstractArray)\n",
      "        error(\"Cannot update array parameter $name with a value of type $(typeof(value)).\")\n",
      "\n",
      "    elseif !(eltype(value) <: eltype(param.values))\n",
      "        try\n",
      "            value = convert(Array{eltype(param.values)}, value)\n",
      "        catch e\n",
      "            error(\"Cannot update parameter $name; expected array of type $(eltype(param.values)) but got $(eltype(value)).\")\n",
      "        end\n",
      "    end\n",
      "\n",
      "    # Check if the parameter dimensions match the model dimensions.  Note that we \n",
      "    # previously checked if parameter dimensions matched the dimensions of the \n",
      "    # parameter they were to replace, but given dimensions of a model can be changed,\n",
      "    # we now choose to enforce that the new dimensions match the current model state, \n",
      "    # whatever that is.\n",
      "\n",
      "    expected_size = ([length(dim_keys(obj, d)) for d in dim_names(param)]...,) \n",
      "    size(value) != expected_size ? error(\"Cannot update parameter $name; expected array of size $expected_size but got array of size $(size(value)).\") : nothing\n",
      "\n",
      "    # check if updating timestep labels is necessary\n",
      "    if param.values isa TimestepArray\n",
      "        time_label_change = time_labels(param.values) != dim_keys(obj, :time)\n",
      "        N = ndims(value)\n",
      "        if time_label_change\n",
      "            T = eltype(value)\n",
      "            ti = get_time_index_position(param)\n",
      "            new_timestep_array = get_timestep_array(obj, T, N, ti, value)\n",
      "            set_external_param!(obj, name, ArrayModelParameter(new_timestep_array, dim_names(param)))\n",
      "        else\n",
      "            copyto!(param.values.data, value)\n",
      "        end\n",
      "    else\n",
      "        copyto!(param.values, value)\n",
      "    end\n",
      "\n",
      "    dirty!(obj)\n",
      "    nothing\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    update_params!(obj::AbstractCompositeComponentDef, parameters::Dict{T, Any}; update_timesteps = nothing) where T\n",
      "\n",
      "For each (k, v) in the provided `parameters` dictionary, `update_param!`\n",
      "is called to update the external parameter by name k to value v. Each key k must be a symbol or convert to a\n",
      "symbol matching the name of an external parameter that already exists in the\n",
      "component definition.\n",
      "\"\"\"\n",
      "function update_params!(obj::AbstractCompositeComponentDef, parameters::Dict; update_timesteps = nothing)\n",
      "    !isnothing(update_timesteps) ? @warn(\"Use of the `update_timesteps` keyword argument is no longer supported or needed, time labels will be adjusted automatically if necessary.\") : nothing\n",
      "    parameters = Dict(Symbol(k) => v for (k, v) in parameters)\n",
      "    for (param_name, value) in parameters\n",
      "        _update_param!(obj, param_name, value)\n",
      "    end\n",
      "    nothing\n",
      "end\n",
      "\n",
      "function add_connector_comps!(obj::AbstractCompositeComponentDef)\n",
      "    conns = internal_param_conns(obj)\n",
      "    i = 1 # counter to track the number of connector comps added\n",
      "\n",
      "    for comp_def in compdefs(obj)\n",
      "        comp_name = nameof(comp_def)\n",
      "        comp_path = comp_def.comp_path\n",
      "\n",
      "        # first need to see if we need to add any connector components for this component\n",
      "        internal_conns  = filter(x -> x.dst_comp_path == comp_path, conns)\n",
      "        need_conn_comps = filter(x -> x.backup !== nothing, internal_conns)\n",
      "\n",
      "        # isempty(need_conn_comps) || @info \"Need connectors comps: $need_conn_comps\"\n",
      "\n",
      "        for conn in need_conn_comps\n",
      "            add_backup!(obj, conn.backup)\n",
      "\n",
      "            num_dims = length(size(external_param(obj, conn.backup).values))\n",
      "\n",
      "            if ! (num_dims in (1, 2))\n",
      "                error(\"Connector components for parameters with > 2 dimensions are not implemented.\")\n",
      "            end\n",
      "\n",
      "            # Fetch the definition of the appropriate connector commponent\n",
      "            conn_comp_def = (num_dims == 1 ? Mimi.ConnectorCompVector : Mimi.ConnectorCompMatrix)\n",
      "            conn_comp_name = connector_comp_name(i) # generate a new name\n",
      "            i += 1 # increment connector comp counter\n",
      "\n",
      "            # Add the connector component before the user-defined component that \n",
      "            # required it, and for now let the first and last of the component \n",
      "            # be free and thus be set to the same as the model\n",
      "            conn_comp = add_comp!(obj, conn_comp_def, conn_comp_name, before=comp_name)\n",
      "            conn_path = conn_comp.comp_path\n",
      "\n",
      "            # add a connection between src_component and the ConnectorComp\n",
      "            add_internal_param_conn!(obj, InternalParameterConnection(conn.src_comp_path, conn.src_var_name,\n",
      "                                                                      conn_path, :input1,\n",
      "                                                                      conn.ignoreunits))\n",
      "\n",
      "            # add a connection between ConnectorComp and dst_component\n",
      "            add_internal_param_conn!(obj, InternalParameterConnection(conn_path, :output,\n",
      "                                                                      conn.dst_comp_path, conn.dst_par_name,\n",
      "                                                                      conn.ignoreunits))\n",
      "\n",
      "            # add a connection between ConnectorComp and the external backup data\n",
      "            add_external_param_conn!(obj, ExternalParameterConnection(conn_path, :input2, conn.backup))\n",
      "\n",
      "            # set the first and last parameters for WITHIN the component which \n",
      "            # decide when backup is used and when connection is used\n",
      "            src_comp_def = compdef(obj, conn.src_comp_path)\n",
      "\n",
      "            param_last = last_period(obj, src_comp_def)\n",
      "            param_first = first_period(obj, src_comp_def)\n",
      "            conn.backup_offset !== nothing ? param_first = param_first + conn.backup_offset : nothing\n",
      "\n",
      "            set_param!(obj, conn_comp_name, :first, Symbol(conn_comp_name, \"_\", :first), param_first)\n",
      "            set_param!(obj, conn_comp_name, :last, Symbol(conn_comp_name, \"_\", :last), param_last)\n",
      "        end\n",
      "    end\n",
      "\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "    _pad_parameters!(obj::ModelDef)\n",
      "\n",
      "Take each external parameter of the Model Definition `obj` and `update_param!` \n",
      "with new data values that are altered to match a new time dimension by (1) trimming\n",
      "the values down if the time dimension has been shortened and (2) padding with missings \n",
      "as necessary.\n",
      "\"\"\"\n",
      "function _pad_parameters!(obj::ModelDef)\n",
      "\n",
      "    model_times = time_labels(obj)\n",
      "\n",
      "    for (name, param) in obj.external_params\n",
      "        if (param isa ArrayModelParameter) && (:time in param.dim_names)\n",
      "\n",
      "           param_times = _get_param_times(param)\n",
      "           padded_data = _get_padded_data(param, param_times, model_times)\n",
      "           update_param!(obj, name, padded_data)\n",
      "\n",
      "        end\n",
      "    end\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    _get_padded_data(param::ArrayModelParameter, param_times::Vector, model_times::Vector)\n",
      "\n",
      "Obtain the new data values for the Array Model Paramter `param` with current \n",
      "time labels `param_times` such that they are altered to match a new time dimension \n",
      "with keys `model_times` by (1) trimming the values down if the time dimension has \n",
      "been shortened and (2) padding with missings as necessary.\n",
      "\"\"\"\n",
      "function _get_padded_data(param::ArrayModelParameter, param_times::Vector, model_times::Vector)\n",
      "\n",
      "    data = param.values.data\n",
      "    ti = get_time_index_position(param)\n",
      "\n",
      "    # first handle the back end \n",
      "    model_last = last(model_times)\n",
      "    param_last = last(param_times)\n",
      "\n",
      "    if model_last < param_last # trim down the data\n",
      "        \n",
      "        trim_idx = findfirst(isequal(last(model_times)), param_times) \n",
      "        idxs = repeat(Any[:], ndims(data))\n",
      "        idxs[ti] = 1:trim_idx\n",
      "        data = data[idxs...]\n",
      "\n",
      "    elseif model_last > param_last # pad the data\n",
      "\n",
      "        pad_length = length(model_times[findfirst(isequal(param_last), model_times)+1:end])\n",
      "        dims = [size(data)...]\n",
      "        dims[ti] = pad_length\n",
      "        end_padding_rows = Array{Union{Missing, Number}}(missing, dims...)\n",
      "        data = vcat(data, end_padding_rows)\n",
      "\n",
      "    end\n",
      "\n",
      "    # now handle the front end \n",
      "    model_first = first(model_times)\n",
      "    param_first = first(param_times)\n",
      "\n",
      "    # note we do not allow for any trimming off the front end\n",
      "    if model_first < param_first\n",
      "\n",
      "        pad_length = length(model_times[1:findfirst(isequal(param_first), model_times)-1])\n",
      "        dims = [size(data)...]\n",
      "        dims[ti] = pad_length\n",
      "        begin_padding_rows = Array{Union{Missing, Number}}(missing, dims...)\n",
      "        data = vcat(begin_padding_rows, data)\n",
      "\n",
      "    end\n",
      "\n",
      "    return data \n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    _get_param_times(param::ArrayModelParameter{TimestepArray{FixedTimestep{FIRST, STEP, LAST}, T, N, ti, S}})\n",
      "\n",
      "Return the time labels that parameterize the `TimestepValue` which in turn parameterizes\n",
      "the ArrayModelParameter `param`. \n",
      "\"\"\"\n",
      "function _get_param_times(param::ArrayModelParameter{TimestepArray{FixedTimestep{FIRST, STEP, LAST}, T, N, ti, S}}) where {FIRST, STEP, LAST, T, N, ti, S}\n",
      "    return collect(FIRST:STEP:LAST)\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    _get_param_times(param::ArrayModelParameter{TimestepArray{VariableTimestep{TIMES}, T, N, ti, S}})\n",
      "\n",
      "Return the time labels that parameterize the `TimestepValue` which in turn parameterizes\n",
      "the ArrayModelParameter `param`. \n",
      "\"\"\"\n",
      "function _get_param_times(param::ArrayModelParameter{TimestepArray{VariableTimestep{TIMES}, T, N, ti, S}}) where {TIMES, T, N, ti, S}\n",
      "    return [TIMES...]\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  60\n",
      "rigetti/QSimulator.jl\n",
      "src/composite-systems.jl\n",
      "########################################\n",
      "\n",
      "export ## Types\n",
      "       ## Methods\n",
      "       unitary_propagator\n",
      "\n",
      "CompositeQSystem() = CompositeQSystem(QSystem[],\n",
      "                                      Interaction[],\n",
      "                                      ParametricInteraction[],\n",
      "                                      Tuple{Vector{IndexSet},Vector{IndexSet},Vector{IndexSet}}[],\n",
      "                                      Tuple{Vector{IndexSet},Vector{IndexSet},Vector{IndexSet}}[],\n",
      "                                      Tuple{Vector{IndexSet},Vector{IndexSet},Vector{IndexSet}}[],\n",
      "                                      Dissipation[])\n",
      "\n",
      "function getindex(c::CompositeQSystem, key::AbstractString)\n",
      "    for s in c.subSystems\n",
      "        if label(s) == key\n",
      "            return s\n",
      "        end\n",
      "    end\n",
      "    throw(KeyError(key))\n",
      "end\n",
      "\n",
      "+(s1::QSystem, s2::QSystem) = (c = CompositeQSystem(); c += s1; c += s2; c)\n",
      "+(s::QSystem, i::Interaction) = (c = CompositeQSystem(); c += s; c += i; c)\n",
      "\n",
      "function +(c::CompositeQSystem, q::QSystem)\n",
      "    append!(c.subSystems, [q])\n",
      "    update_expansion_indices!(c)\n",
      "    return c\n",
      "end\n",
      "\n",
      "function +(c::CompositeQSystem, i::Interaction)\n",
      "    append!(c.interactions, [i])\n",
      "    update_expansion_indices!(c)\n",
      "    return c\n",
      "end\n",
      "\n",
      "function +(c::CompositeQSystem, pi::ParametricInteraction)\n",
      "    append!(c.parametericInteractions, [pi])\n",
      "    return c\n",
      "end\n",
      "\n",
      "function +(c::CompositeQSystem, d::Dissipation)\n",
      "    append!(c.dissipators, [d])\n",
      "    update_expansion_indices!(c)\n",
      "    return c\n",
      "end\n",
      "\n",
      "function update_expansion_indices!(c::CompositeQSystem)\n",
      "    ddims = [dims(c); dims(c)]\n",
      "    subsystems = length(c.subSystems)\n",
      "\n",
      "    c.subSystemExpansions = [(IndexSet[],IndexSet[],IndexSet[]) for _ = 1:length(c.subSystems)]\n",
      "    for (ct, sys) in enumerate(c.subSystems)\n",
      "        c.subSystemExpansions[ct] = (expand_indices([ct], dims(c)),            # operator\n",
      "                                     expand_indices([ct], ddims),              # superoperator right\n",
      "                                     expand_indices([ct.+subsystems], ddims))   # superoperator left\n",
      "    end\n",
      "\n",
      "    c.interactionExpansions = [(IndexSet[],IndexSet[],IndexSet[]) for _ = 1:length(c.interactions)]\n",
      "    for (ct, i) in enumerate(c.interactions)\n",
      "        pos_list = find_subsystem_pos(c,i)\n",
      "        c.interactionExpansions[ct] = (expand_indices(pos_list, dims(c)), # operator\n",
      "                                       expand_indices(pos_list, ddims),   # superoperator right\n",
      "                                       expand_indices(map(x->x.+subsystems,pos_list), ddims)) #superoperator left\n",
      "    end\n",
      "\n",
      "    c.dissipatorExpansions = [(IndexSet[], IndexSet[], IndexSet[]) for _ = 1:length(c.dissipators)]\n",
      "    for (ct, d) in enumerate(c.dissipators)\n",
      "        subsys = find_subsystem_pos(c, d)\n",
      "        # for efficiency, we need expansion for an operator acting on the left,\n",
      "        # another for one acting on the right, and one for operators acting on both sides\n",
      "        c.dissipatorExpansions[ct]= (expand_indices( [subsys.+subsystems;], ddims),  # left\n",
      "                                     expand_indices( [subsys;], ddims),             # right\n",
      "                                     expand_indices( [subsys; subsys.+subsystems], ddims)) # bilateral\n",
      "    end\n",
      "end\n",
      "\n",
      "labels(c::CompositeQSystem) = [label(s) for s in c.subSystems]\n",
      "dims(c::CompositeQSystem) = [dim(s) for s in c.subSystems]\n",
      "dim(c::CompositeQSystem) = prod([dim(s) for s in c.subSystems])\n",
      "\n",
      "function find_subsystem_pos(c::CompositeQSystem, s::QSystem)\n",
      "    @assert s in c.subSystems \"Oops! Subsystem not found.\"\n",
      "    findall(in([s]), c.subSystems)\n",
      "end\n",
      "\n",
      "find_subsystem_pos(c::CompositeQSystem, i::Interaction) = [find_subsystem_pos(c, i.system1); find_subsystem_pos(c, i.system2)]\n",
      "find_subsystem_pos(c::CompositeQSystem, i::FluxTransmon) = find_subsystem_pos(c, i.transmon)\n",
      "find_subsystem_pos(c::CompositeQSystem, i::SemiClassicalDipole) = find_subsystem_pos(c, i.system2)\n",
      "find_subsystem_pos(c::CompositeQSystem, i::RotatingSemiClassicalDipole) = find_subsystem_pos(c, i.system2)\n",
      "\n",
      "function find_subsystem_pos(c::CompositeQSystem, d::Dissipation)\n",
      "    @assert d in c.dissipators \"Oops! Dissipator not found in composite system.\"\n",
      "    findall(in([d.system]), c.subSystems)\n",
      "end\n",
      "\n",
      "function hamiltonian(c::CompositeQSystem, t::Float64=0.0)\n",
      "\n",
      "    if length(c.subSystems) != 0\n",
      "        #Initialize Hamiltonian\n",
      "        Htot = zeros(ComplexF64, dim(c), dim(c))\n",
      "\n",
      "        #Add in all the terms\n",
      "        hamiltonian_add!(Htot, c, t)\n",
      "\n",
      "        return Htot\n",
      "    else\n",
      "        error(\"No systems added to composite system yet.\")\n",
      "    end\n",
      "end\n",
      "\n",
      "function hamiltonian_add!(Ham::AbstractMatrix{T}, c::CompositeQSystem, t::Float64) where {T<:Number}\n",
      "    #Fast system hamiltonian calculator with total Hamiltonian preallocated\n",
      "\n",
      "    #Zero the Hamiltonian memory\n",
      "    if issparse(Ham)\n",
      "        # TODO: check: is it safe to assume that we will not make liouv denser and denser?\n",
      "        rows,cols,_ = findnz(Ham)\n",
      "        for i = 1:length(rows)\n",
      "            Ham[rows[i],cols[i]] = 0.0\n",
      "        end\n",
      "    else\n",
      "        fill!(Ham, zero(eltype(Ham)))\n",
      "    end\n",
      "\n",
      "    #Update the subsystems with the parameteric interactions\n",
      "    for pi in c.parametericInteractions\n",
      "        update_params(c, pi, t)\n",
      "    end\n",
      "\n",
      "    #Add together subsystem Hamiltonians\n",
      "    for (subsys, expander) in zip(c.subSystems, c.subSystemExpansions)\n",
      "        expand_add!(Ham, hamiltonian(subsys, t), expander[1])\n",
      "    end\n",
      "\n",
      "    #Add interactions\n",
      "    for (subsys, expander) in zip(c.interactions, c.interactionExpansions)\n",
      "        expand_add!(Ham, hamiltonian(subsys,t), expander[1])\n",
      "    end\n",
      "end\n",
      "\n",
      "function liouvillian_dual_add!(liouv::Matrix{ComplexF64}, c::CompositeQSystem, t::Float64 )\n",
      "    #Fast system superoperator calculator with liouvillian preallocated\n",
      "\n",
      "    #Zero the preallocated operators\n",
      "#    liouv[:] .= 0.0  # use either .= or fill!\n",
      "    fill!(liouv, 0.0)\n",
      "\n",
      "    #Update the subsystems with the parameteric interactions\n",
      "    for pi in c.parametericInteractions\n",
      "        update_params(c, pi, t)\n",
      "    end\n",
      "\n",
      "    #Add together subsystem Hamiltonians\n",
      "    for (subsys, expander) in zip(c.subSystems, c.subSystemExpansions)\n",
      "        expand_add!(liouv, transpose(hamiltonian(subsys, t)), expander[2], mult=-1im) # superoperator right\n",
      "        expand_add!(liouv,           hamiltonian(subsys, t),  expander[3], mult= 1im) # superoperator left\n",
      "    end\n",
      "\n",
      "    #Add interactions\n",
      "    for (subsys, expander) in zip(c.interactions, c.interactionExpansions)\n",
      "        expand_add!(liouv, transpose(hamiltonian(subsys, t)), expander[2], mult=-1im) # superoperator right\n",
      "        expand_add!(liouv,           hamiltonian(subsys, t),  expander[3], mult= 1im) # superoperator left\n",
      "    end\n",
      "\n",
      "    # Add the Liouvillian for the dissipators\n",
      "    for (subsys, expander) in zip(c.dissipators, c.dissipatorExpansions)\n",
      "        expand_add!(liouv, liouvillian_left(subsys,t),  expander[1]) # left\n",
      "        expand_add!(liouv, liouvillian_right(subsys,t), expander[2]) # right\n",
      "        expand_add!(liouv, liouvillian_bilat(subsys,t), expander[3]) # bilateral\n",
      "    end\n",
      "end\n",
      "\n",
      "function liouvillian_add!(liouv::AbstractMatrix{T}, c::CompositeQSystem, t::Float64 ) where {T<:Number}\n",
      "    #Fast system superoperator calculator with liouvillian preallocated\n",
      "\n",
      "    #Zero the preallocated operators.\n",
      "    if issparse(liouv)\n",
      "        # TODO: check: is it safe to assume that we will not make liouv denser and denser?\n",
      "        rows,cols,_ = findnz(liouv)\n",
      "        for i = 1:length(rows)\n",
      "            liouv[rows[i],cols[i]] = 0.0\n",
      "        end\n",
      "    else\n",
      "        liouv[:] = 0.0\n",
      "    end\n",
      "\n",
      "    #Update the subsystems with the parameteric interactions\n",
      "    for pi in c.parametericInteractions\n",
      "        update_params(c, pi, t)\n",
      "    end\n",
      "\n",
      "    #Add together subsystem Hamiltonians\n",
      "    for (subsys, expander) in zip(c.subSystems, c.subSystemExpansions)\n",
      "        expand_add!(liouv, transpose(hamiltonian(subsys, t)), expander[2], mult= 1im) # superoperator right\n",
      "        expand_add!(liouv,           hamiltonian(subsys, t),  expander[3], mult=-1im) # superoperator left\n",
      "    end\n",
      "\n",
      "    #Add interactions\n",
      "    for (subsys, expander) in zip(c.interactions, c.interactionExpansions)\n",
      "        expand_add!(liouv, transpose(hamiltonian(subsys, t)), expander[2], mult= 1im) # superoperator right\n",
      "        expand_add!(liouv,           hamiltonian(subsys, t),  expander[3], mult=-1im) # superoperator left\n",
      "    end\n",
      "\n",
      "    # Add the Liouvillian for the dissipators\n",
      "    for (subsys, expander) in zip(c.dissipators, c.dissipatorExpansions)\n",
      "        expand_add!(liouv, liouvillian_left(subsys,t),  expander[1]) # left\n",
      "        expand_add!(liouv, liouvillian_right(subsys,t), expander[2]) # right\n",
      "        expand_add!(liouv, liouvillian_bilat(subsys,t)', expander[3]) # bilateral\n",
      "    end\n",
      "end\n",
      "\n",
      "function expand(m::Matrix, actingOn::Vector, dims::Vector)\n",
      "    #Expand an operator onto a larger Hilbert space\n",
      "    # m: matrix form of  operator\n",
      "    # actingOn: array of which subsystem index the operator should be acting on\n",
      "    # dims: array of dimensions of all the subsystems\n",
      "\n",
      "    @assert size(m, 1) == prod(dims[actingOn]) \"Oops! Dimensions of matrix do not match dims argument.\"\n",
      "\n",
      "    #Create the large matrix by tensoring on identity\n",
      "    l = length(dims)\n",
      "    eyeIndices = filter(x->!(x in actingOn), 1:l)\n",
      "    M = isempty(eyeIndices) ? m : kron(m, eye(eltype(m), prod(dims[eyeIndices])))\n",
      "\n",
      "    #Reshape into multi-dimensional array given by subsystem dimensions\n",
      "    #Since we have a matrix we repeat for rows then columns\n",
      "    M = reshape(M, tuple([dims; dims]...))\n",
      "\n",
      "    #Permute magic\n",
      "    forwardPerm = [actingOn; eyeIndices]\n",
      "    reversePerm = invperm(forwardPerm)\n",
      "    #Handle the way tensor product indices work (last subsystem is fastest)\n",
      "    reversePerm = reverse((l+1) .- reversePerm)\n",
      "    M = permutedims(M, [reversePerm; reversePerm .+ l])\n",
      "\n",
      "    #Reshape back\n",
      "    return reshape(M, prod(dims), prod(dims))\n",
      "end\n",
      "\n",
      "function expand(m::Matrix, indices::Vector, sizeM::Int )\n",
      "    M = zeros(eltype(m), (sizeM, sizeM))\n",
      "    for (ct, inds) in enumerate(indices)\n",
      "        M[inds] = m[ct]\n",
      "    end\n",
      "    return M\n",
      "end\n",
      "\n",
      "function expand_add!(M::AbstractMatrix{T}, m::AbstractMatrix{U}, indices::Vector; mult=1.0 ) where {T<:Number,U<:Number}\n",
      "    #Add to certain indices of M with terms from m according to expansion indices.\n",
      "    for ct=1:length(indices)\n",
      "        # M[indices[ct]] += m[ct]\n",
      "        for idx = indices[ct]\n",
      "            M[idx] += mult*m[ct]\n",
      "        end\n",
      "    end\n",
      "end\n",
      "\n",
      "function expand_indices(actingOn::Vector, dims::Vector)\n",
      "    #Calculate the indices for expansion\n",
      "    actingOnDim = prod(dims[actingOn])\n",
      "    sm = (actingOnDim, actingOnDim)\n",
      "    lenm = actingOnDim^2;\n",
      "    M = expand(reshape([1:lenm;], sm), actingOn, dims)\n",
      "    M_one_d = reshape(M, prod(size(M)))\n",
      "    return IndexSet[findall(M_one_d .== x) for x in 1:lenm]\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  61\n",
      "tlienart/FranklinMarkdown.jl\n",
      "test/snoop.jl\n",
      "########################################\n",
      "\n",
      "using SnoopCompile\n",
      "\n",
      "tinf = @snoopi_deep include(\"runtests.jl\")\n",
      "itrigs = inference_triggers(tinf)\n",
      "\n",
      "fitrigs = filter(itrig -> itrig.callerframes[end].linfo.def.module === FranklinParser, itrigs)\n",
      "\n",
      "# Jan 30, 3 triggers, can probably ignore.\n",
      "# July 16: itrigs has 4 elements for Base._* (probably irrelevant)\n",
      "#          fitrigs has 0 elements\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  62\n",
      "thomastaudt/MathGL.jl\n",
      "src/shortnames.jl\n",
      "########################################\n",
      "\n",
      "# shortnames.jl -- containing the code for the Shortname submodule of MathGL.jl\n",
      "using MathGL\n",
      "export MathGL\n",
      "\n",
      "# Export all types with shorter names\n",
      "typealias Graph MathGL.Graph \n",
      "typealias AbstractData MathGL.AbstractData \n",
      "typealias Graph MathGL.Graph \n",
      "typealias Data MathGL.Data \n",
      "\n",
      "export Graph, AbstractData, Graph, Data\n",
      "\n",
      "# Export all macros\n",
      "export @mglplot\n",
      "\n",
      "# Export the remaining functions or at least many of them. Should be more selective.\n",
      "adjust       =  MathGL.adjust\n",
      "alpha        =  MathGL.alpha\n",
      "ambient      =  MathGL.ambient\n",
      "arc          =  MathGL.arc\n",
      "arrowsize    =  MathGL.arrowsize\n",
      "aspect       =  MathGL.aspect\n",
      "axis         =  MathGL.axis\n",
      "axisstl      =  MathGL.axisstl\n",
      "background   =  MathGL.background\n",
      "ball         =  MathGL.ball\n",
      "barwidth     =  MathGL.barwidth\n",
      "box          =  MathGL.box\n",
      "calcscr      =  MathGL.calcscr\n",
      "calcxyz      =  MathGL.calcxyz\n",
      "circle       =  MathGL.circle\n",
      "clearframe   =  MathGL.clearframe\n",
      "clf          =  MathGL.clf\n",
      "closegif     =  MathGL.closegif\n",
      "colorid      =  MathGL.colorid\n",
      "columnplot   =  MathGL.columnplot\n",
      "combine      =  MathGL.combine\n",
      "cone         =  MathGL.cone\n",
      "contfx       =  MathGL.contfx\n",
      "contfy       =  MathGL.contfy\n",
      "contfz       =  MathGL.contfz\n",
      "contx        =  MathGL.contx\n",
      "conty        =  MathGL.conty\n",
      "contz        =  MathGL.contz\n",
      "crange       =  MathGL.crange\n",
      "crust        =  MathGL.crust\n",
      "ctick        =  MathGL.ctick\n",
      "curve        =  MathGL.curve\n",
      "cut          =  MathGL.cut\n",
      "defaultfont  =  MathGL.defaultfont\n",
      "delframe     =  MathGL.delframe\n",
      "densx        =  MathGL.densx\n",
      "densy        =  MathGL.densy\n",
      "densz        =  MathGL.densz\n",
      "dew          =  MathGL.dew\n",
      "diffuse      =  MathGL.diffuse\n",
      "dots         =  MathGL.dots\n",
      "drop         =  MathGL.drop\n",
      "ellipse      =  MathGL.ellipse\n",
      "endframe     =  MathGL.endframe\n",
      "endgroup     =  MathGL.endgroup\n",
      "errbox       =  MathGL.errbox\n",
      "#=eval         =  MathGL.eval=#\n",
      "exportmgld   =  MathGL.exportmgld\n",
      "face         =  MathGL.face\n",
      "facenum      =  MathGL.facenum\n",
      "flow         =  MathGL.flow\n",
      "fog          =  MathGL.fog\n",
      "font         =  MathGL.font\n",
      "fplot        =  MathGL.fplot\n",
      "fsurf        =  MathGL.fsurf\n",
      "getframe     =  MathGL.getframe\n",
      "getheight    =  MathGL.getheight\n",
      "getnumframe  =  MathGL.getnumframe\n",
      "getrgb       =  MathGL.getrgb\n",
      "getrgba      =  MathGL.getrgba\n",
      "getwidth     =  MathGL.getwidth\n",
      "grad         =  MathGL.grad\n",
      "gridplot     =  MathGL.gridplot\n",
      "height       =  MathGL.height\n",
      "importmgld   =  MathGL.importmgld\n",
      "inplot       =  MathGL.inplot\n",
      "light        =  MathGL.light\n",
      "line         =  MathGL.line\n",
      "loadfont     =  MathGL.loadfont\n",
      "mark         =  MathGL.mark\n",
      "marksize     =  MathGL.marksize\n",
      "mask         =  MathGL.mask\n",
      "meshnum      =  MathGL.meshnum\n",
      "mgl          =  MathGL.mgl\n",
      "mpirecv      =  MathGL.mpirecv\n",
      "mpisend      =  MathGL.mpisend\n",
      "multiplot    =  MathGL.multiplot\n",
      "newframe     =  MathGL.newframe\n",
      "numthreads   =  MathGL.numthreads\n",
      "origin       =  MathGL.origin\n",
      "origintick   =  MathGL.origintick\n",
      "palette      =  MathGL.palette\n",
      "perspective  =  MathGL.perspective\n",
      "pipe         =  MathGL.pipe\n",
      "plotfactor   =  MathGL.plotfactor\n",
      "plot         =  MathGL.plot\n",
      "plotid       =  MathGL.plotid\n",
      "polygon      =  MathGL.polygon\n",
      "quadplot     =  MathGL.quadplot\n",
      "quality      =  MathGL.quality\n",
      "ranges       =  MathGL.ranges\n",
      "rasterize    =  MathGL.rasterize\n",
      "#=reset        =  MathGL.reset=#\n",
      "resetframes  =  MathGL.resetframes\n",
      "restorefont  =  MathGL.restorefont\n",
      "rhomb        =  MathGL.rhomb\n",
      "rotate       =  MathGL.rotate\n",
      "rotatetext   =  MathGL.rotatetext\n",
      "scheme       =  MathGL.scheme\n",
      "setnumframe  =  MathGL.setnumframe\n",
      "setsize      =  MathGL.setsize\n",
      "showframe    =  MathGL.showframe\n",
      "sphere       =  MathGL.sphere\n",
      "startgif     =  MathGL.startgif\n",
      "startgroup   =  MathGL.startgroup\n",
      "stickplot    =  MathGL.stickplot\n",
      "stop         =  MathGL.stop\n",
      "subplot      =  MathGL.subplot\n",
      "surf         =  MathGL.surf\n",
      "ternary      =  MathGL.ternary\n",
      "text         =  MathGL.text\n",
      "ticklen      =  MathGL.ticklen\n",
      "tickrotate   =  MathGL.tickrotate\n",
      "tickshift    =  MathGL.tickshift\n",
      "tickskip     =  MathGL.tickskip\n",
      "title        =  MathGL.title\n",
      "transptype   =  MathGL.transptype\n",
      "traj         =  MathGL.traj\n",
      "tricont      =  MathGL.tricont\n",
      "triplot      =  MathGL.triplot\n",
      "tuneticks    =  MathGL.tuneticks\n",
      "vect         =  MathGL.vect\n",
      "vect3        =  MathGL.vect3\n",
      "view         =  MathGL.view\n",
      "width        =  MathGL.width\n",
      "writebmp     =  MathGL.writebmp\n",
      "writebps     =  MathGL.writebps\n",
      "writeeps     =  MathGL.writeeps\n",
      "#=write        =  MathGL.write=#\n",
      "writegif     =  MathGL.writegif\n",
      "writejpg     =  MathGL.writejpg\n",
      "writejson    =  MathGL.writejson\n",
      "writeobj     =  MathGL.writeobj\n",
      "writeoff     =  MathGL.writeoff\n",
      "writepng     =  MathGL.writepng\n",
      "writeprc     =  MathGL.writeprc\n",
      "writestl     =  MathGL.writestl\n",
      "writesvg     =  MathGL.writesvg\n",
      "writetex     =  MathGL.writetex\n",
      "writetga     =  MathGL.writetga\n",
      "writexyz     =  MathGL.writexyz\n",
      "xrange       =  MathGL.xrange\n",
      "xrotate      =  MathGL.xrotate\n",
      "xtick        =  MathGL.xtick\n",
      "yrange       =  MathGL.yrange\n",
      "yrotate      =  MathGL.yrotate\n",
      "ytick        =  MathGL.ytick\n",
      "zoom         =  MathGL.zoom\n",
      "zoomaxis     =  MathGL.zoomaxis\n",
      "zrange       =  MathGL.zrange\n",
      "zrotate      =  MathGL.zrotate\n",
      "ztick        =  MathGL.ztick\n",
      "\n",
      "export adjust\n",
      "export alpha\n",
      "export ambient\n",
      "export arc\n",
      "export arrowsize\n",
      "export aspect\n",
      "export axis\n",
      "export axisstl\n",
      "export background\n",
      "export ball\n",
      "export barwidth\n",
      "export box\n",
      "export calcscr\n",
      "export calcxyz\n",
      "export circle\n",
      "export clearframe\n",
      "export clf\n",
      "export closegif\n",
      "export colorid\n",
      "export columnplot\n",
      "export combine\n",
      "export cone\n",
      "export contx\n",
      "export conty\n",
      "export contz\n",
      "export contfx\n",
      "export contfy\n",
      "export contfz\n",
      "export crange\n",
      "export crust\n",
      "export ctick\n",
      "export curve\n",
      "export cut\n",
      "export defaultfont\n",
      "export delframe\n",
      "export densx\n",
      "export densy\n",
      "export densz\n",
      "export dew\n",
      "export diffuse\n",
      "export dots\n",
      "export drop\n",
      "export ellipse\n",
      "export endframe\n",
      "export endgroup\n",
      "export errbox\n",
      "#=export eval=#\n",
      "export exportmgld\n",
      "export face\n",
      "export facenum\n",
      "export flow\n",
      "export fog\n",
      "export font\n",
      "export fplot\n",
      "export fsurf\n",
      "export getframe\n",
      "export getheight\n",
      "export getnumframe\n",
      "export getrgb\n",
      "export getrgba\n",
      "export getwidth\n",
      "export grad\n",
      "export gridplot\n",
      "export height\n",
      "export importmgld\n",
      "export inplot\n",
      "export light\n",
      "export line\n",
      "export loadfont\n",
      "export mark\n",
      "export marksize\n",
      "export mask\n",
      "export meshnum\n",
      "export mgl\n",
      "export mpirecv\n",
      "export mpisend\n",
      "export multiplot\n",
      "export newframe\n",
      "export numthr\n",
      "export origin\n",
      "export origintick\n",
      "export palette\n",
      "export perspective\n",
      "export pipe\n",
      "export plotfactor\n",
      "export plot\n",
      "export plotid\n",
      "export polygon\n",
      "export quadplot\n",
      "export quality\n",
      "export ranges\n",
      "export rasterize\n",
      "export reset\n",
      "export resetframes\n",
      "export restorefont\n",
      "export rhomb\n",
      "export rotate\n",
      "export rotatetext\n",
      "export scheme\n",
      "export setnumframe\n",
      "export setsize\n",
      "export showframe\n",
      "export sphere\n",
      "export startgif\n",
      "export startgroup\n",
      "export stickplot\n",
      "export stop\n",
      "export subplot\n",
      "export surf\n",
      "export ternary\n",
      "export text\n",
      "export ticklen\n",
      "export tickrotate\n",
      "export tickshift\n",
      "export tickskip\n",
      "export title\n",
      "export transptype\n",
      "export traj\n",
      "export tricont\n",
      "export triplot\n",
      "export tuneticks\n",
      "export view\n",
      "export vect\n",
      "export vect3\n",
      "export width\n",
      "export writebmp\n",
      "export writebps\n",
      "export writeeps\n",
      "#=export write=#\n",
      "export writegif\n",
      "export writejpg\n",
      "export writejson\n",
      "export writeobj\n",
      "export writeoff\n",
      "export writepng\n",
      "export writeprc\n",
      "export writestl\n",
      "export writesvg\n",
      "export writetex\n",
      "export writetga\n",
      "export writexyz\n",
      "export xrange\n",
      "export xrotate\n",
      "export xtick\n",
      "export yrange\n",
      "export yrotate\n",
      "export ytick\n",
      "export zoom\n",
      "export zoomaxis\n",
      "export zrange\n",
      "export zrotate\n",
      "export ztick\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  63\n",
      "wildart/LMCLUS.jl\n",
      "test/mdl_test.jl\n",
      "########################################\n",
      "\n",
      "using LinearAlgebra\n",
      "using LMCLUS\n",
      "using Statistics\n",
      "using Distributions\n",
      "using Test\n",
      "import Random\n",
      "\n",
      "@testset \"MDL\" begin\n",
      "\n",
      "    @testset \"Quantization\" begin\n",
      "        @test LMCLUS.MDL.univar([1.0]) ≈ [1 ./ 12.0]\n",
      "        @test LMCLUS.MDL.optbins([1.], 1.) == [one(UInt64)]\n",
      "        bins, ɛ, c, itr = LMCLUS.MDL.optquant([1.], 1e-2)\n",
      "        @test bins[1] == 29\n",
      "        @test ɛ < 1e-2\n",
      "        bins, ɛ, c, itr = LMCLUS.MDL.optquant([Inf], 1e-2)\n",
      "        @test bins[1] == 29\n",
      "        @test ɛ < 1e-2\n",
      "        bins, ɛ, c, itr = LMCLUS.MDL.optquant([NaN], 1e-2)\n",
      "        @test bins[1] == 1\n",
      "        @test ɛ < 1e-2\n",
      "    end\n",
      "\n",
      "    @testset \"Calculations\" begin\n",
      "        # Generate manifold data\n",
      "        function generate_lm(N::Int, M::Int, C::Int,\n",
      "                        B::Matrix{Float64},\n",
      "                        bounds::Matrix{Float64}, θ::Float64,\n",
      "                        D::Symbol = :Uniform;  σs::Vector{Float64} = ones(N))\n",
      "            @assert size(bounds) == (N,2) \"Define bounds for every dimension\"\n",
      "            @assert size(B) == (N,M) \"Define bounds for every dimension\"\n",
      "            manifold = Manifold(M, zeros(N), B, round.(Int, range(1, stop=C, length=C)), θ, 0.0)\n",
      "\n",
      "            c = 1\n",
      "            X = zeros(N,C)\n",
      "            while c <= C\n",
      "                if D == :Gaussian\n",
      "                    for i in 1:N\n",
      "                        R = abs(bounds[i,2]-bounds[i,1])\n",
      "                        X[i,c] = rand(Normal(0.,σs[i]))\n",
      "                    end\n",
      "                else\n",
      "                    for i in 1:N\n",
      "                        R = abs(bounds[i,2]-bounds[i,1])\n",
      "                        X[i,c] = rand()*R - R/2.\n",
      "                    end\n",
      "                end\n",
      "                if distance_to_manifold(X[:,c], B)[1] < θ\n",
      "                    c += 1\n",
      "                end\n",
      "            end\n",
      "\n",
      "            return X, manifold\n",
      "        end\n",
      "\n",
      "        Pm = 64      # Precision encoding constant for model\n",
      "        Pd = 32      # Precision encoding constant for data\n",
      "        N = 2        # Space dimension\n",
      "        M = 1        # Linear manifold dimension\n",
      "        C = 100      # Size of a LM cluster\n",
      "        B = Matrix(I,N,M) # Basis vectors\n",
      "        bounds = hcat(fill(-1.,N), fill(1., N)) # LM cluster bounds\n",
      "        θ = 0.8      # distance threshold\n",
      "        σs = [1.0, 0.25] # diag covariances\n",
      "        ɛ = 1e-2\n",
      "        tot = 1000\n",
      "        tol = 1e-8\n",
      "\n",
      "        Random.seed!(923487298)\n",
      "        B *= rand()\n",
      "\n",
      "        Random.seed!(923487298)\n",
      "        Xg, Mg = generate_lm(N, M, C, B, bounds, θ, :Gausian; σs = σs)\n",
      "        LMCLUS.adjustbasis!(Mg, Xg)\n",
      "        @test LMCLUS.hasfullbasis(Mg)\n",
      "\n",
      "        @test LMCLUS.MDL.calculate(LMCLUS.MDL.Raw, Mg, Xg, Pm, Pd) == Pm*N*C\n",
      "        @test LMCLUS.MDL.calculate(LMCLUS.MDL.ZeroDim, Mg, Xg, Pm, Pd) == 221\n",
      "\n",
      "        @test LMCLUS.MDL.calculate(LMCLUS.MDL.Uniform, Mg, Xg, Pm, Pd)  == 5623\n",
      "        @test LMCLUS.MDL.calculate(LMCLUS.MDL.Gaussian, Mg, Xg, Pm, Pd) == 3534\n",
      "\n",
      "        # Empirical entropy from optimal quantization\n",
      "        @test LMCLUS.MDL.calculate(LMCLUS.MDL.Empirical, Mg, Xg, Pm, Pd, ɛ = 1e-2) == 3889\n",
      "        # Empirical entropy from fixed bin size quantization\n",
      "        @test LMCLUS.MDL.calculate(LMCLUS.MDL.Empirical, Mg, Xg, Pm, Pd, ɛ = 20.0) == 3808\n",
      "\n",
      "        # Optimal quantizing\n",
      "        @test LMCLUS.MDL.calculate(LMCLUS.MDL.OptimalQuant, Mg, Xg, Pm, Pd, ɛ = 1e-2) == 4093\n",
      "        @test LMCLUS.mdl(Mg, Xg, Pm, Pd, ɛ = 1e-2) == 4093\n",
      "\n",
      "        Mg.d = 0\n",
      "        @test LMCLUS.MDL.calculate(LMCLUS.MDL.SizeIndependent, Mg, Xg, Pm, Pd, ɛ = 1e-2) == 9152\n",
      "        Mg.d = 1\n",
      "        @test LMCLUS.MDL.calculate(LMCLUS.MDL.SizeIndependent, Mg, Xg, Pm, Pd, ɛ = 1e-2) == 3008\n",
      "\n",
      "        # Test size dependence\n",
      "        Random.seed!(923487298)\n",
      "        Xg, Mg = generate_lm(N, M, 10*C, B, bounds, θ, :Gausian; σs = σs)\n",
      "        LMCLUS.adjustbasis!(Mg, Xg)\n",
      "        @test LMCLUS.hasfullbasis(Mg)\n",
      "        @test LMCLUS.MDL.calculate(LMCLUS.MDL.OptimalQuant, Mg, Xg, Pm, Pd, ɛ = 1e-2) == 39306\n",
      "        @test LMCLUS.MDL.calculate(LMCLUS.MDL.SizeIndependent, Mg, Xg, Pm, Pd, ɛ = 1e-2) == 3136\n",
      "\n",
      "    end\n",
      "\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  64\n",
      "dthierry/princetonDacLti\n",
      "src/mods/lp_deb_11_d.jl\n",
      "########################################\n",
      "\n",
      "# vim: set wrap\n",
      "#: by David Thierry 2021\n",
      "#: Set all the eqns to hslice - 1\n",
      "using JuMP\n",
      "using SCIP\n",
      "using DataFrames\n",
      "using CSV\n",
      "\n",
      "#: Data frames section\n",
      "#: Load parameters\n",
      "\n",
      "df_gas = DataFrame(CSV.File(\"../reg/gas_coeffs.csv\"))\n",
      "df_steam_full_power = DataFrame(CSV.File(\"../reg/steam_coeffs.csv\"))\n",
      "df_steam_full_steam = DataFrame(CSV.File(\"../reg/steam_coeffs_v3.csv\"))\n",
      "\n",
      "#: Load Prices\n",
      "df_pow_c = DataFrame(CSV.File(\"../resources/FLECCSPriceSeriesData.csv\"))\n",
      "df_ng_c = DataFrame(CSV.File(\"../resources/natural_gas_price.csv\"))\n",
      "\n",
      "\n",
      "#: Assign parameters\n",
      "\n",
      "#: Gas parameters\n",
      "bPowGasTeLoad = df_gas[1, 2]\n",
      "aPowGasTeLoad = df_gas[1, 3]\n",
      "\n",
      "bFuelEload = df_gas[2, 2]\n",
      "aFuelEload = df_gas[2, 3]\n",
      "lbcoToTonneco = 0.4535924 / 1000\n",
      "bEmissFactEload = df_gas[3, 2] * lbcoToTonneco\n",
      "aEmissFactEload = df_gas[3, 3] * lbcoToTonneco\n",
      "\n",
      "bPowHpEload = df_gas[4, 2] / 1000  #: To scale the kW to MW\n",
      "aPowHpEload = df_gas[4, 3] / 1000\n",
      "\n",
      "bPowIpEload = df_gas[5, 2] / 1000\n",
      "aPowIpEload = df_gas[5, 3] / 1000\n",
      "\n",
      "bAuxRateGas = df_gas[6, 2] / 1000\n",
      "aAuxRateGas = df_gas[6, 3] / 1000\n",
      "\n",
      "#: Steam params\n",
      "bCcRebDutyEload = df_steam_full_steam[2, 2]\n",
      "aCcRebDutyEload = df_steam_full_steam[2, 3]\n",
      "\n",
      "#: Full power gives you the min steam\n",
      "bDacSteaBaseEload = df_steam_full_power[3, 2]  \n",
      "aDacSteaBaseEload = df_steam_full_power[3, 3]\n",
      "\n",
      "bSideSteaEload = df_steam_full_steam[3, 2] - df_steam_full_power[3, 2]\n",
      "aSideSteaEload = df_steam_full_steam[3, 3] - df_steam_full_power[3, 3]\n",
      "\n",
      "bAuxRateStea = df_steam_full_power[4, 2] / 1000\n",
      "aAuxRateStea = df_steam_full_power[4, 3] / 1000\n",
      "\n",
      "aLpSteaToPow = 78.60233832  # MMBtu to kwh\n",
      "\n",
      "kwhToMmbtu = 3412.1416416 / 1e+06\n",
      "#aSteaUseRateDacAir = 1944 * kwhToMmbtu\n",
      "#aSteaUseRateDacFlue = 1944 * kwhToMmbtu\n",
      "# 7 GJ/tonneCO\n",
      "aSteaUseRateDacAir = 5 * (7 * 1e+06 / 3600) * kwhToMmbtu\n",
      "aSteaUseRateDacFlue = 5 * (7 * 1e+06 / 3600) * kwhToMmbtu\n",
      "\n",
      "aPowUseRateDacAir = 500 / 1000\n",
      "aPowUseRateDacFlue = 250 / 1000\n",
      "# 1 mmol/gSorb #\n",
      "# per gCo/gSorb\n",
      "gCogSorbRatio = 1e-03 * 44.0095\n",
      "\n",
      "aSorbCo2CapFlue = 1 * gCogSorbRatio\n",
      "aSorbCo2CapAir = gCogSorbRatio\n",
      "#aSorbAmountFreshFlue = 176. * 10  # Tonne sorb\n",
      "#aSorbAmountFreshAir = 176. * 10  # Tonne sorb\n",
      "\n",
      "aSorbAmountFreshFlue = 176. * 10   # Tonne sorb (Max. heat basis)\n",
      "aSorbAmountFreshAir = 3162.18 - 176. * 10  # Tonne sorb (Max. heat basis)\n",
      "\n",
      "\n",
      "aCapRatePcc = 0.97\n",
      "# 2.4 MJ/kg (1,050 Btu/lb) CO2 page 379/\n",
      "#aSteaUseRatePcc = aSteaUseRateDacFlue * 0.2\n",
      "#aSteaUseRatePcc = 2.4 * 1000 * 1000 / 3600 * kwhToMmbtu \n",
      "#println(aSteaUseRatePcc)\n",
      "# aPowUseRatePcc = 0.173514487  # MWh/tonneCoi2 (old)\n",
      "aSteaUseRatePcc = 2.69 + 0.0218 + 0.00127 # MMBTU/tonne CO2 (trimeric)\n",
      "println(aSteaUseRatePcc)\n",
      "aPowUseRatePcc = 0.047 # MWh/tonne CO2 (trimeric)\n",
      "\n",
      "#: Horizon Lenght\n",
      "tHorz = 24 * 10 - 1\n",
      "\n",
      "\n",
      "#: Slices per hour\n",
      "hSlice = 4  # the number of slices of a given hour\n",
      "# There are tHorz - 1 slices\n",
      "# Each slice has hSlice points, but only states have the 0th\n",
      "\n",
      "# If there's several slices in an hour we kind of need to divide the\n",
      "# hourly-based quantities :(\n",
      "\n",
      "\n",
      "\n",
      "# Correction for low load\n",
      "slopeFactor =  (0.01/ 0.1) / ((.95 - .75) / (0.9 - 0.6))\n",
      "\n",
      "# Dictionaries with the disjunction parameters\n",
      "\n",
      "## Slope\n",
      "aPowGt = Dict(0 => 1, 1 => aPowGasTeLoad * slopeFactor, 2 => aPowGasTeLoad)\n",
      "aFuel = Dict(0 => 1, 1 => aFuelEload, 2 => aFuelEload)\n",
      "aEmis = Dict(0 => 1, 1 => aEmissFactEload, 2 => aEmissFactEload)\n",
      "aAuxGt = Dict(0 => 1, \n",
      "    1 => aAuxRateGas * slopeFactor, \n",
      "    2 => aAuxRateGas)\n",
      "aPowHp = Dict(0 => 1, 1 => aPowHpEload * slopeFactor, \n",
      "    2 => aPowHpEload)\n",
      "aPowIp = Dict(0 => 1, 1 => aPowIpEload * slopeFactor, \n",
      "    2 => aPowIpEload)\n",
      "aCcReb = Dict(\n",
      "    0 => 1, \n",
      "    1 => aCcRebDutyEload * slopeFactor, \n",
      "    2 => aCcRebDutyEload)\n",
      "aDacSb = Dict(0 => 1, 1 => aDacSteaBaseEload * slopeFactor, \n",
      "    2 => aDacSteaBaseEload)\n",
      "aSideS = Dict(0 => 1, 1 => aSideSteaEload * slopeFactor, 2 => aSideSteaEload)\n",
      "aAuxSt = Dict(0 => 1, 1 => aAuxRateStea * slopeFactor, 2 => aAuxRateStea)\n",
      "\n",
      "ldics = [\"aPowGt\", \"aFuel\", \"aEmis\", \"aAuxGt\", \"aPowHp\", \"aPowIp\", \"aCcReb\", \"aDacSb\", \"aSideS\", \"aAuxSt\"]\n",
      "println(\"Slopes\")\n",
      "for v in ldics\n",
      "    s = Symbol(v)\n",
      "    println(v, eval(s))\n",
      "end\n",
      "\n",
      "## b\n",
      "bPowGt = Dict(0 => 0, \n",
      "    1 => 60 * (-aPowGt[1] + aPowGt[2]) + bPowGasTeLoad, \n",
      "    2 => bPowGasTeLoad)\n",
      "bFuel = Dict(0 => 0, 1 => bFuelEload, 2 => bFuelEload)\n",
      "bEmis = Dict(0 => 0, 1 => bEmissFactEload, 2 => bEmissFactEload)\n",
      "bAuxGt = Dict(0 => 0, \n",
      "    1 => 60 * (-aAuxGt[1] + aAuxGt[2]) + bAuxRateGas, \n",
      "    2 => bAuxRateGas)\n",
      "bPowHp = Dict(0 => 0, \n",
      "    1 => 60 * (-aPowHp[1] + aPowHp[2]) + bPowHpEload,\n",
      "    2 => bPowHpEload)\n",
      "bPowIp = Dict(0 => 0,\n",
      "    1 => 60 * (-aPowIp[1] + aPowIp[2]) + bPowIpEload,\n",
      "    2 => bPowIpEload\n",
      "    )\n",
      "bCcReb = Dict(0 => 0,\n",
      "    1 => 60 * (-aCcReb[1] + aCcReb[2]) + bCcRebDutyEload,\n",
      "    2 => bCcRebDutyEload)\n",
      "bDacSb = Dict(0 => 0,\n",
      "    1 => 60 * (-aDacSb[1] + aDacSb[2]) + bDacSteaBaseEload,\n",
      "    2 => bDacSteaBaseEload)\n",
      "bSideS = Dict(0 => 0,\n",
      "    1 => 60 * (-aSideS[1] + aSideS[2]) + bSideSteaEload,\n",
      "    2 => bSideSteaEload)\n",
      "bAuxSt = Dict(0 => 0,\n",
      "    1 => 60 * (-aAuxSt[1] + aAuxSt[2]) + bAuxRateStea,\n",
      "    2 => bAuxRateStea)\n",
      "\n",
      "\n",
      "ldics = [\"bPowGt\", \"bFuel\", \"bEmis\", \"bAuxGt\", \"bPowHp\", \"bPowIp\", \"bCcReb\", \"bDacSb\", \"bSideS\", \"bAuxSt\"]\n",
      "println(\"InterC\")\n",
      "for v in ldics\n",
      "    s = Symbol(v)\n",
      "    println(v, eval(s))\n",
      "end\n",
      "\n",
      "\n",
      "# USD/MWh\n",
      "pow_price =(df_pow_c[!, \"MiNg_150_ERCOT\"])  # USD/MWh\n",
      "\n",
      "# pow_price =(df_pow_c[!, \"MiNg_150_PJM-W\"])  # USD/MWh\n",
      "#: Natural gas price\n",
      "# 0.056 lb/cuft STP\n",
      "#std_w_ng1000cuft = 0.056 * 1000\n",
      "#cNgPerLbUsd = (3.5 / 1000) / 0.056\n",
      "\n",
      "# Cost of natural gas\n",
      "cNgPerMmbtu = 3.5\n",
      "\n",
      "m = Model()\n",
      "\n",
      "# aPowUseRateComp = 0.279751187  # MWh/tonneCo2\n",
      "aPowUseRateComp = 0.076 # MWh/tonneCo2 (Trimeric)\n",
      "\n",
      "# Other costs\n",
      "cCostInvCombTurb = 1e+02\n",
      "cCostInvSteaTurb = 1e+02\n",
      "cCostInvTransInter = 1e+02\n",
      "cCostInvPcc = 1e+02\n",
      "cCostInvDac = 1e+03\n",
      "cCostInvComp = 1e+01\n",
      "\n",
      "# Cost parameters.\n",
      "cEmissionPrice = 1.5e+02 # USD/tonne CO2\n",
      "cCo2TranspPrice = 1e+00\n",
      "pCo2Credit = 1e+00\n",
      "\n",
      "\n",
      "#vCapCombTurb = 3.\n",
      "vCapSteaTurb = 2.\n",
      "vCapTransInter = 5.\n",
      "vCapPcc = 20.\n",
      "vCapComp = 1000.\n",
      "# Capital Cost DAC USD/tCo2/yr \n",
      "cCostInvDacUsdtCo2yr = 750\n",
      "cCostFixedDacUsdtCo2yr = 25\n",
      "cCostVariableDacUsdtCo2yr = 12\n",
      "\n",
      "nMod = 2\n",
      "\n",
      "# 0 -> off\n",
      "# 1 -> warm-up\n",
      "# 2 -> on\n",
      "\n",
      "# 0 for off 2 for other ones.\n",
      "extrPoint = Dict(0 => 0, 1 => 0:1, 2 => 0:1)\n",
      "@variable(m, 0 <= lambda[0:tHorz, i=0:nMod, extrPoint[i]] <= 1)\n",
      "# On/Off\n",
      "@variable(m, y[0:tHorz, 0:nMod], Bin, start = 0)  # On and off\n",
      "# Transition\n",
      "@variable(m, z[0:tHorz, j1 = 0:nMod, j2 = 0:nMod], Bin, start = 0)\n",
      "\n",
      "for i in 0:tHorz\n",
      "    set_start_value(y[i, 1], 1)\n",
      "end\n",
      "\n",
      "@variable(m, xLoad[0:tHorz, 0:nMod])\n",
      "\n",
      "\n",
      "@variable(m, 0 <= xeLoad[0:tHorz] <= 100)\n",
      "\n",
      "\n",
      "@variable(m, 0 <= xPowGasTur[0:tHorz])\n",
      "@variable(m, 0 <= xPowGross[0:tHorz])\n",
      "@variable(m, 0 <= xPowOut[0:tHorz])\n",
      "\n",
      "@variable(m, 0 <= xAuxPowGasT[0:tHorz])\n",
      "\n",
      "# Steam Turbine\n",
      "@variable(m, 0 <= xPowHp[0:tHorz])\n",
      "@variable(m, 0 <= xPowIp[0:tHorz])\n",
      "@variable(m, 0 <= xPowLp[0:tHorz])\n",
      "\n",
      "@variable(m, 0 <= xFuel[0:tHorz])\n",
      "@variable(m, 0 <= xCo2Fuel[0:tHorz])\n",
      "@variable(m, 0 <= xDacSteaDuty[0:tHorz])\n",
      "\n",
      "\n",
      "@variable(m, 0 <= xCcRebDuty[0:tHorz])\n",
      "@variable(m, 0 <= xDacSteaBaseDuty[0:tHorz])\n",
      "\n",
      "@variable(m, 0 <= xAllocSteam[0:tHorz])\n",
      "@variable(m, 0 <= xSteaPowLp[0:tHorz])\n",
      "@variable(m, 0 <= xSideSteaDac[0:tHorz])\n",
      "\n",
      "#\n",
      "@variable(m, 0 <= xPowSteaTur[0:tHorz])\n",
      "@variable(m, 0 <= xAuxPowSteaT[0:tHorz])\n",
      "\n",
      "# Disagretated variables\n",
      "\n",
      "@variable(m, 0 <= xPowGt[0:tHorz, 0:nMod])\n",
      "@variable(m, 0 <= xFuelNu[0:tHorz, 0:nMod])\n",
      "@variable(m, 0 <= xEmis[0:tHorz, 0:nMod])\n",
      "@variable(m, 0 <= xAuxGt[0:tHorz, 0:nMod])\n",
      "@variable(m, 0 <= xPowHpNu[0:tHorz, 0:nMod])\n",
      "@variable(m, 0 <= xPowIpNu[0:tHorz, 0:nMod])\n",
      "@variable(m, 0 <= xPccReb[0:tHorz, 0:nMod])\n",
      "@variable(m, 0 <= xDacSb[0:tHorz, 0:nMod])\n",
      "@variable(m, 0 <= xAllocS[0:tHorz, 0:nMod])\n",
      "@variable(m, 0 <= xAuxSt[0:tHorz, 0:nMod])\n",
      "\n",
      "\n",
      "\n",
      "#@constraint(m, powgtDisEq[i = 0:tHorz, k = 0:nMod],\n",
      "#    xPowGt[i, k] = aPowGt[k] * xLoad[i, k] + bPowGt[k])\n",
      "#@constraint(m, powGasTur[i = 0:tHorz], \n",
      "#            xPowGasTur[i] == sum(xPowGt[i, k] for k in 0:nMod)\n",
      "#           )\n",
      "\n",
      "# Pcc\n",
      "#@variable(m, 0 <= xCo2CapPcc[0:tHorz - 1] <= vCapPcc)\n",
      "@variable(m, 0 <= xCo2CapPcc[0:tHorz])\n",
      "@variable(m, 0 <= xSteaUsePcc[0:tHorz])\n",
      "@variable(m, 0 <= xPowUsePcc[0:tHorz])\n",
      "@variable(m, 0 <= xCo2PccOut[0:tHorz])\n",
      "#@variable(m, 0 <= vCo2PccVent[0:tHorz - 1] <= 0.1)\n",
      "@variable(m, 0 <= vCo2PccVent[0:tHorz])\n",
      "#vCo2PccVent = 0.0\n",
      "@variable(m, 0 <= xCo2DacFlueIn[0:tHorz])\n",
      "@variable(m, 0 <= xPccSteaSlack[0:tHorz])\n",
      "\n",
      "# Dac-Flue\n",
      "@variable(m, 0 <= xA0Flue[0:tHorz, 0:hSlice-1]) # Kind of input \n",
      "\n",
      "@variable(m, 0 <= xA1Flue[0:tHorz, 0:hSlice]) # State\n",
      "\n",
      "\n",
      "@variable(m, 0 <= xR0Flue[0:tHorz, 0:hSlice-1])  # Kind of input\n",
      "\n",
      "@variable(m, 0 <= xR1Flue[0:tHorz, 0:hSlice])  # State\n",
      "@variable(m, 0 <= xFflue[0:tHorz, 0:hSlice])  # State\n",
      "@variable(m, 0 <= xSflue[0:tHorz, 0:hSlice])  # State\n",
      "\n",
      "\n",
      "@variable(m, 0 <= xCo2CapDacFlue[0:tHorz, 0:hSlice-1])\n",
      "@variable(m, 0 <= xSteaUseDacFlue[0:tHorz, 0:hSlice-1])\n",
      "@variable(m, 0 <= xPowUseDacFlue[0:tHorz, 0:hSlice-1])\n",
      "@variable(m, 0 <= xCo2DacVentFlue[0:tHorz])\n",
      "\n",
      "# Dac-Air\n",
      "@variable(m, 0 <= xA0Air[0:tHorz, 0:hSlice-1]) # Kind of input\n",
      "\n",
      "@variable(m, 0 <= xA1Air[0:tHorz, 0:hSlice]) # State\n",
      "@variable(m, 0 <= xA2Air[0:tHorz, 0:hSlice]) # State\n",
      "\n",
      "@variable(m, 0 <= xR0Air[0:tHorz, 0:hSlice-1])  # Kind of input\n",
      "\n",
      "@variable(m, 0 <= xR1Air[0:tHorz, 0:hSlice])  # State\n",
      "@variable(m, 0 <= xFair[0:tHorz, 0:hSlice])  # State\n",
      "@variable(m, 0 <= xSair[0:tHorz, 0:hSlice])  # State\n",
      "\n",
      "\n",
      "@variable(m, 0 <= xCo2CapDacAir[0:tHorz, 0:hSlice-1])\n",
      "@variable(m, 0 <= xSteaUseDacAir[0:tHorz, 0:hSlice-1])\n",
      "@variable(m, 0 <= xPowUseDacAir[0:tHorz, 0:hSlice-1])\n",
      "\n",
      "@variable(m, 0 <= xDacSteaSlack[0:tHorz])\n",
      "# DAC hourly capacity\n",
      "#\n",
      "\n",
      "\n",
      "\n",
      "# CO2 compression\n",
      "@variable(m, 0 <= xCo2Comp[0:tHorz])\n",
      "@variable(m, 0 <= xPowUseComp[0:tHorz])\n",
      "#@variable(m, 0 <= vCapComp)\n",
      "@variable(m, xCo2Vent[0:tHorz])  # This used to be only positive.\n",
      "\n",
      "@variable(m, 0 <= xAuxPow[0:tHorz])\n",
      "\n",
      "# Constraints\n",
      "# Op mode\n",
      "# Down times\n",
      "# Up times\n",
      "\n",
      "# Disjunction 0 (off)\n",
      "\n",
      "extreme_d_0 = [0]\n",
      "extreme_d_1 = [20.0, 50.0]\n",
      "extreme_d_2 = [60.0, 100.0]\n",
      "\n",
      "ep_list = [extreme_d_0, extreme_d_1, extreme_d_2]\n",
      "\n",
      "# Convex conbination\n",
      "@constraint(m, cConvxEq[i = 0:tHorz, mod = 0:nMod],\n",
      "    sum(lambda[i, mod, k] * ep_list[mod + 1][k + 1] for k in extrPoint[mod]) ==\n",
      "    xLoad[i, mod]  # There is only a single extreme\n",
      "    )\n",
      "\n",
      "# jth mode\n",
      "# Lambda constraint\n",
      "@constraint(m, xLambdaEq[i = 0:tHorz, mod = 0:nMod],\n",
      "    sum(lambda[i, mod, k] for k in extrPoint[mod]) == y[i, mod]\n",
      "    )\n",
      "\n",
      "# Big M\n",
      "@constraint(m, bmconEq[i = 0:tHorz, mod = 0:nMod],\n",
      "    xLoad[i, mod] <= maximum(ep_list[mod + 1])* y[i, mod]\n",
      "    )\n",
      "\n",
      "\n",
      "# Overall Disjunction\n",
      "\n",
      "@constraint(m, gasLeq[i = 0:tHorz],\n",
      "    xeLoad[i] == sum(xLoad[i, mod] for mod in 0:nMod)\n",
      "    )\n",
      "\n",
      "\n",
      "@constraint(m, sumyEq[i = 0:tHorz],\n",
      "    sum(y[i, mod] for mod in 0:nMod) == 1\n",
      "    )\n",
      "\n",
      "# Switch\n",
      "\n",
      "@constraint(m, switchCon[i = 1:tHorz, mod = 0:nMod],\n",
      "    sum(z[i, k, mod] for k in 0:nMod) - \n",
      "    sum(z[i, mod, k] for k in 0:nMod) \n",
      "    == y[i, mod] - y[i - 1, mod])\n",
      "\n",
      "# Forbidden\n",
      "# from off to full\n",
      "@constraint(m, forbConOffFullEq[i = 0:tHorz],\n",
      "    z[i, 0, 2] == 0)\n",
      "# from full to warm-up\n",
      "@constraint(m, forbConEq2[i = 0:tHorz],\n",
      "    z[i, 2, 1] == 0)\n",
      "# from warm-up to off\n",
      "#@constraint(m, forbConwarmpuoff[i = 0:tHorz],\n",
      "#    z[i, 1, 0] == 0)\n",
      "\n",
      "# Ramping Constraints\n",
      "rup = [0, 15, 30]\n",
      "rdown = [0, 15, 30]\n",
      "\n",
      "@constraints(m, begin \n",
      "    rampup1eq[i=1:tHorz], xLoad[i, 1] - xLoad[i-1, 1] <= rup[2] * y[i, 1]\n",
      "    rampup2eq[i=1:tHorz], xLoad[i, 2] - xLoad[i-1, 2] <= rup[3] * y[i, 2]\n",
      "end)\n",
      "\n",
      "#@constraints(m, begin \n",
      "    #rampdo1eq[i=1:tHorz], xLoad[i - 1, 1] - xLoad[i, 1] <= rdown[2] * y[i, 1]\n",
      "    #rampdo2eq[i=1:tHorz], xLoad[i - 1, 2] - xLoad[i, 2] <= rdown[3] * y[i, 2]\n",
      "#end)\n",
      "\n",
      "# Minimum stay \n",
      "KminOff = [[0, 36, 0], [0, 0, 0], [48, 0, 0]]\n",
      "\n",
      "# off to on(1)\n",
      "@constraint(m, minstay01[i = 1:tHorz],\n",
      "    y[i, 1] >= sum(z[i - k, 0, 1] for k in 0:(24-1) if (i-k) >= 0)\n",
      "    )\n",
      "# on(2) to off\n",
      "@constraint(m, minstay20[i = 1:tHorz],\n",
      "    y[i, 0] >= sum(z[i - k, 2, 0] for k in 0:(48-1) if (i-k) >= 0)\n",
      "    )\n",
      "\n",
      "\n",
      "# Disagregated variables constraints\n",
      "@constraint(m, powgtdeq[i = 0:tHorz, mod = 0:nMod],\n",
      "    xPowGt[i, mod] == aPowGt[mod] * xLoad[i, mod] + bPowGt[mod] * y[i, mod]\n",
      "    )\n",
      "@constraint(m, fueldeq[i = 0:tHorz, mod = 0:nMod],\n",
      "    xFuelNu[i, mod] == aFuel[mod] * xLoad[i, mod] + bFuel[mod] * y[i, mod]\n",
      "    )\n",
      "@constraint(m, emissdeq[i = 0:tHorz, mod = 0:nMod],\n",
      "    xEmis[i, mod] == aEmis[mod] * xLoad[i, mod] + bEmis[mod] * y[i, mod]\n",
      "    )\n",
      "@constraint(m, auxgtdeq[i = 0:tHorz, mod = 0:nMod],\n",
      "    xAuxGt[i, mod] == aAuxGt[mod] * xLoad[i, mod] + bAuxGt[mod] * y[i, mod]\n",
      "    )\n",
      "@constraint(m, powhpdeq[i = 0:tHorz, mod = 0:nMod],\n",
      "    xPowHpNu[i, mod] == aPowHp[mod] * xLoad[i, mod] + bPowHp[mod] * y[i, mod]\n",
      "    )\n",
      "@constraint(m, powipdeq[i = 0:tHorz, mod = 0:nMod],\n",
      "    xPowIpNu[i, mod] == aPowIp[mod] * xLoad[i, mod] + bPowIp[mod] * y[i, mod]\n",
      "    )\n",
      "@constraint(m, pccrebdeq[i = 0:tHorz, mod = 0:nMod],\n",
      "    xPccReb[i, mod] == aCcReb[mod] * xLoad[i, mod] + bCcReb[mod] * y[i, mod]\n",
      "    )\n",
      "@constraint(m, dacsbtdeq[i = 0:tHorz, mod = 0:nMod],\n",
      "    xDacSb[i, mod] == aDacSb[mod] * xLoad[i, mod] + bDacSb[mod] * y[i, mod]\n",
      "    )\n",
      "@constraint(m, allocstdeq[i = 0:tHorz, mod = 0:nMod],\n",
      "    xAllocS[i, mod] == aSideS[mod] * xLoad[i, mod] + bSideS[mod] * y[i, mod]\n",
      "    )\n",
      "@constraint(m, auxstdeq[i = 0:tHorz, mod = 0:nMod],\n",
      "    xAuxSt[i, mod] == aAuxSt[mod] * xLoad[i, mod] + bAuxSt[mod] * y[i, mod]\n",
      "    )\n",
      "\n",
      "\n",
      "# Gas Turbine\n",
      "@constraint(m, powGasTur[i = 0:tHorz], \n",
      "            xPowGasTur[i] == sum(xPowGt[i, mod] for mod in 0:nMod)\n",
      "           )\n",
      "# \n",
      "@constraint(m, fuelEq[i = 0:tHorz], \n",
      "            xFuel[i] == sum(xFuelNu[i, mod] for mod in 0:nMod)\n",
      "           )\n",
      "# \n",
      "@constraint(m, co2FuelEq[i = 0:tHorz], \n",
      "            xCo2Fuel[i] == sum(xEmis[i, mod] for mod in 0:nMod)\n",
      "           )\n",
      "\n",
      "@constraint(m, auxPowGasT[i = 0:tHorz],\n",
      "            xAuxPowGasT[i] == sum(xAuxGt[i, mod] for mod in 0:nMod)\n",
      "           )\n",
      "# \n",
      "# Steam\n",
      "# \n",
      "@constraint(m, powHpEq[i = 0:tHorz], \n",
      "            xPowHp[i] == sum(xPowHpNu[i, mod] for mod in 0:nMod)\n",
      "           )\n",
      "# \n",
      "@constraint(m, powIpEq[i = 0:tHorz], \n",
      "            xPowIp[i] == sum(xPowIpNu[i, mod] for mod in 0:nMod)\n",
      "           )\n",
      "\n",
      "# \n",
      "@constraint(m, powLpEq[i = 0:tHorz], \n",
      "            xPowLp[i] == xSteaPowLp[i] * aLpSteaToPow / 1000\n",
      "           )\n",
      "# \n",
      "@constraint(m, powerSteaEq[i = 0:tHorz], \n",
      "            xPowSteaTur[i] == \n",
      "            xPowHp[i] + xPowIp[i] + xPowLp[i]\n",
      "           )\n",
      "\n",
      "@constraint(m, ccRebDutyEq[i = 0:tHorz],\n",
      "            xCcRebDuty[i] == sum(xPccReb[i, mod] for mod in 0:nMod)\n",
      "           )\n",
      "\n",
      "@constraint(m, dacSteaDutyEq[i = 0:tHorz],\n",
      "            xDacSteaBaseDuty[i] == sum(xDacSb[i, mod] for mod in 0:nMod)\n",
      "           )\n",
      "\n",
      "\n",
      "@constraint(m, sideSteaEloadEq[i = 0:tHorz],\n",
      "            xAllocSteam[i] == sum(xAllocS[i, mod] for mod in 0:nMod)\n",
      "           )\n",
      "\n",
      "@constraint(m, sideSteaRatioEq[i = 0:tHorz],\n",
      "            xAllocSteam[i] == xSideSteaDac[i] + xSteaPowLp[i]\n",
      "           )\n",
      "\n",
      "@constraint(m, availSteaDacEq[i = 0:tHorz],\n",
      "            xDacSteaDuty[i] == xDacSteaBaseDuty[i] + xSideSteaDac[i]\n",
      "           )\n",
      "\n",
      "@constraint(m, auxPowSteaTEq[i = 0:tHorz],\n",
      "            xAuxPowSteaT[i] == sum(xAuxSt[i, mod] for mod in 0:nMod)\n",
      "           )\n",
      "\n",
      "# PCC\n",
      "# \n",
      "#@constraint(m, co2CapPccEq[i = 0:tHorz - 1], \n",
      "#xCo2CapPcc[i] == aCo2PccCapRate * xCo2Fuel[i])\n",
      "@constraint(m, co2CapPccEq[i = 0:tHorz], \n",
      "            xCo2CapPcc[i] == aCapRatePcc * xCo2Fuel[i])\n",
      "# \n",
      "@constraint(m, co2PccOutEq[i = 0:tHorz], \n",
      "            xCo2PccOut[i] == xCo2Fuel[i] - xCo2CapPcc[i])\n",
      "# \n",
      "@constraint(m, co2DacFlueInEq[i = 0:tHorz], \n",
      "            xCo2DacFlueIn[i] == xCo2PccOut[i] - vCo2PccVent[i])\n",
      "# \n",
      "# @constraint(m, co2CapPccIn[i = 0:tHorz - 1], xCo2CapPcc[i] <= vCapPcc)\n",
      "# Dav: Sometimes there is not enough steam, so we have to relax this constraint \n",
      "@constraint(m, steamUsePccEq[i = 0:tHorz], \n",
      "            xSteaUsePcc[i] <= aSteaUseRatePcc * xCo2CapPcc[i])\n",
      "# \n",
      "@constraint(m, powerUsePccEq[i = 0:tHorz], \n",
      "            xPowUsePcc[i] == aPowUseRatePcc * xCo2CapPcc[i]\n",
      "           )\n",
      "\n",
      "@constraint(m, pccSteaSlack[i = 0:tHorz], \n",
      "            xPccSteaSlack[i] == xCcRebDuty[i] - xSteaUsePcc[i])\n",
      "\n",
      "# DAC-Flue\n",
      "# Flue gas takes 15 minutes to saturation?\n",
      "#: \"State equation\"\n",
      "@constraint(m, a1dFlueEq[i = 0:tHorz, j=1:hSlice], \n",
      "            xA1Flue[i, j] == xA0Flue[i, j-1]\n",
      "           )\n",
      "\n",
      "#: \"State equation\"\n",
      "@constraint(m, aRdFlueEq[i = 0:tHorz, j=1:hSlice], \n",
      "            xR1Flue[i, j] == xR0Flue[i, j-1]\n",
      "           )\n",
      "#: \"State equation\"\n",
      "@constraint(m, storeFflueeq[i = 0:tHorz, j = 1:hSlice], \n",
      "            xFflue[i, j] == xFflue[i, j-1] - xA0Flue[i, j-1] + xR1Flue[i, j-1]\n",
      "           )\n",
      "#: \"State equation\"\n",
      "@constraint(m, storeSflueeq[i = 0:tHorz, j = 1:hSlice], \n",
      "            xSflue[i, j] == xSflue[i, j-1] - xR0Flue[i, j-1] + xA1Flue[i, j-1]\n",
      "           )\n",
      "# Initial conditions\n",
      "@constraint(m, icXa1FlueEq, xA1Flue[0, 0] == 0.)\n",
      "@constraint(m, icAR1FlueEq, xR1Flue[0, 0] == 0.)\n",
      "@constraint(m, capDacFlueEq, xFflue[0, 0] == aSorbAmountFreshFlue)\n",
      "@constraint(m, icSsFlueEq, xSflue[0, 0] == 0.)\n",
      "# End-point constraints we need to get rid of them and then put them back\n",
      "@constraint(m, endXa1FlueEq, xA1Flue[tHorz, hSlice] == 0.)\n",
      "@constraint(m, endAR1FlueEq, xR1Flue[tHorz, hSlice] == 0.)\n",
      "@constraint(m, endDacFlueEq, xFflue[tHorz, hSlice] == aSorbAmountFreshFlue)\n",
      "@constraint(m, endSsFlueEq, xSflue[tHorz, hSlice] == 0.)\n",
      "#\n",
      "#These dac related variables must start at 0 and end at 1-hslice\n",
      "@constraint(m, co2CapDacFlueEq[i = 0:tHorz, j = 0:hSlice-1], \n",
      "            xCo2CapDacFlue[i, j] == \n",
      "            #aSorbCo2CapFlue * xR1Flue[i, j]\n",
      "            aSorbCo2CapFlue * xA1Flue[i, j]\n",
      "           )\n",
      "#\n",
      "@constraint(m, steamUseDacFlueEq[i = 0:tHorz, j = 0:hSlice-1], \n",
      "            xSteaUseDacFlue[i, j] == \n",
      "            #aSteaUseRateDacFlue * xCo2CapDacFlue[i, j]\n",
      "            aSteaUseRateDacFlue * aSorbCo2CapFlue * xR1Flue[i, j]\n",
      "           )\n",
      "#\n",
      "@constraint(m, powUseDacFlueEq[i = 0:tHorz, j = 0:hSlice-1], \n",
      "            xPowUseDacFlue[i, j] == aPowUseRateDacFlue * xCo2CapDacFlue[i, j]\n",
      "           )\n",
      "\n",
      "# DAC-Air\n",
      "# Bluntly assume we can just take CO2 from air in pure form.\n",
      "# \"State equation\"\n",
      "@constraint(m, a1dAirEq[i = 0:tHorz, j = 1:hSlice], \n",
      "            xA1Air[i, j] == xA0Air[i, j - 1]\n",
      "           )\n",
      "# \"State equation\"\n",
      "@constraint(m, a2dAirEq[i = 0:tHorz, j = 1:hSlice], \n",
      "            xA2Air[i, j] == xA1Air[i, j - 1]\n",
      "           )\n",
      "# \"State equation\"\n",
      "@constraint(m, aRdAirEq[i = 0:tHorz, j = 1:hSlice], \n",
      "            xR1Air[i, j] == xR0Air[i, j - 1]\n",
      "           )\n",
      "# \"State equation\"\n",
      "@constraint(m, storeFairEq[i = 0:tHorz, j = 1:hSlice], \n",
      "            xFair[i, j] == xFair[i, j-1] - xA0Air[i, j-1] + xR1Air[i, j-1]\n",
      "           )\n",
      "# \"State equation\"\n",
      "@constraint(m, storeSaireq[i = 0:tHorz, j = 1:hSlice], \n",
      "            xSair[i, j] == xSair[i, j-1] - xR0Air[i, j-1] + xA2Air[i, j-1]\n",
      "           )\n",
      "\n",
      "# Initial conditions - Air\n",
      "#@constraint(m, capDacAirEq, xFair[0] == xSorbFreshAir)\n",
      "@constraint(m, capDacAirEq, xFair[0, 0] == aSorbAmountFreshAir)\n",
      "@constraint(m, icA1AirEq, xA1Air[0, 0] == 0.)\n",
      "@constraint(m, icA2AirEq, xA2Air[0, 0] == 0.)\n",
      "@constraint(m, icAR1AirEq, xR1Air[0, 0] == 0.)\n",
      "@constraint(m, icSsAirEq, xSair[0, 0] == 0.)\n",
      "# End-point conditions - Air\n",
      "\n",
      "@constraint(m, endDacAirEq, xFair[tHorz, hSlice] == aSorbAmountFreshAir)\n",
      "@constraint(m, endA1AirEq, xA1Air[tHorz, hSlice] == 0.)\n",
      "@constraint(m, endA2AirEq, xA2Air[tHorz, hSlice] == 0.)\n",
      "@constraint(m, endAR1AirEq, xR1Air[tHorz, hSlice] == 0.)\n",
      "@constraint(m, endSsAirEq, xSair[tHorz, hSlice] == 0.)\n",
      "\n",
      "#@constraint(m, endDacAirEq, xFair[0] == xSorbFreshAir)\n",
      "#@constraint(m, endDacAirEq, xFair[0, 0] == aSorbAmountFreshAir)\n",
      "#@constraint(m, endA1AirEq, xA1Air[0, 0] == 0.)\n",
      "#@constraint(m, endA2AirEq, xA2Air[0, 0] == 0.)\n",
      "#@constraint(m, endAR1AirEq, xR1Air[0, 0] == 0.)\n",
      "#@constraint(m, endSsAirEq, xSair[0, 0] == 0.)\n",
      "\n",
      "#\n",
      "@constraint(m, co2CapDacAirEq[i = 0:tHorz, j=0:hSlice-1], \n",
      "            xCo2CapDacAir[i, j] == \n",
      "            #aSorbCo2CapAir * xR1Air[i, j]\n",
      "            (aSorbCo2CapAir * xA1Air[i, j]/2 + aSorbCo2CapAir * xA2Air[i, j]/2)\n",
      "           )\n",
      "# \n",
      "@constraint(m, steamUseDacAirEq[i = 0:tHorz, j=0:hSlice-1], \n",
      "            xSteaUseDacAir[i, j] == \n",
      "            #aSteaUseRateDacAir * xCo2CapDacAir[i, j]\n",
      "            aSteaUseRateDacAir * aSorbCo2CapAir * xR1Air[i, j]\n",
      "           )\n",
      "# \n",
      "@constraint(m, powUseDacAirEq[i = 0:tHorz, j=0:hSlice-1], \n",
      "            xPowUseDacAir[i, j] == aPowUseRateDacAir * xCo2CapDacAir[i, j]\n",
      "           )\n",
      "# We need the integral over the whole time for DAC\n",
      "@constraint(m, dacSteaSlackEq[i = 0:tHorz], \n",
      "            xDacSteaSlack[i] == xDacSteaDuty[i] \n",
      "            - sum(xSteaUseDacFlue[i, j] for j in 0:hSlice - 1)\n",
      "            - sum(xSteaUseDacAir[i, j] for j in 0:hSlice - 1)\n",
      "           )\n",
      "\n",
      "# Equal to the amount vented, at least in flue mode.\n",
      "# Integral for DAC\n",
      "@constraint(m, co2DacFlueVentEq[i = 0:tHorz], \n",
      "            xCo2DacVentFlue[i] == xCo2DacFlueIn[i] \n",
      "            - sum(xCo2CapDacFlue[i, j] for j in  0:hSlice-1)\n",
      "           )\n",
      "\n",
      "\n",
      "# Co2 Compression\n",
      "# \n",
      "# We need the integral over the whole time for DAC\n",
      "@constraint(m, co2CompEq[i = 0:tHorz], \n",
      "            xCo2Comp[i] == xCo2CapPcc[i] \n",
      "            + sum(xCo2CapDacFlue[i, j] for j in 0:hSlice-1)\n",
      "            + sum(xCo2CapDacAir[i, j] for j in 0:hSlice-1)\n",
      "           )\n",
      "# \n",
      "@constraint(m, powUseCompEq[i = 0:tHorz], \n",
      "            xPowUseComp[i] == aPowUseRateComp * xCo2Comp[i]\n",
      "           )\n",
      "# \n",
      "@constraint(m, co2VentEq[i = 0:tHorz], \n",
      "            xCo2Vent[i] == vCo2PccVent[i] \n",
      "            + xCo2DacVentFlue[i] - sum(xCo2CapDacAir[i, j] \n",
      "                for j in 0:hSlice-1)\n",
      "           )\n",
      "\n",
      "## Overall\n",
      "\n",
      "#\n",
      "@constraint(m, powGrossEq[i = 0:tHorz], \n",
      "            xPowGross[i] == xPowGasTur[i] + xPowSteaTur[i]\n",
      "           )\n",
      "@constraint(m, auxPowEq[i = 0:tHorz],\n",
      "            xAuxPow[i] == xAuxPowGasT[i] + xAuxPowSteaT[i])\n",
      "\n",
      "@constraint(m, powOutEq[i = 0:tHorz], \n",
      "            xPowOut[i] == xPowGross[i] \n",
      "            - xPowUsePcc[i]\n",
      "            - sum(xPowUseDacFlue[i, j] for j in 0:hSlice-1)\n",
      "            - sum(xPowUseDacAir[i, j] for j in 0:hSlice-1)\n",
      "            - xPowUseComp[i] \n",
      "            - xAuxPow[i]\n",
      "           )\n",
      "\n",
      "\n",
      "# Continuity of states\n",
      "@constraint(m, \n",
      "            contxfflue[i = 1:tHorz], xFflue[i, 0] == xFflue[i - 1, hSlice])\n",
      "@constraint(m, \n",
      "            conta1flue[i = 1:tHorz], xA1Flue[i, 0] == xA1Flue[i - 1, hSlice])\n",
      "\n",
      "@constraint(m, \n",
      "            contcxsflue[i = 1:tHorz], xSflue[i, 0] == xSflue[i - 1, hSlice])\n",
      "@constraint(m, \n",
      "            contr1flue[i = 1:tHorz], xR1Flue[i, 0] == xR1Flue[i - 1, hSlice])\n",
      "\n",
      "@constraint(m, \n",
      "            contxfair[i = 1:tHorz], xFair[i, 0] == xFair[i - 1, hSlice])\n",
      "@constraint(m, \n",
      "            conta1air[i = 1:tHorz], xA1Air[i, 0] == xA1Air[i - 1, hSlice])\n",
      "@constraint(m, \n",
      "            conta2air[i = 1:tHorz], xA2Air[i, 0] == xA2Air[i - 1, hSlice])\n",
      "@constraint(m, \n",
      "            contcxsair[i = 1:tHorz], xSair[i, 0] == xSair[i - 1, hSlice])\n",
      "@constraint(m, \n",
      "            contr1air[i = 1:tHorz], xR1Air[i, 0] == xR1Air[i - 1, hSlice])\n",
      "\n",
      "\n",
      "shutdowncost = cNgPerMmbtu * (bFuelEload + 60 * aFuelEload)\n",
      "shutdownfromwarm = cNgPerMmbtu * (bFuelEload + 60 * aFuelEload) * 24\n",
      "startupcost = cNgPerMmbtu * (bFuelEload + 60 * aFuelEload) / 2\n",
      "# Objective function expression\n",
      "@expression(m, eObjfExpr, \n",
      "    sum(cNgPerMmbtu * xFuel[i]\n",
      "        + cEmissionPrice * xCo2Vent[i] \n",
      "        + cCo2TranspPrice * xCo2Comp[i]\n",
      "        - pow_price[i + 1] * xPowOut[i]\n",
      "        for i in 0:tHorz)\n",
      "        +\n",
      "    sum(shutdowncost * z[i, 2, 0] + startupcost * z[i, 0, 1]\n",
      "        + shutdownfromwarm * z[i, 1, 0]\n",
      "        for i in 0:tHorz)\n",
      "    )\n",
      "\n",
      "@objective(m, Min, eObjfExpr)\n",
      "\n",
      "print(\"The number of variables\\t\")\n",
      "println(num_variables(m))\n",
      "print(\"The number of constraints\\n\")\n",
      "\n",
      "n = 0\n",
      "for i in list_of_constraint_types(m)\n",
      "    global n\n",
      "    println(num_constraints(m, i[1], i[2]))\n",
      "    n += num_constraints(m, i[1], i[2])\n",
      "end\n",
      "\n",
      "\n",
      "println()\n",
      "\n",
      "# Set optimizer options\n",
      "set_optimizer(m, SCIP.Optimizer)\n",
      "#set_optimizer_attribute(m, \"LogLevel\", 3)\n",
      "#set_optimizer_attribute(m, \"PresolveType\", 1)\n",
      "\n",
      "optimize!(m)\n",
      "println(termination_status(m))\n",
      "\n",
      "#f = open(\"model.lp\", \"w\")\n",
      "#print(f, m)\n",
      "#close(f)\n",
      "\n",
      "#write_to_file(m, \"lp_mk0.mps\")\n",
      "#write_to_file(m, \"lp_mk10.lp\", format=MOI.FileFormats.FORMAT_LP)\n",
      "\n",
      "#format::MOI.FileFormats.FileFormat = MOI.FileFormats.FORMAT_AUTOMATIC\n",
      "\n",
      "# Co2 Data Frame\n",
      "df_co = DataFrame(Symbol(\"Co2Fuel\") => Float64[], # Pairs.\n",
      "                  Symbol(\"Co2CapPcc\") => Float64[],\n",
      "                  Symbol(\"Co2PccOut\") => Float64[],\n",
      "                  Symbol(\"vCo2PccVent\") => Float64[],\n",
      "                  Symbol(\"Co2DacFlueIn\") => Float64[],\n",
      "                  Symbol(\"Co2CapDacFlue\") => Float64[],\n",
      "                  Symbol(\"Co2CapDacAir\") => Float64[],\n",
      "                  Symbol(\"Co2DacVentFlue\") => Float64[],\n",
      "                  Symbol(\"Co2Vent\") => Float64[],\n",
      "                 )\n",
      "\n",
      "# Co2 / hSlice\n",
      "for i in 0:tHorz\n",
      "    co2fuel = value(xCo2Fuel[i])\n",
      "    co2pcc = value(xCo2CapPcc[i])\n",
      "    co2pccout = value(xCo2PccOut[i])\n",
      "    co2pccvent = value(vCo2PccVent[i])\n",
      "    co2dacfluein = value(xCo2DacFlueIn[i])\n",
      "    co2dacflue = sum(value(xCo2CapDacFlue[i, j]) for j in 0:hSlice-1)\n",
      "    co2dacair = sum(value(xCo2CapDacAir[i, j]) for j in 0:hSlice-1)\n",
      "    co2dacventflue = value(xCo2DacVentFlue[i])\n",
      "    co2vent = value(xCo2Vent[i])\n",
      "    push!(df_co,(\n",
      "        value(co2fuel),\n",
      "        value(co2pcc),\n",
      "        value(co2pccout),\n",
      "        value(co2pccvent),\n",
      "        value(co2dacfluein),\n",
      "        value(co2dacflue),\n",
      "        value(co2dacair),\n",
      "        value(co2dacventflue),\n",
      "        value(co2vent),\n",
      "        ))\n",
      "end\n",
      "\n",
      "# Power Data Frame.\n",
      "df_pow = DataFrame(\n",
      "                  Symbol(\"PowGasTur\") => Float64[], # Pairs.\n",
      "                  Symbol(\"PowSteaTurb\") => Float64[],\n",
      "                  Symbol(\"PowHp\") => Float64[],\n",
      "                  Symbol(\"PowIp\") => Float64[],\n",
      "                  Symbol(\"PowLp\") => Float64[],\n",
      "                  Symbol(\"PowUsePcc\") => Float64[],\n",
      "                  Symbol(\"PowUseDacFlue\") => Float64[],\n",
      "                  Symbol(\"PowUseDacAir\") => Float64[],\n",
      "                  Symbol(\"PowUseComp\") => Float64[],\n",
      "                  Symbol(\"AuxPowGasT\") => Float64[],\n",
      "                  Symbol(\"AuxPowSteaT\") => Float64[],\n",
      "                  Symbol(\"PowGross\") => Float64[],\n",
      "                  Symbol(\"PowOut\") => Float64[],\n",
      "                  Symbol(\"xeLoad\") => Float64[],\n",
      "                 )\n",
      "\n",
      "\n",
      "# Pow / hSlice\n",
      "for i in 0:tHorz\n",
      "    ygastelecload = value(xeLoad[i])\n",
      "    powgastur = value(xPowGasTur[i])\n",
      "    powsteatur = value(xPowSteaTur[i])\n",
      "    powhp = value(xPowHp[i])\n",
      "    powip = value(xPowIp[i])\n",
      "    powlp = value(xPowLp[i])\n",
      "    powusepcc = value(xPowUsePcc[i])\n",
      "    powusedacflue = sum(value(xPowUseDacFlue[i, j]) for j in 0:hSlice-1)\n",
      "    powusedacair = sum(value(xPowUseDacAir[i, j]) for j in 0:hSlice-1)\n",
      "    powusecomp = value(xPowUseComp[i])\n",
      "    auxpowgast = value(xAuxPowGasT[i])\n",
      "    auxpowsteat = value(xAuxPowSteaT[i])\n",
      "    powgross = value(xPowGross[i])\n",
      "    powout = value(xPowOut[i])\n",
      "    push!(df_pow, (\n",
      "        powgastur,\n",
      "        powsteatur,\n",
      "        powhp,\n",
      "        powip,\n",
      "        powlp,\n",
      "        powusepcc,\n",
      "        powusedacflue,\n",
      "        powusedacair,\n",
      "        powusecomp,\n",
      "        auxpowgast,\n",
      "        auxpowsteat,\n",
      "        powgross,\n",
      "        powout,\n",
      "        ygastelecload\n",
      "        ))\n",
      "end\n",
      "\n",
      "\n",
      "# Steam DataFrame\n",
      "df_steam = DataFrame(\n",
      "                     Symbol(\"CcRebDuty\") => Float64[],\n",
      "                     Symbol(\"SteaUsePcc\") => Float64[],\n",
      "                     Symbol(\"PccSteaSlack\") => Float64[],\n",
      "                     Symbol(\"DacSteaDuty\") => Float64[],\n",
      "                     Symbol(\"SteaUseDacFlue\") => Float64[],\n",
      "                     Symbol(\"SteaUseDacAir\") => Float64[],\n",
      "                     Symbol(\"DacSteaSlack\") => Float64[],\n",
      "                     Symbol(\"SideStea\") => Float64[],\n",
      "                     Symbol(\"DacSteaBaseDuty\") => Float64[],\n",
      "                     Symbol(\"SideSteaDac\") => Float64[],\n",
      "                     Symbol(\"Fuel\") => Float64[]\n",
      "                    )\n",
      "\n",
      "# Steam / hSlice\n",
      "for i in 0:tHorz\n",
      "    ccrebduty = value(xCcRebDuty[i])\n",
      "    steausepcc = value(xSteaUsePcc[i])\n",
      "    pccsteaslack = value(xPccSteaSlack[i])\n",
      "    dacsteaduty = value(xDacSteaDuty[i])\n",
      "    steausedacflue = sum(value(xSteaUseDacFlue[i, j]) for j in 0:hSlice-1)\n",
      "    steausedacair = sum(value(xSteaUseDacAir[i, j]) for j in 0:hSlice-1)\n",
      "    dacsteaslack = value(xDacSteaSlack[i])\n",
      "    sidesteam = value(xAllocSteam[i])\n",
      "    dacsteabaseduty = value(xDacSteaBaseDuty[i])\n",
      "    sidesteadac = value(xSideSteaDac[i])\n",
      "    xfuel = value(xFuel[i])\n",
      "    push!(df_steam, \n",
      "        (\n",
      "            ccrebduty,\n",
      "            steausepcc,\n",
      "            pccsteaslack,\n",
      "            dacsteaduty,\n",
      "            steausedacflue,\n",
      "            steausedacair,\n",
      "            dacsteaslack,\n",
      "            sidesteam,\n",
      "            dacsteabaseduty,\n",
      "            sidesteadac,\n",
      "            xfuel\n",
      "            ))\n",
      "end\n",
      "\n",
      "# DAC-flue DataFrame\n",
      "df_dac_flue = DataFrame(\n",
      "    :time => Float64[],\n",
      "    :xFflue => Float64[],\n",
      "    :xSflue => Float64[],\n",
      "    :xA0Flue => Float64[],\n",
      "    :xA1Flue => Float64[],\n",
      "    :xR0Flue => Float64[],\n",
      "    :xR1Flue => Float64[]\n",
      "    )\n",
      "\n",
      "sliceFact = 1/hSlice\n",
      "for i in 0:tHorz\n",
      "    for j in 0:hSlice-1\n",
      "        currtime = i + j * sliceFact\n",
      "        push!(df_dac_flue,(\n",
      "            currtime,\n",
      "            value(xFflue[i, j]), \n",
      "            value(xSflue[i, j]),\n",
      "            value(xA0Flue[i, j]), \n",
      "            value(xA1Flue[i, j]), \n",
      "            value(xR0Flue[i, j]), \n",
      "            value(xR1Flue[i, j]))\n",
      "        )\n",
      "    end\n",
      "end\n",
      "\n",
      "# DAC-air DataFrame\n",
      "df_dac_air = DataFrame(\n",
      "    :time => Float64[],\n",
      "    :xFair => Float64[],\n",
      "    :xSair => Float64[],\n",
      "    :xA0Air => Float64[],\n",
      "    :xA1Air => Float64[],\n",
      "    :xA2Air => Float64[],\n",
      "    :xR0Air => Float64[],\n",
      "    :xR1Air => Float64[])\n",
      "\n",
      "for i in 0:tHorz\n",
      "    for j in 0:hSlice-1\n",
      "        currtime = i + j * sliceFact\n",
      "        push!(df_dac_air,(\n",
      "            currtime,\n",
      "            value(xFair[i, j]), \n",
      "            value(xSair[i, j]),\n",
      "            value(xA0Air[i, j]), \n",
      "            value(xA1Air[i, j]), \n",
      "            value(xA2Air[i, j]),\n",
      "            value(xR0Air[i, j]), \n",
      "            value(xR1Air[i, j])))\n",
      "    end\n",
      "end\n",
      "\n",
      "\n",
      "df_pow_price = DataFrame(\n",
      "                         price = Float64[]\n",
      "                        )\n",
      "for i in 0:tHorz\n",
      "    push!(df_pow_price, (pow_price[i + 1],))\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "# Cost DataFrame\n",
      "df_cost = DataFrame(\n",
      "                    cNG = Float64[],\n",
      "                    cCo2Em = Float64[],\n",
      "                    cTransp = Float64[],\n",
      "                    PowSales = Float64[]\n",
      "                   )\n",
      "\n",
      "for i in 0:tHorz\n",
      "    cng = cNgPerMmbtu * value(xFuel[i])\n",
      "    cco = cEmissionPrice * value(xCo2Vent[i])\n",
      "    ctr = cCo2TranspPrice * value(xCo2Comp[i])\n",
      "    cpow = pow_price[i + 1] * value(xPowOut[i])\n",
      "    push!(df_cost, (cng, cco, ctr, cpow))\n",
      "end\n",
      "\n",
      "df_time_slice = DataFrame(:time => Float64[])\n",
      "\n",
      "for i in 0:tHorz\n",
      "    for j in 0:hSlice-1\n",
      "        currtime = i + j * sliceFact\n",
      "        push!(df_time_slice, (currtime, ))\n",
      "    end\n",
      "end\n",
      "\n",
      "\n",
      "df_binary = DataFrame(\n",
      "    :y0 => Float64[],\n",
      "    :y1 => Float64[],\n",
      "    :y2 => Float64[],\n",
      "    :z00 => Float64[],\n",
      "    :z01 => Float64[],\n",
      "    :z02 => Float64[],\n",
      "    :z10 => Float64[],\n",
      "    :z11 => Float64[],\n",
      "    :z12 => Float64[],\n",
      "    :z20 => Float64[],\n",
      "    :z21 => Float64[],\n",
      "    :z22 => Float64[],\n",
      "    )\n",
      "\n",
      "for i in 0:tHorz\n",
      "    push!(df_binary, \n",
      "        (\n",
      "            value(y[i, 0]),\n",
      "            value(y[i, 1]),\n",
      "            value(y[i, 2]),\n",
      "            value(z[i, 0, 0]),\n",
      "            value(z[i, 0, 1]),\n",
      "            value(z[i, 0, 2]),\n",
      "            value(z[i, 1, 0]),\n",
      "            value(z[i, 1, 1]),\n",
      "            value(z[i, 1, 2]),\n",
      "            value(z[i, 2, 0]),\n",
      "            value(z[i, 2, 1]),\n",
      "            value(z[i, 2, 2]),\n",
      "        ))\n",
      "end\n",
      "\n",
      "df_pr = DataFrame(\n",
      "    :load0 => Float64[], \n",
      "    :load1 => Float64[], \n",
      "    :load2 => Float64[], \n",
      "    :lambda0 => Float64[], \n",
      "    :lambda10 => Float64[],\n",
      "    :lambda11 => Float64[],\n",
      "    :lambda20 => Float64[],\n",
      "    :lambda21 => Float64[]\n",
      "    )\n",
      "\n",
      "for i in 0:tHorz\n",
      "    push!(df_pr, (\n",
      "        value(xLoad[i, 0]), \n",
      "        value(xLoad[i, 1]), \n",
      "        value(xLoad[i, 2]),\n",
      "        value(lambda[i, 0, 0]), \n",
      "        value(lambda[i, 1, 0]),\n",
      "        value(lambda[i, 1, 1]),\n",
      "        value(lambda[i, 2, 0]),\n",
      "        value(lambda[i, 2, 1]),\n",
      "        ))\n",
      "end\n",
      "\n",
      "# Write CSV\n",
      "CSV.write(\"df_co.csv\", df_co)\n",
      "CSV.write(\"df_pow.csv\", df_pow)\n",
      "CSV.write(\"df_steam.csv\", df_steam)\n",
      "CSV.write(\"df_dac_flue.csv\", df_dac_flue)\n",
      "CSV.write(\"df_dac_air.csv\", df_dac_air)\n",
      "CSV.write(\"df_pow_price.csv\", df_pow_price)\n",
      "CSV.write(\"df_cost.csv\", df_cost)\n",
      "CSV.write(\"df_time_slice.csv\", df_time_slice)\n",
      "CSV.write(\"df_binary.csv\", df_binary)\n",
      "CSV.write(\"df_pr.csv\", df_pr)\n",
      "\n",
      "df_diss = DataFrame(\n",
      "    \"load0\" => Float64[],\n",
      "    \"load1\" => Float64[],\n",
      "    \"load2\" => Float64[],\n",
      "    \"powgt0\" => Float64[],\n",
      "    \"powgt1\" => Float64[],\n",
      "    \"powgt2\" => Float64[],\n",
      "    \"fuel0\" => Float64[],\n",
      "    \"fuel1\" => Float64[],\n",
      "    \"fuel2\" => Float64[],\n",
      "    \"emiss0\" => Float64[],\n",
      "    \"emiss1\" => Float64[],\n",
      "    \"emiss2\" => Float64[],\n",
      "    \"auxgt0\" => Float64[],\n",
      "    \"auxgt1\" => Float64[],\n",
      "    \"auxgt2\" => Float64[],\n",
      "    \"powhp0\" => Float64[],\n",
      "    \"powhp1\" => Float64[],\n",
      "    \"powhp2\" => Float64[],\n",
      "    \"powip0\" => Float64[],\n",
      "    \"powip1\" => Float64[],\n",
      "    \"powip2\" => Float64[],\n",
      "    \"pccreb0\" => Float64[],\n",
      "    \"pccreb1\" => Float64[],\n",
      "    \"pccreb2\" => Float64[],\n",
      "    \"dacsb0\" => Float64[],\n",
      "    \"dacsb1\" => Float64[],\n",
      "    \"dacsb2\" => Float64[],\n",
      "    \"allocst0\" => Float64[],\n",
      "    \"allocst1\" => Float64[],\n",
      "    \"allocst2\" => Float64[],\n",
      "    \"auxst0\" => Float64[],\n",
      "    \"auxst1\" => Float64[],\n",
      "    \"auxst2\" => Float64[])\n",
      "\n",
      "dvars = [\"xLoad\", \"xPowGt\", \"xFuelNu\", \"xEmis\", \"xAuxGt\", \"xPowHpNu\", \"xPowIpNu\", \"xPccReb\", \"xDacSb\", \"xAllocS\", \"xAuxSt\"]\n",
      "for i in 0:tHorz\n",
      "    l0 = []\n",
      "    for v in dvars\n",
      "        s = Symbol(v)\n",
      "        l = [value(m[s][i, mod]) for mod in 0:nMod]\n",
      "        l0 = vcat(l0, l)\n",
      "    end\n",
      "    push!(df_diss, l0)\n",
      "end\n",
      "\n",
      "CSV.write(\"df_diss.csv\", df_diss)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  65\n",
      "YangshuaiWang/TightBinding.jl\n",
      "test/runtests.jl\n",
      "########################################\n",
      "\n",
      "using TightBinding\n",
      "using JuLIP\n",
      "using JuLIP.Testing\n",
      "using Base.Test\n",
      "\n",
      "COMPAREATOMS = false    # if Atoms.jl is installed\n",
      "COMPAREQUIP = false     # if QUIP and quippy are installed\n",
      "TESTDEPTH = 1\n",
      "\n",
      "println(\"============================================\")\n",
      "println(\"    TightBinding Tests  \")\n",
      "println(\"============================================\")\n",
      "\n",
      "# =========== Main tests =================\n",
      "# include(\"testtoymodel.jl\")\n",
      "# include(\"testnrltb.jl\")\n",
      "# include(\"testcontour.jl\")\n",
      "# include(\"testsiteE.jl\")\n",
      "# include(\"testkwon.jl\")\n",
      "include(\"testdual.jl\")\n",
      "# include(\"test0T.jl\")\n",
      "\n",
      "# ============= Compare with Atoms.jl and QUIP implementations\n",
      "if COMPAREATOMS; include(\"compareatoms.jl\"); end\n",
      "if COMPAREQUIP; include(\"comparequip.jl\"); end\n",
      "\n",
      "# ============= Performance benchmarks\n",
      "# (uncomment these only for performance tests)\n",
      "# include(\"benchmarkEandFrc.jl\")\n",
      "# include(\"perfsiteE.jl\")\n",
      "\n",
      "\n",
      "# =========== TEMP =======\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  66\n",
      "logankilpatrick/Oceananigans.jl\n",
      "src/diagnostics.jl\n",
      "########################################\n",
      "\n",
      "using Statistics: mean, std\n",
      "using Printf\n",
      "\n",
      "struct CFLChecker <: Diagnostic end\n",
      "struct VelocityDivergence <: Diagnostic end\n",
      "\n",
      "struct FieldSummary <: Diagnostic\n",
      "    diagnostic_frequency::Int\n",
      "    fields::Array{Field,1}\n",
      "    field_names::Array{AbstractString,1}\n",
      "end\n",
      "\n",
      "function run_diagnostic(model::Model, fs::FieldSummary)\n",
      "    for (field, field_name) in zip(fs.fields, fs.field_names)\n",
      "        padded_name = lpad(field_name, 4)\n",
      "        field_min = minimum(field.data)\n",
      "        field_max = maximum(field.data)\n",
      "        field_mean = mean(field.data)\n",
      "        field_abs_mean = mean(abs.(field.data))\n",
      "        field_std = std(field.data)\n",
      "        @printf(\"%s: min=%.6g, max=%.6g, mean=%.6g, absmean=%.6g, std=%.6g\\n\",\n",
      "                padded_name, field_min, field_max, field_mean, field_abs_mean, field_std)\n",
      "    end\n",
      "end\n",
      "\n",
      "struct NaNChecker <: Diagnostic\n",
      "    diagnostic_frequency::Int\n",
      "    fields::Array{Field,1}\n",
      "    field_names::Array{AbstractString,1}\n",
      "end\n",
      "\n",
      "function run_diagnostic(model::Model, nc::NaNChecker)\n",
      "    for (field, field_name) in zip(nc.fields, nc.field_names)\n",
      "        if any(isnan, field.data)  # This is also fast on CuArrays.\n",
      "            t, i = model.clock.time, model.clock.iteration\n",
      "            println(\"time = $t, iteration = $i\")\n",
      "            println(\"NaN found in $field_name. Aborting simulation.\")\n",
      "            exit(1)\n",
      "        end\n",
      "    end\n",
      "end\n",
      "\n",
      "mutable struct Nusselt_wT <: Diagnostic\n",
      "    diagnostic_frequency::Int\n",
      "    Nu::Array{AbstractFloat,1}\n",
      "    Nu_inst::Array{AbstractFloat,1}\n",
      "    wT_cumulative_running_avg::AbstractFloat\n",
      "end\n",
      "\n",
      "function run_diagnostic(model::Model, diag::Nusselt_wT)\n",
      "    α = 207e-6  # Volumetric expansion coefficient [K⁻¹] of water at 20°C.\n",
      "    g = model.constants.g\n",
      "\n",
      "    w, T = model.velocities.w.data, model.tracers.T.data\n",
      "    V = model.grid.Lx * model.grid.Ly * model.grid.Lz\n",
      "    wT_avg = sum(w .* T) / V\n",
      "\n",
      "    n = length(diag.Nu)  # Number of \"samples\" so far.\n",
      "    diag.wT_cumulative_running_avg = (wT_avg + n*model.clock.Δt*diag.wT_cumulative_running_avg) / ((n+1)*model.clock.Δt)\n",
      "\n",
      "    Lz, κ, ΔT = model.grid.Lz, model.configuration.κh, 1\n",
      "    Nu_wT = 1 + (Lz^2 / (κ*α*g*ΔT^2)) * diag.wT_cumulative_running_avg\n",
      "\n",
      "    push!(diag.Nu, Nu_wT)\n",
      "\n",
      "    Nu_wT_inst = 1 + (Lz^2 / (κ*α*g*ΔT^2)) * wT_avg\n",
      "    push!(diag.Nu_inst, Nu_wT_inst)\n",
      "end\n",
      "\n",
      "mutable struct Nusselt_Chi <: Diagnostic\n",
      "    diagnostic_frequency::Int\n",
      "    Nu::Array{AbstractFloat,1}\n",
      "    Nu_inst::Array{AbstractFloat,1}\n",
      "    ∇T²_cumulative_running_avg::AbstractFloat\n",
      "end\n",
      "\n",
      "function norm_gradient_squared!(g::RegularCartesianGrid, f::CellField, ∇f²::CellField, stmp::StepperTemporaryFields)\n",
      "    dfdx, dfdy, dfdz = otmp.fFX, otmp.fFY, otmp.fFZ\n",
      "\n",
      "    δx!(g, f, dfdx)\n",
      "    δy!(g, f, dfdy)\n",
      "    δz!(g, f, dfdz)\n",
      "\n",
      "    @. ∇f².data = dfdx.data^2 + dfdy.data^2 + dfdz.data^2\n",
      "    nothing\n",
      "end\n",
      "\n",
      "function run_diagnostic(model::Model, diag::Nusselt_Chi)\n",
      "    T = model.tracers.T\n",
      "    ∇T² = model.stepper_tmp.fC1\n",
      "    norm_gradient_squared!(model.grid, T, ∇T², model.stepper_tmp)\n",
      "\n",
      "    V = model.grid.Lx * model.grid.Ly * model.grid.Lz\n",
      "    ∇T²_avg = sum(∇T²) / V\n",
      "\n",
      "    n = length(diag.Nu)  # Number of \"samples\" so far.\n",
      "    diag.∇T²_cumulative_running_avg = (∇T²_avg + n*model.clock.Δt*diag.∇T²_cumulative_running_avg) / ((n+1)*model.clock.Δt)\n",
      "\n",
      "    Lz, ΔT = model.grid.Lz, 1\n",
      "    Nu_Chi = 1 + (Lz/ΔT)^2 * diag.∇T²_cumulative_running_avg\n",
      "\n",
      "    push!(diag.Nu, Nu_Chi)\n",
      "\n",
      "    ∇T²_inst = 1 + (Lz/ΔT)^2 * ∇T²_avg\n",
      "    push!(diag.Nu_inst, ∇T²_inst)\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  67\n",
      "mikelehu/IRKGL16.jl\n",
      "ODEProblems/InitialNBody15.jl\n",
      "########################################\n",
      "\n",
      "function InitialNBody15(T)\n",
      "\n",
      "   \"\"\"\n",
      "        Initial Value from DE430\n",
      "        Given in the next order:\n",
      "          Sun,Mercury,Venus,Earth+Moon,Mars,Jupiter,Saturn,Uranus,Neptune,Pluto,\n",
      "          Ceres, Pallas, Vesta, Iris, Bamberga\n",
      "   \"\"\"\n",
      "\n",
      "Gm = [parse(BigFloat,\"0.295912208285591100e-3\"),\n",
      "      parse(BigFloat,\"0.491248045036476000e-10\"),\n",
      "      parse(BigFloat,\"0.724345233264412000e-9\"),\n",
      "      parse(BigFloat,\"0.888769244512563400e-9\")+parse(T,\"0.109318945074237400e-10\"),\n",
      "      parse(BigFloat,\"0.954954869555077000e-10\"),\n",
      "      parse(BigFloat,\"0.282534584083387000e-6\"),\n",
      "      parse(BigFloat,\"0.845970607324503000e-7\"),\n",
      "      parse(BigFloat,\"0.129202482578296000e-7\"),\n",
      "      parse(BigFloat,\"0.152435734788511000e-7\"),\n",
      "      parse(BigFloat,\"0.217844105197418000e-11\"),\n",
      "      # Ceres, Pallas, Vesta, Iris, Bamberga\n",
      "      parse(BigFloat,\"0.140047655617234400e-12\"),\n",
      "      parse(BigFloat,\"0.310444819893871300e-13\"),\n",
      "      parse(BigFloat,\"0.385475018780881000e-13\"),\n",
      "      parse(BigFloat,\"0.213643444257140700e-14\"),\n",
      "      parse(BigFloat,\"0.138862658985619900e-14\")\n",
      "  ]\n",
      "\n",
      "N=length(Gm)\n",
      "\n",
      "q = [parse(BigFloat,\"0.00450250878464055477\"), parse(BigFloat,\"0.00076707642709100705\"), parse(BigFloat,\"0.00026605791776697764\"),\n",
      "     parse(BigFloat,\"0.36176271656028195477\"), parse(BigFloat,\"-0.09078197215676599295\"),parse(BigFloat,\"-0.08571497256275117236\"),\n",
      "     parse(BigFloat,\"0.61275194083507215477\"), parse(BigFloat,\"-0.34836536903362219295\"),parse(BigFloat,\"-0.19527828667594382236\"),\n",
      "     parse(BigFloat,\"0.12051741410138465477\"), parse(BigFloat,\"-0.92583847476914859295\"),parse(BigFloat,\"-0.40154022645315222236\"),\n",
      "     parse(BigFloat,\"-0.11018607714879824523\"),parse(BigFloat,\" -1.32759945030298299295\"),parse(BigFloat,\"-0.60588914048429142236\"),\n",
      "     parse(BigFloat,\"-5.37970676855393644523\"),parse(BigFloat,\" -0.83048132656339789295\"),parse(BigFloat,\"-0.22482887442656542236\"),\n",
      "     parse(BigFloat,\"7.89439068290953155477\"), parse(BigFloat,\"4.59647805517127300705\"), parse(BigFloat,\"1.55869584283189997764\"),\n",
      "     parse(BigFloat,\"-18.26540225387235944523\"), parse(BigFloat,\"-1.16195541867586999295\"),parse(BigFloat,\"-0.25010605772133802236\"),\n",
      "     parse(BigFloat,\"-16.05503578023336944523\"), parse(BigFloat,\"-23.94219155985470899295\"),parse(BigFloat,\"-9.40015796880239402236\"),\n",
      "     parse(BigFloat,\"-30.48331376718383944523\"), parse(BigFloat,\"-0.87240555684104999295\"), parse(BigFloat,\"8.91157617249954997764\")\n",
      "]\n",
      "\n",
      "v = [parse(BigFloat,\"-0.00000035174953607552\"), parse(T,\"0.00000517762640983341\"), parse(T,\"0.00000222910217891203\"),\n",
      "     parse(BigFloat,\"0.00336749397200575848\"), parse(T,\"0.02489452055768343341\"), parse(T,\"0.01294630040970409203\"),\n",
      "     parse(BigFloat,\"0.01095206842352823448\"), parse(T,\"0.01561768426786768341\"), parse(T,\"0.00633110570297786403\"),\n",
      "     parse(BigFloat,\"0.01681126830978379448\"), parse(T,\"0.00174830923073434441\"), parse(T,\"0.00075820289738312913\"),\n",
      "     parse(BigFloat,\"0.01448165305704756448\"), parse(T,\"0.00024246307683646861\"), parse(T,\"-0.00028152072792433877\"),\n",
      "     parse(BigFloat,\"0.00109201259423733748\"), parse(BigFloat,\"-0.00651811661280738459\"), parse(BigFloat,\"-0.00282078276229867897\"),\n",
      "     parse(BigFloat,\"-0.00321755651650091552\"), parse(BigFloat,\"0.00433581034174662541\"), parse(BigFloat,\"0.00192864631686015503\"),\n",
      "     parse(BigFloat,\"0.00022119039101561468\"), parse(BigFloat,\"-0.00376247500810884459\"), parse(BigFloat,\"-0.00165101502742994997\"),\n",
      "     parse(BigFloat,\"0.00264276984798005548\"), parse(BigFloat,\"-0.00149831255054097759\"), parse(BigFloat,\"-0.00067904196080291327\"),\n",
      "     parse(BigFloat,\"0.00032220737349778078\"), parse(BigFloat,\"-0.00314357639364532859\"), parse(BigFloat,\"-0.00107794975959731297\")\n",
      "]\n",
      "\n",
      "\n",
      "# Ceres, Pallas, Vesta, Iris, Bamberga\n",
      "qsun=q[1:3]\n",
      "qCeres=qsun+[parse(BigFloat,\"1.438681809676469747\"),parse(BigFloat,\"-2.204373633189407045\"), parse(BigFloat,\"-1.326397853361325874\")]\n",
      "qPallas=qsun+[parse(BigFloat,\"0.203832272462290465\"),parse(BigFloat,\"-3.209619436062307152\"), parse(BigFloat,\"0.623843179079393351\")]\n",
      "qVesta=qsun+[parse(BigFloat,\"0.182371836377417107\"),parse(BigFloat,\"2.386628211277654010\"), parse(BigFloat,\"0.924596062836265498\")]\n",
      "qIris=qsun+[parse(BigFloat,\"1.892475267790300286\"),parse(BigFloat,\"-0.848414748075139946\"), parse(BigFloat,\"-0.157159319044464590\")]\n",
      "qBamberga=qsun+[parse(BigFloat,\"1.398759064223541682\"),parse(BigFloat,\"-1.287476729008325105\"), parse(BigFloat,\"-0.669098428660833799\")]\n",
      "\n",
      "vsun=v[1:3]\n",
      "vCeres=vsun+[parse(BigFloat,\"0.008465406136316316\"), parse(BigFloat,\"0.004684247977335608\"), parse(BigFloat,\"0.000466157738595739\")]\n",
      "vPallas=vsun+[parse(BigFloat,\"0.008534313855651248\"), parse(BigFloat,\"-0.000860659210123161\"), parse(BigFloat,\"-0.000392901992572746\")]\n",
      "vVesta=vsun+[parse(BigFloat,\"-0.010174496747119257\"), parse(BigFloat,\"0.000041478190529952\"), parse(BigFloat,\"0.001344157634155624\")]\n",
      "vIris=vsun+[parse(BigFloat,\"0.002786950314570632\"), parse(BigFloat,\"0.011314057384917047\"), parse(BigFloat,\"0.004975132577079665\")]\n",
      "vBamberga=vsun+[parse(BigFloat,\"0.007164363244556328\"), parse(BigFloat,\"0.009219958777618218\"), parse(BigFloat,\"0.006857861727407507\")]\n",
      "\n",
      "\n",
      "q = [q; qCeres; qPallas; qVesta; qIris; qBamberga]\n",
      "v = [v; vCeres; vPallas; vVesta; vIris; vBamberga]\n",
      "\n",
      "q0 = reshape(q,3,:)\n",
      "v0 = reshape(v,3,:)\n",
      "\n",
      "q0bar = [sum(Gm .* q0[j,:])/sum(Gm) for j in 1:3]\n",
      "v0bar = [sum(Gm .* v0[j,:])/sum(Gm) for j in 1:3]\n",
      "\n",
      "q0 = q0 .- q0bar\n",
      "v0 = v0 .- v0bar\n",
      "\n",
      "u0 = Array{T}(undef,2,3,N)\n",
      "u0[1,:,:] = v0\n",
      "u0[2,:,:] = q0\n",
      "\n",
      "return u0, convert.(T,Gm)\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  68\n",
      "AlisaLC/stdlib\n",
      "lib/node_modules/@stdlib/math/base/special/atan2/test/fixtures/julia/runner.jl\n",
      "########################################\n",
      "\n",
      "#!/usr/bin/env julia\n",
      "#\n",
      "# @license Apache-2.0\n",
      "#\n",
      "# Copyright (c) 2018 The Stdlib Authors.\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "#    http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "\n",
      "import JSON\n",
      "\n",
      "\"\"\"\n",
      "    gen( x, y, name )\n",
      "\n",
      "Generate fixture data and write to file.\n",
      "\n",
      "# Arguments\n",
      "\n",
      "* `x`: denominator domain\n",
      "* `y`: numerator domain\n",
      "* `name::AbstractString`: output filename\n",
      "\n",
      "# Examples\n",
      "\n",
      "``` julia\n",
      "julia> x = range( -1000.0, stop = 1000.0, length = 2001 );\n",
      "julia> y = range( 0.0, stop = 1000.0, length = 1001 );\n",
      "julia> gen( x, y, \\\"data.json\\\" );\n",
      "```\n",
      "\"\"\"\n",
      "function gen( x, y, name )\n",
      "\tz = Array{Float64}( undef, length(x) );\n",
      "\tfor i in eachindex(x)\n",
      "\t\tz[ i ] = atan.( y[i], x[i] );\n",
      "\tend\n",
      "\n",
      "\t# Store data to be written to file as a collection:\n",
      "\tdata = Dict([\n",
      "\t\t(\"x\", x),\n",
      "\t\t(\"y\", y),\n",
      "\t\t(\"expected\", z)\n",
      "\t]);\n",
      "\n",
      "\t# Based on the script directory, create an output filepath:\n",
      "\tfilepath = joinpath( dir, name );\n",
      "\n",
      "\t# Write the data to the output filepath as JSON:\n",
      "\toutfile = open( filepath, \"w\" );\n",
      "\twrite( outfile, JSON.json(data) );\n",
      "\tclose( outfile );\n",
      "end\n",
      "\n",
      "# Get the filename:\n",
      "file = @__FILE__;\n",
      "\n",
      "# Extract the directory in which this file resides:\n",
      "dir = dirname( file );\n",
      "\n",
      "# Random (x positive, y positive):\n",
      "x = rand( 5001 ) .* 500.0;\n",
      "y = rand( 5001 ) .* 500.0;\n",
      "gen( x, y, \"positive_positive.json\" );\n",
      "\n",
      "# Random (x negative, y positive):\n",
      "x = -rand( 1001 ) .* 500.0;\n",
      "y = rand( 1001 ) .* 500.0;\n",
      "gen( x, y, \"negative_positive.json\" );\n",
      "\n",
      "# Random (x negative, y negative):\n",
      "x = -rand( 1001 ) .* 500.0;\n",
      "y = -rand( 1001 ) .* 500.0;\n",
      "gen( x, y, \"negative_negative.json\" );\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  69\n",
      "davidanthoff/GlobalSensitivityAnalysis.jl\n",
      "test/unit_tests.jl\n",
      "########################################\n",
      "\n",
      "using Test\n",
      "using Distributions\n",
      "\n",
      "include(\"../src/utils.jl\")\n",
      "include(\"../src/sample_sobol.jl\")\n",
      "include(\"../src/test_functions/ishigami.jl\")\n",
      "include(\"../src/analyze_sobol.jl\")\n",
      "\n",
      "##\n",
      "## 1. utils\n",
      "##\n",
      "\n",
      "# SobolData\n",
      "N = 100\n",
      "calc_second_order = false\n",
      "parameters = OrderedDict(\n",
      "    :param1 => Normal(0,1),\n",
      "    :param2 => LogNormal(5, 20),\n",
      "    :param3 => TriangularDist(0, 4, 1)\n",
      ")\n",
      "\n",
      "data1 = SobolData(params = parameters, calc_second_order = calc_second_order, N = N)\n",
      "@test data1.params[:param1] == parameters[:param1]\n",
      "@test data1.params[:param2] == parameters[:param2]\n",
      "@test data1.params[:param2] == parameters[:param2]\n",
      "@test data1.params[:param3] == parameters[:param3]\n",
      "@test data1.N == N\n",
      "@test data1.calc_second_order == calc_second_order\n",
      "\n",
      "data2 = SobolData()\n",
      "@test data2.params == nothing\n",
      "@test data2.N == 1000\n",
      "@test data2.calc_second_order == true\n",
      "\n",
      "data3 = SobolData(params = parameters)\n",
      "data4 = SobolData(calc_second_order = false)\n",
      "data5 = SobolData(N = 100)\n",
      "\n",
      "# scale_sobol_seq!\n",
      "seq = rand(100, 8)\n",
      "original_seq = copy(seq)\n",
      "dists = [Normal(1, 0.2), Uniform(0.75, 1.25), LogNormal(0, 0.5), TriangularDist(0, 4, 1)]\n",
      "scale_sobol_seq!(seq, dists)\n",
      "@test size(seq) == size(original_seq)\n",
      "@test seq != original_seq\n",
      "\n",
      "##\n",
      "## 2. Sample Sobol\n",
      "##\n",
      "\n",
      "samples = sample(data1)\n",
      "@test size(samples, 2) == length(data1.params)\n",
      "if data1.calc_second_order\n",
      "    @test size(samples,1) == data1.N * (2 * length(data1.params) + 2)\n",
      "else\n",
      "    @test size(samples,1) == data1.N * (length(data1.params) + 2)\n",
      "end\n",
      "\n",
      "samples3 = sample(data3)\n",
      "@test size(samples3, 2) == length(data3.params)\n",
      "if data3.calc_second_order\n",
      "    @test size(samples3,1) == data3.N * (2 * length(data3.params) + 2)\n",
      "else\n",
      "    @test size(samples3,1) == data3.N * (length(data3.params) + 2)\n",
      "end\n",
      "\n",
      "@test_throws ErrorException sample(data2) # params are nothing\n",
      "@test_throws ErrorException sample(data4) # params are nothing\n",
      "@test_throws ErrorException sample(data5) # params are nothing\n",
      "\n",
      "##\n",
      "## 4a. Analyze Sobol\n",
      "##\n",
      "\n",
      "Y1 = ishigami(samples)\n",
      "results = analyze(data1, Y1)\n",
      "for Si in results[:firstorder]\n",
      "    @test Si <= 1\n",
      "end\n",
      "for CI in results[:firstorder_conf]\n",
      "    @test CI > 0 \n",
      "end\n",
      "for St in results[:totalorder]\n",
      "    @test St <= 1\n",
      "end\n",
      "for CI in results[:totalorder_conf]\n",
      "    @test CI > 0 \n",
      "end\n",
      "@test sum(results[:totalorder]) > sum(results[:firstorder])\n",
      "\n",
      "Y3 = ishigami(samples3)\n",
      "results = analyze(data3, Y3)\n",
      "for Si in results[:firstorder]\n",
      "    @test Si <= 1\n",
      "end\n",
      "for CI in results[:firstorder_conf]\n",
      "    @test ismissing(CI) || CI > 0\n",
      "end\n",
      "for S2i in results[:secondorder]\n",
      "    @test ismissing(S2i) || S2i <= 1\n",
      "end\n",
      "for CI in results[:secondorder_conf]\n",
      "    @test ismissing(CI) || CI > 0\n",
      "end\n",
      "for St in results[:totalorder]\n",
      "    @test St <= 1\n",
      "end\n",
      "for CI in results[:totalorder_conf]\n",
      "    @test ismissing(CI) || CI > 0\n",
      "end\n",
      "@test sum(results[:totalorder]) > sum(results[:firstorder])\n",
      "\n",
      "##\n",
      "## 4b. Analyze Sobol Optional Keyword Args\n",
      "##\n",
      "\n",
      "data = SobolData(\n",
      "    params = OrderedDict(:x1 => Normal(1, 0.2),\n",
      "        :x2 => Uniform(0.75, 1.25),\n",
      "        :x3 => LogNormal(0, 0.5)),\n",
      "    N = 1000\n",
      ")\n",
      "samples = sample(data)\n",
      "Y = ishigami(samples)\n",
      "results = analyze(data, Y)\n",
      "\n",
      "@test_throws ErrorException analyze(data, Y; num_resamples = nothing)\n",
      "@test_throws ErrorException analyze(data, Y; conf_level = nothing)\n",
      "\n",
      "@test length(analyze(data, Y; num_resamples = nothing, conf_level = nothing)) == 3 # no confidence intervals\n",
      "results = analyze(data, Y; progress_meter = false) # no progress bar should show\n",
      "\n",
      "@test length(analyze(data, Y; N_override = 10)) == 6 \n",
      "results_override = analyze(data, Y, N_override = data.N)\n",
      "results_original = analyze(data, Y)\n",
      "@test results_override[:firstorder] == results_original[:firstorder]\n",
      "@test results_override[:totalorder] == results_original[:totalorder] \n",
      "@test_throws ErrorException analyze(data1, Y1; N_override = data.N + 1) # N_override > N\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  70\n",
      "danielzhaotongliu/MALTrendsWeb\n",
      "backend/anime_data/snapshots_13655.jl\n",
      "########################################\n",
      "\n",
      "{\"timestamp\": 1579986294.0, \"score\": 7.58, \"score_count\": 75881}\n",
      "{\"timestamp\": 1565469072.0, \"score\": 7.6, \"score_count\": 73197}\n",
      "{\"timestamp\": 1565467228.0, \"score\": 7.6, \"score_count\": 73197}\n",
      "{\"timestamp\": 1564844685.0, \"score\": 7.6, \"score_count\": 73197}\n",
      "{\"timestamp\": 1564796493.0, \"score\": 7.6, \"score_count\": 73119}\n",
      "{\"timestamp\": 1564455226.0, \"score\": 7.6, \"score_count\": 73119}\n",
      "{\"timestamp\": 1564357481.0, \"score\": 7.6, \"score_count\": 73119}\n",
      "{\"timestamp\": 1563070647.0, \"score\": 7.6, \"score_count\": 72882}\n",
      "{\"timestamp\": 1562190516.0, \"score\": 7.6, \"score_count\": 72722}\n",
      "{\"timestamp\": 1562142715.0, \"score\": 7.6, \"score_count\": 72722}\n",
      "{\"timestamp\": 1561844932.0, \"score\": 7.6, \"score_count\": 72641}\n",
      "{\"timestamp\": 1561836522.0, \"score\": 7.6, \"score_count\": 72641}\n",
      "{\"timestamp\": 1561629048.0, \"score\": 7.6, \"score_count\": 72641}\n",
      "{\"timestamp\": 1561164742.0, \"score\": 7.6, \"score_count\": 72546}\n",
      "{\"timestamp\": 1560997667.0, \"score\": 7.6, \"score_count\": 72546}\n",
      "{\"timestamp\": 1561629253.0, \"score\": 7.6, \"score_count\": 72641}\n",
      "{\"timestamp\": 1553317874.0, \"score\": 7.6, \"score_count\": 71226}\n",
      "{\"timestamp\": 1529217453.0, \"score\": 7.61, \"score_count\": 67024}\n",
      "{\"timestamp\": 1468505236.0, \"score\": 7.65, \"score_count\": 50549}\n",
      "{\"timestamp\": 1467899574.0, \"score\": 7.65, \"score_count\": 50337}\n",
      "{\"timestamp\": 1461470041.0, \"score\": 7.66, \"score_count\": 48229}\n",
      "{\"timestamp\": 1461347787.0, \"score\": 7.66, \"score_count\": 48172}\n",
      "{\"timestamp\": 1459273647.0, \"score\": 7.66, \"score_count\": 47296}\n",
      "{\"timestamp\": 1442702245.0, \"score\": 7.67, \"score_count\": 41777}\n",
      "{\"timestamp\": 1448700453.0, \"score\": 7.67, \"score_count\": 43630}\n",
      "{\"timestamp\": 1442047039.0, \"score\": 7.67, \"score_count\": 41546}\n",
      "{\"timestamp\": 1560892786.0, \"score\": 7.6, \"score_count\": 72546}\n",
      "{\"timestamp\": 1560817701.0, \"score\": 7.6, \"score_count\": 72463}\n",
      "{\"timestamp\": 1560545417.0, \"score\": 7.6, \"score_count\": 72463}\n",
      "{\"timestamp\": 1560290558.0, \"score\": 7.6, \"score_count\": 72414}\n",
      "{\"timestamp\": 1560193271.0, \"score\": 7.6, \"score_count\": 72414}\n",
      "{\"timestamp\": 1560056732.0, \"score\": 7.6, \"score_count\": 72414}\n",
      "{\"timestamp\": 1560031171.0, \"score\": 7.6, \"score_count\": 72334}\n",
      "{\"timestamp\": 1560019563.0, \"score\": 7.6, \"score_count\": 72334}\n",
      "{\"timestamp\": 1559962528.0, \"score\": 7.6, \"score_count\": 72334}\n",
      "{\"timestamp\": 1559956306.0, \"score\": 7.6, \"score_count\": 72334}\n",
      "{\"timestamp\": 1559953399.0, \"score\": 7.6, \"score_count\": 72334}\n",
      "{\"timestamp\": 1559946781.0, \"score\": 7.6, \"score_count\": 72334}\n",
      "{\"timestamp\": 1559943946.0, \"score\": 7.6, \"score_count\": 72334}\n",
      "{\"timestamp\": 1559942221.0, \"score\": 7.6, \"score_count\": 72334}\n",
      "{\"timestamp\": 1559940592.0, \"score\": 7.6, \"score_count\": 72334}\n",
      "{\"timestamp\": 1559930015.0, \"score\": 7.6, \"score_count\": 72334}\n",
      "{\"timestamp\": 1559873521.0, \"score\": 7.6, \"score_count\": 72334}\n",
      "{\"timestamp\": 1559869758.0, \"score\": 7.6, \"score_count\": 72334}\n",
      "{\"timestamp\": 1559843405.0, \"score\": 7.6, \"score_count\": 72334}\n",
      "{\"timestamp\": 1559838783.0, \"score\": 7.6, \"score_count\": 72334}\n",
      "{\"timestamp\": 1559785799.0, \"score\": 7.6, \"score_count\": 72334}\n",
      "{\"timestamp\": 1559773345.0, \"score\": 7.6, \"score_count\": 72334}\n",
      "{\"timestamp\": 1559760109.0, \"score\": 7.6, \"score_count\": 72334}\n",
      "{\"timestamp\": 1559751177.0, \"score\": 7.6, \"score_count\": 72334}\n",
      "{\"timestamp\": 1559701065.0, \"score\": 7.6, \"score_count\": 72334}\n",
      "{\"timestamp\": 1559620862.0, \"score\": 7.6, \"score_count\": 72334}\n",
      "{\"timestamp\": 1559678923.0, \"score\": 7.6, \"score_count\": 72334}\n",
      "{\"timestamp\": 1559404629.0, \"score\": 7.6, \"score_count\": 72272}\n",
      "{\"timestamp\": 1559323894.0, \"score\": 7.6, \"score_count\": 72272}\n",
      "{\"timestamp\": 1559259549.0, \"score\": 7.6, \"score_count\": 72272}\n",
      "{\"timestamp\": 1559165858.0, \"score\": 7.6, \"score_count\": 72231}\n",
      "{\"timestamp\": 1559064871.0, \"score\": 7.6, \"score_count\": 72231}\n",
      "{\"timestamp\": 1559057358.0, \"score\": 7.6, \"score_count\": 72231}\n",
      "{\"timestamp\": 1559007387.0, \"score\": 7.6, \"score_count\": 72231}\n",
      "{\"timestamp\": 1559003170.0, \"score\": 7.6, \"score_count\": 72231}\n",
      "{\"timestamp\": 1558980290.0, \"score\": 7.6, \"score_count\": 72231}\n",
      "{\"timestamp\": 1558883079.0, \"score\": 7.6, \"score_count\": 72181}\n",
      "{\"timestamp\": 1558826318.0, \"score\": 7.6, \"score_count\": 72181}\n",
      "{\"timestamp\": 1558803734.0, \"score\": 7.6, \"score_count\": 72181}\n",
      "{\"timestamp\": 1558710703.0, \"score\": 7.6, \"score_count\": 72181}\n",
      "{\"timestamp\": 1558567348.0, \"score\": 7.6, \"score_count\": 72133}\n",
      "{\"timestamp\": 1558463598.0, \"score\": 7.6, \"score_count\": 72133}\n",
      "{\"timestamp\": 1558457671.0, \"score\": 7.6, \"score_count\": 72133}\n",
      "{\"timestamp\": 1558139809.0, \"score\": 7.6, \"score_count\": 72102}\n",
      "{\"timestamp\": 1558047504.0, \"score\": 7.6, \"score_count\": 72062}\n",
      "{\"timestamp\": 1557675143.0, \"score\": 7.6, \"score_count\": 72015}\n",
      "{\"timestamp\": 1557581309.0, \"score\": 7.6, \"score_count\": 71971}\n",
      "{\"timestamp\": 1557369265.0, \"score\": 7.6, \"score_count\": 71971}\n",
      "{\"timestamp\": 1557282437.0, \"score\": 7.6, \"score_count\": 71901}\n",
      "{\"timestamp\": 1557088676.0, \"score\": 7.6, \"score_count\": 71901}\n",
      "{\"timestamp\": 1557018995.0, \"score\": 7.6, \"score_count\": 71901}\n",
      "{\"timestamp\": 1556934470.0, \"score\": 7.6, \"score_count\": 71901}\n",
      "{\"timestamp\": 1556655918.0, \"score\": 7.6, \"score_count\": 71863}\n",
      "{\"timestamp\": 1556638040.0, \"score\": 7.6, \"score_count\": 71863}\n",
      "{\"timestamp\": 1556632630.0, \"score\": 7.6, \"score_count\": 71863}\n",
      "{\"timestamp\": 1556508041.0, \"score\": 7.6, \"score_count\": 71816}\n",
      "{\"timestamp\": 1556396934.0, \"score\": 7.6, \"score_count\": 71816}\n",
      "{\"timestamp\": 1556311406.0, \"score\": 7.6, \"score_count\": 71816}\n",
      "{\"timestamp\": 1556141262.0, \"score\": 7.6, \"score_count\": 71780}\n",
      "{\"timestamp\": 1556057456.0, \"score\": 7.6, \"score_count\": 71743}\n",
      "{\"timestamp\": 1555624982.0, \"score\": 7.6, \"score_count\": 71698}\n",
      "{\"timestamp\": 1555446380.0, \"score\": 7.6, \"score_count\": 71649}\n",
      "{\"timestamp\": 1555281606.0, \"score\": 7.6, \"score_count\": 71649}\n",
      "{\"timestamp\": 1555205972.0, \"score\": 7.6, \"score_count\": 71602}\n",
      "{\"timestamp\": 1555037309.0, \"score\": 7.6, \"score_count\": 71602}\n",
      "{\"timestamp\": 1555017758.0, \"score\": 7.6, \"score_count\": 71547}\n",
      "{\"timestamp\": 1554949604.0, \"score\": 7.6, \"score_count\": 71547}\n",
      "{\"timestamp\": 1554929222.0, \"score\": 7.6, \"score_count\": 71547}\n",
      "{\"timestamp\": 1554914989.0, \"score\": 7.6, \"score_count\": 71547}\n",
      "{\"timestamp\": 1554902861.0, \"score\": 7.6, \"score_count\": 71547}\n",
      "{\"timestamp\": 1554763620.0, \"score\": 7.6, \"score_count\": 71547}\n",
      "{\"timestamp\": 1554586512.0, \"score\": 7.6, \"score_count\": 71499}\n",
      "{\"timestamp\": 1554406640.0, \"score\": 7.6, \"score_count\": 71433}\n",
      "{\"timestamp\": 1554392746.0, \"score\": 7.6, \"score_count\": 71433}\n",
      "{\"timestamp\": 1553975332.0, \"score\": 7.6, \"score_count\": 71383}\n",
      "{\"timestamp\": 1553969094.0, \"score\": 7.6, \"score_count\": 71383}\n",
      "{\"timestamp\": 1553823746.0, \"score\": 7.6, \"score_count\": 71335}\n",
      "{\"timestamp\": 1553805844.0, \"score\": 7.6, \"score_count\": 71335}\n",
      "{\"timestamp\": 1553634434.0, \"score\": 7.6, \"score_count\": 71286}\n",
      "{\"timestamp\": 1553633519.0, \"score\": 7.6, \"score_count\": 71286}\n",
      "{\"timestamp\": 1553557623.0, \"score\": 7.6, \"score_count\": 71286}\n",
      "{\"timestamp\": 1553318631.0, \"score\": 7.6, \"score_count\": 71226}\n",
      "{\"timestamp\": 1553317884.0, \"score\": 7.6, \"score_count\": 71226}\n",
      "{\"timestamp\": 1553289125.0, \"score\": 7.6, \"score_count\": 71226}\n",
      "{\"timestamp\": 1553216612.0, \"score\": 7.6, \"score_count\": 71226}\n",
      "{\"timestamp\": 1553210301.0, \"score\": 7.6, \"score_count\": 71226}\n",
      "{\"timestamp\": 1553135551.0, \"score\": 7.6, \"score_count\": 71226}\n",
      "{\"timestamp\": 1553130936.0, \"score\": 7.6, \"score_count\": 71226}\n",
      "{\"timestamp\": 1553128575.0, \"score\": 7.6, \"score_count\": 71226}\n",
      "{\"timestamp\": 1552782140.0, \"score\": 7.6, \"score_count\": 71131}\n",
      "{\"timestamp\": 1552780653.0, \"score\": 7.6, \"score_count\": 71131}\n",
      "{\"timestamp\": 1552773722.0, \"score\": 7.6, \"score_count\": 71131}\n",
      "{\"timestamp\": 1552747762.0, \"score\": 7.6, \"score_count\": 71131}\n",
      "{\"timestamp\": 1552680521.0, \"score\": 7.6, \"score_count\": 71131}\n",
      "{\"timestamp\": 1552599301.0, \"score\": 7.6, \"score_count\": 71131}\n",
      "{\"timestamp\": 1552528848.0, \"score\": 7.6, \"score_count\": 71082}\n",
      "{\"timestamp\": 1552508388.0, \"score\": 7.6, \"score_count\": 71082}\n",
      "{\"timestamp\": 1552421577.0, \"score\": 7.6, \"score_count\": 71082}\n",
      "{\"timestamp\": 1552363434.0, \"score\": 7.6, \"score_count\": 71082}\n",
      "{\"timestamp\": 1552254241.0, \"score\": 7.6, \"score_count\": 71027}\n",
      "{\"timestamp\": 1552230167.0, \"score\": 7.6, \"score_count\": 71027}\n",
      "{\"timestamp\": 1552184932.0, \"score\": 7.6, \"score_count\": 71027}\n",
      "{\"timestamp\": 1552147414.0, \"score\": 7.6, \"score_count\": 71027}\n",
      "{\"timestamp\": 1552100749.0, \"score\": 7.6, \"score_count\": 71027}\n",
      "{\"timestamp\": 1552012350.0, \"score\": 7.6, \"score_count\": 70962}\n",
      "{\"timestamp\": 1551907092.0, \"score\": 7.6, \"score_count\": 70962}\n",
      "{\"timestamp\": 1551580889.0, \"score\": 7.6, \"score_count\": 70900}\n",
      "{\"timestamp\": 1551313453.0, \"score\": 7.6, \"score_count\": 70866}\n",
      "{\"timestamp\": 1551224725.0, \"score\": 7.6, \"score_count\": 70793}\n",
      "{\"timestamp\": 1551221936.0, \"score\": 7.6, \"score_count\": 70793}\n",
      "{\"timestamp\": 1551215664.0, \"score\": 7.6, \"score_count\": 70793}\n",
      "{\"timestamp\": 1551139796.0, \"score\": 7.6, \"score_count\": 70793}\n",
      "{\"timestamp\": 1551128153.0, \"score\": 7.6, \"score_count\": 70793}\n",
      "{\"timestamp\": 1551061497.0, \"score\": 7.6, \"score_count\": 70793}\n",
      "{\"timestamp\": 1551045156.0, \"score\": 7.6, \"score_count\": 70793}\n",
      "{\"timestamp\": 1551025043.0, \"score\": 7.6, \"score_count\": 70793}\n",
      "{\"timestamp\": 1551019819.0, \"score\": 7.6, \"score_count\": 70793}\n",
      "{\"timestamp\": 1550977080.0, \"score\": 7.6, \"score_count\": 70793}\n",
      "{\"timestamp\": 1550944887.0, \"score\": 7.6, \"score_count\": 70793}\n",
      "{\"timestamp\": 1550697912.0, \"score\": 7.6, \"score_count\": 70736}\n",
      "{\"timestamp\": 1550630858.0, \"score\": 7.6, \"score_count\": 70736}\n",
      "{\"timestamp\": 1550696158.0, \"score\": 7.6, \"score_count\": 70736}\n",
      "{\"timestamp\": 1550627477.0, \"score\": 7.6, \"score_count\": 70736}\n",
      "{\"timestamp\": 1550621979.0, \"score\": 7.6, \"score_count\": 70736}\n",
      "{\"timestamp\": 1550618611.0, \"score\": 7.6, \"score_count\": 70736}\n",
      "{\"timestamp\": 1550539969.0, \"score\": 7.6, \"score_count\": 70736}\n",
      "{\"timestamp\": 1550511354.0, \"score\": 7.6, \"score_count\": 70667}\n",
      "{\"timestamp\": 1550450084.0, \"score\": 7.6, \"score_count\": 70667}\n",
      "{\"timestamp\": 1550448911.0, \"score\": 7.6, \"score_count\": 70667}\n",
      "{\"timestamp\": 1550425424.0, \"score\": 7.6, \"score_count\": 70667}\n",
      "{\"timestamp\": 1550283912.0, \"score\": 7.6, \"score_count\": 70667}\n",
      "{\"timestamp\": 1550272953.0, \"score\": 7.6, \"score_count\": 70667}\n",
      "{\"timestamp\": 1550193408.0, \"score\": 7.6, \"score_count\": 70667}\n",
      "{\"timestamp\": 1550017045.0, \"score\": 7.6, \"score_count\": 70599}\n",
      "{\"timestamp\": 1550006584.0, \"score\": 7.6, \"score_count\": 70599}\n",
      "{\"timestamp\": 1550005020.0, \"score\": 7.6, \"score_count\": 70599}\n",
      "{\"timestamp\": 1549945590.0, \"score\": 7.6, \"score_count\": 70599}\n",
      "{\"timestamp\": 1549930144.0, \"score\": 7.6, \"score_count\": 70599}\n",
      "{\"timestamp\": 1549925463.0, \"score\": 7.6, \"score_count\": 70599}\n",
      "{\"timestamp\": 1549846548.0, \"score\": 7.6, \"score_count\": 70599}\n",
      "{\"timestamp\": 1549752030.0, \"score\": 7.6, \"score_count\": 70543}\n",
      "{\"timestamp\": 1547870545.0, \"score\": 7.6, \"score_count\": 70229}\n",
      "{\"timestamp\": 1547850353.0, \"score\": 7.6, \"score_count\": 70229}\n",
      "{\"timestamp\": 1547846281.0, \"score\": 7.6, \"score_count\": 70229}\n",
      "{\"timestamp\": 1547775075.0, \"score\": 7.6, \"score_count\": 70158}\n",
      "{\"timestamp\": 1547697762.0, \"score\": 7.6, \"score_count\": 70158}\n",
      "{\"timestamp\": 1547687685.0, \"score\": 7.6, \"score_count\": 70158}\n",
      "{\"timestamp\": 1547680049.0, \"score\": 7.6, \"score_count\": 70158}\n",
      "{\"timestamp\": 1547675847.0, \"score\": 7.6, \"score_count\": 70158}\n",
      "{\"timestamp\": 1547673556.0, \"score\": 7.6, \"score_count\": 70158}\n",
      "{\"timestamp\": 1547609974.0, \"score\": 7.6, \"score_count\": 70158}\n",
      "{\"timestamp\": 1547599842.0, \"score\": 7.6, \"score_count\": 70158}\n",
      "{\"timestamp\": 1547588838.0, \"score\": 7.6, \"score_count\": 70158}\n",
      "{\"timestamp\": 1547524449.0, \"score\": 7.6, \"score_count\": 70158}\n",
      "{\"timestamp\": 1547509798.0, \"score\": 7.6, \"score_count\": 70158}\n",
      "{\"timestamp\": 1547500234.0, \"score\": 7.6, \"score_count\": 70158}\n",
      "{\"timestamp\": 1547437370.0, \"score\": 7.6, \"score_count\": 70089}\n",
      "{\"timestamp\": 1547395906.0, \"score\": 7.6, \"score_count\": 70089}\n",
      "{\"timestamp\": 1547349871.0, \"score\": 7.6, \"score_count\": 70089}\n",
      "{\"timestamp\": 1547346822.0, \"score\": 7.6, \"score_count\": 70089}\n",
      "{\"timestamp\": 1547330476.0, \"score\": 7.6, \"score_count\": 70089}\n",
      "{\"timestamp\": 1547323481.0, \"score\": 7.6, \"score_count\": 70089}\n",
      "{\"timestamp\": 1547322792.0, \"score\": 7.6, \"score_count\": 70089}\n",
      "{\"timestamp\": 1547317108.0, \"score\": 7.6, \"score_count\": 70089}\n",
      "{\"timestamp\": 1547312718.0, \"score\": 7.6, \"score_count\": 70089}\n",
      "{\"timestamp\": 1547310433.0, \"score\": 7.6, \"score_count\": 70089}\n",
      "{\"timestamp\": 1547261407.0, \"score\": 7.6, \"score_count\": 70089}\n",
      "{\"timestamp\": 1547251714.0, \"score\": 7.6, \"score_count\": 70089}\n",
      "{\"timestamp\": 1547242436.0, \"score\": 7.6, \"score_count\": 70089}\n",
      "{\"timestamp\": 1547177596.0, \"score\": 7.6, \"score_count\": 70089}\n",
      "{\"timestamp\": 1547172889.0, \"score\": 7.6, \"score_count\": 70089}\n",
      "{\"timestamp\": 1547157640.0, \"score\": 7.6, \"score_count\": 70089}\n",
      "{\"timestamp\": 1547091100.0, \"score\": 7.6, \"score_count\": 69998}\n",
      "{\"timestamp\": 1547089387.0, \"score\": 7.6, \"score_count\": 69998}\n",
      "{\"timestamp\": 1546642643.0, \"score\": 7.6, \"score_count\": 69921}\n",
      "{\"timestamp\": 1546640226.0, \"score\": 7.6, \"score_count\": 69921}\n",
      "{\"timestamp\": 1546618634.0, \"score\": 7.6, \"score_count\": 69921}\n",
      "{\"timestamp\": 1546552602.0, \"score\": 7.6, \"score_count\": 69921}\n",
      "{\"timestamp\": 1546541606.0, \"score\": 7.6, \"score_count\": 69921}\n",
      "{\"timestamp\": 1546535218.0, \"score\": 7.6, \"score_count\": 69921}\n",
      "{\"timestamp\": 1546531806.0, \"score\": 7.6, \"score_count\": 69921}\n",
      "{\"timestamp\": 1546489073.0, \"score\": 7.6, \"score_count\": 69921}\n",
      "{\"timestamp\": 1546482763.0, \"score\": 7.6, \"score_count\": 69921}\n",
      "{\"timestamp\": 1546385990.0, \"score\": 7.6, \"score_count\": 69865}\n",
      "{\"timestamp\": 1546355638.0, \"score\": 7.6, \"score_count\": 69865}\n",
      "{\"timestamp\": 1546313001.0, \"score\": 7.6, \"score_count\": 69865}\n",
      "{\"timestamp\": 1546295991.0, \"score\": 7.6, \"score_count\": 69865}\n",
      "{\"timestamp\": 1546290877.0, \"score\": 7.6, \"score_count\": 69865}\n",
      "{\"timestamp\": 1546290100.0, \"score\": 7.6, \"score_count\": 69865}\n",
      "{\"timestamp\": 1546218953.0, \"score\": 7.6, \"score_count\": 69865}\n",
      "{\"timestamp\": 1546211842.0, \"score\": 7.6, \"score_count\": 69865}\n",
      "{\"timestamp\": 1546186443.0, \"score\": 7.6, \"score_count\": 69865}\n",
      "{\"timestamp\": 1546142192.0, \"score\": 7.6, \"score_count\": 69771}\n",
      "{\"timestamp\": 1546124012.0, \"score\": 7.6, \"score_count\": 69771}\n",
      "{\"timestamp\": 1546110989.0, \"score\": 7.6, \"score_count\": 69771}\n",
      "{\"timestamp\": 1546102682.0, \"score\": 7.6, \"score_count\": 69771}\n",
      "{\"timestamp\": 1546057688.0, \"score\": 7.6, \"score_count\": 69771}\n",
      "{\"timestamp\": 1546050846.0, \"score\": 7.6, \"score_count\": 69771}\n",
      "{\"timestamp\": 1546031811.0, \"score\": 7.6, \"score_count\": 69771}\n",
      "{\"timestamp\": 1546021879.0, \"score\": 7.6, \"score_count\": 69771}\n",
      "{\"timestamp\": 1546007061.0, \"score\": 7.6, \"score_count\": 69771}\n",
      "{\"timestamp\": 1545938568.0, \"score\": 7.6, \"score_count\": 69771}\n",
      "{\"timestamp\": 1545863814.0, \"score\": 7.6, \"score_count\": 69771}\n",
      "{\"timestamp\": 1545855978.0, \"score\": 7.6, \"score_count\": 69771}\n",
      "{\"timestamp\": 1545853876.0, \"score\": 7.6, \"score_count\": 69771}\n",
      "{\"timestamp\": 1545791497.0, \"score\": 7.6, \"score_count\": 69708}\n",
      "{\"timestamp\": 1545706857.0, \"score\": 7.6, \"score_count\": 69708}\n",
      "{\"timestamp\": 1545532576.0, \"score\": 7.6, \"score_count\": 69708}\n",
      "{\"timestamp\": 1545357944.0, \"score\": 7.6, \"score_count\": 69642}\n",
      "{\"timestamp\": 1545327147.0, \"score\": 7.6, \"score_count\": 69642}\n",
      "{\"timestamp\": 1545272746.0, \"score\": 7.6, \"score_count\": 69642}\n",
      "{\"timestamp\": 1545246621.0, \"score\": 7.6, \"score_count\": 69642}\n",
      "{\"timestamp\": 1545243322.0, \"score\": 7.6, \"score_count\": 69642}\n",
      "{\"timestamp\": 1545181660.0, \"score\": 7.6, \"score_count\": 69642}\n",
      "{\"timestamp\": 1545171554.0, \"score\": 7.6, \"score_count\": 69642}\n",
      "{\"timestamp\": 1545168495.0, \"score\": 7.6, \"score_count\": 69642}\n",
      "{\"timestamp\": 1545161091.0, \"score\": 7.6, \"score_count\": 69642}\n",
      "{\"timestamp\": 1545018649.0, \"score\": 7.6, \"score_count\": 69614}\n",
      "{\"timestamp\": 1544995682.0, \"score\": 7.6, \"score_count\": 69614}\n",
      "{\"timestamp\": 1544925264.0, \"score\": 7.6, \"score_count\": 69590}\n",
      "{\"timestamp\": 1544915551.0, \"score\": 7.6, \"score_count\": 69590}\n",
      "{\"timestamp\": 1544909236.0, \"score\": 7.6, \"score_count\": 69590}\n",
      "{\"timestamp\": 1544752158.0, \"score\": 7.6, \"score_count\": 69562}\n",
      "{\"timestamp\": 1544404379.0, \"score\": 7.6, \"score_count\": 69488}\n",
      "{\"timestamp\": 1544397316.0, \"score\": 7.6, \"score_count\": 69488}\n",
      "{\"timestamp\": 1544394865.0, \"score\": 7.6, \"score_count\": 69488}\n",
      "{\"timestamp\": 1544306007.0, \"score\": 7.6, \"score_count\": 69488}\n",
      "{\"timestamp\": 1544219114.0, \"score\": 7.6, \"score_count\": 69488}\n",
      "{\"timestamp\": 1544140915.0, \"score\": 7.6, \"score_count\": 69488}\n",
      "{\"timestamp\": 1544132783.0, \"score\": 7.6, \"score_count\": 69488}\n",
      "{\"timestamp\": 1543976385.0, \"score\": 7.6, \"score_count\": 69463}\n",
      "{\"timestamp\": 1543684947.0, \"score\": 7.6, \"score_count\": 69409}\n",
      "{\"timestamp\": 1543440844.0, \"score\": 7.6, \"score_count\": 69386}\n",
      "{\"timestamp\": 1543285731.0, \"score\": 7.6, \"score_count\": 69359}\n",
      "{\"timestamp\": 1543243235.0, \"score\": 7.6, \"score_count\": 69359}\n",
      "{\"timestamp\": 1543116471.0, \"score\": 7.61, \"score_count\": 69329}\n",
      "{\"timestamp\": 1543024208.0, \"score\": 7.61, \"score_count\": 69311}\n",
      "{\"timestamp\": 1542940264.0, \"score\": 7.61, \"score_count\": 69311}\n",
      "{\"timestamp\": 1542934935.0, \"score\": 7.61, \"score_count\": 69311}\n",
      "{\"timestamp\": 1542417930.0, \"score\": 7.61, \"score_count\": 69227}\n",
      "{\"timestamp\": 1542340229.0, \"score\": 7.61, \"score_count\": 69199}\n",
      "{\"timestamp\": 1542337903.0, \"score\": 7.61, \"score_count\": 69199}\n",
      "{\"timestamp\": 1542249890.0, \"score\": 7.61, \"score_count\": 69199}\n",
      "{\"timestamp\": 1542161671.0, \"score\": 7.61, \"score_count\": 69170}\n",
      "{\"timestamp\": 1542143231.0, \"score\": 7.61, \"score_count\": 69170}\n",
      "{\"timestamp\": 1542074670.0, \"score\": 7.61, \"score_count\": 69170}\n",
      "{\"timestamp\": 1542057904.0, \"score\": 7.61, \"score_count\": 69170}\n",
      "{\"timestamp\": 1541903237.0, \"score\": 7.61, \"score_count\": 69140}\n",
      "{\"timestamp\": 1541866463.0, \"score\": 7.61, \"score_count\": 69140}\n",
      "{\"timestamp\": 1541886795.0, \"score\": 7.61, \"score_count\": 69140}\n",
      "{\"timestamp\": 1541864195.0, \"score\": 7.61, \"score_count\": 69140}\n",
      "{\"timestamp\": 1541808129.0, \"score\": 7.61, \"score_count\": 69112}\n",
      "{\"timestamp\": 1541733412.0, \"score\": 7.61, \"score_count\": 69112}\n",
      "{\"timestamp\": 1541715891.0, \"score\": 7.61, \"score_count\": 69112}\n",
      "{\"timestamp\": 1541648339.0, \"score\": 7.61, \"score_count\": 69068}\n",
      "{\"timestamp\": 1541556339.0, \"score\": 7.61, \"score_count\": 69068}\n",
      "{\"timestamp\": 1541649164.0, \"score\": 7.61, \"score_count\": 69068}\n",
      "{\"timestamp\": 1541517729.0, \"score\": 7.61, \"score_count\": 69068}\n",
      "{\"timestamp\": 1541468091.0, \"score\": 7.61, \"score_count\": 69037}\n",
      "{\"timestamp\": 1541465016.0, \"score\": 7.61, \"score_count\": 69037}\n",
      "{\"timestamp\": 1541385441.0, \"score\": 7.61, \"score_count\": 69037}\n",
      "{\"timestamp\": 1529254508.0, \"score\": 7.61, \"score_count\": 67024}\n",
      "{\"timestamp\": 1541380486.0, \"score\": 7.61, \"score_count\": 69037}\n",
      "{\"timestamp\": 1527263927.0, \"score\": 7.61, \"score_count\": 66768}\n",
      "{\"timestamp\": 1526236147.0, \"score\": 7.61, \"score_count\": 66523}\n",
      "{\"timestamp\": 1522339265.0, \"score\": 7.61, \"score_count\": 65429}\n",
      "{\"timestamp\": 1516471433.0, \"score\": 7.62, \"score_count\": 63890}\n",
      "{\"timestamp\": 1489578352.0, \"score\": 7.63, \"score_count\": 56748}\n",
      "{\"timestamp\": 1485539999.0, \"score\": 7.64, \"score_count\": 55703}\n",
      "{\"timestamp\": 1485539792.0, \"score\": 7.64, \"score_count\": 55703}\n",
      "{\"timestamp\": 1484614471.0, \"score\": 7.64, \"score_count\": 55397}\n",
      "{\"timestamp\": 1484614073.0, \"score\": 7.64, \"score_count\": 55397}\n",
      "{\"timestamp\": 1478614726.0, \"score\": 7.64, \"score_count\": 53667}\n",
      "{\"timestamp\": 1470963901.0, \"score\": 7.65, \"score_count\": 51402}\n",
      "{\"timestamp\": 1467978743.0, \"score\": 7.65, \"score_count\": 50363}\n",
      "{\"timestamp\": 1464484686.0, \"score\": 7.65, \"score_count\": 49173}\n",
      "{\"timestamp\": 1463715296.0, \"score\": 7.65, \"score_count\": 48949}\n",
      "{\"timestamp\": 1463714804.0, \"score\": 7.65, \"score_count\": 48949}\n",
      "{\"timestamp\": 1463602100.0, \"score\": 7.65, \"score_count\": 48911}\n",
      "{\"timestamp\": 1462230458.0, \"score\": 7.66, \"score_count\": 48484}\n",
      "{\"timestamp\": 1460899978.0, \"score\": 7.66, \"score_count\": 48003}\n",
      "{\"timestamp\": 1460672584.0, \"score\": 7.66, \"score_count\": 47920}\n",
      "{\"timestamp\": 1460651626.0, \"score\": 7.66, \"score_count\": 47906}\n",
      "{\"timestamp\": 1458304558.0, \"score\": 7.66, \"score_count\": 46910}\n",
      "{\"timestamp\": 1458129267.0, \"score\": 7.66, \"score_count\": 46845}\n",
      "{\"timestamp\": 1457966839.0, \"score\": 7.66, \"score_count\": 46805}\n",
      "{\"timestamp\": 1457510594.0, \"score\": 7.66, \"score_count\": 46632}\n",
      "{\"timestamp\": 1456744323.0, \"score\": 7.66, \"score_count\": 46407}\n",
      "{\"timestamp\": 1457317490.0, \"score\": 7.66, \"score_count\": 46571}\n",
      "{\"timestamp\": 1455938790.0, \"score\": 7.66, \"score_count\": 46123}\n",
      "{\"timestamp\": 1455651312.0, \"score\": 7.66, \"score_count\": 46029}\n",
      "{\"timestamp\": 1454589926.0, \"score\": 7.66, \"score_count\": 45685}\n",
      "{\"timestamp\": 1454426878.0, \"score\": 7.66, \"score_count\": 45635}\n",
      "{\"timestamp\": 1453829176.0, \"score\": 7.66, \"score_count\": 45456}\n",
      "{\"timestamp\": 1453683587.0, \"score\": 7.66, \"score_count\": 45410}\n",
      "{\"timestamp\": 1453610613.0, \"score\": 7.66, \"score_count\": 45386}\n",
      "{\"timestamp\": 1544217463.0, \"score\": 7.6, \"score_count\": 69488}\n",
      "{\"timestamp\": 1544241005.0, \"score\": 7.6, \"score_count\": 69488}\n",
      "{\"timestamp\": 1545268975.0, \"score\": 7.6, \"score_count\": 69642}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  71\n",
      "mauro3/GeoStatsBase.jl\n",
      "src/paths/source.jl\n",
      "########################################\n",
      "\n",
      "# ------------------------------------------------------------------\n",
      "# Licensed under the MIT License. See LICENSE in the project root.\n",
      "# ------------------------------------------------------------------\n",
      "\n",
      "\"\"\"\n",
      "    SourcePath(sources, batchsize=10^3)\n",
      "\n",
      "Traverse a spatial object from `sources` and outwards.\n",
      "Optionally pass a `batchsize` for KD-tree evaluations.\n",
      "\"\"\"\n",
      "struct SourcePath <: AbstractPath\n",
      "  sources::Vector{Int}\n",
      "  batchsize::Int\n",
      "end\n",
      "\n",
      "SourcePath(sources) = SourcePath(sources, 10^3)\n",
      "\n",
      "function traverse(object, path::SourcePath)\n",
      "  sources   = path.sources\n",
      "  batchsize = path.batchsize\n",
      "  @assert allunique(sources) \"non-unique sources\"\n",
      "  @assert all(1 .≤ sources .≤ nelms(object)) \"sources must be valid locations\"\n",
      "  @assert length(sources) ≤ nelms(object) \"more sources than points in object\"\n",
      "\n",
      "  # coordinate matrix for source points\n",
      "  S = coordinates(object, sources)\n",
      "\n",
      "  # fit search tree\n",
      "  kdtree = KDTree(S)\n",
      "\n",
      "  # other locations that are not sources\n",
      "  others = setdiff(1:nelms(object), sources)\n",
      "\n",
      "  # process points in batches\n",
      "  batches = Iterators.partition(others, batchsize)\n",
      "\n",
      "  # pre-allocate memory for coordinates\n",
      "  X = Matrix{coordtype(object)}(undef, ncoords(object), batchsize)\n",
      "\n",
      "  # compute distances to sources\n",
      "  dists = []\n",
      "  for batch in batches\n",
      "    coordinates!(X, object, batch)\n",
      "    _, ds = knn(kdtree, view(X,:,1:length(batch)), length(sources), true)\n",
      "    append!(dists, ds)\n",
      "  end\n",
      "\n",
      "  [sources; view(others, sortperm(dists))]\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  72\n",
      "casv2/ACE.jl\n",
      "src/rpi/rotations3d.jl\n",
      "########################################\n",
      "\n",
      "\n",
      "# --------------------------------------------------------------------------\n",
      "# ACE.jl and SHIPs.jl: Julia implementation of the Atomic Cluster Expansion\n",
      "# Copyright (c) 2019 Christoph Ortner <christophortner0@gmail.com>\n",
      "# Licensed under ASL - see ASL.md for terms and conditions.\n",
      "# --------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "module Rotations3D\n",
      "\n",
      "using StaticArrays\n",
      "using LinearAlgebra: norm, rank, svd, Diagonal\n",
      "using ACE.SphericalHarmonics: index_y\n",
      "using Combinatorics: permutations\n",
      "\n",
      "export ClebschGordan, Rot3DCoeffs, ri_basis, rpi_basis\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "`ClebschGordan: ` storing precomputed Clebsch-Gordan coefficients; see\n",
      "`?clebschgordan` for the convention that is use.\n",
      "\"\"\"\n",
      "struct ClebschGordan{T}\n",
      "\tvals::Dict{Tuple{Int, Int, Int, Int, Int, Int}, T}\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "`Rot3DCoeffs: ` storing recursively precomputed coefficients for a\n",
      "rotation-invariant basis.\n",
      "\"\"\"\n",
      "struct Rot3DCoeffs{T}\n",
      "   vals::Vector{Dict}\n",
      "   cg::ClebschGordan{T}\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "# -----------------------------------\n",
      "# iterating over an m collection\n",
      "# -----------------------------------\n",
      "\n",
      "_mvec(::CartesianIndex{0}) = SVector(Int(0))\n",
      "\n",
      "_mvec(mpre::CartesianIndex) = SVector(Tuple(mpre)..., - sum(Tuple(mpre)))\n",
      "\n",
      "struct MRange{N, T2}\n",
      "   ll::SVector{N, Int}\n",
      "   cartrg::T2\n",
      "end\n",
      "\n",
      "Base.length(mr::MRange) = sum(_->1, _mrange(mr.ll))\n",
      "\n",
      "\"\"\"\n",
      "Given an l-vector `ll` iterate over all combinations of `mm` vectors  of\n",
      "the same length such that `sum(mm) == 0`\n",
      "\"\"\"\n",
      "_mrange(ll) = MRange(ll, Iterators.Stateful(\n",
      "                     CartesianIndices(ntuple(i -> -ll[i]:ll[i], length(ll)-1))))\n",
      "\n",
      "function Base.iterate(mr::MRange{1}, args...)\n",
      "   if isempty(mr.cartrg)\n",
      "      return nothing\n",
      "   end\n",
      "   while !isempty(mr.cartrg)\n",
      "      popfirst!(mr.cartrg)\n",
      "   end\n",
      "   return SVector{1, Int}(0), nothing\n",
      "end\n",
      "\n",
      "function Base.iterate(mr::MRange, args...)\n",
      "   while true\n",
      "      if isempty(mr.cartrg)\n",
      "         return nothing\n",
      "      end\n",
      "      mpre = popfirst!(mr.cartrg)\n",
      "      if abs(sum(mpre.I)) <= mr.ll[end]\n",
      "         return _mvec(mpre), nothing\n",
      "      end\n",
      "   end\n",
      "   error(\"we should never be here\")\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "# ----------------------------------------------------------------------\n",
      "#     ClebschGordan code\n",
      "# ----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "cg_conditions(j1,m1, j2,m2, J,M) =\n",
      "\tcg_l_condition(j1, j2, J)   &&\n",
      "\tcg_m_condition(m1, m2, M)   &&\n",
      "\t(abs(m1) <= j1) && (abs(m2) <= j2) && (abs(M) <= J)\n",
      "\n",
      "cg_l_condition(j1, j2, J) = (abs(j1-j2) <= J <= j1 + j2)\n",
      "\n",
      "cg_m_condition(m1, m2, M) = (M == m1 + m2)\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "`clebschgordan(j1, m1, j2, m2, J, M, T=Float64)` :\n",
      "\n",
      "A reference implementation of Clebsch-Gordon coefficients based on\n",
      "\n",
      "https://hal.inria.fr/hal-01851097/document\n",
      "Equation (4-6)\n",
      "\n",
      "This heavily uses BigInt and BigFloat and should therefore not be employed\n",
      "for performance critical tasks, but only precomputation.\n",
      "\n",
      "The ordering of parameters corresponds to the following convention:\n",
      "```\n",
      "clebschgordan(j1, m1, j2, m2, J, M) = C_{j1m1j2m2}^{JM}\n",
      "```\n",
      "where\n",
      "```\n",
      "   D_{m1k1}^{l1} D_{m2k2}^{l2}}\n",
      "\t=\n",
      "\t∑_j  C_{l1m1l2m2}^{j(m1+m2)} C_{l1k1l2k2}^{j2(k1+k2)} D_{(m1+m2)(k1+k2)}^{j}\n",
      "```\n",
      "\"\"\"\n",
      "function clebschgordan(j1, m1, j2, m2, J, M, T=Float64)\n",
      "\tif !cg_conditions(j1, m1, j2, m2, J, M)\n",
      "\t\treturn zero(T)\n",
      "\tend\n",
      "\n",
      "   N = (2*J+1) *\n",
      "       factorial(big(j1+m1)) * factorial(big(j1-m1)) *\n",
      "       factorial(big(j2+m2)) * factorial(big(j2-m2)) *\n",
      "       factorial(big(J+M)) * factorial(big(J-M)) /\n",
      "       factorial(big( j1+j2-J)) /\n",
      "       factorial(big( j1-j2+J)) /\n",
      "       factorial(big(-j1+j2+J)) /\n",
      "       factorial(big(j1+j2+J+1))\n",
      "\n",
      "   G = big(0)\n",
      "   # 0 ≦ k ≦ j1+j2-J\n",
      "   # 0 ≤ j1-m1-k ≤ j1-j2+J   <=>   j2-J-m1 ≤ k ≤ j1-m1\n",
      "   # 0 ≤ j2+m2-k ≤ -j1+j2+J  <=>   j1-J+m2 ≤ k ≤ j2+m2\n",
      "   lb = (0, j2-J-m1, j1-J+m2)\n",
      "   ub = (j1+j2-J, j1-m1, j2+m2)\n",
      "   for k in maximum(lb):minimum(ub)\n",
      "      bk = big(k)\n",
      "      G += (-1)^k *\n",
      "           binomial(big( j1+j2-J), big(k)) *\n",
      "           binomial(big( j1-j2+J), big(j1-m1-k)) *\n",
      "           binomial(big(-j1+j2+J), big(j2+m2-k))\n",
      "   end\n",
      "\n",
      "   return T(sqrt(N) * G)\n",
      "end\n",
      "\n",
      "\n",
      "ClebschGordan(T=Float64) =\n",
      "\tClebschGordan{T}(Dict{Tuple{Int,Int,Int,Int,Int,Int}, T}())\n",
      "\n",
      "_cg_key(j1, m1, j2, m2, J, M) = (j1, m1, j2, m2, J, M)\n",
      "\t# Int.((index_y(j1,m1), index_y(j2,m2), index_y(J,M)))\n",
      "\n",
      "function (cg::ClebschGordan{T})(j1, m1, j2, m2, J, M) where {T}\n",
      "\tif !cg_conditions(j1,m1, j2,m2, J,M)\n",
      "\t\treturn zero(T)\n",
      "\tend\n",
      "\tkey = _cg_key(j1, m1, j2, m2, J, M)\n",
      "\tif haskey(cg.vals, key)\n",
      "\t\treturn cg.vals[key]\n",
      "\tend\n",
      "\tval = clebschgordan(j1, m1, j2, m2, J, M, T)\n",
      "\tcg.vals[key] = val\n",
      "\treturn val\n",
      "end\n",
      "\n",
      "\n",
      "# ----------------------------------------------------------------------\n",
      "#     Rot3DCoeffs code: generalized cg coefficients\n",
      "#\n",
      "#  Note: in this section kk is a tuple of m-values, it is not\n",
      "#        related to the k index in the 1-p basis (or radial basis)\n",
      "# ----------------------------------------------------------------------\n",
      "\n",
      "dicttype(N::Integer) = dicttype(Val(N))\n",
      "\n",
      "dicttype(::Val{N}) where {N} =\n",
      "   Dict{Tuple{SVector{N,Int}, SVector{N,Int}, SVector{N,Int}}, Float64}\n",
      "\n",
      "Rot3DCoeffs(T=Float64) = Rot3DCoeffs(Dict[], ClebschGordan(T))\n",
      "\n",
      "\n",
      "function get_vals(A::Rot3DCoeffs, valN::Val{N}) where {N}\n",
      "\tif length(A.vals) < N\n",
      "\t\tfor n = length(A.vals)+1:N\n",
      "\t\t\tpush!(A.vals, dicttype(n)())\n",
      "\t\tend\n",
      "\tend\n",
      "   return A.vals[N]::dicttype(valN)\n",
      "end\n",
      "\n",
      "_key(ll::StaticVector{N}, mm::StaticVector{N}, kk::StaticVector{N}) where {N} =\n",
      "      (SVector{N, Int}(ll), SVector{N, Int}(mm), SVector{N, Int}(kk))\n",
      "\n",
      "function (A::Rot3DCoeffs{T})(ll::StaticVector{N},\n",
      "                            mm::StaticVector{N},\n",
      "                            kk::StaticVector{N}) where {T, N}\n",
      "   if       sum(mm) != 0 ||\n",
      "            sum(kk) != 0 ||\n",
      "            !all(abs.(mm) .<= ll) ||\n",
      "            !all(abs.(kk) .<= ll)\n",
      "      return T(0)\n",
      "   end\n",
      "   vals = get_vals(A, Val(N))  # this should infer the type!\n",
      "   key = _key(ll, mm, kk)\n",
      "   if haskey(vals, key)\n",
      "      val  = vals[key]\n",
      "   else\n",
      "      val = _compute_val(A, key...)\n",
      "      vals[key] = val\n",
      "   end\n",
      "   return val\n",
      "end\n",
      "\n",
      "# the recursion has two steps so we need to define the\n",
      "# coupling coefficients for N = 1, 2\n",
      "# TODO: actually this seems false; it is only one recursion step, and a bit\n",
      "#       or reshuffling should allow us to get rid of the {N = 2} case.\n",
      "\n",
      "function (A::Rot3DCoeffs{T})(ll::StaticVector{1},\n",
      "                            mm::StaticVector{1},\n",
      "                            kk::StaticVector{1}) where {T}\n",
      "   if ll[1] == mm[1] == kk[1] == 0\n",
      "      return T(1)\n",
      "   else\n",
      "      return T(0)\n",
      "   end\n",
      "end\n",
      "\n",
      "function (A::Rot3DCoeffs{T})(ll::StaticVector{2},\n",
      "                            mm::StaticVector{2},\n",
      "                            kk::StaticVector{2}) where {T}\n",
      "   if ll[1] != ll[2] || sum(mm) != 0 || sum(kk) != 0\n",
      "      return T(0)\n",
      "   else\n",
      "      return T( 8 * pi^2 / (2*ll[1]+1) * (-1)^(mm[1]-kk[1]) )\n",
      "   end\n",
      "end\n",
      "\n",
      "# next comes the recursion step for N ≧ 3\n",
      "\n",
      "function _compute_val(A::Rot3DCoeffs{T}, ll::StaticVector{N},\n",
      "                                        mm::StaticVector{N},\n",
      "                                        kk::StaticVector{N}) where {T, N}\n",
      "\tval = T(0)\n",
      "   llp = ll[1:N-2]\n",
      "   mmp = mm[1:N-2]\n",
      "   kkp = kk[1:N-2]\n",
      "   for j = abs(ll[N-1]-ll[N]):(ll[N-1]+ll[N])\n",
      "      if abs(kk[N-1]+kk[N]) > j || abs(mm[N-1]+mm[N]) > j\n",
      "         continue\n",
      "      end\n",
      "\t\tcgk = try\n",
      "\t\t\tA.cg(ll[N-1], kk[N-1], ll[N], kk[N], j, kk[N-1]+kk[N])\n",
      "\t\tcatch\n",
      "\t\t\t@show (ll[N-1], kk[N-1], ll[N], kk[N], j, kk[N-1]+kk[N])\n",
      "\t\t\tT(0)\n",
      "\t\tend\n",
      "\t\tcgm = A.cg(ll[N-1], mm[N-1], ll[N], mm[N], j, mm[N-1]+mm[N])\n",
      "\t\tif cgk * cgm  != 0\n",
      "\t\t\tval += cgk * cgm * A( SVector(llp..., j),\n",
      "\t\t\t\t\t\t\t\t       SVector(mmp..., mm[N-1]+mm[N]),\n",
      "\t\t\t\t\t\t\t\t       SVector(kkp..., kk[N-1]+kk[N]) )\n",
      "\t\tend\n",
      "   end\n",
      "   return val\n",
      "end\n",
      "\n",
      "\n",
      "# ----------------------------------------------------------------------\n",
      "#   construction of a possible set of generalised CG coefficient;\n",
      "#   numerically via SVD\n",
      "# ----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "function ri_basis(A::Rot3DCoeffs{T}, ll::SVector; ordered=false) where {T}\n",
      "\tCC = compute_Al(A, ll, Val(ordered))\n",
      "\tsvdC = svd(CC)\n",
      "\trk = rank(Diagonal(svdC.S))\n",
      "\treturn svdC.U[:, 1:rk]'\n",
      "end\n",
      "\n",
      "\n",
      "# unordered\n",
      "function compute_Al(A::Rot3DCoeffs{T}, ll::SVector, ::Val{false}) where {T}\n",
      "\tlen = length(_mrange(ll))\n",
      "   CC = zeros(T, len, len)\n",
      "   for (im, mm) in enumerate(_mrange(ll)), (ik, kk) in enumerate(_mrange(ll))\n",
      "      CC[ik, im] = A(ll, mm, kk)\n",
      "   end\n",
      "   return CC\n",
      "end\n",
      "\n",
      "# # ordered; TODO: check this out, clean it up and test it!!!\n",
      "# function compute_Al(A::Rot3DCoeffs{T}, ll::SVector, ::Val{true}) where {T}\n",
      "# \tnum_mm_sorted = sum(mm -> issorted(mm), _mrange(ll))\n",
      "# \t# @show num_mm_sorted\n",
      "# \tnum_mm = length(_mrange(ll))\n",
      "#    CC = zeros(T, num_mm, num_mm_sorted)\n",
      "# \tim = 0\n",
      "#    for mm in _mrange(ll)\n",
      "# \t\tif issorted(mm) # -> make this sorted relative to ll!!!\n",
      "# \t\t\tim += 1\n",
      "# \t\t\tfor (ik, kk) in enumerate(_mrange(ll))\n",
      "# \t\t      CC[ik, im] = A(ll, mm, kk)\n",
      "# \t\t\tend\n",
      "# \t\tend\n",
      "# \tend\n",
      "#    return CC\n",
      "# end\n",
      "#\n",
      "#\n",
      "# # two utility functions which are probably never used!\n",
      "#\n",
      "# compute_Al(ll::SVector{N}; ordered = false) where {N} =\n",
      "# \t\tcompute_Al(Rot3DCoeffs(N, sum(ll)), ll; ordered=ordered)\n",
      "#\n",
      "# compute_Al(A::Rot3DCoeffs, ll::SVector{N}; ordered = false) where {N} =\n",
      "# \t\tcompute_Al(A, ll, Val(ordered))\n",
      "\n",
      "\n",
      "# TODO: this could use some documentation\n",
      "\n",
      "rpi_basis(A::Rot3DCoeffs, zz, nn, ll) =\n",
      "\t\t\trpi_basis(A, SVector(zz...), SVector(nn...), SVector(ll...))\n",
      "\n",
      "function rpi_basis(A::Rot3DCoeffs,\n",
      "\t\t\t\t\t\t zz::SVector{N},\n",
      "\t\t\t\t\t\t nn::SVector{N, Int},\n",
      "\t\t\t\t\t\t ll::SVector{N, Int}) where {N}\n",
      "\tUri = ri_basis(A, ll)\n",
      "\tMri = collect( _mrange(ll) )   # rows...\n",
      "\tG = _gramian(zz, nn, ll, Uri, Mri)\n",
      "   S = svd(G)\n",
      "   rk = rank(G; rtol =  1e-7)\n",
      "\tUrpi = S.U[:, 1:rk]'\n",
      "\treturn Diagonal(sqrt.(S.S[1:rk])) * Urpi * Uri, Mri\n",
      "end\n",
      "\n",
      "\n",
      "function _gramian(zz, nn, ll, Uri, Mri)\n",
      "   N = length(nn)\n",
      "   nri = size(Uri, 1)\n",
      "   @assert size(Uri, 1) == nri\n",
      "   G = zeros(nri, nri)\n",
      "   for σ in permutations(1:N)\n",
      "      if (zz[σ] != zz) || (nn[σ] != nn) || (ll[σ] != ll); continue; end\n",
      "      for (iU1, mm1) in enumerate(Mri), (iU2, mm2) in enumerate(Mri)\n",
      "         if mm1[σ] == mm2\n",
      "            for i1 = 1:nri, i2 = 1:nri\n",
      "               G[i1, i2] += conj(Uri[i1, iU1]) * Uri[i2, iU2]\n",
      "            end\n",
      "         end\n",
      "      end\n",
      "   end\n",
      "   return G\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  73\n",
      "cesmix-mit/MDP\n",
      "src/Julia/Gencode/nopotentialgrad.jl\n",
      "########################################\n",
      "\n",
      "#****************************************************************************                               \n",
      "#                     Molecular Dynamics Potentials (MDP)\n",
      "#                            CESMIX-MIT Project  \n",
      "# \n",
      "#  Contributing authors: Ngoc-Cuong Nguyen (cuongng@mit.edu, exapde@gmail.com)\n",
      "#****************************************************************************\n",
      "\n",
      "function nopotentialgrad(foldername, filename, u, xij, xik, xil, xi, xj, xk, xl, qi, qj, qk, ql, ti, tj, tk, tl, ai, aj, ak, al, mu, eta, kappa, pot)\n",
      "\n",
      "ifile = 0;\n",
      "gen = 0;\n",
      "if pot==0\n",
      "    stropu, strcpu, strgpu = gendensitygrad(foldername,filename, u, mu, mu, eta, kappa, gen, ifile);\n",
      "elseif pot==1    \n",
      "    stropu, strcpu, strgpu = gensinglegrad(foldername, filename, u, xi, qi, ti, ai, mu, eta, kappa, gen, ifile);\n",
      "elseif pot==2\n",
      "    stropu, strcpu, strgpu = genpairgrad(foldername, filename, u, xij, qi, qj, ti, tj, ai, aj, mu, eta, kappa, gen, ifile);\n",
      "elseif pot==3\n",
      "    stropu, strcpu, strgpu = gentripletgrad(foldername, filename, u, xij, xik, qi, qj, qk, ti, tj, tk, ai, aj, ak, mu, eta, kappa, gen, ifile);\n",
      "elseif pot==4    \n",
      "    stropu, strcpu, strgpu = genquadrupletgrad(foldername, filename, u, xij, xik, xil, qi, qj, qk, ql, ti, tj, tk, tl, ai, aj, ak, al, mu, eta, kappa, gen, ifile);\n",
      "end    \n",
      "cppfiles(foldername, filename, stropu, strcpu, strgpu, 1);\n",
      "\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  74\n",
      "tkelman/Sparrow.jl\n",
      "src/xyzmap.jl\n",
      "########################################\n",
      "\n",
      "type XYZMap <: Graph\n",
      "\tdataGroups::Vector{DataGroup}\n",
      "end\n",
      "\n",
      "XYZMap(dg::DataGroup) = XYZMap([dg])\n",
      "\n",
      "function plotData(g::XYZMap, showLegend::Bool, fid)\n",
      "\tglobal dgCount\n",
      "\n",
      "\tfor x in 1:length(g.dataGroups)\n",
      "\t\tif x == 1\n",
      "\t\t\tprintln(fid, \"xyz-map\")\n",
      "\t\tend\n",
      "\n",
      "\t\tdg = g.dataGroups[x]\n",
      "\t\tif dg.lineColor == \"blank\"\n",
      "\t\t\tdg.lineColor = goodColors[mod(x, length(goodColors))]\n",
      "\t\tend\n",
      "\n",
      "\t\tif dg.markerColor == \"blank\"\n",
      "\t\t\tdg.markerColor = goodColors[mod(x, length(goodColors))]\n",
      "\t\tend\n",
      "\n",
      "\t\tif dg.markerType == \"blank\"\n",
      "\t\t\tdg.markerType = goodSymbols[mod(x, length(goodSymbols))]\n",
      "\t\tend\n",
      "\n",
      "\t\tprintln(fid, \"color \"*dg.lineColor)\n",
      "\t\tprintln(fid, \"line-style \"*dg.lineStyle)\n",
      "\t\tprintln(fid, \"marker-color \"*dg.markerColor)\n",
      "\t\tprintln(fid, \"marker \"*dg.markerType)\n",
      "\t\tprintln(fid, \"marker-line-width $(dg.markerLineWidth)\")\n",
      "\t\tprintln(fid, \"marker-min-scale $(dg.markerScale[1])\")\n",
      "\t\tprintln(fid, \"marker-scale $(dg.markerScale[2])\")\n",
      "\t\tprintln(fid, \"error-bar-line-width $(dg.errorLineWidth)\")\n",
      "\t\tif showLegend\n",
      "\t\t\tdgCount += 1\n",
      "\t\t\tif dg.legend.label == \"\\'Data Group \\'\"\n",
      "\t\t\t\tprintln(fid, \"legend \"*dg.legend.label*string(dgCount))\n",
      "\t\t\telse\n",
      "\t\t\t\tprintln(fid, \"legend \"*dg.legend.label)\n",
      "\t\t\tend\n",
      "\t\tend\n",
      "\n",
      "\t\tpush!(dataFs, sparrowD*\"data.sparrow\"*randstring(5))\n",
      "\t\tif isempty(find(DataFrames.names(dg) .== :yerr))\n",
      "\t\t\twritedlm(dataFs[end], [dg.data[:x] dg.data[:y]])\n",
      "\t\t\tprintln(fid, \"plot $(dataFs[end])@\\$1:\\$2\")\n",
      "\t\telse\n",
      "\t\t\twritedlm(dataFs[end], [dg.data[:x] dg.data[:y] dg.data[:yerr]])\n",
      "\t\t\tprintln(fid, \"plot $(dataFs[end])@\\$1:\\$2:yerr=\\$3\")\n",
      "\t\tend\n",
      "\tend\n",
      "end\n",
      "\n",
      "function xyzmap(dgs::Vector{DataGroup})\n",
      "\tplot(PlotFrame(XYZMap(dgs)))\n",
      "end\n",
      "\n",
      "function xyzmap(dg::DataGroup)\n",
      "\tplot(PlotFrame(XYZMap(dg)))\n",
      "end\n",
      "\n",
      "function xyzmap(dfs::Vector{DataFrame})\n",
      "\tdgs = DataGroup[]\n",
      "\tfor df in dfs\n",
      "\t\tpush!(dgs, DataGroup(df))\n",
      "\tend\n",
      "\txyzmap(dgs)\n",
      "end\n",
      "\n",
      "function xyzmap(df::DataFrame)\n",
      "\txyzmap(DataGroup(df))\n",
      "end\n",
      "\n",
      "function xyzmap(ys::Array{Float64, 2})\n",
      "\tdfs = DataFrame[]\n",
      "\tfor r = 1:size(y, 1)\n",
      "\t\tpush!(dfs, DataFrame(x = collect(1:length(y)), y = y[r,:]))\n",
      "\tend\n",
      "\txyzmap(dfs)\n",
      "end\n",
      "\n",
      "function xyzmap(xs::Array{Float64, 2}, ys::Array{Float64, 2})\n",
      "\tdfs = DataFrame[]\n",
      "\tfor r = 1:size(y, 1)\n",
      "\t\tpush!(dfs, DataFrame(x = x[r,:], y = y[r,:]))\n",
      "\tend\n",
      "\txyzmap(dfs)\n",
      "end\n",
      "\n",
      "function xyzmap(xs::Array{Float64, 2}, ys::Array{Float64, 2}, yerrs::Array{Float64, 2})\n",
      "\tdfs = DataFrame[]\n",
      "\tfor r = 1:size(ys, 1)\n",
      "\t\tpush!(dfs, DataFrame(x = vec(xs[r,:]), y = vec(ys[r,:]), yerr = vec(yerrs[r,:])))\n",
      "\tend\n",
      "\txyzmap(dfs)\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  75\n",
      "zsteve/OptimalTransport.jl\n",
      "test/exact.jl\n",
      "########################################\n",
      "\n",
      "using OptimalTransport\n",
      "\n",
      "using Distances\n",
      "using PythonOT: PythonOT\n",
      "using Tulip\n",
      "using MathOptInterface\n",
      "using Distributions\n",
      "using HCubature\n",
      "\n",
      "using LinearAlgebra\n",
      "using Random\n",
      "using SparseArrays\n",
      "\n",
      "const MOI = MathOptInterface\n",
      "const POT = PythonOT\n",
      "\n",
      "Random.seed!(100)\n",
      "\n",
      "@testset \"exact.jl\" begin\n",
      "    @testset \"Earth-Movers Distance\" begin\n",
      "        M = 200\n",
      "        N = 250\n",
      "        μ = normalize!(rand(M), 1)\n",
      "        ν = normalize!(rand(N), 1)\n",
      "\n",
      "        @testset \"example\" begin\n",
      "            # create random cost matrix\n",
      "            C = pairwise(SqEuclidean(), rand(1, M), rand(1, N); dims=2)\n",
      "\n",
      "            # compute optimal transport map and cost with POT\n",
      "            pot_P = POT.emd(μ, ν, C)\n",
      "            pot_cost = POT.emd2(μ, ν, C)\n",
      "\n",
      "            # compute optimal transport map and cost with Tulip\n",
      "            lp = Tulip.Optimizer()\n",
      "            P = emd(μ, ν, C, lp)\n",
      "            @test size(C) == size(P)\n",
      "            @test MOI.get(lp, MOI.TerminationStatus()) == MOI.OPTIMAL\n",
      "            @test maximum(abs, P .- pot_P) < 1e-2\n",
      "\n",
      "            lp = Tulip.Optimizer()\n",
      "            cost = emd2(μ, ν, C, lp)\n",
      "            @test dot(C, P) ≈ cost atol = 1e-5\n",
      "            @test MOI.get(lp, MOI.TerminationStatus()) == MOI.OPTIMAL\n",
      "            @test cost ≈ pot_cost atol = 1e-5\n",
      "        end\n",
      "\n",
      "        @testset \"pre-computed plan\" begin\n",
      "            # create random cost matrix\n",
      "            C = pairwise(SqEuclidean(), rand(1, M), rand(1, N); dims=2)\n",
      "\n",
      "            # compute optimal transport map\n",
      "            P = emd(μ, ν, C, Tulip.Optimizer())\n",
      "\n",
      "            # do not use μ and ν to ensure that provided map is used\n",
      "            cost = emd2(similar(μ), similar(ν), C, Tulip.Optimizer(); plan=P)\n",
      "            @test cost ≈ emd2(μ, ν, C, Tulip.Optimizer())\n",
      "        end\n",
      "\n",
      "        # https://github.com/JuliaOptimalTransport/OptimalTransport.jl/issues/71\n",
      "        @testset \"cost matrix with integers\" begin\n",
      "            C = pairwise(SqEuclidean(), rand(1:10, 1, M), rand(1:10, 1, N); dims=2)\n",
      "            emd2(μ, ν, C, Tulip.Optimizer())\n",
      "        end\n",
      "    end\n",
      "\n",
      "    @testset \"1D Optimal Transport for Convex Cost\" begin\n",
      "        @testset \"continuous distributions\" begin\n",
      "            # two normal distributions (has analytical solution)\n",
      "            μ = Normal(randn(), rand())\n",
      "            ν = Normal(randn(), rand())\n",
      "\n",
      "            # compute OT plan\n",
      "            γ = ot_plan(sqeuclidean, μ, ν)\n",
      "            x = randn()\n",
      "            @test γ(x) ≈ quantile(ν, cdf(μ, x))\n",
      "\n",
      "            # compute OT cost\n",
      "            c = ot_cost(sqeuclidean, μ, ν)\n",
      "            @test c ≈ (mean(μ) - mean(ν))^2 + (std(μ) - std(ν))^2\n",
      "\n",
      "            # do not use ν to ensure that the provided plan is used\n",
      "            @test ot_cost(sqeuclidean, μ, Normal(randn(), rand()); plan=γ) ≈ c\n",
      "        end\n",
      "\n",
      "        @testset \"semidiscrete case\" begin\n",
      "            μ = Normal(randn(), rand())\n",
      "            νprobs = normalize!(rand(30), 1)\n",
      "            ν = Categorical(νprobs)\n",
      "\n",
      "            # compute OT plan\n",
      "            γ = ot_plan(euclidean, μ, ν)\n",
      "            x = randn()\n",
      "            @test γ(x) ≈ quantile(ν, cdf(μ, x))\n",
      "\n",
      "            # compute OT cost, without and with provided plan\n",
      "            # do not use ν in the second case to ensure that the provided plan is used\n",
      "            c = ot_cost(euclidean, μ, ν)\n",
      "            @test ot_cost(euclidean, μ, Categorical(reverse(νprobs)); plan=γ) ≈ c\n",
      "\n",
      "            # check that OT cost is consistent with OT cost of a discretization\n",
      "            m = 500\n",
      "            xs = rand(μ, m)\n",
      "            μdiscrete = fill(1 / m, m)\n",
      "            C = pairwise(Euclidean(), xs', (1:length(νprobs))'; dims=2)\n",
      "            c2 = emd2(μdiscrete, νprobs, C, Tulip.Optimizer())\n",
      "            @test c2 ≈ c rtol = 1e-1\n",
      "        end\n",
      "\n",
      "        @testset \"discrete case\" begin\n",
      "            # random source and target marginal\n",
      "            m = 30\n",
      "            μprobs = normalize!(rand(m), 1)\n",
      "            μsupport = randn(m)\n",
      "            μ = DiscreteNonParametric(μsupport, μprobs)\n",
      "\n",
      "            n = 50\n",
      "            νprobs = normalize!(rand(n), 1)\n",
      "            νsupport = randn(n)\n",
      "            ν = DiscreteNonParametric(νsupport, νprobs)\n",
      "\n",
      "            # compute OT plan\n",
      "            γ = @inferred(ot_plan(euclidean, μ, ν))\n",
      "            @test γ isa SparseMatrixCSC\n",
      "            @test size(γ) == (m, n)\n",
      "            @test vec(sum(γ; dims=2)) ≈ μ.p\n",
      "            @test vec(sum(γ; dims=1)) ≈ ν.p\n",
      "\n",
      "            # consistency checks\n",
      "            I, J, W = findnz(γ)\n",
      "            @test all(w > zero(w) for w in W)\n",
      "            @test sum(W) ≈ 1\n",
      "            @test sort(unique(I)) == 1:m\n",
      "            @test sort(unique(J)) == 1:n\n",
      "            @test sort(I .+ J) == 2:(m + n)\n",
      "\n",
      "            # compute OT cost\n",
      "            c = @inferred(ot_cost(euclidean, μ, ν))\n",
      "\n",
      "            # compare with computation with explicit cost matrix\n",
      "            # DiscreteNonParametric sorts the support automatically, here we have to sort\n",
      "            # manually\n",
      "            C = pairwise(Euclidean(), μsupport', νsupport'; dims=2)\n",
      "            c2 = emd2(μprobs, νprobs, C, Tulip.Optimizer())\n",
      "            @test c2 ≈ c rtol = 1e-5\n",
      "\n",
      "            # compare with POT\n",
      "            # disabled currently since https://github.com/PythonOT/POT/issues/169 causes bounds\n",
      "            # error\n",
      "            # @test γ ≈ POT.emd_1d(μ.support, ν.support; a=μ.p, b=μ.p, metric=\"euclidean\")\n",
      "            # @test c ≈ POT.emd2_1d(μ.support, ν.support; a=μ.p, b=μ.p, metric=\"euclidean\")\n",
      "\n",
      "            # do not use the probabilities of μ and ν to ensure that the provided plan is\n",
      "            # used\n",
      "            μ2 = DiscreteNonParametric(μsupport, reverse(μprobs))\n",
      "            ν2 = DiscreteNonParametric(νsupport, reverse(νprobs))\n",
      "            c2 = @inferred(ot_cost(euclidean, μ2, ν2; plan=γ))\n",
      "            @test c2 ≈ c\n",
      "            c2 = @inferred(ot_cost(euclidean, μ2, ν2; plan=Matrix(γ)))\n",
      "            @test c2 ≈ c\n",
      "        end\n",
      "    end\n",
      "\n",
      "    @testset \"Multivariate Gaussians\" begin\n",
      "        @testset \"translation with constant covariance\" begin\n",
      "            m = randn(100)\n",
      "            τ = rand(100)\n",
      "            Σ = Matrix(Hermitian(rand(100, 100) + 100I))\n",
      "            μ = MvNormal(m, Σ)\n",
      "            ν = MvNormal(m .+ τ, Σ)\n",
      "            @test ot_cost(SqEuclidean(), μ, ν) ≈ norm(τ)^2\n",
      "\n",
      "            x = rand(100, 10)\n",
      "            T = ot_plan(SqEuclidean(), μ, ν)\n",
      "            @test pdf(ν, mapslices(T, x; dims=1)) ≈ pdf(μ, x)\n",
      "        end\n",
      "\n",
      "        @testset \"comparison to grid approximation\" begin\n",
      "            μ = MvNormal([0, 0], [1 0; 0 2])\n",
      "            ν = MvNormal([10, 10], [2 0; 0 1])\n",
      "            # Constructing circular grid approximation\n",
      "            # Angular grid step\n",
      "            θ = collect(0:0.2:(2π))\n",
      "            θx = cos.(θ)\n",
      "            θy = sin.(θ)\n",
      "            # Radius grid step\n",
      "            δ = collect(0:0.2:1)\n",
      "            μsupp = [0.0 0.0]\n",
      "            νsupp = [10.0 10.0]\n",
      "            for i in δ[2:end]\n",
      "                a = [θx .* i θy .* i * 2]\n",
      "                b = [θx .* i * 2 θy .* i] .+ [10 10]\n",
      "                μsupp = vcat(μsupp, a)\n",
      "                νsupp = vcat(νsupp, b)\n",
      "            end\n",
      "\n",
      "            # Create discretized distribution\n",
      "            μprobs = normalize!(pdf(μ, μsupp'), 1)\n",
      "            νprobs = normalize!(pdf(ν, νsupp'), 1)\n",
      "            C = pairwise(SqEuclidean(), μsupp', νsupp'; dims=2)\n",
      "            @test emd2(μprobs, νprobs, C, Tulip.Optimizer()) ≈ ot_cost(SqEuclidean(), μ, ν) rtol =\n",
      "                1e-3\n",
      "\n",
      "            # Use hcubature integration to perform ``\\\\int c(x,T(x)) d\\\\mu``\n",
      "            T = ot_plan(SqEuclidean(), μ, ν)\n",
      "            c_hcubature, _ = hcubature([-10, -10], [10, 10]) do x\n",
      "                return sqeuclidean(x, T(x)) * pdf(μ, x)\n",
      "            end\n",
      "            @test ot_cost(SqEuclidean(), μ, ν) ≈ c_hcubature rtol = 1e-3\n",
      "        end\n",
      "    end\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  76\n",
      "wherrera10/SailingNavigation.jl\n",
      "src/SailingNavigation.jl\n",
      "########################################\n",
      "\n",
      "module SailingNavigation\n",
      "\n",
      "export Position, lat, lon, GridPoint, TimeSlice, TimedPath, closestpoint, surround\n",
      "export RoutingProblem, minimumtimeroute\n",
      "\n",
      "using GeometryTypes\n",
      "using SailingPolars\n",
      "\n",
      "# NB: This uses latitude (often considered to be y) first then longitude (often considered to be x).\n",
      "# This latitude, then longitude ordering is as per ISO 6709 (en.wikipedia.org/wiki/ISO_6709)\n",
      "\n",
      "# Position is a Float32 2-tuple of latitude and longitude in degrees\n",
      "Position = Point2f0\n",
      "\n",
      "# latitude from Position\n",
      "lat(p::Position) = p[1]\n",
      "\n",
      "# longitude from Position\n",
      "lon(p::Position) = p[2]\n",
      "\n",
      "# A GridPoint is a Position with the SurfaceParameters of wind and current at the Position\n",
      "mutable struct GridPoint\n",
      "    pt::Position\n",
      "    sp::SurfaceParameters\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    TimeSlice\n",
      "\n",
      "A TimeSlice is a matrix of GridPoints, each Position point with their SurfaceParameters\n",
      "A Vector of TimeSlice can give the surface characteristics for an ocean region over time.\n",
      "\"\"\"\n",
      "TimeSlice = Matrix{GridPoint}\n",
      "\n",
      "\"\"\"\n",
      "    mutable struct RoutingProblem\n",
      "\n",
      "timeinterval: the seconds duration for each TimeSlice\n",
      "timeframe: a vector of sequential timeslices for the ocean region\n",
      "obstacleindices: the Cartesian indices in each timeslice for\n",
      "    obstacles, such as land or shoals, where the ship may not go\n",
      "startindex: the timeslice position for time of starting\n",
      "start: starting location on grid of GridPoints\n",
      "finish: destination / finish location on grid of GridPoints\n",
      "allowrepeatvisits: whether the vessel may overlap its prior path, usually false\n",
      "\"\"\"\n",
      "mutable struct RoutingProblem\n",
      "    timeinterval::Float64 # minutes between timeframe slices\n",
      "    timeframe::Vector{TimeSlice}\n",
      "    obstacleindices::Vector{Point2{Int}}\n",
      "    startindex::Int\n",
      "    start::Point2{Int}\n",
      "    finish::Point2{Int}\n",
      "    allowrepeatvisits::Bool\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    mutable struct TimedPath\n",
      "\n",
      "duration: minutes total to travel the path\n",
      "path: vector of Cartesian indices of points in grid for path to travel\n",
      "\"\"\"\n",
      "mutable struct TimedPath\n",
      "    duration::Float64\n",
      "    path::Vector{Point2{Int}}\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    closestpoint(p, mat)\n",
      "\n",
      "Get the closest GridPoint in matrix mat to a given position p.\n",
      "p: Cartesian indices of a Position (latitude, longitude in degrees) in grid of GridPoints\n",
      "mat: matrix of Gridpoints\n",
      "\"\"\"\n",
      "closestpoint(p, mat) = findmin(gp -> haversine(p[1], p[2], gp.pt[1], gp.pt[2])[1], mat)[2]\n",
      "\n",
      "function surround(p, mat, excluded)\n",
      "    neighbors = Point2{Int}[(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n",
      "    (xmax, ymax) = size(mat)\n",
      "    return filter(q -> 1 <= q[1] <= xmax && 1 <= q[2] <= ymax && !(q in excluded),\n",
      "        [x + p for x in neighbors])\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    function minimumtimeroute(rp::RoutingProblem, sp::SailingPolar, verbose=false)\n",
      "\n",
      "Get the route (as a TimedPath) that minimizes time from start to finish for a given\n",
      "RoutingProblem (sea parameters) given sailing polar data (ship parameters).\n",
      "\"\"\"\n",
      "function minimumtimeroute(rp::RoutingProblem, sp::SailingPolar, verbose=false)\n",
      "    timedpaths = [TimedPath(0.0, [rp.start])]\n",
      "    completed, mintime, minpath = false, 1000.0, TimedPath(1000.0, [])\n",
      "    for i in 1:1000\n",
      "        newpaths = TimedPath[]\n",
      "        verbose && println(\"Checking \", length(timedpaths), \" paths of length \",\n",
      "            length(timedpaths[1].path) - 1)\n",
      "        for tpath in timedpaths\n",
      "            if tpath.path[end] == rp.finish\n",
      "                completed = true\n",
      "                push!(newpaths, tpath)\n",
      "            else\n",
      "                p1 = tpath.path[end]\n",
      "                slice = rp.timeframe[div(Int(round(tpath.duration)),\n",
      "                                     Int(round(rp.timeinterval))) %\n",
      "                                     length(rp.timeframe) + 1]\n",
      "                for p2 in surround([p1[1], p1[2]], slice, rp.obstacleindices)\n",
      "                    !rp.allowrepeatvisits && p2 in tpath.path && continue\n",
      "                    gp1, gp2 = slice[p1[1], p1[2]], slice[p2[1], p2[2]]\n",
      "                    lat1, lon1, lat2, lon2 = gp1.pt[1], gp1.pt[2], gp2.pt[1], gp2.pt[2]\n",
      "                    t = sailsegmenttime(sp, gp1.sp, lat1, lon1, lat2, lon2)\n",
      "                    path = deepcopy(tpath.path)\n",
      "                    push!(path, p2)\n",
      "                    push!(newpaths, TimedPath(tpath.duration + t, path))\n",
      "                end\n",
      "            end\n",
      "        end\n",
      "        timedpaths = unique(newpaths)\n",
      "        if completed\n",
      "            mindur = minimum(map(x -> x.duration, timedpaths))\n",
      "            finished = filter(x -> x.path[end] == rp.finish, timedpaths)\n",
      "            minfindur, idx = findmin(map(x -> x.duration, finished))\n",
      "            verbose && println(\"Current finished minimum: \", finished[idx], \", others $mindur\")\n",
      "            if mindur == minfindur\n",
      "                minpath = finished[idx]\n",
      "                break\n",
      "            end\n",
      "        end\n",
      "    end\n",
      "    return minpath\n",
      "end\n",
      "\n",
      "end # module\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  77\n",
      "pikacxe/Primenjeni-Algoritmi\n",
      "Primer3/population.jl\n",
      "########################################\n",
      "\n",
      "include(\"entity.jl\")\n",
      "\n",
      "\n",
      "function generatePopulation(n, genesLength)\n",
      "    data = []\n",
      "    for i in 1:n\n",
      "        entity = generateEntity(genesLength)\n",
      "        push!(data,entity)\n",
      "    end\n",
      "    return data\n",
      "end\n",
      "\n",
      "function calculatePopulationFitness!(data,values, weights, maxCapacity)\n",
      "    for i in 1:length(data)\n",
      "        calculateFitness!(data[i],values,weights,maxCapacity)\n",
      "    end\n",
      "    sort!(data, by = d -> d.fitness, rev = false)\n",
      "end\n",
      "\n",
      "function printPopulation(data)\n",
      "    for i in 1:length(data)\n",
      "        printEntity(data[i])\n",
      "    end\n",
      "end\n",
      "\n",
      "\n",
      "function selectPopulation(data,n)\n",
      "    return copy(data[1:n])\n",
      "end\n",
      "\n",
      "function crossoverPopulation(data,crossoverPoint1,crossoverPoint2)\n",
      "    newData = []\n",
      "    for i in 1:length(data)\n",
      "        for j in 1:length(data)\n",
      "            entity1 = deepcopy(data[i])\n",
      "            entity2 = deepcopy(data[j])\n",
      "            crossover!(entity1,entity2,crossoverPoint1,crossoverPoint2)\n",
      "            push!(newData,entity1)\n",
      "            push!(newData,entity2) \n",
      "        end \n",
      "    end\n",
      "    return newData\n",
      "end\n",
      "\n",
      "function mutatePopulation!(data, mutatePercentage)\n",
      "    for i in 1:length(data) \n",
      "        mutate!(data[i],mutatePercentage)\n",
      "    end\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  78\n",
      "apatlpo/UnderwaterAcoustics.jl\n",
      "src/pm_bellhop.jl\n",
      "########################################\n",
      "\n",
      "export Bellhop\n",
      "\n",
      "\"\"\"\n",
      "$(TYPEDEF)\n",
      "A propagation model based on an external FORTRAN Bellhop executable.\n",
      "\"\"\"\n",
      "struct Bellhop{T} <: PropagationModel{T}\n",
      "  env::T\n",
      "  nbeams::Int\n",
      "  minangle::Float32\n",
      "  maxangle::Float32\n",
      "  gaussian::Bool\n",
      "  debug::Bool\n",
      "  function Bellhop(env, nbeams, minangle, maxangle, gaussian, debug)\n",
      "    nbeams < 0 && (nbeams = 0)\n",
      "    -π/2 ≤ minangle ≤ π/2 || throw(ArgumentError(\"minangle should be between -π/2 and π/2\"))\n",
      "    -π/2 ≤ maxangle ≤ π/2 || throw(ArgumentError(\"maxangle should be between -π/2 and π/2\"))\n",
      "    minangle < maxangle || throw(ArgumentError(\"maxangle should be more than minangle\"))\n",
      "    new{typeof(env)}(check(Bellhop, env), nbeams, Float32(minangle), Float32(maxangle), gaussian, debug)\n",
      "  end\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    Bellhop(env; gaussian=false, debug=false)\n",
      "    Bellhop(env, nbeams, minangle, maxangle, gaussian, debug)\n",
      "\n",
      "Create a Bellhop propagation model.\n",
      "\"\"\"\n",
      "Bellhop(env; gaussian=false, debug=false) = Bellhop(env, 0, -80°, 80°, gaussian, debug)\n",
      "\n",
      "### interface functions\n",
      "\n",
      "function check(::Type{Bellhop}, env::Union{<:UnderwaterEnvironment,Missing})\n",
      "  if env === missing\n",
      "    mktempdir(prefix=\"bellhop_\") do dirname\n",
      "      try\n",
      "        bellhop(dirname, false)\n",
      "      catch e\n",
      "        e isa BellhopError && e.details == [\"Unable to execute bellhop.exe\"] && throw(e)\n",
      "      end\n",
      "    end\n",
      "  else\n",
      "    seabed(env) isa RayleighReflectionCoef || throw(ArgumentError(\"Seabed type not supported\"))\n",
      "    seasurface(env) === Vacuum || throw(ArgumentError(\"Only vacuum seasurface supported\"))\n",
      "  end\n",
      "  env\n",
      "end\n",
      "\n",
      "function arrivals(model::Bellhop, tx1::AcousticSource, rx1::AcousticReceiver)\n",
      "  mktempdir(prefix=\"bellhop_\") do dirname\n",
      "    writeenv(model, [tx1], [rx1], \"A\", dirname)\n",
      "    bellhop(dirname, model.debug)\n",
      "    readarrivals(joinpath(dirname, \"model.arr\"))\n",
      "  end\n",
      "end\n",
      "\n",
      "function transfercoef(model::Bellhop, tx1::AcousticSource, rx::AcousticReceiverGrid2D; mode=:coherent)\n",
      "  if mode === :coherent\n",
      "    taskcode = \"C\"\n",
      "  elseif mode === :incoherent\n",
      "    taskcode = \"I\"\n",
      "  elseif mode === :semicoherent\n",
      "    taskcode = \"S\"\n",
      "  else\n",
      "    throw(ArgumentError(\"Unknown mode :\" * string(mode)))\n",
      "  end\n",
      "  mktempdir(prefix=\"bellhop_\") do dirname\n",
      "    writeenv(model, [tx1], rx, taskcode, dirname)\n",
      "    bellhop(dirname, model.debug)\n",
      "    readshd(joinpath(dirname, \"model.shd\"))\n",
      "  end\n",
      "end\n",
      "\n",
      "function transfercoef(model::Bellhop, tx1::AcousticSource, rx1::AcousticReceiver; mode=:coherent)\n",
      "  if mode === :coherent\n",
      "    taskcode = \"C\"\n",
      "  elseif mode === :incoherent\n",
      "    taskcode = \"I\"\n",
      "  elseif mode === :semicoherent\n",
      "    taskcode = \"S\"\n",
      "  else\n",
      "    throw(ArgumentError(\"Unknown mode :\" * string(mode)))\n",
      "  end\n",
      "  mktempdir(prefix=\"bellhop_\") do dirname\n",
      "    writeenv(model, [tx1], [rx1], taskcode, dirname)\n",
      "    bellhop(dirname, model.debug)\n",
      "    readshd(joinpath(dirname, \"model.shd\"))[1]\n",
      "  end\n",
      "end\n",
      "\n",
      "function eigenrays(model::Bellhop, tx1::AcousticSource, rx1::AcousticReceiver)\n",
      "  mktempdir(prefix=\"bellhop_\") do dirname\n",
      "    writeenv(model, [tx1], [rx1], \"E\", dirname)\n",
      "    bellhop(dirname, model.debug)\n",
      "    readrays(joinpath(dirname, \"model.ray\"))\n",
      "  end\n",
      "end\n",
      "\n",
      "function rays(model::Bellhop, tx1::AcousticSource, θ::AbstractArray, rmax)\n",
      "  θ isa AbstractRange || length(θ) == 1 || throw(ArgumentError(\"Bellhop only supports uniformly spaced angles\"))\n",
      "  all(-π/2 .< θ .< π/2) || throw(ArgumentError(\"θ must be between -π/2 and π/2\"))\n",
      "  mktempdir(prefix=\"bellhop_\") do dirname\n",
      "    writeenv(model, [tx1], [AcousticReceiver(rmax, 0.0)], \"R\", dirname; minangle=minimum(θ), maxangle=maximum(θ), nbeams=length(θ))\n",
      "    bellhop(dirname, model.debug)\n",
      "    readrays(joinpath(dirname, \"model.ray\"))\n",
      "  end\n",
      "end\n",
      "\n",
      "rays(model::Bellhop, tx1::AcousticSource, θ, rmax) = rays(model, tx1, [θ], rmax)[1]\n",
      "\n",
      "### helper functions\n",
      "\n",
      "struct BellhopError <: Exception\n",
      "  details::Vector{String}\n",
      "end\n",
      "\n",
      "function Base.show(io::IO, e::BellhopError)\n",
      "  if length(e.details) == 1\n",
      "    println(io, e.details[1])\n",
      "  else\n",
      "    println(io, \"Bellhop said:\")\n",
      "    for s ∈ e.details\n",
      "      println(io, \"  \", s)\n",
      "    end\n",
      "  end\n",
      "end\n",
      "\n",
      "function bellhop(dirname, debug)\n",
      "  infilebase = joinpath(dirname, \"model\")\n",
      "  outfilename = joinpath(dirname, \"output.txt\")\n",
      "  try\n",
      "    run(pipeline(ignorestatus(`bellhop.exe $infilebase`); stdout=outfilename, stderr=outfilename))\n",
      "    if debug\n",
      "      @info \"Bellhop run completed in $dirname, press ENTER to delete intermediate files...\"\n",
      "      readline()\n",
      "    end\n",
      "  catch\n",
      "    throw(BellhopError([\"Unable to execute bellhop.exe\"]))\n",
      "  end\n",
      "  err = String[]\n",
      "  checkerr!(err, outfilename)\n",
      "  checkerr!(err, joinpath(dirname, \"model.prt\"))\n",
      "  if length(err) > 0\n",
      "    throw(BellhopError(err))\n",
      "  end\n",
      "end\n",
      "\n",
      "function checkerr!(err, filename)\n",
      "  output = false\n",
      "  open(filename) do f\n",
      "    for s in eachline(f)\n",
      "      if output || occursin(\"ERROR\", uppercase(s))\n",
      "        push!(err, s)\n",
      "        output = true\n",
      "      end\n",
      "    end\n",
      "  end\n",
      "end\n",
      "\n",
      "function writeenv(model::Bellhop, tx::Vector{<:AcousticSource}, rx::AbstractArray{<:AcousticReceiver}, taskcode, dirname; minangle=model.minangle, maxangle=model.maxangle, nbeams=model.nbeams)\n",
      "  all(location(tx1)[1] == 0.0 for tx1 ∈ tx) || throw(ArgumentError(\"Bellhop requires transmitters at (0, 0, z)\"))\n",
      "  all(location(tx1)[2] == 0.0 for tx1 ∈ tx) || throw(ArgumentError(\"Bellhop 2D requires transmitters in the x-z plane\"))\n",
      "  all(location(rx1)[1] >= 0.0 for rx1 ∈ rx) || throw(ArgumentError(\"Bellhop requires receivers to be in the +x halfspace\"))\n",
      "  all(location(rx1)[2] == 0.0 for rx1 ∈ rx) || throw(ArgumentError(\"Bellhop 2D requires receivers in the x-z plane\"))\n",
      "  env = model.env\n",
      "  name = split(basename(dirname), \"_\")[end]\n",
      "  filename = joinpath(dirname, \"model.env\")\n",
      "  open(filename, \"w\") do io\n",
      "    println(io, \"'\", name, \"'\")\n",
      "    flist = [nominalfrequency(tx1) for tx1 ∈ tx]\n",
      "    f = sum(flist) / length(flist)\n",
      "    maximum(abs.(flist .- f))/f > 0.2 && @warn(\"Source frequency varies by more than 20% from nominal frequency\")\n",
      "    @printf(io, \"%0.6f\\n\", f)\n",
      "    println(io, \"1\")\n",
      "    if length(rx) == 1\n",
      "      maxr = location(rx[1])[1]\n",
      "    elseif rx isa AcousticReceiverGrid2D\n",
      "      maxr = maximum(rx.xrange)\n",
      "    else\n",
      "      throw(ArgumentError(\"Receivers must be on a 2D grid\"))\n",
      "    end\n",
      "    ss = ssp(env)\n",
      "    sspi = \"S\"\n",
      "    ss isa SampledSSP1D && ss.interp === :linear && (sspi = \"C\")\n",
      "    print(io, \"'\", sspi, \"VWT\")\n",
      "    alt = altimetry(env)\n",
      "    if !(alt isa FlatSurface)\n",
      "      print(io, \"*\")\n",
      "      createadfile(joinpath(dirname, \"model.ati\"), alt, (p...) -> -altitude(p...), maxr, f)\n",
      "    end\n",
      "    println(io, \"'\")\n",
      "    bathy = bathymetry(env)\n",
      "    waterdepth = maxdepth(bathy)\n",
      "    @printf(io, \"1 0.0 %0.6f\\n\", waterdepth)\n",
      "    if ss isa IsoSSP\n",
      "      @printf(io, \"0.0 %0.6f /\\n\", soundspeed(ss, 0.0, 0.0, 0.0), )\n",
      "      @printf(io, \"%0.6f %0.6f /\\n\", waterdepth, soundspeed(ss, 0.0, 0.0, 0.0))\n",
      "    elseif ss isa SampledSSP1D\n",
      "      for i ∈ 1:length(ss.z)\n",
      "        @printf(io, \"%0.6f %0.6f /\\n\", -ss.z[i], ss.c[i])\n",
      "      end\n",
      "    else\n",
      "      for d ∈ range(0.0, waterdepth; length=recommendlength(waterdepth, f))\n",
      "        @printf(io, \"%0.6f %0.6f /\\n\", d, soundspeed(ss, 0.0, 0.0, -d))\n",
      "      end\n",
      "      floor(waterdepth) != waterdepth && @printf(io, \"%0.6f %0.6f /\\n\", waterdepth, soundspeed(ss, 0.0, 0.0, -waterdepth))\n",
      "    end\n",
      "    print(io, \"'A\")\n",
      "    if !(bathy isa ConstantDepth)\n",
      "      print(io, \"*\")\n",
      "      createadfile(joinpath(dirname, \"model.bty\"), bathy, depth, maxr, f)\n",
      "    end\n",
      "    println(io, \"' 0.0\") # bottom roughness = 0\n",
      "    bed = seabed(env)\n",
      "    c2 = soundspeed(ss, 0.0, 0.0, -waterdepth) * bed.cᵣ\n",
      "    α = bed.δ * 40π / log(10)      # based on APL-UW TR 9407 (1994), IV-9 equation (4)\n",
      "    @printf(io, \"%0.6f %0.6f 0.0 %0.6f %0.6f /\\n\", waterdepth, c2, bed.ρᵣ, α)\n",
      "    printarray(io, [-location(tx1)[3] for tx1 ∈ tx])\n",
      "    if length(rx) == 1\n",
      "      printarray(io, [-location(rx[1])[3]])\n",
      "      printarray(io, [maxr / 1000.0])\n",
      "    elseif rx isa AcousticReceiverGrid2D\n",
      "      printarray(io, reverse(-rx.zrange))\n",
      "      printarray(io, rx.xrange ./ 1000.0)\n",
      "    end\n",
      "    println(io, \"'\", taskcode, model.gaussian ? \"B'\" : \"'\")\n",
      "    @printf(io, \"%d\\n\", nbeams)\n",
      "    @printf(io, \"%0.6f %0.6f /\\n\", rad2deg(minangle), rad2deg(maxangle))\n",
      "    @printf(io, \"0.0 %0.6f %0.6f\\n\", 1.01*waterdepth, 1.01 * maxr / 1000.0)\n",
      "  end\n",
      "end\n",
      "\n",
      "function printarray(io, a::AbstractVector)\n",
      "  println(io, length(a))\n",
      "  for a1 ∈ a\n",
      "    @printf(io, \"%0.6f \", a1)\n",
      "  end\n",
      "  println(io, \"/\")\n",
      "end\n",
      "\n",
      "function recommendlength(x, f)\n",
      "  # recommendation based on nominal half-wavelength spacing\n",
      "  λ = 1500.0 / f\n",
      "  clamp(round(Int, 2x / λ) + 1, 25, 1000)\n",
      "end\n",
      "\n",
      "function createadfile(filename, data, func, maxr, f)\n",
      "  open(filename, \"w\") do io\n",
      "    interp = \"L\"\n",
      "    if data isa SampledDepth || data isa SampledAltitude\n",
      "      x = data.x\n",
      "      data.interp !== :linear && (interp = \"C\")\n",
      "    else\n",
      "      x = range(0.0, maxr; length=recommendlength(maxr, f))\n",
      "    end\n",
      "    println(io, \"'\", interp, \"'\")\n",
      "    println(io, length(x))\n",
      "    for i ∈ 1:length(x)\n",
      "      @printf(io, \"%0.6f %0.6f\\n\", x[i]/1000.0, func(data, x[i], 0.0))\n",
      "    end\n",
      "  end\n",
      "end\n",
      "\n",
      "function readrays(filename)\n",
      "  rays = RayArrival{Float64,Float64}[]\n",
      "  open(filename, \"r\") do io\n",
      "    [readline(io) for i ∈ 1:7]\n",
      "    while !eof(io)\n",
      "      s = strip(readline(io))\n",
      "      length(s) == 0 && break\n",
      "      aod = parse(Float64, s)\n",
      "      pts, sb, bb = parse.(Int, split(strip(readline(io)) ,r\" +\"))\n",
      "      raypath = Array{NTuple{3,Float64}}(undef, pts)\n",
      "      for k ∈ 1:pts\n",
      "        x, d = parse.(Float64, split(strip(readline(io)) ,r\" +\"))\n",
      "        raypath[k] = (x, 0.0, -d)\n",
      "      end\n",
      "      push!(rays, RayArrival(NaN64, NaN64, sb, bb, -deg2rad(aod), NaN64, raypath))\n",
      "    end\n",
      "  end\n",
      "  rays\n",
      "end\n",
      "\n",
      "function readarrivals(filename)\n",
      "  arrivals = RayArrival{Float64,Missing}[]\n",
      "  open(filename, \"r\") do io\n",
      "    s = strip(readline(io))\n",
      "    if occursin(\"2D\", s)\n",
      "      f = parse(Float64, strip(readline(io)))\n",
      "      v = split(strip(readline(io)) ,r\" +\")\n",
      "      n = parse(Int, v[1])\n",
      "      txdepth = parse.(Float64, v[2:end])\n",
      "      n == length(txdepth) || error(\"Wrong number of txdepth entries in arrivals\")\n",
      "      v = split(strip(readline(io)) ,r\" +\")\n",
      "      n = parse(Int, v[1])\n",
      "      rxdepth = parse.(Float64, v[2:end])\n",
      "      n == length(rxdepth) || error(\"Wrong number of rxdepth entries in arrivals\")\n",
      "      v = split(strip(readline(io)) ,r\" +\")\n",
      "      n = parse(Int, v[1])\n",
      "      rxrange = parse.(Float64, v[2:end])\n",
      "      n == length(rxrange) || error(\"Wrong number of rxrange entries in arrivals\")\n",
      "    else\n",
      "      v = split(s ,r\" +\")\n",
      "      f = parse(Float64, v[1])\n",
      "      n1, n2, n3 = parse.(Int, v[2:4])\n",
      "      txdepth = parse.(Float64, split(strip(readline(io)) ,r\" +\"))\n",
      "      rxdepth = parse.(Float64, split(strip(readline(io)) ,r\" +\"))\n",
      "      rxrange = parse.(Float64, split(strip(readline(io)) ,r\" +\"))\n",
      "      n1 == length(txdepth) || error(\"Wrong number of txdepth entries in arrivals\")\n",
      "      n2 == length(rxdepth) || error(\"Wrong number of rxdepth entries in arrivals\")\n",
      "      n3 == length(rxrange) || error(\"Wrong number of rxrange entries in arrivals\")\n",
      "    end\n",
      "    for j ∈ 1:length(txdepth)\n",
      "      readline(io)\n",
      "      for k ∈ 1:length(rxdepth)\n",
      "        for m ∈ 1:length(rxrange)\n",
      "          count = parse(Int, strip(readline(io)))\n",
      "          for n ∈ 1:count\n",
      "            v = split(strip(readline(io)) ,r\" +\")\n",
      "            length(v) == 8 || error(\"Wrong number of data entries in arrivals\")\n",
      "            A, ph, t, _, aod, aoa = parse.(Float64, v[1:6])\n",
      "            sb, bb = parse.(Int, v[7:8])\n",
      "            push!(arrivals, RayArrival(t, A * cis(deg2rad(ph)), sb, bb, -deg2rad(aod), deg2rad(aoa)))\n",
      "          end\n",
      "        end\n",
      "      end\n",
      "    end\n",
      "  end\n",
      "  sort(arrivals; by = a -> a.time)\n",
      "end\n",
      "\n",
      "function readshd(filename)\n",
      "  open(filename, \"r\") do io\n",
      "    r = read(io, UInt32)\n",
      "    seek(io, 4r)\n",
      "    b = Array{UInt8}(undef, 10)\n",
      "    read!(io, b)\n",
      "    strip(String(b)) == \"rectilin\" || error(\"Bad shd file format: incorrect ptype\")\n",
      "    seek(io, 8r)\n",
      "    nfreq = read(io, UInt32)\n",
      "    nfreq == 1 || error(\"Bad shd file format: incorrect nfreq\")\n",
      "    nθ = read(io, UInt32)\n",
      "    nθ == 1 || error(\"Bad shd file format: incorrect nθ\")\n",
      "    nsx = read(io, UInt32)\n",
      "    nsy = read(io, UInt32)\n",
      "    nsd = read(io, UInt32)\n",
      "    nsd == 1 || error(\"Bad shd file format: incorrect nsd\")\n",
      "    nrd = read(io, UInt32)\n",
      "    nrr = read(io, UInt32)\n",
      "    pressure = Array{ComplexF32}(undef, nrr, nrd)\n",
      "    for ird ∈ 0:nrd-1\n",
      "      recnum = 10 + ird\n",
      "      seek(io, recnum * 4r)\n",
      "      temp = Array{ComplexF32}(undef, nrr)\n",
      "      read!(io, temp)\n",
      "      pressure[:,ird+1] .= -temp    # negative because Bellhop seems to have a 180° phase inversion\n",
      "    end\n",
      "    reverse(pressure; dims=2)\n",
      "  end\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  79\n",
      "danielzhaotongliu/MALTrendsWeb\n",
      "backend/anime_data/snapshots_16067.jl\n",
      "########################################\n",
      "\n",
      "{\"timestamp\": 1571659377.0, \"score\": 8.19, \"score_count\": 155677}\n",
      "{\"timestamp\": 1565469110.0, \"score\": 8.2, \"score_count\": 151900}\n",
      "{\"timestamp\": 1564853352.0, \"score\": 8.2, \"score_count\": 151900}\n",
      "{\"timestamp\": 1564796525.0, \"score\": 8.2, \"score_count\": 151656}\n",
      "{\"timestamp\": 1562190544.0, \"score\": 8.2, \"score_count\": 150460}\n",
      "{\"timestamp\": 1562142673.0, \"score\": 8.2, \"score_count\": 150460}\n",
      "{\"timestamp\": 1561844972.0, \"score\": 8.2, \"score_count\": 150213}\n",
      "{\"timestamp\": 1561836553.0, \"score\": 8.2, \"score_count\": 150213}\n",
      "{\"timestamp\": 1561253434.0, \"score\": 8.2, \"score_count\": 149968}\n",
      "{\"timestamp\": 1561164775.0, \"score\": 8.2, \"score_count\": 149968}\n",
      "{\"timestamp\": 1560892812.0, \"score\": 8.2, \"score_count\": 149968}\n",
      "{\"timestamp\": 1560828619.0, \"score\": 8.2, \"score_count\": 149968}\n",
      "{\"timestamp\": 1560817739.0, \"score\": 8.2, \"score_count\": 149754}\n",
      "{\"timestamp\": 1560545458.0, \"score\": 8.2, \"score_count\": 149754}\n",
      "{\"timestamp\": 1560290584.0, \"score\": 8.2, \"score_count\": 149627}\n",
      "{\"timestamp\": 1541111075.0, \"score\": 8.22, \"score_count\": 139564}\n",
      "{\"timestamp\": 1512000374.0, \"score\": 8.26, \"score_count\": 121416}\n",
      "{\"timestamp\": 1480199592.0, \"score\": 8.32, \"score_count\": 97606}\n",
      "{\"timestamp\": 1480199591.0, \"score\": 8.32, \"score_count\": 97606}\n",
      "{\"timestamp\": 1467306091.0, \"score\": 8.35, \"score_count\": 87022}\n",
      "{\"timestamp\": 1462097739.0, \"score\": 8.36, \"score_count\": 82504}\n",
      "{\"timestamp\": 1462039910.0, \"score\": 8.36, \"score_count\": 82464}\n",
      "{\"timestamp\": 1462097738.0, \"score\": 8.36, \"score_count\": 82504}\n",
      "{\"timestamp\": 1461783748.0, \"score\": 8.36, \"score_count\": 82258}\n",
      "{\"timestamp\": 1448648299.0, \"score\": 8.4, \"score_count\": 69884}\n",
      "{\"timestamp\": 1560227542.0, \"score\": 8.2, \"score_count\": 149627}\n",
      "{\"timestamp\": 1560193300.0, \"score\": 8.2, \"score_count\": 149627}\n",
      "{\"timestamp\": 1560056760.0, \"score\": 8.2, \"score_count\": 149627}\n",
      "{\"timestamp\": 1560019596.0, \"score\": 8.2, \"score_count\": 149391}\n",
      "{\"timestamp\": 1560031207.0, \"score\": 8.2, \"score_count\": 149391}\n",
      "{\"timestamp\": 1559962555.0, \"score\": 8.2, \"score_count\": 149391}\n",
      "{\"timestamp\": 1559953435.0, \"score\": 8.2, \"score_count\": 149391}\n",
      "{\"timestamp\": 1559946808.0, \"score\": 8.2, \"score_count\": 149391}\n",
      "{\"timestamp\": 1559940634.0, \"score\": 8.2, \"score_count\": 149391}\n",
      "{\"timestamp\": 1559930055.0, \"score\": 8.2, \"score_count\": 149391}\n",
      "{\"timestamp\": 1559838825.0, \"score\": 8.2, \"score_count\": 149391}\n",
      "{\"timestamp\": 1559843480.0, \"score\": 8.2, \"score_count\": 149391}\n",
      "{\"timestamp\": 1559760138.0, \"score\": 8.2, \"score_count\": 149391}\n",
      "{\"timestamp\": 1559869784.0, \"score\": 8.2, \"score_count\": 149391}\n",
      "{\"timestamp\": 1559678963.0, \"score\": 8.2, \"score_count\": 149391}\n",
      "{\"timestamp\": 1559620903.0, \"score\": 8.2, \"score_count\": 149391}\n",
      "{\"timestamp\": 1559323930.0, \"score\": 8.2, \"score_count\": 149220}\n",
      "{\"timestamp\": 1559259587.0, \"score\": 8.2, \"score_count\": 149220}\n",
      "{\"timestamp\": 1559185543.0, \"score\": 8.2, \"score_count\": 149071}\n",
      "{\"timestamp\": 1559057394.0, \"score\": 8.2, \"score_count\": 149071}\n",
      "{\"timestamp\": 1558826354.0, \"score\": 8.21, \"score_count\": 148966}\n",
      "{\"timestamp\": 1558803772.0, \"score\": 8.21, \"score_count\": 148966}\n",
      "{\"timestamp\": 1558710741.0, \"score\": 8.21, \"score_count\": 148966}\n",
      "{\"timestamp\": 1558567393.0, \"score\": 8.21, \"score_count\": 148841}\n",
      "{\"timestamp\": 1558464145.0, \"score\": 8.21, \"score_count\": 148841}\n",
      "{\"timestamp\": 1558463542.0, \"score\": 8.21, \"score_count\": 148841}\n",
      "{\"timestamp\": 1558457700.0, \"score\": 8.21, \"score_count\": 148841}\n",
      "{\"timestamp\": 1558139837.0, \"score\": 8.21, \"score_count\": 148633}\n",
      "{\"timestamp\": 1558047542.0, \"score\": 8.21, \"score_count\": 148633}\n",
      "{\"timestamp\": 1557975222.0, \"score\": 8.21, \"score_count\": 148633}\n",
      "{\"timestamp\": 1557581348.0, \"score\": 8.21, \"score_count\": 148423}\n",
      "{\"timestamp\": 1557518585.0, \"score\": 8.21, \"score_count\": 148423}\n",
      "{\"timestamp\": 1557516692.0, \"score\": 8.21, \"score_count\": 148423}\n",
      "{\"timestamp\": 1557516052.0, \"score\": 8.21, \"score_count\": 148423}\n",
      "{\"timestamp\": 1557369298.0, \"score\": 8.21, \"score_count\": 148423}\n",
      "{\"timestamp\": 1557282494.0, \"score\": 8.21, \"score_count\": 148179}\n",
      "{\"timestamp\": 1557097833.0, \"score\": 8.21, \"score_count\": 148179}\n",
      "{\"timestamp\": 1557088712.0, \"score\": 8.21, \"score_count\": 148179}\n",
      "{\"timestamp\": 1557019042.0, \"score\": 8.21, \"score_count\": 148179}\n",
      "{\"timestamp\": 1556832121.0, \"score\": 8.21, \"score_count\": 148080}\n",
      "{\"timestamp\": 1556655951.0, \"score\": 8.21, \"score_count\": 148080}\n",
      "{\"timestamp\": 1556638083.0, \"score\": 8.21, \"score_count\": 148080}\n",
      "{\"timestamp\": 1556632668.0, \"score\": 8.21, \"score_count\": 148080}\n",
      "{\"timestamp\": 1556508077.0, \"score\": 8.21, \"score_count\": 147953}\n",
      "{\"timestamp\": 1556396976.0, \"score\": 8.21, \"score_count\": 147953}\n",
      "{\"timestamp\": 1556311444.0, \"score\": 8.21, \"score_count\": 147832}\n",
      "{\"timestamp\": 1556141297.0, \"score\": 8.21, \"score_count\": 147832}\n",
      "{\"timestamp\": 1556057489.0, \"score\": 8.21, \"score_count\": 147690}\n",
      "{\"timestamp\": 1555625013.0, \"score\": 8.21, \"score_count\": 147546}\n",
      "{\"timestamp\": 1555446418.0, \"score\": 8.21, \"score_count\": 147395}\n",
      "{\"timestamp\": 1555206002.0, \"score\": 8.21, \"score_count\": 147278}\n",
      "{\"timestamp\": 1555037549.0, \"score\": 8.21, \"score_count\": 147278}\n",
      "{\"timestamp\": 1555017801.0, \"score\": 8.21, \"score_count\": 147131}\n",
      "{\"timestamp\": 1554949659.0, \"score\": 8.21, \"score_count\": 147131}\n",
      "{\"timestamp\": 1554929259.0, \"score\": 8.21, \"score_count\": 147131}\n",
      "{\"timestamp\": 1554851468.0, \"score\": 8.21, \"score_count\": 147131}\n",
      "{\"timestamp\": 1554763648.0, \"score\": 8.21, \"score_count\": 147131}\n",
      "{\"timestamp\": 1554586547.0, \"score\": 8.21, \"score_count\": 146991}\n",
      "{\"timestamp\": 1554413126.0, \"score\": 8.21, \"score_count\": 146796}\n",
      "{\"timestamp\": 1554412462.0, \"score\": 8.21, \"score_count\": 146796}\n",
      "{\"timestamp\": 1554406672.0, \"score\": 8.21, \"score_count\": 146796}\n",
      "{\"timestamp\": 1554392778.0, \"score\": 8.21, \"score_count\": 146796}\n",
      "{\"timestamp\": 1553969125.0, \"score\": 8.21, \"score_count\": 146615}\n",
      "{\"timestamp\": 1553634466.0, \"score\": 8.21, \"score_count\": 146351}\n",
      "{\"timestamp\": 1553557655.0, \"score\": 8.21, \"score_count\": 146351}\n",
      "{\"timestamp\": 1553289158.0, \"score\": 8.21, \"score_count\": 146204}\n",
      "{\"timestamp\": 1553216641.0, \"score\": 8.21, \"score_count\": 146204}\n",
      "{\"timestamp\": 1553633551.0, \"score\": 8.21, \"score_count\": 146351}\n",
      "{\"timestamp\": 1553135596.0, \"score\": 8.21, \"score_count\": 146204}\n",
      "{\"timestamp\": 1553130969.0, \"score\": 8.21, \"score_count\": 146204}\n",
      "{\"timestamp\": 1552782169.0, \"score\": 8.21, \"score_count\": 145927}\n",
      "{\"timestamp\": 1552780681.0, \"score\": 8.21, \"score_count\": 145927}\n",
      "{\"timestamp\": 1552773748.0, \"score\": 8.21, \"score_count\": 145927}\n",
      "{\"timestamp\": 1552747799.0, \"score\": 8.21, \"score_count\": 145927}\n",
      "{\"timestamp\": 1552680549.0, \"score\": 8.21, \"score_count\": 145927}\n",
      "{\"timestamp\": 1552599333.0, \"score\": 8.21, \"score_count\": 145927}\n",
      "{\"timestamp\": 1552528889.0, \"score\": 8.21, \"score_count\": 145808}\n",
      "{\"timestamp\": 1552508422.0, \"score\": 8.21, \"score_count\": 145808}\n",
      "{\"timestamp\": 1552421614.0, \"score\": 8.21, \"score_count\": 145808}\n",
      "{\"timestamp\": 1552363464.0, \"score\": 8.21, \"score_count\": 145808}\n",
      "{\"timestamp\": 1552254344.0, \"score\": 8.21, \"score_count\": 145642}\n",
      "{\"timestamp\": 1552184959.0, \"score\": 8.21, \"score_count\": 145642}\n",
      "{\"timestamp\": 1552147486.0, \"score\": 8.21, \"score_count\": 145642}\n",
      "{\"timestamp\": 1552100778.0, \"score\": 8.21, \"score_count\": 145642}\n",
      "{\"timestamp\": 1552091216.0, \"score\": 8.21, \"score_count\": 145642}\n",
      "{\"timestamp\": 1552012379.0, \"score\": 8.21, \"score_count\": 145471}\n",
      "{\"timestamp\": 1551907126.0, \"score\": 8.21, \"score_count\": 145471}\n",
      "{\"timestamp\": 1551580920.0, \"score\": 8.21, \"score_count\": 145291}\n",
      "{\"timestamp\": 1551313264.0, \"score\": 8.21, \"score_count\": 145188}\n",
      "{\"timestamp\": 1551224813.0, \"score\": 8.21, \"score_count\": 144957}\n",
      "{\"timestamp\": 1551221973.0, \"score\": 8.21, \"score_count\": 144957}\n",
      "{\"timestamp\": 1551215697.0, \"score\": 8.21, \"score_count\": 144957}\n",
      "{\"timestamp\": 1551139847.0, \"score\": 8.21, \"score_count\": 144957}\n",
      "{\"timestamp\": 1551128184.0, \"score\": 8.21, \"score_count\": 144957}\n",
      "{\"timestamp\": 1551061528.0, \"score\": 8.21, \"score_count\": 144957}\n",
      "{\"timestamp\": 1551059118.0, \"score\": 8.21, \"score_count\": 144957}\n",
      "{\"timestamp\": 1551045185.0, \"score\": 8.21, \"score_count\": 144957}\n",
      "{\"timestamp\": 1551025073.0, \"score\": 8.21, \"score_count\": 144957}\n",
      "{\"timestamp\": 1551019849.0, \"score\": 8.21, \"score_count\": 144957}\n",
      "{\"timestamp\": 1550977111.0, \"score\": 8.21, \"score_count\": 144957}\n",
      "{\"timestamp\": 1550944917.0, \"score\": 8.21, \"score_count\": 144957}\n",
      "{\"timestamp\": 1550696191.0, \"score\": 8.21, \"score_count\": 144776}\n",
      "{\"timestamp\": 1550627510.0, \"score\": 8.21, \"score_count\": 144776}\n",
      "{\"timestamp\": 1550540003.0, \"score\": 8.21, \"score_count\": 144776}\n",
      "{\"timestamp\": 1550511385.0, \"score\": 8.21, \"score_count\": 144600}\n",
      "{\"timestamp\": 1550618642.0, \"score\": 8.21, \"score_count\": 144776}\n",
      "{\"timestamp\": 1550450111.0, \"score\": 8.21, \"score_count\": 144600}\n",
      "{\"timestamp\": 1550448971.0, \"score\": 8.21, \"score_count\": 144600}\n",
      "{\"timestamp\": 1550425452.0, \"score\": 8.21, \"score_count\": 144600}\n",
      "{\"timestamp\": 1550283947.0, \"score\": 8.21, \"score_count\": 144600}\n",
      "{\"timestamp\": 1550272986.0, \"score\": 8.21, \"score_count\": 144600}\n",
      "{\"timestamp\": 1550193438.0, \"score\": 8.21, \"score_count\": 144600}\n",
      "{\"timestamp\": 1550017077.0, \"score\": 8.21, \"score_count\": 144436}\n",
      "{\"timestamp\": 1550006614.0, \"score\": 8.21, \"score_count\": 144436}\n",
      "{\"timestamp\": 1550005059.0, \"score\": 8.21, \"score_count\": 144436}\n",
      "{\"timestamp\": 1549945620.0, \"score\": 8.21, \"score_count\": 144436}\n",
      "{\"timestamp\": 1549930176.0, \"score\": 8.21, \"score_count\": 144436}\n",
      "{\"timestamp\": 1549846582.0, \"score\": 8.21, \"score_count\": 144436}\n",
      "{\"timestamp\": 1549752062.0, \"score\": 8.21, \"score_count\": 144270}\n",
      "{\"timestamp\": 1549380725.0, \"score\": 8.21, \"score_count\": 144101}\n",
      "{\"timestamp\": 1547870579.0, \"score\": 8.22, \"score_count\": 143319}\n",
      "{\"timestamp\": 1547850388.0, \"score\": 8.22, \"score_count\": 143319}\n",
      "{\"timestamp\": 1547846390.0, \"score\": 8.22, \"score_count\": 143319}\n",
      "{\"timestamp\": 1547775110.0, \"score\": 8.22, \"score_count\": 143124}\n",
      "{\"timestamp\": 1547697796.0, \"score\": 8.22, \"score_count\": 143124}\n",
      "{\"timestamp\": 1547680181.0, \"score\": 8.22, \"score_count\": 143124}\n",
      "{\"timestamp\": 1547675976.0, \"score\": 8.22, \"score_count\": 143124}\n",
      "{\"timestamp\": 1547673733.0, \"score\": 8.22, \"score_count\": 143124}\n",
      "{\"timestamp\": 1547610010.0, \"score\": 8.22, \"score_count\": 143124}\n",
      "{\"timestamp\": 1547599886.0, \"score\": 8.22, \"score_count\": 143124}\n",
      "{\"timestamp\": 1547588974.0, \"score\": 8.22, \"score_count\": 143124}\n",
      "{\"timestamp\": 1547524487.0, \"score\": 8.22, \"score_count\": 143124}\n",
      "{\"timestamp\": 1547509920.0, \"score\": 8.22, \"score_count\": 143124}\n",
      "{\"timestamp\": 1547500410.0, \"score\": 8.22, \"score_count\": 143124}\n",
      "{\"timestamp\": 1547437405.0, \"score\": 8.22, \"score_count\": 142895}\n",
      "{\"timestamp\": 1547395968.0, \"score\": 8.22, \"score_count\": 142895}\n",
      "{\"timestamp\": 1547349897.0, \"score\": 8.22, \"score_count\": 142895}\n",
      "{\"timestamp\": 1547346853.0, \"score\": 8.22, \"score_count\": 142895}\n",
      "{\"timestamp\": 1547330509.0, \"score\": 8.22, \"score_count\": 142895}\n",
      "{\"timestamp\": 1547323575.0, \"score\": 8.22, \"score_count\": 142895}\n",
      "{\"timestamp\": 1547322841.0, \"score\": 8.22, \"score_count\": 142895}\n",
      "{\"timestamp\": 1547317170.0, \"score\": 8.22, \"score_count\": 142895}\n",
      "{\"timestamp\": 1547312749.0, \"score\": 8.22, \"score_count\": 142895}\n",
      "{\"timestamp\": 1547310467.0, \"score\": 8.22, \"score_count\": 142895}\n",
      "{\"timestamp\": 1547261436.0, \"score\": 8.22, \"score_count\": 142895}\n",
      "{\"timestamp\": 1547251745.0, \"score\": 8.22, \"score_count\": 142895}\n",
      "{\"timestamp\": 1547242472.0, \"score\": 8.22, \"score_count\": 142895}\n",
      "{\"timestamp\": 1547177630.0, \"score\": 8.22, \"score_count\": 142895}\n",
      "{\"timestamp\": 1547172921.0, \"score\": 8.22, \"score_count\": 142895}\n",
      "{\"timestamp\": 1547157716.0, \"score\": 8.22, \"score_count\": 142895}\n",
      "{\"timestamp\": 1547091153.0, \"score\": 8.22, \"score_count\": 142637}\n",
      "{\"timestamp\": 1547089427.0, \"score\": 8.22, \"score_count\": 142637}\n",
      "{\"timestamp\": 1546642734.0, \"score\": 8.22, \"score_count\": 142341}\n",
      "{\"timestamp\": 1546640350.0, \"score\": 8.22, \"score_count\": 142341}\n",
      "{\"timestamp\": 1546618747.0, \"score\": 8.22, \"score_count\": 142341}\n",
      "{\"timestamp\": 1546552702.0, \"score\": 8.22, \"score_count\": 142341}\n",
      "{\"timestamp\": 1546541648.0, \"score\": 8.22, \"score_count\": 142341}\n",
      "{\"timestamp\": 1546535250.0, \"score\": 8.22, \"score_count\": 142341}\n",
      "{\"timestamp\": 1546531873.0, \"score\": 8.22, \"score_count\": 142341}\n",
      "{\"timestamp\": 1546482798.0, \"score\": 8.22, \"score_count\": 142341}\n",
      "{\"timestamp\": 1546386037.0, \"score\": 8.22, \"score_count\": 142140}\n",
      "{\"timestamp\": 1546355681.0, \"score\": 8.22, \"score_count\": 142140}\n",
      "{\"timestamp\": 1546313042.0, \"score\": 8.22, \"score_count\": 142140}\n",
      "{\"timestamp\": 1546296050.0, \"score\": 8.22, \"score_count\": 142140}\n",
      "{\"timestamp\": 1546290130.0, \"score\": 8.22, \"score_count\": 142140}\n",
      "{\"timestamp\": 1546218980.0, \"score\": 8.22, \"score_count\": 142140}\n",
      "{\"timestamp\": 1546211867.0, \"score\": 8.22, \"score_count\": 142140}\n",
      "{\"timestamp\": 1546186470.0, \"score\": 8.22, \"score_count\": 141869}\n",
      "{\"timestamp\": 1546142218.0, \"score\": 8.22, \"score_count\": 141869}\n",
      "{\"timestamp\": 1546124039.0, \"score\": 8.22, \"score_count\": 141869}\n",
      "{\"timestamp\": 1546111019.0, \"score\": 8.22, \"score_count\": 141869}\n",
      "{\"timestamp\": 1546057718.0, \"score\": 8.22, \"score_count\": 141869}\n",
      "{\"timestamp\": 1546031883.0, \"score\": 8.22, \"score_count\": 141869}\n",
      "{\"timestamp\": 1546021916.0, \"score\": 8.22, \"score_count\": 141869}\n",
      "{\"timestamp\": 1546007090.0, \"score\": 8.22, \"score_count\": 141869}\n",
      "{\"timestamp\": 1545938690.0, \"score\": 8.22, \"score_count\": 141869}\n",
      "{\"timestamp\": 1545863841.0, \"score\": 8.22, \"score_count\": 141869}\n",
      "{\"timestamp\": 1545856009.0, \"score\": 8.22, \"score_count\": 141869}\n",
      "{\"timestamp\": 1545853906.0, \"score\": 8.22, \"score_count\": 141869}\n",
      "{\"timestamp\": 1545791526.0, \"score\": 8.22, \"score_count\": 141672}\n",
      "{\"timestamp\": 1545775519.0, \"score\": 8.22, \"score_count\": 141672}\n",
      "{\"timestamp\": 1545706880.0, \"score\": 8.22, \"score_count\": 141672}\n",
      "{\"timestamp\": 1545532621.0, \"score\": 8.22, \"score_count\": 141672}\n",
      "{\"timestamp\": 1545357973.0, \"score\": 8.22, \"score_count\": 141469}\n",
      "{\"timestamp\": 1545269025.0, \"score\": 8.22, \"score_count\": 141469}\n",
      "{\"timestamp\": 1545327176.0, \"score\": 8.22, \"score_count\": 141469}\n",
      "{\"timestamp\": 1545272770.0, \"score\": 8.22, \"score_count\": 141469}\n",
      "{\"timestamp\": 1545181686.0, \"score\": 8.22, \"score_count\": 141469}\n",
      "{\"timestamp\": 1545171580.0, \"score\": 8.22, \"score_count\": 141469}\n",
      "{\"timestamp\": 1545168524.0, \"score\": 8.22, \"score_count\": 141469}\n",
      "{\"timestamp\": 1545243366.0, \"score\": 8.22, \"score_count\": 141469}\n",
      "{\"timestamp\": 1545161124.0, \"score\": 8.22, \"score_count\": 141469}\n",
      "{\"timestamp\": 1545018673.0, \"score\": 8.22, \"score_count\": 141379}\n",
      "{\"timestamp\": 1544925295.0, \"score\": 8.22, \"score_count\": 141289}\n",
      "{\"timestamp\": 1544995711.0, \"score\": 8.22, \"score_count\": 141379}\n",
      "{\"timestamp\": 1544915574.0, \"score\": 8.22, \"score_count\": 141289}\n",
      "{\"timestamp\": 1544909263.0, \"score\": 8.22, \"score_count\": 141289}\n",
      "{\"timestamp\": 1544752181.0, \"score\": 8.22, \"score_count\": 141200}\n",
      "{\"timestamp\": 1544397341.0, \"score\": 8.22, \"score_count\": 140997}\n",
      "{\"timestamp\": 1544394892.0, \"score\": 8.22, \"score_count\": 140997}\n",
      "{\"timestamp\": 1544306033.0, \"score\": 8.22, \"score_count\": 140997}\n",
      "{\"timestamp\": 1544241027.0, \"score\": 8.22, \"score_count\": 140997}\n",
      "{\"timestamp\": 1544219144.0, \"score\": 8.22, \"score_count\": 140997}\n",
      "{\"timestamp\": 1544217493.0, \"score\": 8.22, \"score_count\": 140997}\n",
      "{\"timestamp\": 1544145285.0, \"score\": 8.22, \"score_count\": 140997}\n",
      "{\"timestamp\": 1544140941.0, \"score\": 8.22, \"score_count\": 140997}\n",
      "{\"timestamp\": 1544132809.0, \"score\": 8.22, \"score_count\": 140997}\n",
      "{\"timestamp\": 1543976423.0, \"score\": 8.22, \"score_count\": 140936}\n",
      "{\"timestamp\": 1543684974.0, \"score\": 8.22, \"score_count\": 140756}\n",
      "{\"timestamp\": 1543440876.0, \"score\": 8.22, \"score_count\": 140675}\n",
      "{\"timestamp\": 1543285754.0, \"score\": 8.22, \"score_count\": 140601}\n",
      "{\"timestamp\": 1543243269.0, \"score\": 8.22, \"score_count\": 140601}\n",
      "{\"timestamp\": 1543116499.0, \"score\": 8.22, \"score_count\": 140515}\n",
      "{\"timestamp\": 1543024282.0, \"score\": 8.22, \"score_count\": 140452}\n",
      "{\"timestamp\": 1542940287.0, \"score\": 8.22, \"score_count\": 140452}\n",
      "{\"timestamp\": 1542934958.0, \"score\": 8.22, \"score_count\": 140452}\n",
      "{\"timestamp\": 1542417976.0, \"score\": 8.22, \"score_count\": 140206}\n",
      "{\"timestamp\": 1542340377.0, \"score\": 8.22, \"score_count\": 140138}\n",
      "{\"timestamp\": 1542337943.0, \"score\": 8.22, \"score_count\": 140138}\n",
      "{\"timestamp\": 1542249969.0, \"score\": 8.22, \"score_count\": 140138}\n",
      "{\"timestamp\": 1542161698.0, \"score\": 8.22, \"score_count\": 140053}\n",
      "{\"timestamp\": 1542074695.0, \"score\": 8.22, \"score_count\": 140053}\n",
      "{\"timestamp\": 1542057919.0, \"score\": 8.22, \"score_count\": 140053}\n",
      "{\"timestamp\": 1541903329.0, \"score\": 8.22, \"score_count\": 139950}\n",
      "{\"timestamp\": 1541887683.0, \"score\": 8.22, \"score_count\": 139950}\n",
      "{\"timestamp\": 1541886897.0, \"score\": 8.22, \"score_count\": 139950}\n",
      "{\"timestamp\": 1541808127.0, \"score\": 8.22, \"score_count\": 139873}\n",
      "{\"timestamp\": 1541733409.0, \"score\": 8.22, \"score_count\": 139873}\n",
      "{\"timestamp\": 1541729408.0, \"score\": 8.22, \"score_count\": 139873}\n",
      "{\"timestamp\": 1541715888.0, \"score\": 8.22, \"score_count\": 139873}\n",
      "{\"timestamp\": 1541648337.0, \"score\": 8.22, \"score_count\": 139772}\n",
      "{\"timestamp\": 1541556337.0, \"score\": 8.22, \"score_count\": 139772}\n",
      "{\"timestamp\": 1541517728.0, \"score\": 8.22, \"score_count\": 139772}\n",
      "{\"timestamp\": 1541468089.0, \"score\": 8.22, \"score_count\": 139679}\n",
      "{\"timestamp\": 1541385438.0, \"score\": 8.22, \"score_count\": 139679}\n",
      "{\"timestamp\": 1541380483.0, \"score\": 8.22, \"score_count\": 139679}\n",
      "{\"timestamp\": 1541377994.0, \"score\": 8.22, \"score_count\": 139679}\n",
      "{\"timestamp\": 1541371065.0, \"score\": 8.22, \"score_count\": 139679}\n",
      "{\"timestamp\": 1541368067.0, \"score\": 8.22, \"score_count\": 139679}\n",
      "{\"timestamp\": 1541363003.0, \"score\": 8.22, \"score_count\": 139679}\n",
      "{\"timestamp\": 1541355252.0, \"score\": 8.22, \"score_count\": 139679}\n",
      "{\"timestamp\": 1541189085.0, \"score\": 8.22, \"score_count\": 139564}\n",
      "{\"timestamp\": 1541110527.0, \"score\": 8.22, \"score_count\": 139564}\n",
      "{\"timestamp\": 1541102413.0, \"score\": 8.22, \"score_count\": 139564}\n",
      "{\"timestamp\": 1541088919.0, \"score\": 8.22, \"score_count\": 139564}\n",
      "{\"timestamp\": 1541040744.0, \"score\": 8.22, \"score_count\": 139475}\n",
      "{\"timestamp\": 1541038807.0, \"score\": 8.22, \"score_count\": 139475}\n",
      "{\"timestamp\": 1541036689.0, \"score\": 8.22, \"score_count\": 139475}\n",
      "{\"timestamp\": 1540939906.0, \"score\": 8.22, \"score_count\": 139475}\n",
      "{\"timestamp\": 1540931017.0, \"score\": 8.22, \"score_count\": 139475}\n",
      "{\"timestamp\": 1540860711.0, \"score\": 8.22, \"score_count\": 139389}\n",
      "{\"timestamp\": 1540858956.0, \"score\": 8.22, \"score_count\": 139389}\n",
      "{\"timestamp\": 1540844035.0, \"score\": 8.22, \"score_count\": 139389}\n",
      "{\"timestamp\": 1540741640.0, \"score\": 8.22, \"score_count\": 139389}\n",
      "{\"timestamp\": 1540656443.0, \"score\": 8.23, \"score_count\": 139305}\n",
      "{\"timestamp\": 1540605023.0, \"score\": 8.23, \"score_count\": 139305}\n",
      "{\"timestamp\": 1540519853.0, \"score\": 8.23, \"score_count\": 139214}\n",
      "{\"timestamp\": 1540516408.0, \"score\": 8.23, \"score_count\": 139214}\n",
      "{\"timestamp\": 1540432736.0, \"score\": 8.23, \"score_count\": 139214}\n",
      "{\"timestamp\": 1540413181.0, \"score\": 8.23, \"score_count\": 139214}\n",
      "{\"timestamp\": 1540335192.0, \"score\": 8.23, \"score_count\": 139115}\n",
      "{\"timestamp\": 1540167523.0, \"score\": 8.23, \"score_count\": 139038}\n",
      "{\"timestamp\": 1540085651.0, \"score\": 8.23, \"score_count\": 139038}\n",
      "{\"timestamp\": 1540058921.0, \"score\": 8.23, \"score_count\": 139038}\n",
      "{\"timestamp\": 1540049478.0, \"score\": 8.23, \"score_count\": 139038}\n",
      "{\"timestamp\": 1540045902.0, \"score\": 8.23, \"score_count\": 139038}\n",
      "{\"timestamp\": 1539979784.0, \"score\": 8.23, \"score_count\": 138946}\n",
      "{\"timestamp\": 1539791868.0, \"score\": 8.23, \"score_count\": 138862}\n",
      "{\"timestamp\": 1539743762.0, \"score\": 8.23, \"score_count\": 138862}\n",
      "{\"timestamp\": 1539721314.0, \"score\": 8.23, \"score_count\": 138862}\n",
      "{\"timestamp\": 1539569280.0, \"score\": 8.23, \"score_count\": 138754}\n",
      "{\"timestamp\": 1539568643.0, \"score\": 8.23, \"score_count\": 138754}\n",
      "{\"timestamp\": 1539536696.0, \"score\": 8.23, \"score_count\": 138754}\n",
      "{\"timestamp\": 1539535655.0, \"score\": 8.23, \"score_count\": 138754}\n",
      "{\"timestamp\": 1539531369.0, \"score\": 8.23, \"score_count\": 138754}\n",
      "{\"timestamp\": 1539529176.0, \"score\": 8.23, \"score_count\": 138754}\n",
      "{\"timestamp\": 1539395212.0, \"score\": 8.23, \"score_count\": 138643}\n",
      "{\"timestamp\": 1539380526.0, \"score\": 8.23, \"score_count\": 138643}\n",
      "{\"timestamp\": 1539379111.0, \"score\": 8.23, \"score_count\": 138643}\n",
      "{\"timestamp\": 1538958589.0, \"score\": 8.23, \"score_count\": 138275}\n",
      "{\"timestamp\": 1538928885.0, \"score\": 8.23, \"score_count\": 138275}\n",
      "{\"timestamp\": 1538920413.0, \"score\": 8.23, \"score_count\": 138275}\n",
      "{\"timestamp\": 1538875391.0, \"score\": 8.23, \"score_count\": 138275}\n",
      "{\"timestamp\": 1538779544.0, \"score\": 8.23, \"score_count\": 138173}\n",
      "{\"timestamp\": 1545246649.0, \"score\": 8.22, \"score_count\": 141469}\n",
      "{\"timestamp\": 1553805877.0, \"score\": 8.21, \"score_count\": 146463}\n",
      "{\"timestamp\": 1553823774.0, \"score\": 8.21, \"score_count\": 146463}\n",
      "{\"timestamp\": 1553975367.0, \"score\": 8.21, \"score_count\": 146615}\n",
      "{\"timestamp\": 1559943987.0, \"score\": 8.2, \"score_count\": 149391}\n",
      "{\"timestamp\": 1559956340.0, \"score\": 8.2, \"score_count\": 149391}\n",
      "{\"timestamp\": 1453082799.0, \"score\": 8.38, \"score_count\": 74036}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  80\n",
      "XingyuZhang2018/VUMPS.jl\n",
      "src/vumpsruntime.jl\n",
      "########################################\n",
      "\n",
      "using JLD2\n",
      "\n",
      "export obs_env\n",
      "export AbstractLattice, SquareLattice\n",
      "abstract type AbstractLattice end\n",
      "struct SquareLattice <: AbstractLattice end\n",
      "\n",
      "export VUMPSRuntime, SquareVUMPSRuntime\n",
      "# NOTE: should be renamed to more explicit names\n",
      "\"\"\"\n",
      "    VUMPSRuntime{LT}\n",
      "\n",
      "a struct to hold the tensors during the `vumps` algorithm, each is a `Ni` x `Nj` Matrix, containing\n",
      "- `d × d × d × d'` `M[i,j]` tensor\n",
      "- `D × d' × D` `AL[i,j]` tensor\n",
      "- `D × D`     `C[i,j]` tensor\n",
      "- `D × d' × D` `AR[i,j]` tensor\n",
      "- `D × d' × D` `FL[i,j]` tensor\n",
      "- `D × d' × D` `FR[i,j]` tensor\n",
      "and `LT` is a AbstractLattice to define the lattice type.\n",
      "\"\"\"\n",
      "struct VUMPSRuntime{LT,T,N,AT <: AbstractArray{<:AbstractArray,2},CT,ET1,ET2}\n",
      "    M::AT\n",
      "    AL::ET1\n",
      "    C::CT\n",
      "    AR::ET1\n",
      "    FL::ET2\n",
      "    FR::ET2\n",
      "    function VUMPSRuntime{LT}(M::AT, AL::ET1, C::CT, AR::ET1, FL::ET2, FR::ET2) where {LT <: AbstractLattice,AT <: AbstractArray{<:AbstractArray,2}, CT <: AbstractArray{<:AbstractArray,2}, ET1 <: AbstractArray{<:AbstractArray,2}, ET2 <: AbstractArray{<:AbstractArray,2}}\n",
      "        T, N = eltype(M[1,1]), ndims(M[1,1])\n",
      "        new{LT,T,N,AT,CT,ET1,ET2}(M, AL, C, AR, FL, FR)\n",
      "    end\n",
      "end\n",
      "\n",
      "const SquareVUMPSRuntime{T,AT} = VUMPSRuntime{SquareLattice,T,4,AT}\n",
      "function SquareVUMPSRuntime(M::AT, AL, C, AR, FL, FR) where {AT <: AbstractArray{<:AbstractArray,2}}\n",
      "    ndims(M[1,1]) == 4 || throw(DimensionMismatch(\"M dimensions error, should be `4`, got $(ndims(M[1,1])).\"))\n",
      "    VUMPSRuntime{SquareLattice}(M, AL, C, AR, FL, FR)\n",
      "end\n",
      "\n",
      "@doc raw\"\n",
      "    SquareVUMPSRuntime(M::AbstractArray{T,4}, env::Val, χ::Int)\n",
      "\n",
      "create a `SquareVUMPSRuntime` with M-tensor `M`. The `NixNj` `AL,C,AR,FL,FR`\n",
      "tensors are initialized according to `env`. If `env = Val(:random)`,\n",
      "the `A[i,j]` is initialized as a random `D×d×D` tensor,and `AL[i,j],C[i,j],AR[i,j]` are the corresponding \n",
      "canonical form. `FL,FR` is the left and right environment.\n",
      "\n",
      "# example\n",
      "\n",
      "```jldoctest; setup = :(using VUMPS)\n",
      "julia> Ni, Nj = 2, 2;\n",
      "\n",
      "julia> M = Array{Array{ComplexF64,3},2}(undef, Ni, Nj);\n",
      "\n",
      "julia> for j = 1:Nj, i = 1:Ni\n",
      "           M[i,j] = rand(2,2,2,2)\n",
      "       end\n",
      "\n",
      "julia> rt = SquareVUMPSRuntime(M, Val(:random), 4);\n",
      "\n",
      "julia> size(rt.AL) == (2,2)\n",
      "true\n",
      "\n",
      "julia> size(rt.AL[1,1]) == (4,2,4)\n",
      "true\n",
      "```\n",
      "\"\n",
      "function SquareVUMPSRuntime(M::AbstractArray{<:AbstractArray,2}, env, χ::Int; verbose=false)\n",
      "    return SquareVUMPSRuntime(M, _initializect_square(M, env, χ; verbose=verbose)...)\n",
      "end\n",
      "\n",
      "function _initializect_square(M::AbstractArray{<:AbstractArray,2}, env::Val{:random}, χ::Int; verbose=false)\n",
      "    A = initialA(M, χ)\n",
      "    AL, L = leftorth(A)\n",
      "    R, AR = rightorth(AL)\n",
      "    _, FL = leftenv(AL, AL, M)\n",
      "    _, FR = rightenv(AR, AR, M)\n",
      "    C = LRtoC(L,R)\n",
      "    Ni, Nj = size(M)\n",
      "    verbose && print(\"random initial $(Ni)×$(Nj) vumps_χ$(χ) environment-> \")\n",
      "    AL, C, AR, FL, FR\n",
      "end\n",
      "\n",
      "function _initializect_square(M::AbstractArray{<:AbstractArray,2}, chkp_file::String, χ::Int; verbose=false)\n",
      "    env = load(chkp_file)[\"env\"]\n",
      "    Ni, Nj = size(M)\n",
      "    atype = _arraytype(M[1,1])\n",
      "    verbose && print(\"vumps $(Ni)×$(Nj) environment load from $(chkp_file) -> \")   \n",
      "    AL, C, AR, FL, FR = env.AL, env.C, env.AR, env.FL, env.FR\n",
      "    Zygote.@ignore begin\n",
      "        AL, C, AR, FL, FR = Array{atype{ComplexF64,3},2}(env.AL), Array{atype{ComplexF64,2},2}(env.C), Array{atype{ComplexF64,3},2}(env.AR), Array{atype{ComplexF64,3},2}(env.FL), Array{atype{ComplexF64,3},2}(env.FR)\n",
      "    end\n",
      "    AL, C, AR, FL, FR\n",
      "end\n",
      "\n",
      "function vumps(rt::VUMPSRuntime; tol::Real=1e-10, maxiter::Int=10, miniter::Int=1, verbose=false, show_every = Inf)\n",
      "    # initialize\n",
      "    olderror = Inf\n",
      "    vumps_counting = show_every_count(show_every)\n",
      "\n",
      "    stopfun = StopFunction(olderror, -1, tol, maxiter, miniter)\n",
      "    rt, err = fixedpoint(res -> vumpstep(res...;show_counting=vumps_counting), (rt, olderror), stopfun)\n",
      "    verbose && println(\"vumps done@step: $(stopfun.counter), error=$(err)\")\n",
      "    return rt\n",
      "end\n",
      "\n",
      "function show_every_count(n::Number)\n",
      "    i = 0\n",
      "    counting() = (i += 1; mod(i,n)==0 ? i : 0)\n",
      "    return counting\n",
      "end\n",
      "\n",
      "function vumpstep(rt::VUMPSRuntime, err; show_counting = show_every_count(Inf))\n",
      "    temp = show_counting()\n",
      "    temp != 0 && println(\"vumps@step: $(temp), error=$(err)\")\n",
      "    M, AL, C, AR, FL, FR = rt.M, rt.AL, rt.C, rt.AR, rt.FL, rt.FR\n",
      "    AC = ALCtoAC(AL,C)\n",
      "    _, ACp = ACenv(AC, FL, M, FR)\n",
      "    _, Cp = Cenv(C, FL, FR)\n",
      "    ALp, ARp, _, _ = ACCtoALAR(ACp, Cp)\n",
      "    _, FL = leftenv(AL, ALp, M, FL)\n",
      "    _, FR = rightenv(AR, ARp, M, FR)\n",
      "    _, ACp = ACenv(ACp, FL, M, FR)\n",
      "    _, Cp = Cenv(Cp, FL, FR)\n",
      "    ALp, ARp, errL, errR = ACCtoALAR(ACp, Cp)\n",
      "    erroverlap = error(ALp, Cp, ARp, FL, M, FR)\n",
      "    err = erroverlap + errL + errR\n",
      "    # @show error(ALp, Cp, ARp, FL, M, FR)\n",
      "    # err = errL + errR\n",
      "    err > 1e-8 && temp >= 10 && println(\"errL=$errL, errR=$errR, erroverlap=$erroverlap\")\n",
      "    return SquareVUMPSRuntime(M, ALp, Cp, ARp, FL, FR), err\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    uptodown(i,Ni,Nj)\n",
      "\n",
      "````\n",
      "i -> (i,j) -> (Nj +1 - i,j) -> ir\n",
      "````\n",
      "\"\"\"\n",
      "function uptodown(i,Ni,Nj)\n",
      "    Liner = LinearIndices((1:Ni,1:Nj))\n",
      "    Cart = CartesianIndices((1:Ni,1:Nj))\n",
      "    Index = Cart[i]\n",
      "    i,j = Index[1],Index[2]\n",
      "    ir = Ni + 1 - i\n",
      "    Liner[ir,j]\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    env = vumps_env(M::AbstractArray; χ::Int, tol::Real=1e-10, maxiter::Int=10, miniter::Int=1, verbose = false, savefile = false, infolder::String=\"./data/\", outfolder::String=\"./data/\", direction::String= \"up\", downfromup = false, show_every = Inf)\n",
      "\n",
      "sometimes the finally observable is symetric, so we can use the same up and down environment. \n",
      "\"\"\"\n",
      "function vumps_env(M::AbstractArray; χ::Int, tol::Real=1e-10, maxiter::Int=10, miniter::Int=1, verbose = false, savefile = false, infolder::String=\"./data/\", outfolder::String=\"./data/\", direction::String= \"up\", downfromup = false, show_every = Inf)\n",
      "    verbose && (direction == \"up\" ? print(\"↑ \") : print(\"↓ \"))\n",
      "    downfromup && direction == \"down\" && (direction = \"up\")\n",
      "    \n",
      "    D = size(M[1,1],1)\n",
      "    savefile && mkpath(outfolder)\n",
      "    in_chkp_file = infolder*\"/$(direction)_D$(D)_χ$(χ).jld2\"\n",
      "\n",
      "    if isfile(in_chkp_file)                               \n",
      "        rtup = SquareVUMPSRuntime(M, in_chkp_file, χ; verbose = verbose)   \n",
      "    else\n",
      "        rtup = SquareVUMPSRuntime(M, Val(:random), χ; verbose = verbose)\n",
      "    end\n",
      "    env = vumps(rtup; tol=tol, maxiter=maxiter, miniter=miniter, verbose = verbose, show_every = show_every)\n",
      "\n",
      "    Zygote.@ignore savefile && begin\n",
      "        out_chkp_file = outfolder*\"/$(direction)_D$(D)_χ$(χ).jld2\"\n",
      "        ALs, Cs, ARs, FLs, FRs = Array{Array{ComplexF64,3},2}(env.AL), Array{Array{ComplexF64,2},2}(env.C), Array{Array{ComplexF64,3},2}(env.AR), Array{Array{ComplexF64,3},2}(env.FL), Array{Array{ComplexF64,3},2}(env.FR)\n",
      "        envsave = SquareVUMPSRuntime(M, ALs, Cs, ARs, FLs, FRs)\n",
      "        save(out_chkp_file, \"env\", envsave)\n",
      "    end\n",
      "    env\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    M, ALu, Cu, ARu, ALd, Cd, ARd, FL, FR, envup.FL, envup.FR = obs_env(M::AbstractArray; χ::Int, tol::Real=1e-10, maxiter::Int=10, miniter::Int=1, verbose=false, savefile= false, infolder::String=\"./data/\", outfolder::String=\"./data/\", updown = true, downfromup = false, show_every = Inf)\n",
      "\n",
      "If `Ni,Nj>1` and `Mij` are different bulk tensor, the up and down environment are different. So to calculate observable, we must get ACup and ACdown, which is easy to get by overturning the `Mij`. Then be cautious to get the new `FL` and `FR` environment.\n",
      "\"\"\"\n",
      "function obs_env(M::AbstractArray; χ::Int, tol::Real=1e-10, maxiter::Int=10, miniter::Int=1, verbose=false, savefile= false, infolder::String=\"./data/\", outfolder::String=\"./data/\", updown = true, downfromup = false, show_every = Inf)\n",
      "    M /= norm(M)\n",
      "    envup = vumps_env(M; χ=χ, tol=tol, maxiter=maxiter, miniter=miniter, verbose=verbose, savefile=savefile, infolder=infolder,outfolder=outfolder, direction=\"up\", downfromup=downfromup, show_every = show_every)\n",
      "    ALu,ARu,Cu = envup.AL,envup.AR,envup.C\n",
      "\n",
      "    D = size(M[1,1],1)\n",
      "    atype = _arraytype(M[1,1])\n",
      "    in_chkp_file_obs = infolder*\"/obs_D$(D)_χ$(χ).jld2\"\n",
      "    if isfile(in_chkp_file_obs)   \n",
      "        verbose && println(\"←→ observable environment load from $(in_chkp_file_obs)\")\n",
      "        FL, FR = load(in_chkp_file_obs)[\"env\"]\n",
      "        Zygote.@ignore begin\n",
      "            FL, FR = Array{atype{ComplexF64,3},2}(FL), Array{atype{ComplexF64,3},2}(FR)\n",
      "        end\n",
      "    else\n",
      "        FL, FR = envup.FL, envup.FR\n",
      "    end\n",
      "\n",
      "    if updown \n",
      "        Ni, Nj = size(ALu)\n",
      "        Md = [permutedims(M[uptodown(i,Ni,Nj)], (1,4,3,2)) for i = 1:Ni*Nj]\n",
      "        Md = reshape(Md, Ni, Nj)\n",
      "\n",
      "        envdown = vumps_env(Md; χ=χ, tol=tol, maxiter=maxiter, miniter=miniter, verbose=verbose, savefile=savefile, infolder=infolder, outfolder=outfolder, direction=\"down\", downfromup=downfromup, show_every = show_every)\n",
      "        ALd, ARd, Cd = envdown.AL, envdown.AR, envdown.C\n",
      "    else\n",
      "        ALd, ARd, Cd = ALu, ARu, Cu\n",
      "    end\n",
      "\n",
      "    _, FL = obs_FL(ALu, ALd, M, FL)\n",
      "    _, FR = obs_FR(ARu, ARd, M, FR)\n",
      "    Zygote.@ignore savefile && begin\n",
      "        out_chkp_file_obs = outfolder*\"/obs_D$(D)_χ$(χ).jld2\"\n",
      "        envsave = (Array{Array{ComplexF64,3},2}(FL), Array{Array{ComplexF64,3},2}(FR))\n",
      "        save(out_chkp_file_obs, \"env\", envsave)\n",
      "    end\n",
      "    return M, ALu, Cu, ARu, ALd, Cd, ARd, FL, FR, envup.FL, envup.FR\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  81\n",
      "Samples-Playgrounds/Samples.Julia\n",
      "samples/HTTP_get.jl\n",
      "########################################\n",
      "\n",
      "# https://dev.solita.fi/2020/04/07/trying-out-julia.html #\n",
      "\n",
      "import Pkg\n",
      "Pkg.instantiate() # downloads all dependencies for the current project\n",
      "\n",
      "Pkg.add(\"JSON\")\n",
      "Pkg.add(\"HTTP\")\n",
      "Pkg.add(\"Plots\")\n",
      "Pkg.add(\"StatsPlots\")\n",
      "\n",
      "using HTTP, JSON, Plots, StatsPlots\n",
      "\n",
      "resp = HTTP.get(\"https://api.covid19api.com/country/croatia/status/confirmed\")\n",
      "str = String(resp.body)\n",
      "jobj = JSON.Parser.parse(str)\n",
      "\n",
      "println(jobj[1])\n",
      "\n",
      "cases = map(x -> get(x, \"Cases\", 0), jobj)\n",
      "plot(cases, xlabel = \"Number of Cases\")\n",
      "\n",
      "savefig(\"cases_simple.png\") #Save plot as png image\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  82\n",
      "Pramodh-G/julia\n",
      "base/version.jl\n",
      "########################################\n",
      "\n",
      "# This file is a part of Julia. License is MIT: https://julialang.org/license\n",
      "\n",
      "## semantic version numbers (https://semver.org/)\n",
      "\n",
      "const VerTuple = Tuple{Vararg{Union{UInt64,String}}}\n",
      "\n",
      "const VInt = UInt32\n",
      "\"\"\"\n",
      "    VersionNumber\n",
      "\n",
      "Version number type which follow the specifications of\n",
      "[semantic versioning](https://semver.org/), composed of major, minor\n",
      "and patch numeric values, followed by pre-release and build\n",
      "alpha-numeric annotations. See also [`@v_str`](@ref).\n",
      "\n",
      "# Examples\n",
      "```jldoctest\n",
      "julia> VersionNumber(\"1.2.3\")\n",
      "v\"1.2.3\"\n",
      "\n",
      "julia> VersionNumber(\"2.0.1-rc1\")\n",
      "v\"2.0.1-rc1\"\n",
      "```\n",
      "\"\"\"\n",
      "struct VersionNumber\n",
      "    major::VInt\n",
      "    minor::VInt\n",
      "    patch::VInt\n",
      "    prerelease::VerTuple\n",
      "    build::VerTuple\n",
      "\n",
      "    function VersionNumber(major::VInt, minor::VInt, patch::VInt,\n",
      "            pre::VerTuple,\n",
      "            bld::VerTuple)\n",
      "        major >= 0 || throw(ArgumentError(\"invalid negative major version: $major\"))\n",
      "        minor >= 0 || throw(ArgumentError(\"invalid negative minor version: $minor\"))\n",
      "        patch >= 0 || throw(ArgumentError(\"invalid negative patch version: $patch\"))\n",
      "        for ident in pre\n",
      "            if ident isa Integer\n",
      "                ident >= 0 || throw(ArgumentError(\"invalid negative pre-release identifier: $ident\"))\n",
      "            else\n",
      "                if !occursin(r\"^(?:|[0-9a-z-]*[a-z-][0-9a-z-]*)$\"i, ident) ||\n",
      "                    isempty(ident) && !(length(pre)==1 && isempty(bld))\n",
      "                    throw(ArgumentError(\"invalid pre-release identifier: $(repr(ident))\"))\n",
      "                end\n",
      "            end\n",
      "        end\n",
      "        for ident in bld\n",
      "            if ident isa Integer\n",
      "                ident >= 0 || throw(ArgumentError(\"invalid negative build identifier: $ident\"))\n",
      "            else\n",
      "                if !occursin(r\"^(?:|[0-9a-z-]*[a-z-][0-9a-z-]*)$\"i, ident) ||\n",
      "                    isempty(ident) && length(bld)!=1\n",
      "                    throw(ArgumentError(\"invalid build identifier: $(repr(ident))\"))\n",
      "                end\n",
      "            end\n",
      "        end\n",
      "        new(major, minor, patch, pre, bld)\n",
      "    end\n",
      "end\n",
      "VersionNumber(major::Integer, minor::Integer = 0, patch::Integer = 0,\n",
      "        pre::Tuple{Vararg{Union{Integer,AbstractString}}} = (),\n",
      "        bld::Tuple{Vararg{Union{Integer,AbstractString}}} = ()) =\n",
      "    VersionNumber(VInt(major), VInt(minor), VInt(patch),\n",
      "        map(x->x isa Integer ? UInt64(x) : String(x), pre),\n",
      "        map(x->x isa Integer ? UInt64(x) : String(x), bld))\n",
      "\n",
      "VersionNumber(v::Tuple) = VersionNumber(v...)\n",
      "\n",
      "function print(io::IO, v::VersionNumber)\n",
      "    v == typemax(VersionNumber) && return print(io, \"∞\")\n",
      "    print(io, v.major)\n",
      "    print(io, '.')\n",
      "    print(io, v.minor)\n",
      "    print(io, '.')\n",
      "    print(io, v.patch)\n",
      "    if !isempty(v.prerelease)\n",
      "        print(io, '-')\n",
      "        join(io, v.prerelease,'.')\n",
      "    end\n",
      "    if !isempty(v.build)\n",
      "        print(io, '+')\n",
      "        join(io, v.build,'.')\n",
      "    end\n",
      "end\n",
      "show(io::IO, v::VersionNumber) = print(io, \"v\\\"\", v, \"\\\"\")\n",
      "\n",
      "Broadcast.broadcastable(v::VersionNumber) = Ref(v)\n",
      "\n",
      "const VERSION_REGEX = r\"^\n",
      "    v?                                      # prefix        (optional)\n",
      "    (\\d+)                                   # major         (required)\n",
      "    (?:\\.(\\d+))?                            # minor         (optional)\n",
      "    (?:\\.(\\d+))?                            # patch         (optional)\n",
      "    (?:(-)|                                 # pre-release   (optional)\n",
      "    ([a-z][0-9a-z-]*(?:\\.[0-9a-z-]+)*|-(?:[0-9a-z-]+\\.)*[0-9a-z-]+)?\n",
      "    (?:(\\+)|\n",
      "    (?:\\+((?:[0-9a-z-]+\\.)*[0-9a-z-]+))?    # build         (optional)\n",
      "    ))\n",
      "$\"ix\n",
      "\n",
      "function split_idents(s::AbstractString)\n",
      "    idents = eachsplit(s, '.')\n",
      "    pidents = Union{UInt64,String}[occursin(r\"^\\d+$\", ident) ? parse(UInt64, ident) : String(ident) for ident in idents]\n",
      "    return tuple(pidents...)::VerTuple\n",
      "end\n",
      "\n",
      "function tryparse(::Type{VersionNumber}, v::AbstractString)\n",
      "    v == \"∞\" && return typemax(VersionNumber)\n",
      "    m = match(VERSION_REGEX, String(v)::String)\n",
      "    m === nothing && return nothing\n",
      "    major, minor, patch, minus, prerl, plus, build = m.captures\n",
      "    major = parse(VInt, major::AbstractString)\n",
      "    minor = minor !== nothing ? parse(VInt, minor) : VInt(0)\n",
      "    patch = patch !== nothing ? parse(VInt, patch) : VInt(0)\n",
      "    if prerl !== nothing && !isempty(prerl) && prerl[1] == '-'\n",
      "        prerl = prerl[2:end] # strip leading '-'\n",
      "    end\n",
      "    prerl = prerl !== nothing ? split_idents(prerl) : minus !== nothing ? (\"\",) : ()\n",
      "    build = build !== nothing ? split_idents(build) : plus  !== nothing ? (\"\",) : ()\n",
      "    return VersionNumber(major, minor, patch, prerl::VerTuple, build::VerTuple)\n",
      "end\n",
      "\n",
      "function parse(::Type{VersionNumber}, v::AbstractString)\n",
      "    ver = tryparse(VersionNumber, v)\n",
      "    ver === nothing && throw(ArgumentError(\"invalid version string: $v\"))\n",
      "    return ver\n",
      "end\n",
      "\n",
      "VersionNumber(v::AbstractString) = parse(VersionNumber, v)\n",
      "\n",
      "\"\"\"\n",
      "    @v_str\n",
      "\n",
      "String macro used to parse a string to a [`VersionNumber`](@ref).\n",
      "\n",
      "# Examples\n",
      "```jldoctest\n",
      "julia> v\"1.2.3\"\n",
      "v\"1.2.3\"\n",
      "\n",
      "julia> v\"2.0.1-rc1\"\n",
      "v\"2.0.1-rc1\"\n",
      "```\n",
      "\"\"\"\n",
      "macro v_str(v); VersionNumber(v); end\n",
      "\n",
      "function typemax(::Type{VersionNumber})\n",
      "    ∞ = typemax(VInt)\n",
      "    VersionNumber(∞, ∞, ∞, (), (\"\",))\n",
      "end\n",
      "\n",
      "typemin(::Type{VersionNumber}) = v\"0-\"\n",
      "\n",
      "ident_cmp(a::Integer, b::Integer) = cmp(a, b)\n",
      "ident_cmp(a::Integer, b::String ) = isempty(b) ? +1 : -1\n",
      "ident_cmp(a::String,  b::Integer) = isempty(a) ? -1 : +1\n",
      "ident_cmp(a::String,  b::String ) = cmp(a, b)\n",
      "\n",
      "function ident_cmp(A::VerTuple, B::VerTuple)\n",
      "    for (a, b) in Iterators.Zip{Tuple{VerTuple,VerTuple}}((A, B))\n",
      "        c = ident_cmp(a, b)\n",
      "        (c != 0) && return c\n",
      "    end\n",
      "    length(A) < length(B) ? -1 :\n",
      "    length(B) < length(A) ? +1 : 0\n",
      "end\n",
      "\n",
      "function ==(a::VersionNumber, b::VersionNumber)\n",
      "    (a.major != b.major) && return false\n",
      "    (a.minor != b.minor) && return false\n",
      "    (a.patch != b.patch) && return false\n",
      "    (ident_cmp(a.prerelease, b.prerelease) != 0) && return false\n",
      "    (ident_cmp(a.build, b.build) != 0) && return false\n",
      "    return true\n",
      "end\n",
      "\n",
      "issupbuild(v::VersionNumber) = length(v.build)==1 && isempty(v.build[1])\n",
      "\n",
      "function isless(a::VersionNumber, b::VersionNumber)\n",
      "    (a.major < b.major) && return true\n",
      "    (a.major > b.major) && return false\n",
      "    (a.minor < b.minor) && return true\n",
      "    (a.minor > b.minor) && return false\n",
      "    (a.patch < b.patch) && return true\n",
      "    (a.patch > b.patch) && return false\n",
      "    (!isempty(a.prerelease) && isempty(b.prerelease)) && return true\n",
      "    (isempty(a.prerelease) && !isempty(b.prerelease)) && return false\n",
      "    c = ident_cmp(a.prerelease,b.prerelease)\n",
      "    (c < 0) && return true\n",
      "    (c > 0) && return false\n",
      "    (!issupbuild(a) && issupbuild(b)) && return true\n",
      "    (issupbuild(a) && !issupbuild(b)) && return false\n",
      "    c = ident_cmp(a.build,b.build)\n",
      "    (c < 0) && return true\n",
      "    return false\n",
      "end\n",
      "\n",
      "function hash(v::VersionNumber, h::UInt)\n",
      "    h += 0x8ff4ffdb75f9fede % UInt\n",
      "    h = hash(v.major, h)\n",
      "    h = hash(v.minor, h)\n",
      "    h = hash(v.patch, h)\n",
      "    h = hash(v.prerelease, ~h)\n",
      "    h = hash(v.build, ~h)\n",
      "end\n",
      "\n",
      "lowerbound(v::VersionNumber) = VersionNumber(v.major, v.minor, v.patch, (\"\",), ())\n",
      "upperbound(v::VersionNumber) = VersionNumber(v.major, v.minor, v.patch, (), (\"\",))\n",
      "\n",
      "thispatch(v::VersionNumber) = VersionNumber(v.major, v.minor, v.patch)\n",
      "thisminor(v::VersionNumber) = VersionNumber(v.major, v.minor, 0)\n",
      "thismajor(v::VersionNumber) = VersionNumber(v.major, 0, 0)\n",
      "\n",
      "nextpatch(v::VersionNumber) = v < thispatch(v) ? thispatch(v) : VersionNumber(v.major, v.minor, v.patch+1)\n",
      "nextminor(v::VersionNumber) = v < thisminor(v) ? thisminor(v) : VersionNumber(v.major, v.minor+1, 0)\n",
      "nextmajor(v::VersionNumber) = v < thismajor(v) ? thismajor(v) : VersionNumber(v.major+1, 0, 0)\n",
      "\n",
      "## julia version info\n",
      "\n",
      "\"\"\"\n",
      "    VERSION\n",
      "\n",
      "A `VersionNumber` object describing which version of Julia is in use. For details see\n",
      "[Version Number Literals](@ref man-version-number-literals).\n",
      "\"\"\"\n",
      "const VERSION = try\n",
      "    ver = VersionNumber(VERSION_STRING)\n",
      "    if !isempty(ver.prerelease) && !GIT_VERSION_INFO.tagged_commit\n",
      "        if GIT_VERSION_INFO.build_number >= 0\n",
      "            ver = VersionNumber(ver.major, ver.minor, ver.patch, (ver.prerelease..., GIT_VERSION_INFO.build_number), ver.build)\n",
      "        else\n",
      "            println(\"WARNING: no build number found for pre-release version\")\n",
      "            ver = VersionNumber(ver.major, ver.minor, ver.patch, (ver.prerelease..., \"unknown\"), ver.build)\n",
      "        end\n",
      "    elseif GIT_VERSION_INFO.build_number > 0\n",
      "        println(\"WARNING: ignoring non-zero build number for VERSION\")\n",
      "    end\n",
      "    ver\n",
      "catch e\n",
      "    println(\"while creating Base.VERSION, ignoring error $e\")\n",
      "    VersionNumber(0)\n",
      "end\n",
      "\n",
      "const libllvm_version = if endswith(libllvm_version_string, \"jl\")\n",
      "    # strip the \"jl\" SONAME suffix (JuliaLang/julia#33058)\n",
      "    # (LLVM does never report a prerelease version anyway)\n",
      "    VersionNumber(libllvm_version_string[1:end-2])\n",
      "else\n",
      "    VersionNumber(libllvm_version_string)\n",
      "end\n",
      "\n",
      "libllvm_path() = ccall(:jl_get_libllvm, Any, ())\n",
      "\n",
      "function banner(io::IO = stdout)\n",
      "    if GIT_VERSION_INFO.tagged_commit\n",
      "        commit_string = TAGGED_RELEASE_BANNER\n",
      "    elseif isempty(GIT_VERSION_INFO.commit)\n",
      "        commit_string = \"\"\n",
      "    else\n",
      "        days = Int(floor((ccall(:jl_clock_now, Float64, ()) - GIT_VERSION_INFO.fork_master_timestamp) / (60 * 60 * 24)))\n",
      "        days = max(0, days)\n",
      "        unit = days == 1 ? \"day\" : \"days\"\n",
      "        distance = GIT_VERSION_INFO.fork_master_distance\n",
      "        commit = GIT_VERSION_INFO.commit_short\n",
      "\n",
      "        if distance == 0\n",
      "            commit_string = \"Commit $(commit) ($(days) $(unit) old master)\"\n",
      "        else\n",
      "            branch = GIT_VERSION_INFO.branch\n",
      "            commit_string = \"$(branch)/$(commit) (fork: $(distance) commits, $(days) $(unit))\"\n",
      "        end\n",
      "    end\n",
      "\n",
      "    commit_date = isempty(Base.GIT_VERSION_INFO.date_string) ? \"\" : \" ($(split(Base.GIT_VERSION_INFO.date_string)[1]))\"\n",
      "\n",
      "    if get(io, :color, false)\n",
      "        c = text_colors\n",
      "        tx = c[:normal] # text\n",
      "        jl = c[:normal] # julia\n",
      "        d1 = c[:bold] * c[:blue]    # first dot\n",
      "        d2 = c[:bold] * c[:red]     # second dot\n",
      "        d3 = c[:bold] * c[:green]   # third dot\n",
      "        d4 = c[:bold] * c[:magenta] # fourth dot\n",
      "\n",
      "        print(io,\"\"\"               $(d3)_$(tx)\n",
      "           $(d1)_$(tx)       $(jl)_$(tx) $(d2)_$(d3)(_)$(d4)_$(tx)     |  Documentation: https://docs.julialang.org\n",
      "          $(d1)(_)$(jl)     | $(d2)(_)$(tx) $(d4)(_)$(tx)    |\n",
      "           $(jl)_ _   _| |_  __ _$(tx)   |  Type \\\"?\\\" for help, \\\"]?\\\" for Pkg help.\n",
      "          $(jl)| | | | | | |/ _` |$(tx)  |\n",
      "          $(jl)| | |_| | | | (_| |$(tx)  |  Version $(VERSION)$(commit_date)\n",
      "         $(jl)_/ |\\\\__'_|_|_|\\\\__'_|$(tx)  |  $(commit_string)\n",
      "        $(jl)|__/$(tx)                   |\n",
      "\n",
      "        \"\"\")\n",
      "    else\n",
      "        print(io,\"\"\"\n",
      "                       _\n",
      "           _       _ _(_)_     |  Documentation: https://docs.julialang.org\n",
      "          (_)     | (_) (_)    |\n",
      "           _ _   _| |_  __ _   |  Type \\\"?\\\" for help, \\\"]?\\\" for Pkg help.\n",
      "          | | | | | | |/ _` |  |\n",
      "          | | |_| | | | (_| |  |  Version $(VERSION)$(commit_date)\n",
      "         _/ |\\\\__'_|_|_|\\\\__'_|  |  $(commit_string)\n",
      "        |__/                   |\n",
      "\n",
      "        \"\"\")\n",
      "    end\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  83\n",
      "mmattocks/BioMotifInference.jl\n",
      "test/ensemble_tests.jl\n",
      "########################################\n",
      "\n",
      "\n",
      "@testset \"Ensemble assembly and nested sampling functions\" begin\n",
      "    ensembledir = randstring()\n",
      "    spensembledir = randstring()\n",
      "    distdir = randstring()\n",
      "\n",
      "    source_pwm = [.7 .1 .1 .1\n",
      "    .1 .1 .1 .7\n",
      "    .1 .1 .7 .1]\n",
      "\n",
      "    source_pwm_2 = [.6 .1 .1 .2\n",
      "    .2 .1 .1 .6\n",
      "    .1 .2 .6 .1]\n",
      "\n",
      "    src_length_limits=2:12\n",
      "    no_sources=3\n",
      "\n",
      "    source_priors = assemble_source_priors(no_sources, [source_pwm, source_pwm_2])\n",
      "    mix_prior=.5\n",
      "\n",
      "    bg_scores = log.(fill(.1, (30,4)))\n",
      "    obs=[BioSequences.LongSequence{DNAAlphabet{2}}(\"CCGTTGACGATGTGATGAATAATGAAAGAA\")\n",
      "    BioSequences.LongSequence{DNAAlphabet{2}}(\"CCCCGATGATGACCGTTGACCAGATGGATG\")\n",
      "    BioSequences.LongSequence{DNAAlphabet{2}}(\"CCCCGATGATGACCCCGATTTTGAAAAAAA\")\n",
      "    BioSequences.LongSequence{DNAAlphabet{2}}(\"TCATCATGCTGATGATGAATCAGATGAAAG\")\n",
      "    ]\n",
      "\n",
      "    order_seqs = BioBackgroundModels.get_order_n_seqs(obs, 0)\n",
      "    coded_seqs = BioBackgroundModels.code_seqs(order_seqs)\n",
      "    obs=Array(transpose(coded_seqs))\n",
      "\n",
      "    ensemble = IPM_Ensemble(ensembledir, 150, source_priors, (falses(0,0),mix_prior), bg_scores, obs, src_length_limits)\n",
      "    ensemble = IPM_Ensemble(ensembledir, 200, source_priors, (falses(0,0),mix_prior), bg_scores, obs, src_length_limits) #test resumption\n",
      "\n",
      "    sp_ensemble = IPM_Ensemble(spensembledir, 200, source_priors, (falses(0,0),mix_prior), bg_scores, obs, src_length_limits, posterior_switch=true)\n",
      "\n",
      "    @test length(ensemble.models) == 200\n",
      "    for model in ensemble.models\n",
      "        @test -350 < model.log_Li < -150\n",
      "    end\n",
      "\n",
      "    @test length(sp_ensemble.models) == 200\n",
      "    for model in sp_ensemble.models\n",
      "        @test -350 < model.log_Li < -150\n",
      "    end\n",
      "\n",
      "    assembler=addprocs(1)\n",
      "\n",
      "    @everywhere using BioMotifInference\n",
      "\n",
      "    dist_ensemble=IPM_Ensemble(assembler, distdir, 150, source_priors, (falses(0,0),mix_prior), bg_scores, obs, src_length_limits)\n",
      "    dist_ensemble=IPM_Ensemble(assembler, distdir, 200, source_priors, (falses(0,0),mix_prior), bg_scores, obs, src_length_limits) #test resumption\n",
      "\n",
      "    @test length(dist_ensemble.models) == 200\n",
      "    for model in ensemble.models\n",
      "        @test -350 < model.log_Li < -150\n",
      "    end\n",
      "\n",
      "    rmprocs(assembler)\n",
      "    rm(distdir, recursive=true)\n",
      "\n",
      "    models_to_permute = 600\n",
      "    funclimit=200\n",
      "    funcvec=full_perm_funcvec\n",
      "\n",
      "    instruct = Permute_Instruct(funcvec, ones(length(funcvec))./length(funcvec),models_to_permute,200, min_clmps=fill(.02,length(funcvec)))\n",
      "\n",
      "    @info \"Testing convergence displays...\"\n",
      "    sp_logZ = converge_ensemble!(sp_ensemble, instruct, converge_factor=500.,  wk_disp=true, tuning_disp=true, ens_disp=true, conv_plot=true, src_disp=true, lh_disp=true, liwi_disp=true, max_iterates=50)\n",
      "\n",
      "    sp_ensemble=reset_ensemble!(sp_ensemble)\n",
      "\n",
      "    @info \"Testing threaded convergence...\"\n",
      "    sp_logZ = converge_ensemble!(sp_ensemble, instruct,  converge_factor=500.,wk_disp=false, tuning_disp=false, ens_disp=false, conv_plot=false, src_disp=false, lh_disp=false, liwi_disp=false, backup=(true, 150), max_iterates=300)\n",
      "\n",
      "    @info \"Testing resumption...\"\n",
      "    sp_logZ = converge_ensemble!(sp_ensemble, instruct,  converge_factor=500.,wk_disp=false, tuning_disp=false, ens_disp=false, conv_plot=false, src_disp=false, lh_disp=false, liwi_disp=false, backup=(true, 150))\n",
      "    @test length(sp_ensemble.models) == 200\n",
      "    @test length(sp_ensemble.log_Li) == length(sp_ensemble.log_Xi) == length(sp_ensemble.log_wi) == length(sp_ensemble.log_Liwi) == length(sp_ensemble.log_Zi) == length(sp_ensemble.Hi) == sp_ensemble.model_counter-200\n",
      "    for i in 1:length(sp_ensemble.log_Li)-1\n",
      "        @test sp_ensemble.log_Li[i] <= sp_ensemble.log_Li[i+1]\n",
      "    end\n",
      "    for i in 1:length(sp_ensemble.log_Zi)-1\n",
      "        @test sp_ensemble.log_Zi[i] <= sp_ensemble.log_Zi[i+1]\n",
      "    end\n",
      "    @test sp_logZ > -1500.0\n",
      "\n",
      "    @info \"Testing multiprocess convergence...\"\n",
      "    @info \"Spawning worker pool...\"\n",
      "    worker_pool=addprocs(2, topology=:master_worker)\n",
      "    @everywhere using BioMotifInference\n",
      "\n",
      "    ####CONVERGE############\n",
      "    final_logZ = converge_ensemble!(ensemble, instruct, worker_pool,  converge_factor=500., wk_disp=false, tuning_disp=false, ens_disp=false, conv_plot=false, src_disp=false, lh_disp=false, liwi_disp=false, backup=(true,500), clean=(true, 500, 1000))\n",
      "\n",
      "    convits=length(ensemble.log_Li)\n",
      "\n",
      "    #test converging already converged, wih different converge criterion\n",
      "    final_logZ = converge_ensemble!(ensemble, instruct, worker_pool,  converge_factor=150., converge_criterion=\"compression\", wk_disp=false, tuning_disp=false, ens_disp=false, conv_plot=false, src_disp=false, lh_disp=false, liwi_disp=false, backup=(true,500), clean=(true, 500, 1000))\n",
      "\n",
      "    length(ensemble.log_Li)==convits\n",
      "\n",
      "    rmprocs(worker_pool)\n",
      "\n",
      "    @test length(ensemble.models) == 200\n",
      "    @test length(ensemble.log_Li) == length(ensemble.log_Xi) == length(ensemble.log_wi) == length(ensemble.log_Liwi) == length(ensemble.log_Zi) == length(ensemble.Hi) == ensemble.model_counter-200\n",
      "    for i in 1:length(ensemble.log_Li)-1\n",
      "        @test ensemble.log_Li[i] <= ensemble.log_Li[i+1]\n",
      "    end\n",
      "    for i in 1:length(ensemble.log_Zi)-1\n",
      "        @test ensemble.log_Zi[i] <= ensemble.log_Zi[i+1]\n",
      "    end\n",
      "    @test typeof(final_logZ) == Float64\n",
      "    @test final_logZ > -1500.0\n",
      "\n",
      "    rm(ensembledir, recursive=true)\n",
      "    rm(spensembledir, recursive=true)\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  84\n",
      "avsolatorio/WorldBankDataDive2019ConflictSpendingAsia\n",
      "src/worldbank.jl\n",
      "########################################\n",
      "\n",
      "using HTTP, JSON3, CSV, DataFrames\n",
      "\n",
      "parse_country(obj) = (id = obj.id, name = obj.name, incomde = obj.incomeLevel.id)\n",
      "function parse_datum(obj)\n",
      "    (name = obj.countryiso3code,\n",
      "     indicator = obj.indicator.id,\n",
      "     date = obj.date,\n",
      "     value = isnothing(obj.value) ? missing : obj.value)\n",
      "end\n",
      "function parse_data(;countries = countries, years = \"2009:2019\", indicator = nothing)\n",
      "    isnothing(indicator) && throw(ArgumentError(\"Please provide an indicator\"))\n",
      "    string(\"http://api.worldbank.org/v2/country/$countries/\",\n",
      "                  \"indicator/$indicator?\",\n",
      "                  \"date=2009:2019&per_page=1&format=json\") |>\n",
      "        HTTP.get |>\n",
      "        (response -> response.body) |>\n",
      "        String |>\n",
      "        JSON3.read |>\n",
      "        (obj -> obj[1].total) |>\n",
      "        (total -> string(\"http://api.worldbank.org/v2/country/$countries/\",\n",
      "                      \"indicator/$indicator?\",\n",
      "                      \"date=2009:2019&per_page=$total&format=json\")) |>\n",
      "        HTTP.get |>\n",
      "        (response -> response.body) |>\n",
      "        String |>\n",
      "        JSON3.read |>\n",
      "        last |>\n",
      "        (obj -> [ parse_data(elem) for elem in obj ])\n",
      "end\n",
      "data = \"https://api.worldbank.org/v2/country?region=SAS&format=json\" |>\n",
      "    HTTP.get |>\n",
      "    (response -> response.body) |>\n",
      "    String |>\n",
      "    JSON3.read |>\n",
      "    last |>\n",
      "    (obj -> CSV.write(joinpath(\"data\", \"countries.csv\"),\n",
      "                      parse_country(elem) for elem in obj))\n",
      "countries = CSV.File(joinpath(\"data\", \"countries.csv\")) |>\n",
      "    (obj -> getproperty.(obj, :id)) |>\n",
      "    (obj -> join(obj, ';'))\n",
      "indicators = CSV.read(joinpath(\"data\", \"indicators.tsv\")) |>\n",
      "    (obj -> obj.code)\n",
      "output = reduce(vcat,\n",
      "                parse_data(countries = countries,\n",
      "                           indicator = indicator) for indicator in indicators)\n",
      "CSV.write(joinpath(\"data\", \"worldbank.tsv\"),\n",
      "          output,\n",
      "          delim = '\\t')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  85\n",
      "JuliaBinaryWrappers/pprof_jll.jl\n",
      "src/wrappers/x86_64-unknown-freebsd.jl\n",
      "########################################\n",
      "\n",
      "# Autogenerated wrapper script for pprof_jll for x86_64-unknown-freebsd\n",
      "export pprof\n",
      "\n",
      "JLLWrappers.@generate_wrapper_header(\"pprof\")\n",
      "JLLWrappers.@declare_executable_product(pprof)\n",
      "function __init__()\n",
      "    JLLWrappers.@generate_init_header()\n",
      "    JLLWrappers.@init_executable_product(\n",
      "        pprof,\n",
      "        \"bin/pprof\",\n",
      "    )\n",
      "\n",
      "    JLLWrappers.@generate_init_footer()\n",
      "end  # __init__()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  86\n",
      "eschnett/STL.jl\n",
      "src/StdSharedPtr.jl\n",
      "########################################\n",
      "\n",
      "# StdSharedPtr\n",
      "\n",
      "eval(cxxnewfile(\"StdSharedPtr.cxx\", \"\"\"\n",
      "    #include <memory>\n",
      "    \"\"\"))\n",
      "\n",
      "Base.cconvert(::Type{Ptr{StdSharedPtr{T}}}, ptr::StdSharedPtr{T}) where {T} = ptr.cxx\n",
      "\n",
      "convert_arg(::Type{Ptr{StdSharedPtr{T}}}, ptr::StdSharedPtr{T}) where {T} = ptr.cxx\n",
      "convert_result(::Type{StdSharedPtr{T}}, ptr::Ptr{StdSharedPtr{T}}) where {T} = StdSharedPtr{T}(ptr)\n",
      "\n",
      "StdSharedPtr{T}() where {T} = StdSharedPtr_new(T)\n",
      "\n",
      "function generate(::Type{StdSharedPtr{T}}) where {T}\n",
      "    CT = T == Bool ? \"bool\" : cxxtype[T]\n",
      "    NT = cxxname(CT)\n",
      "\n",
      "    eval(cxxfunction(FnName(Symbol(:StdSharedPtr_new), \"std_shared_ptr_$(NT)_new\", libSTL),\n",
      "                     FnResult(Ptr{StdSharedPtr{T}}, \"std::shared_ptr<$CT> *\", StdSharedPtr{T}, expr -> :(StdSharedPtr{$T}($expr))),\n",
      "                     [FnArg(:type, Nothing, \"type\", \"void\", Type{T}, identity; skip=true)], \"return new std::shared_ptr<$CT>;\"))\n",
      "\n",
      "    eval(cxxfunction(FnName(:StdSharedPtr_delete, \"std_shared_ptr_$(NT)_delete\", libSTL), FnResult(Nothing, \"void\"),\n",
      "                     [FnArg(:ptr, Ptr{StdSharedPtr{T}}, \"ptr\", \"std::shared_ptr<$CT> * restrict\", StdSharedPtr{T}, identity)],\n",
      "                     \"delete ptr;\"))\n",
      "\n",
      "    eval(cxxfunction(FnName(:(Base.copy), \"std_shared_ptr_$(NT)_copy\", libSTL),\n",
      "                     FnResult(Ptr{StdSharedPtr{T}}, \"std::shared_ptr<$CT> *\", StdSharedPtr{T}, expr -> :(StdSharedPtr{$T}($expr))),\n",
      "                     [FnArg(:ptr, Ptr{StdSharedPtr{T}}, \"ptr\", \"std::shared_ptr<$CT> * restrict\", StdSharedPtr{T}, identity)],\n",
      "                     \"return new std::shared_ptr<$CT>(*ptr);\"))\n",
      "\n",
      "    eval(cxxfunction(FnName(:(Base.empty!), \"std_shared_ptr_$(NT)_empty_\", libSTL), FnResult(Nothing, \"void\"),\n",
      "                     [FnArg(:ptr, Ptr{StdSharedPtr{T}}, \"ptr\", \"std::shared_ptr<$CT> * restrict\", StdSharedPtr{T}, identity)],\n",
      "                     \"ptr->reset();\"))\n",
      "\n",
      "    eval(cxxfunction(FnName(:(Base.isempty), \"std_shared_ptr_$(NT)_isempty\", libSTL), FnResult(Bool, \"bool\"),\n",
      "                     [FnArg(:ptr, Ptr{StdSharedPtr{T}}, \"ptr\", \"const std::shared_ptr<$CT> * restrict\", StdSharedPtr{T}, identity)],\n",
      "                     \"return !*ptr;\"))\n",
      "\n",
      "    # if T == Bool\n",
      "    #     eval(cxxfunction(FnName(:(Base.getindex), \"std_shared_ptr_$(NT)_getindex\", libSTL), FnResult(T, CT),\n",
      "    #                      [FnArg(:ptr, Ptr{StdSharedPtr{T}}, \"ptr\", \"std::shared_ptr<$CT> * restrict\", StdSharedPtr{T}, identity)],\n",
      "    #                      \"return **ptr;\"))\n",
      "    # else\n",
      "    eval(cxxfunction(FnName(:(Base.getindex), \"std_shared_ptr_$(NT)_getindex\", libSTL),\n",
      "                     FnResult(Ptr{T}, \"$CT *\", T, expr -> :(convert_result($T, $expr))),\n",
      "                     [FnArg(:ptr, Ptr{StdSharedPtr{T}}, \"ptr\", \"std::shared_ptr<$CT> * restrict\", StdSharedPtr{T}, identity)],\n",
      "                     \"return &**ptr;\"))\n",
      "    # end\n",
      "\n",
      "    eval(cxxfunction(FnName(:(Base.setindex!), \"std_shared_ptr_$(NT)_setindex_\", libSTL), FnResult(Nothing, \"void\"),\n",
      "                     [FnArg(:ptr, Ptr{StdSharedPtr{T}}, \"ptr\", \"std::shared_ptr<$CT> * restrict\", StdSharedPtr{T}, identity),\n",
      "                      FnArg(:val, Ptr{T}, \"val\", \"$CT const *\", Any, expr -> :(convert_arg(Ptr{$T}, convert($T, $expr))))],\n",
      "                     \"**ptr = *val;\"))\n",
      "\n",
      "    eval(cxxfunction(FnName(:use_count, \"std_shared_ptr_$(NT)_use_count\", libSTL),\n",
      "                     FnResult(Csize_t, \"std::size_t\", Int, expr -> :(convert(Int, $expr))),\n",
      "                     [FnArg(:ptr, Ptr{StdSharedPtr{T}}, \"ptr\", \"const std::shared_ptr<$CT> * restrict\", StdSharedPtr{T}, identity)],\n",
      "                     \"return ptr->use_count();\"))\n",
      "\n",
      "    eval(cxxfunction(FnName(:(Base.:(==)), \"std_shared_ptr_$(NT)_equals\", libSTL), FnResult(Bool, \"bool\"),\n",
      "                     [FnArg(:ptr1, Ptr{StdSharedPtr{T}}, \"ptr1\", \"const std::shared_ptr<$CT> * restrict\", StdSharedPtr{T},\n",
      "                            identity),\n",
      "                      FnArg(:ptr2, Ptr{StdSharedPtr{T}}, \"ptr2\", \"const std::shared_ptr<$CT> * restrict\", StdSharedPtr{T},\n",
      "                            identity)], \"return *ptr1 == *ptr2;\"))\n",
      "\n",
      "    eval(cxxfunction(FnName(:make_shared, \"std_make_shared_$(NT)\", libSTL),\n",
      "                     FnResult(Ptr{StdSharedPtr{T}}, \"std::shared_ptr<$CT> *\", StdSharedPtr{T}, expr -> :(StdSharedPtr{$T}($expr))),\n",
      "                     [FnArg(:type, Nothing, \"type\", \"void\", Type{T}, identity; skip=true),\n",
      "                      FnArg(:val, Ptr{T}, \"val\", \"$CT const *\", Any, expr -> :(convert_arg(Ptr{$T}, convert($T, $expr))))],\n",
      "                     \"\"\"\n",
      "                     auto valptr = std::make_shared<$CT>(*val);\n",
      "                     auto ptr = new std::shared_ptr<$CT>;\n",
      "                     ptr->swap(valptr);\n",
      "                     return ptr;\n",
      "                     \"\"\"))\n",
      "\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "const StdSharedPtr_types = value_types\n",
      "for T in sort!(collect(StdSharedPtr_types); by=string)\n",
      "    generate(StdSharedPtr{T})\n",
      "end\n",
      "\n",
      "export use_count\n",
      "export make_shared\n",
      "\n",
      "free(ptr::StdSharedPtr) = StdSharedPtr_delete(ptr)\n",
      "\n",
      "Base.eltype(::StdSharedPtr{T}) where {T} = T\n",
      "\n",
      "################################################################################\n",
      "\n",
      "GCStdSharedPtr{T}() where {T} = GCStdSharedPtr{T}(StdSharedPtr{T}())\n",
      "\n",
      "free(ptr::GCStdSharedPtr) = free(vec.managed)\n",
      "\n",
      "Base.empty(ptr::GCStdSharedPtr) = empty!(ptr.managed)\n",
      "Base.isempty(ptr::GCStdSharedPtr) = isempty(ptr.managed)\n",
      "Base.getindex(ptr::GCStdSharedPtr) = getindex(ptr.managed)\n",
      "Base.setindex!(ptr::GCStdSharedPtr, val) = setindex!(ptr.managed, val)\n",
      "Base.eltype(::GCStdSharedPtr{T}) where {T} = eltype(StdSharedPtr{T})\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  87\n",
      "HenriDeh/ReinforcementLearning.jl\n",
      "src/ReinforcementLearningDatasets/src/deep_ope/d4rl/evaluate.jl\n",
      "########################################\n",
      "\n",
      "export deep_ope_d4rl_evaluate\n",
      "\n",
      "using ReinforcementLearningBase\n",
      "using ReinforcementLearningEnvironments\n",
      "using PyCall\n",
      "using UnicodePlots\n",
      "using Random\n",
      "using ProgressMeter\n",
      "\n",
      "\"\"\"\n",
      "    deep_ope_d4rl_evaluate(env_name, agent, epoch; <keyword arguments>)\n",
      "\n",
      "Return the `UnicodePlot` for the `env_name`, `agent`, `epoch` that is given. Provide `gym_env_name` for specifying the environment explicitly.\n",
      "`γ` is the discount factor which defaults to 1. Seed of the env can be provided in `env_seed`. \n",
      "\"\"\"\n",
      "function deep_ope_d4rl_evaluate(\n",
      "    env_name::String,\n",
      "    agent::String,\n",
      "    epoch::Int;\n",
      "    gym_env_name::Union{String, Nothing}=nothing,\n",
      "    rng::AbstractRNG=MersenneTwister(123),\n",
      "    num_evaluations::Int=10,\n",
      "    γ::Float64=1.0,\n",
      "    noisy::Bool=false,\n",
      "    env_seed::Union{Int, Nothing}=nothing\n",
      ")   \n",
      "    policy_folder = \"$(env_name)_$(agent)_$(epoch)\"\n",
      "\n",
      "    if gym_env_name === nothing\n",
      "        for policy in D4RL_POLICIES\n",
      "            policy_file = split(policy[\"policy_path\"], \"/\")[end]\n",
      "            if chop(policy_file, head=0, tail=4) == policy_folder\n",
      "                gym_env_name = policy[\"task.task_names\"][1]\n",
      "                break\n",
      "            end\n",
      "        end\n",
      "\n",
      "        if gym_env_name === nothing error(\"invalid parameters\") end\n",
      "    end\n",
      "\n",
      "    env = GymEnv(gym_env_name; seed=env_seed)\n",
      "\n",
      "    model = d4rl_policy(env_name, agent, epoch)\n",
      "    scores = Vector{Float64}(undef, num_evaluations)\n",
      "\n",
      "    @showprogress for eval in 1:num_evaluations\n",
      "        score = 0\n",
      "        reset!(env)\n",
      "        while !is_terminated(env)\n",
      "            s = state(env)\n",
      "            a = model(s;rng=rng, noisy=noisy)[1]\n",
      "            s, a , env(a)\n",
      "            r = reward(env)\n",
      "            t = is_terminated(env)\n",
      "            score += r*γ*(1-t)\n",
      "        end\n",
      "        scores[eval] = score\n",
      "    end\n",
      "    plt = lineplot(1:length(scores), scores, title = \"$(gym_env_name) scores\", name = \"scores\", xlabel = \"episode\", canvas = DotCanvas, ylabel = \"score\", border=:ascii)\n",
      "    plt\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  88\n",
      "stephenneuendorffer/brutus\n",
      "Brutus/src/init.jl\n",
      "########################################\n",
      "\n",
      "const GLOBAL_CI_CACHE = GPUCompiler.CodeCache()\n",
      "\n",
      "function __init__()\n",
      "    ccall((:brutus_init, \"libbrutus\"), Cvoid, (Any,), @__MODULE__)\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  89\n",
      "UnofficialJuliaMirror/ApproxFunBase.jl-fbd15aa5-315a-5a7d-a8a4-24992e37be05\n",
      "src/Operators/functionals/CalculusFunctional.jl\n",
      "########################################\n",
      "\n",
      "export DefiniteIntegral,DefiniteLineIntegral\n",
      "\n",
      "abstract type CalculusFunctional{S,T} <: Operator{T} end\n",
      "\n",
      "@functional CalculusFunctional\n",
      "\n",
      "##TODO: Add ConcreteOp\n",
      "\n",
      "macro calculus_functional(Op)\n",
      "    ConcOp=Meta.parse(\"Concrete\"*string(Op))\n",
      "    WrappOp=Meta.parse(string(Op)*\"Wrapper\")\n",
      "    return esc(quote\n",
      "        abstract type $Op{SSS,TTT} <: CalculusFunctional{SSS,TTT} end\n",
      "        struct $ConcOp{S,T} <: $Op{S,T}\n",
      "            domainspace::S\n",
      "        end\n",
      "        struct $WrappOp{BT<:Operator,S<:Space,T} <: $Op{S,T}\n",
      "            op::BT\n",
      "        end\n",
      "\n",
      "        @wrapper $WrappOp\n",
      "\n",
      "\n",
      "        # We expect the operator to be real/complex if the basis is real/complex\n",
      "        $ConcOp(dsp::Space) = $ConcOp{typeof(dsp),prectype(dsp)}(dsp)\n",
      "\n",
      "        $Op() = $Op(UnsetSpace())\n",
      "        $Op(dsp) = $ConcOp(dsp)\n",
      "        $Op(d::Domain) = $Op(Space(d))\n",
      "\n",
      "        ApproxFunBase.promotedomainspace(::$Op,sp::Space) = $Op(sp)\n",
      "\n",
      "\n",
      "        Base.convert(::Type{Operator{T}},Σ::$ConcOp) where {T} =\n",
      "            (T==eltype(Σ) ? Σ : $ConcOp{typeof(Σ.domainspace),T}(Σ.domainspace))::Operator{T}\n",
      "\n",
      "        ApproxFunBase.domain(Σ::$ConcOp) = domain(Σ.domainspace)\n",
      "        ApproxFunBase.domainspace(Σ::$ConcOp) = Σ.domainspace\n",
      "\n",
      "        Base.getindex(::$ConcOp{UnsetSpace},kr::AbstractRange) =\n",
      "            error(\"Spaces cannot be inferred for operator\")\n",
      "\n",
      "        $WrappOp(op::Operator) =\n",
      "            $WrappOp{typeof(op),typeof(domainspace(op)),eltype(op)}(op)\n",
      "\n",
      "\n",
      "        Base.convert(::Type{Operator{T}},Σ::$WrappOp) where {T} =\n",
      "            (T==eltype(Σ) ? Σ : $WrappOp(convert(Operator{T},Σ.op)))::Operator{T}\n",
      "    end)\n",
      "end\n",
      "\n",
      "@calculus_functional(DefiniteIntegral)\n",
      "@calculus_functional(DefiniteLineIntegral)\n",
      "\n",
      "\n",
      "#default implementation\n",
      "\n",
      "DefiniteIntegral(sp::UnsetSpace) = ConcreteDefiniteIntegral(sp)\n",
      "DefiniteLineIntegral(sp::UnsetSpace) = ConcreteDefiniteLineIntegral(sp)\n",
      "\n",
      "function DefiniteIntegral(sp::Space)\n",
      "    if typeof(canonicaldomain(sp)) == typeof(domain(sp))\n",
      "        # try using `Integral`\n",
      "        Q = Integral(sp)\n",
      "        rsp = rangespace(Q)\n",
      "        DefiniteIntegralWrapper((Evaluation(rsp,rightendpoint)-Evaluation(rsp,leftendpoint))*Q)\n",
      "    else\n",
      "        # try mapping to canonical domain\n",
      "        M = Multiplication(fromcanonicalD(sp),setcanonicaldomain(sp))\n",
      "        Op = DefiniteIntegral(rangespace(M))*M\n",
      "        DefiniteIntegralWrapper(SpaceOperator(Op,sp,rangespace(Op)))\n",
      "    end\n",
      "end\n",
      "\n",
      "function DefiniteLineIntegral(sp::Space)\n",
      "    if typeof(canonicaldomain(sp)) == typeof(domain(sp))\n",
      "        error(\"Override DefiniteLineIntegral for $sp\")\n",
      "    end\n",
      "\n",
      "    M = Multiplication(abs(fromcanonicalD(sp)),setcanonicaldomain(sp))\n",
      "    Op = DefiniteLineIntegral(rangespace(M))*M\n",
      "    DefiniteLineIntegralWrapper(SpaceOperator(Op,sp,rangespace(Op)))\n",
      "end\n",
      "\n",
      "\n",
      "#TODO: Remove SPECIALOPS reimplement\n",
      "# *{T,D<:DefiniteIntegral,M<:Multiplication}(A::TimesFunctional{T,D,M},b::Fun) = bilinearform(A.op.f,b)\n",
      "# *{T,D<:DefiniteLineIntegral,M<:Multiplication}(A::TimesFunctional{T,D,M},b::Fun) = linebilinearform(A.op.f,b)\n",
      "# *{T,D<:Union{DefiniteIntegral,DefiniteLineIntegral},\n",
      "#   M<:Multiplication,V}(A::FunctionalOperator{TimesFunctional{T,D,M},V},b::Fun) =\n",
      "#     Fun(A.op*b)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  90\n",
      "jbrea/GaussianProcesses.jl\n",
      "src/GPEelastic.jl\n",
      "########################################\n",
      "\n",
      "import Base.append!\n",
      "append!(gp, x::VecF64, y::Float64) = append!(gp, reshape(x, :, 1), [y])\n",
      "function append!(gp::GPE{X,Y,M,K,P,D}, x::MatF64, y::VecF64) where {X,Y,M,K,P <: ElasticPDMat, D}\n",
      "    size(x, 2) == length(y) || error(\"$(size(x, 2)) observations, but $(length(y)) targets.\")\n",
      "    newcov = [cov(gp.kernel, gp.x, x); cov(gp.kernel, x, x) + (exp(2*gp.logNoise) + 1e-5)*I]\n",
      "    append!(gp.data, gp.kernel, gp.x, x)\n",
      "    append!(gp.x, x)\n",
      "    append!(gp.cK, newcov)\n",
      "    gp.nobs += length(y)\n",
      "    append!(gp.y, y)\n",
      "    update_target!(gp, kern = false, noise = false)\n",
      "end\n",
      "\n",
      "wrap_cK(cK::ElasticPDMat, Σbuffer, chol) = cK\n",
      "mat(cK::ElasticPDMat) = view(cK.mat)\n",
      "cholfactors(cK::ElasticPDMat) = view(cK.chol).factors\n",
      "\n",
      "function ElasticGPE(dim; mean::Mean = MeanZero(), kernel = SE(0.0, 0.0),\n",
      "                    logNoise::Float64 = -2.0, kwargs...)\n",
      "    x = ElasticArray(Array{Float64}(undef, dim, 0))\n",
      "    y = ElasticArray(Array{Float64}(undef, 0))\n",
      "    ElasticGPE(x, y, mean, kernel, logNoise; kwargs...)\n",
      "end\n",
      "function ElasticGPE(x::MatF64, y::VecF64, mean::Mean, kernel::Kernel, \n",
      "                    logNoise::Float64 = -2.0;\n",
      "                    capacity = 10^3, stepsize = 10^3)\n",
      "    data = ElasticKernelData(kernel, x, capacity = capacity, stepsize = stepsize)\n",
      "    N = length(y)\n",
      "    gp = GPE(ElasticArray(x), ElasticArray(y), mean, kernel, data, \n",
      "             ElasticPDMat(Σ_default(x, kernel, data, logNoise), \n",
      "                          capacity = capacity, stepsize = stepsize), \n",
      "             logNoise)\n",
      "    initialise_target!(gp)\n",
      "end\n",
      "export ElasticGPE\n",
      "\n",
      "function prepareappend!(kd, Xnew)\n",
      "    dim, nobs_new = size(Xnew)\n",
      "    nobs = kd.dims[1]\n",
      "    if nobs + nobs_new > kd.capacity[1] \n",
      "        kd.capacity = kd.capacity .+ kd.stepsize\n",
      "        ElasticPDMats.resize!(kd)\n",
      "    end\n",
      "    kd, dim, nobs, nobs_new\n",
      "end\n",
      "\n",
      "function ElasticKernelData(k::Isotropic, X::MatF64; capacity = 10^3, stepsize = 10^3)\n",
      "    kerneldata = IsotropicData(AllElasticArray(2; capacity = (capacity, capacity), stepsize = (stepsize, stepsize)))\n",
      "    nobs = size(X, 2)\n",
      "    distance!(view(kerneldata.R, 1:nobs, 1:nobs), k, X)\n",
      "    setdimension!(kerneldata.R, nobs, 1:2)\n",
      "    kerneldata\n",
      "end\n",
      "function append!(kerneldata::IsotropicData{<:AllElasticArray}, k::Isotropic, X::MatF64, Xnew::MatF64)\n",
      "    kd, dim, nobs, nobs_new = prepareappend!(kerneldata.R, Xnew)\n",
      "    distance!(view(kd, 1:nobs, nobs + 1:nobs + nobs_new), k, X, Xnew)\n",
      "    copyto!(view(kd, nobs + 1:nobs + nobs_new, 1:nobs), transpose(view(kd, 1:nobs, nobs + 1:nobs + nobs_new))) \n",
      "    distance!(view(kd, nobs + 1:nobs + nobs_new, nobs + 1:nobs + nobs_new), k, Xnew)\n",
      "    setdimension!(kd, nobs + nobs_new, 1:2)\n",
      "    kerneldata\n",
      "end\n",
      "append!(kerneldata, k, X, Xnew::VecF64) = append!(kerneldata, k, X, reshape(Xnew, :, 1))\n",
      "\n",
      "function ElasticKernelData(k::StationaryARD, X::MatF64; capacity = 10^3, stepsize = 10^3)\n",
      "    dim, nobs = size(X)\n",
      "    dist_stack = AllElasticArray(3; capacity = (capacity, capacity, size(X, 1)),\n",
      "                                    stepsize = (stepsize, stepsize, 0))\n",
      "    for d in 1:dim\n",
      "        grad_ls = view(dist_stack, 1:nobs, 1:nobs, d)\n",
      "        distance!(grad_ls, SqEuclidean(), view(X, d:d, :))\n",
      "    end\n",
      "    setdimension!(dist_stack, nobs, 1:2)\n",
      "    setdimension!(dist_stack, dim, 3)\n",
      "    StationaryARDData(dist_stack)\n",
      "end\n",
      "function append!(kerneldata::StationaryARDData, kernel::StationaryARD, X::MatF64, Xnew::MatF64)\n",
      "    kd, dim, nobs, nobs_new = prepareappend!(kerneldata.dist_stack, Xnew)\n",
      "    for d in 1:dim\n",
      "        grad_ls = view(kd, 1:nobs, nobs + 1:nobs + nobs_new, d)\n",
      "        distance!(grad_ls, SqEuclidean(), view(X, d:d, :), view(Xnew, d:d, :))\n",
      "        copyto!(view(kd, nobs + 1:nobs + nobs_new, 1:nobs, d),\n",
      "                transpose(grad_ls))\n",
      "        distance!(view(kd, nobs + 1:nobs + nobs_new, \n",
      "                       nobs + 1:nobs + nobs_new, d), SqEuclidean(), view(Xnew, d:d, :))\n",
      "    end\n",
      "    setdimension!(kd, nobs + nobs_new, 1:2)\n",
      "    kerneldata\n",
      "end\n",
      "\n",
      "function ElasticKernelData(k::LinArd, X::MatF64; capacity = 10^3, stepsize = 10^3)\n",
      "    dim, nobs = size(X)\n",
      "    XtX_d = AllElasticArray(3; capacity = (capacity, capacity, size(X, 1)),\n",
      "                                    stepsize = (stepsize, stepsize, 0))\n",
      "    @inbounds @simd for d in 1:dim\n",
      "        for i in 1:nobs\n",
      "            for j in 1:i\n",
      "                XtX_d[i, j, d] = XtX_d[j, i, d] = X[d, i] * X[d, j]\n",
      "            end\n",
      "        end\n",
      "    end\n",
      "    setdimension!(XtX_d, nobs, 1:2)\n",
      "    setdimension!(XtX_d, dim, 3)\n",
      "    LinArdData(XtX_d)\n",
      "end\n",
      "function append!(kerneldata::LinArdData, kernel::LinArd, X::MatF64, Xnew::MatF64)\n",
      "    kd, dim, nobs, nobs_new = prepareappend!(kerneldata.XtX_d, Xnew)\n",
      "    @inbounds @simd for d in 1:dim\n",
      "        for i in 1:nobs\n",
      "            for j in 1:nobs_new\n",
      "                kd[i, nobs + j, d] = kd[nobs + j, i, d] = X[d, i] * Xnew[d, j]\n",
      "            end\n",
      "        end\n",
      "        for i in 1:nobs_new\n",
      "            for j in 1:i\n",
      "                kd[nobs + i, nobs + j, d] = kd[nobs + j, nobs + i, d] = Xnew[d, i] * Xnew[d, j]\n",
      "            end\n",
      "        end\n",
      "    end\n",
      "    setdimension!(kd, nobs + nobs_new, 1:2)\n",
      "    kerneldata\n",
      "end\n",
      "\n",
      "function ElasticKernelData(k::LinIso, X::MatF64; capacity = 10^3, stepsize = 10^3)\n",
      "    dim, nobs = size(X)\n",
      "    XtX = AllElasticArray(2, capacity = (capacity, capacity), stepsize = (stepsize, stepsize))\n",
      "    @inbounds @simd for d in 1:dim\n",
      "        for i in 1:nobs\n",
      "            for j in 1:i\n",
      "                XtX[i, j] = XtX[j, i] += X[d, i] * X[d, j]\n",
      "            end\n",
      "        end\n",
      "    end\n",
      "    setdimension!(XtX, nobs, 1:2)\n",
      "    LinIsoData(XtX)\n",
      "end\n",
      "function append!(kerneldata::LinIsoData, kernel::LinIso, X::MatF64, Xnew::MatF64)\n",
      "    kd, dim, nobs, nobs_new = prepareappend!(kerneldata.XtX, Xnew)\n",
      "    @inbounds @simd for d in 1:dim\n",
      "        for i in 1:nobs\n",
      "            for j in 1:nobs_new\n",
      "                kd[i, j + nobs] = kd[j + nobs, i] += X[d, i] * Xnew[d, j]\n",
      "            end\n",
      "        end\n",
      "        for i in 1:nobs_new\n",
      "            for j in 1:i\n",
      "                kd[i + nobs, j + nobs] = kd[j + nobs, i + nobs] += Xnew[d, i] * Xnew[d, j]\n",
      "            end\n",
      "        end\n",
      "    end\n",
      "    setdimension!(kd, nobs + nobs_new, 1:2)\n",
      "    kerneldata\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  91\n",
      "USEPA/IO-Model-Builder\n",
      "doc/lc_stages_example.jl\n",
      "########################################\n",
      "\n",
      "######### gradle-to-gate calculation\n",
      "\n",
      "# the direct requirements coefficients\n",
      "A = [0.4  0.2  0.1 ;  # 1/Manufacturing/US\n",
      "     0.2  0.1  0.1 ;  # 2/Transport/US\n",
      "     0.3  0.3  0.2 ]  # 3/Energy/US\n",
      "\n",
      "# the satellite table\n",
      "B = [2.0  0.5  1]     # CO2\n",
      "\n",
      "# the demand vector\n",
      "f = [200.0 ;\n",
      "       0.0 ;\n",
      "      50.0 ]\n",
      "\n",
      "# the scaling vector\n",
      "I = eye(size(A)[1])\n",
      "s = (I - A) \\ f\n",
      "\n",
      "# the total LCI result\n",
      "g = B * s  # 1163.27 kg CO2\n",
      "\n",
      "# the direct contribution results\n",
      "G = B * diagm(s)   # [836.735  61.2245  265.306]  kg CO2\n",
      "\n",
      "\n",
      "######### additional requirements in the distribution phase\n",
      "\n",
      "# additional requirements matrix of the distribution phase\n",
      "K = [ 0.0  0.0  0.0 ;  # 1/Manufacturing/US\n",
      "      0.3  0.0  0.1 ;  # 2/Transport/US\n",
      "      0.0  0.0  0.0 ]  # 3/Energy/US\n",
      "\n",
      "# demand vector of the distribution phase\n",
      "fd = K * f  # [0.0  65.0  0.0]'\n",
      "\n",
      "# the scaling vector of the distribution phase\n",
      "sd = (I - A) \\ fd\n",
      "\n",
      "# the total LCI result of the distribution phase\n",
      "gd = B * sd  # 160.131 kg CO2\n",
      "\n",
      "# the direct contribution results of the distribution phase\n",
      "Gd = B * diagm(sd)   # [72.0117  42.6385  45.481]  kg CO2\n",
      "\n",
      "\n",
      "######### additional emissions in the distribution phase\n",
      "\n",
      "Bd = [ 0.0  0.0  5.0]  # kg CO2\n",
      "\n",
      "gd2 = Bd * f   # 250.0 kg CO2\n",
      "\n",
      "Gd2 = Bd * diagm(f)  # [0.0  0.0  250.0] kg CO2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  92\n",
      "lassepe/Meshes.jl\n",
      "test/sampling.jl\n",
      "########################################\n",
      "\n",
      "@testset \"Sampling\" begin\n",
      "  @testset \"RegularSampling\" begin\n",
      "    b = Box(P2(0, 0), P2(2, 2))\n",
      "    ps = sample(b, RegularSampling(3))\n",
      "    @test collect(ps) == P2[(0,0),(1,0),(2,0),(0,1),(1,1),(2,1),(0,2),(1,2),(2,2)]\n",
      "    ps = sample(b, RegularSampling(2, 3))\n",
      "    @test collect(ps) == P2[(0,0),(2,0),(0,1),(2,1),(0,2),(2,2)]\n",
      "\n",
      "    s = Sphere(P2(0, 0), T(2))\n",
      "    ps = sample(s, RegularSampling(4))\n",
      "    ts = P2[(2,0),(0,2),(-2,0),(0,-2)]\n",
      "    for (p, t) in zip(ps, ts)\n",
      "      @test p ≈ t\n",
      "    end\n",
      "\n",
      "    s = Sphere(P3(0, 0, 0), T(2))\n",
      "    ps = sample(s, RegularSampling(2,2))\n",
      "    ts = P3[(1.7320508075688772, 0.0, 1.0),\n",
      "            (1.7320508075688772, 0.0, -1.0),\n",
      "            (-1.7320508075688772, 0.0, 1.0),\n",
      "            (-1.7320508075688772, 0.0, -1.0)]\n",
      "    for (p, t) in zip(ps, ts)\n",
      "      @test p ≈ t\n",
      "    end\n",
      "\n",
      "    b = Ball(P2(0, 0), T(2))\n",
      "    ps = sample(b, RegularSampling(4,3))\n",
      "    ts = P2[(1.0, 0.0), (0.0, 1.0), (-1.0, 0.0), (0.0, -1.0),\n",
      "            (1.5, 0.0), (0.0, 1.5), (-1.5, 0.0), (0.0, -1.5),\n",
      "            (2.0, 0.0), (0.0, 2.0), (-2.0, 0.0), (0.0, -2.0)]\n",
      "    for (p, t) in zip(ps, ts)\n",
      "      @test p ≈ t\n",
      "    end\n",
      "\n",
      "    b = Ball(P3(0, 0, 0), T(2))\n",
      "    ps = sample(b, RegularSampling(3,2,3))\n",
      "    ts = P3[(0.7071067811865475, 0.0, 0.7071067811865476),\n",
      "            (1.0, 0.0, 6.123233995736766e-17),\n",
      "            (0.7071067811865476, 0.0, -0.7071067811865475),\n",
      "            (-0.7071067811865475, 8.659560562354932e-17, 0.7071067811865476),\n",
      "            (-1.0, 1.2246467991473532e-16, 6.123233995736766e-17),\n",
      "            (-0.7071067811865476, 8.659560562354934e-17, -0.7071067811865475),\n",
      "            (1.0606601717798212, 0.0, 1.0606601717798214),\n",
      "            (1.5, 0.0, 9.184850993605148e-17),\n",
      "            (1.0606601717798214, 0.0, -1.0606601717798212),\n",
      "            (-1.0606601717798212, 1.2989340843532398e-16, 1.0606601717798214),\n",
      "            (-1.5, 1.8369701987210297e-16, 9.184850993605148e-17),\n",
      "            (-1.0606601717798214, 1.29893408435324e-16, -1.0606601717798212),\n",
      "            (1.414213562373095, 0.0, 1.4142135623730951),\n",
      "            (2.0, 0.0, 1.2246467991473532e-16),\n",
      "            (1.4142135623730951, 0.0, -1.414213562373095),\n",
      "            (-1.414213562373095, 1.7319121124709863e-16, 1.4142135623730951),\n",
      "            (-2.0, 2.4492935982947064e-16, 1.2246467991473532e-16),\n",
      "            (-1.4142135623730951, 1.7319121124709868e-16, -1.414213562373095)]\n",
      "    for (p, t) in zip(ps, ts)\n",
      "      @test p ≈ t\n",
      "    end\n",
      "  end\n",
      "\n",
      "  @testset \"UniformSampling\" begin\n",
      "    Random.seed!(2021)\n",
      "    d = CartesianGrid{T}(100,100)\n",
      "    s = sample(d, UniformSampling(100))\n",
      "    μ = mean(coordinates.([centroid(s, i) for i in 1:nelements(s)]))\n",
      "    @test nelements(s) == 100\n",
      "    @test isapprox(μ, T[50.,50.], atol=T(10))\n",
      "  end\n",
      "\n",
      "  @testset \"WeightedSampling\" begin\n",
      "    # uniform weights => uniform sampler\n",
      "    Random.seed!(2020)\n",
      "    d = CartesianGrid{T}(100,100)\n",
      "    s = sample(d, WeightedSampling(100))\n",
      "    μ = mean(coordinates.([centroid(s, i) for i in 1:nelements(s)]))\n",
      "    @test nelements(s) == 100\n",
      "    @test isapprox(μ, T[50.,50.], atol=T(10))\n",
      "  end\n",
      "\n",
      "  @testset \"BallSampling\" begin\n",
      "    d = CartesianGrid{T}(100,100)\n",
      "    s = sample(d, BallSampling(T(10)))\n",
      "    n = nelements(s)\n",
      "    x = coordinates(centroid(s, 1))\n",
      "    y = coordinates(centroid(s, 17))\n",
      "    @test n < 100\n",
      "    @test sqrt(sum((x - y).^2)) ≥ T(10)\n",
      "\n",
      "    d = CartesianGrid{T}(100,100)\n",
      "    s = sample(d, BallSampling(T(20)))\n",
      "    n = nelements(s)\n",
      "    x = coordinates(centroid(s, 1))\n",
      "    y = coordinates(centroid(s, 17))\n",
      "    @test n < 50\n",
      "    @test sqrt(sum((x - y).^2)) ≥ T(20)\n",
      "  end\n",
      "\n",
      "  @testset \"Utilities\" begin\n",
      "    # uniform sampling\n",
      "    d = CartesianGrid{T}(10,10)\n",
      "    s = sample(d, 50)\n",
      "    @test nelements(s) == 50\n",
      "    @test s[1] isa Quadrangle\n",
      "\n",
      "    # weighted sampling\n",
      "    d = CartesianGrid{T}(10,10,10)\n",
      "    s = sample(d, 100, rand([1,2], 1000))\n",
      "    @test nelements(s) == 100\n",
      "    @test s[1] isa Hexahedron\n",
      "  end\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  93\n",
      "Smolkaa/ComsolUtils.jl\n",
      "src/_archived/parse_dset.jl\n",
      "########################################\n",
      "\n",
      "## PARSE_DSET\n",
      "#\n",
      "# Log:\n",
      "# 11.05.2021 - Created function [1]\n",
      "#\n",
      "# Authors:\n",
      "# [1] Alexander Smolka (alexander.smolka@tum.de)\n",
      "\n",
      "\"\"\"\n",
      "    parse_dset(raw::CDataRaw)\n",
      "    parse_dset(path::String)\n",
      "\n",
      "!!! note \"COMSOL Version\"\n",
      "    5.3.0.223\n",
      "\n",
      "!!! note \"Julia Version\"\n",
      "    1.6.0\n",
      "\"\"\"\n",
      "function parse_dset(raw::CDataRaw; dim=\"2Dsym\")\n",
      "    # iniate n, u, t, & v\n",
      "    n = String[]\n",
      "    u = String[]\n",
      "    t = Float64[]\n",
      "    v = Dict{String, Any}()\n",
      "\n",
      "    # parse dimension argument (get number of spatial dimensions N)\n",
      "    N, _ = _parsedim(dim)\n",
      "\n",
      "    # loop through all field variables\n",
      "    for i in N+1:length(raw.field)\n",
      "        # get name, unit and time from field string\n",
      "        name, unit, time = _readfieldall(raw.field[i])\n",
      "\n",
      "        # add vector from dictionary to correct matrix in dictionary\n",
      "        v[name] = haskey(v, name) ? hcat(v[name], raw.v[raw.field[i]]) : raw.v[raw.field[i]]\n",
      "\n",
      "        # always push the time to the vector\n",
      "        push!(t, time)\n",
      "\n",
      "        # name MUST be unique\n",
      "        if name ∈ n; continue; end\n",
      "\n",
      "        # if no repetition is happening, push variables to vectors\n",
      "        push!(n, name); push!(u, unit);\n",
      "    end\n",
      "\n",
      "    # unique + sort time vector\n",
      "    t = sort(unique(t))\n",
      "\n",
      "    # build p (position)\n",
      "    p = _parseposition(raw.v, dim)\n",
      "\n",
      "    # return result as CDataParsedDSet object\n",
      "    return CDataParsedDSet(raw.path, raw.meta, n, u, t, p, v)\n",
      "end\n",
      "parse_dset(path::String; dim=\"2Dsym\") = parse_dset(read_spreadsheet(path); dim=dim)\n",
      "\n",
      "## INTERNAL FUNCTION ======================================================== ##\n",
      "function _readfieldall(s::String)\n",
      "    # assumes no parametrix sweep\n",
      "\n",
      "    # expected format: `<name> (<unit>) @ t=<time>`\n",
      "    n, u, _, t = split(s, \" \")\n",
      "    return n, u[2:end-1], parse(Float64, t[3:end])\n",
      "end\n",
      "\n",
      "function _parseposition(v::Dict{String, Any}, dim::String)\n",
      "    if dim == \"2Dsym\"\n",
      "        return CPosition2Dsym(v[\"R\"], v[\"Z\"])\n",
      "    end\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  94\n",
      "rodin-physics/GrapheneQFT.jl\n",
      "src/computed_quantities.jl\n",
      "########################################\n",
      "\n",
      "include(\"defects.jl\")\n",
      "\"\"\"\n",
      "    δG_R(z::ComplexF64,\n",
      "     pairs::Vector{Tuple{GrapheneState,GrapheneState}},\n",
      "     s::GrapheneSystem)\n",
      "\n",
      "The correction to the real-space graphene Green's function in the presence of\n",
      "defects as a function of complex energy `z`.\n",
      "\n",
      "The function returns a vector of `ComplexF64` for each pair of\n",
      "    [`GrapheneState`](@ref)'s in `pairs`.\n",
      "\n",
      "# Arguments\n",
      "* `z`: complex energy\n",
      "* `pairs`: pairs of [`GrapheneState`](@ref)'s for which `δG_R` is calculated\n",
      "* `s`: [`GrapheneSystem`](@ref) for which `δG_R` is calculated\n",
      "\"\"\"\n",
      "function δG_R(\n",
      "    z::ComplexF64,\n",
      "    pairs::Vector{Tuple{GrapheneState,GrapheneState}},\n",
      "    s::GrapheneSystem,\n",
      ")\n",
      "    imps_len = length(s.imps)\n",
      "    scatter_len = length(s.scattering_states)\n",
      "\n",
      "    # Calculate the scattering matrix D which is the same\n",
      "    # for every pair of coordinates\n",
      "    prop_mat = propagator_matrix(z, s.scattering_states)\n",
      "    if scatter_len == 0\n",
      "        return repeat([0.0 + 0.0im], length(pairs))\n",
      "\n",
      "    elseif imps_len == 0\n",
      "        D = s.Δ * inv(Diagonal(ones(scatter_len)) .- prop_mat * s.Δ)\n",
      "\n",
      "    else\n",
      "        Γ0 = 1 ./ (z .- repeat(s.imps, 2)) |> Diagonal |> Array\n",
      "\n",
      "        D =\n",
      "            (s.Δ .+ s.V * Γ0 * adjoint(s.V)) * inv(\n",
      "                Diagonal(ones(scatter_len)) .-\n",
      "                prop_mat * (s.Δ .+ s.V * Γ0 * adjoint(s.V)),\n",
      "            )\n",
      "    end\n",
      "\n",
      "    PropVectorRs = [\n",
      "        [graphene_propagator(x, p[2], z) for x in s.scattering_states] for\n",
      "        p in pairs\n",
      "    ]\n",
      "\n",
      "    PropVectorLs = [\n",
      "        pairs[idx][1] == pairs[idx][2] ? permutedims(PropVectorRs[idx]) :\n",
      "        [\n",
      "            graphene_propagator(pairs[idx][1], x, z) for\n",
      "            x in s.scattering_states\n",
      "        ] |> permutedims for idx = 1:length(pairs)\n",
      "    ]\n",
      "\n",
      "    res = [(PropVectorLs[ii]*D*PropVectorRs[ii])[1] for ii = 1:length(pairs)]\n",
      "    return res\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    G_R(z::ComplexF64,\n",
      "    pairs::Vector{Tuple{GrapheneState,GrapheneState}},\n",
      "    s::GrapheneSystem)\n",
      "\n",
      "The full real-space graphene Green's function in the presence of\n",
      "defects as a function of complex energy `z`.\n",
      "\n",
      "# Arguments\n",
      "* `z`: complex energy\n",
      "* `pairs`: pairs of [`GrapheneState`](@ref)'s for which `G_R` is calculated\n",
      "* `s`: [`GrapheneSystem`](@ref) for which `G_R` is calculated\n",
      "\"\"\"\n",
      "function G_R(\n",
      "    z::ComplexF64,\n",
      "    pairs::Vector{Tuple{GrapheneState,GrapheneState}},\n",
      "    s::GrapheneSystem,\n",
      ")\n",
      "    res =\n",
      "        [graphene_propagator(p[1], p[2], z) for p in pairs] + δG_R(z, pairs, s)\n",
      "    return res\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    δΓ(z::ComplexF64, s::GrapheneSystem)\n",
      "\n",
      "The correction to the impurity Green's function due to the impurities'\n",
      "interaction with graphene.\n",
      "\n",
      "# Arguments\n",
      "* `z`: complex energy\n",
      "* `s`: [`GrapheneSystem`](@ref) for which `δΓ` is calculated\n",
      "\"\"\"\n",
      "function δΓ(z::ComplexF64, s::GrapheneSystem)\n",
      "    if isempty(s.imps)\n",
      "        error(\"No impurity states in the system\")\n",
      "    else\n",
      "        Γ0 = 1 ./ (z .- repeat(s.imps, 2)) |> Diagonal |> Array\n",
      "        prop_mat = propagator_matrix(z, s.scattering_states)\n",
      "\n",
      "        res =\n",
      "            Γ0 *\n",
      "            adjoint(s.V) *\n",
      "            prop_mat *\n",
      "            inv(\n",
      "                Diagonal(ones(length(s.scattering_states))) .-\n",
      "                (s.Δ .+ s.V * Γ0 * adjoint(s.V)) *\n",
      "                prop_mat\n",
      "            ) *\n",
      "            s.V *\n",
      "            Γ0\n",
      "\n",
      "        return res\n",
      "    end\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    Γ(z::ComplexF64, s::GrapheneSystem)\n",
      "\n",
      "The full impurity Green's function with the correction due to the impurities'\n",
      "interaction with graphene.\n",
      "\n",
      "# Arguments\n",
      "* `z`: complex energy\n",
      "* `s`: [`GrapheneSystem`](@ref) for which `Γ` is calculated\n",
      "\"\"\"\n",
      "function Γ(z::ComplexF64, s::GrapheneSystem)\n",
      "    if isempty(s.imps)\n",
      "        error(\"No impurity states in the system\")\n",
      "    else\n",
      "        Γ0 = 1 ./ (z .- repeat(s.imps, 2)) |> Diagonal |> Array\n",
      "        res = Γ0 + δΓ(z, s)\n",
      "    end\n",
      "    return res\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "    δρ_R_graphene(state::GrapheneState, s::GrapheneSystem)\n",
      "\n",
      "The correction to charge density in graphene induced by defects at a given\n",
      "[`GrapheneState`](@ref).\n",
      "\n",
      "# Arguments\n",
      "* `state`: [`GrapheneState`](@ref) for which `δρ_R_graphene` is calculated\n",
      "* `s`: [`GrapheneSystem`](@ref) for which `δρ_R_graphene` is calculated\n",
      "\"\"\"\n",
      "function δρ_R_graphene(state::GrapheneState, s::GrapheneSystem)\n",
      "    if s.T == 0\n",
      "        res = quadgk(\n",
      "            x -> real(δG_R(s.μ + 1im * x, [(state, state)], s)[1]),\n",
      "            0,\n",
      "            Inf,\n",
      "            rtol = 1e-2,\n",
      "        )\n",
      "\n",
      "        return (res[1] / π)::Float64\n",
      "    else\n",
      "        error(\"Finite T given\")\n",
      "    end\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  95\n",
      "tkelman/OIFITS.jl\n",
      "src/oiformat1.jl\n",
      "########################################\n",
      "\n",
      "#\n",
      "# oiformat1.jl --\n",
      "#\n",
      "# Define 1st revision of OI-FITS format.\n",
      "#\n",
      "#------------------------------------------------------------------------------\n",
      "#\n",
      "# This file is part of OIFITS.jl which is licensed under the MIT \"Expat\"\n",
      "# License:\n",
      "#\n",
      "# Copyright (C) 2015: Éric Thiébaut.\n",
      "#\n",
      "#------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "# OI-FITS FORMAT DESCRIPTION TABLES\n",
      "#\n",
      "# The format of the OI-FITS data block is described by a vector of strings\n",
      "# like:\n",
      "#\n",
      "#   [\"KEYWORD FORMAT UNITS DESCR\",\n",
      "#     ...,\n",
      "#     ...,\n",
      "#    \"---------------------------\",\n",
      "#    \"COLUMN  FORMAT UNITS DESCR\",\n",
      "#     ...,\n",
      "#     ...,\n",
      "#     ...]\n",
      "#\n",
      "# where:\n",
      "#\n",
      "#   KEYWORD = keyword for HDU header.\n",
      "#   COLUMN = column name for table (TTYPE).\n",
      "#   FORMAT = nL where n is an integer and L a letter;\n",
      "#       for keywords, 0 means optional and 1 means required;\n",
      "#       for columns, a negative number means abs(n)*NWAVE.\n",
      "#   UNITS = default units.\n",
      "#   DESCR = description/comment.\n",
      "#\n",
      "# There may be any number of keyword definitions and any number of column\n",
      "# definitions, the two parts are separated by a dash line like\n",
      "# \"--------------\".\n",
      "#\n",
      "\n",
      "# OI_TARGET definition (1st revision):\n",
      "add_def(\"OI_TARGET\", 1,\n",
      "        [\"OI_REVN    1I -      revision number of the table definition\",\n",
      "         \"------------------------------------------------------------\",\n",
      "         \"TARGET_ID  1I -      index number\",\n",
      "         \"TARGET    16A -      target name\",\n",
      "         \"RAEP0      1D deg    RA at mean equinox\",\n",
      "         \"DECEP0     1D deg    DEC at mean equinox\",\n",
      "         \"EQUINOX    1E yr     equinox\",\n",
      "         \"RA_ERR     1D deg    error in RA at mean equinox\",\n",
      "         \"DEC_ERR    1D deg    error in DEC at mean equino\",\n",
      "         \"SYSVEL     1D m/s    systemic radial velocity\",\n",
      "         \"VELTYP     8A -      reference for radial velocity\",\n",
      "         \"VELDEF     8A -      definition of radial velocity\",\n",
      "         \"PMRA       1D deg/yr proper motion in RA\",\n",
      "         \"PMDEC      1D deg/yr proper motion in DEC\",\n",
      "         \"PMRA_ERR   1D deg/yr error of proper motion in RA\",\n",
      "         \"PMDEC_ERR  1D deg/yr error of proper motion in DEC\",\n",
      "         \"PARALLAX   1E deg    parallax\",\n",
      "         \"PARA_ERR   1E deg    error in parallax\",\n",
      "         \"SPECTYP   16A -      spectral type\"])\n",
      "\n",
      "# OI_ARRAY definition (1st revision):\n",
      "add_def(\"OI_ARRAY\", 1,\n",
      "        [\"OI_REVN    1I - revision number of the table definition\",\n",
      "         \"ARRNAME    1A - array name for cross-referencing\",\n",
      "         \"FRAME      1A - coordinate frame\",\n",
      "         \"ARRAYX     1D m array center X-coordinate\",\n",
      "         \"ARRAYY     1D m array center Y-coordinate\",\n",
      "         \"ARRAYZ     1D m array center Z-coordinate\",\n",
      "         \"------------------------------------------------------------\",\n",
      "         \"TEL_NAME  16A - telescope name\",\n",
      "         \"STA_NAME  16A - station name\",\n",
      "         \"STA_INDEX  1I - station index\",\n",
      "         \"DIAMETER   1E m element diameter\",\n",
      "         \"STAXYZ     3D m station coordinates relative to array center\"])\n",
      "\n",
      "# OI_WAVELENGTH definition (1st revision):\n",
      "add_def(\"OI_WAVELENGTH\", 1,\n",
      "        [\"OI_REVN    1I - revision number of the table definition\",\n",
      "         \"INSNAME    1A - name of detector for cross-referencing\",\n",
      "         \"------------------------------------------------------------\",\n",
      "         \"EFF_WAVE   1E m effective wavelength of channel\",\n",
      "         \"EFF_BAND   1E m effective bandpass of channel\"])\n",
      "\n",
      "# OI_VIS definition (1st revision):\n",
      "add_def(\"OI_VIS\", 1,\n",
      "        [\"OI_REVN    1I -   revision number of the table definition\",\n",
      "         \"DATE-OBS   1A -   UTC start date of observations\",\n",
      "         \"ARRNAME    0A -   name of corresponding array\",\n",
      "         \"INSNAME    1A -   name of corresponding detector\",\n",
      "         \"------------------------------------------------------------\",\n",
      "         \"TARGET_ID  1I -   target number as index into OI_TARGET table\",\n",
      "         \"TIME       1D s   UTC time of observation\",\n",
      "         \"MJD        1D day modified Julian Day\",\n",
      "         \"INT_TIME   1D s   integration time\",\n",
      "         \"VISAMP    -1D -   visibility amplitude\",\n",
      "         \"VISAMPERR -1D -   error in visibility amplitude\",\n",
      "         \"VISPHI    -1D deg visibility phase\",\n",
      "         \"VISPHIERR -1D deg error in visibility phase\",\n",
      "         \"UCOORD     1D m   U coordinate of the data\",\n",
      "         \"VCOORD     1D m   V coordinate of the data\",\n",
      "         \"STA_INDEX  2I -   station numbers contributing to the data\",\n",
      "         \"FLAG      -1L -   flag\"])\n",
      "\n",
      "# OI_VIS2 definition (1st revision):\n",
      "add_def(\"OI_VIS2\", 1,\n",
      "        [\"OI_REVN    1I -   revision number of the table definition\",\n",
      "         \"DATE-OBS   1A -   UTC start date of observations\",\n",
      "         \"ARRNAME    0A -   name of corresponding array\",\n",
      "         \"INSNAME    1A -   name of corresponding detector\",\n",
      "         \"------------------------------------------------------------\",\n",
      "         \"TARGET_ID  1I -   target number as index into OI_TARGET table\",\n",
      "         \"TIME       1D s   UTC time of observation\",\n",
      "         \"MJD        1D day modified Julian Day\",\n",
      "         \"INT_TIME   1D s   integration time\",\n",
      "         \"VIS2DATA  -1D -   squared visibility\",\n",
      "         \"VIS2ERR   -1D -   error in squared visibility\",\n",
      "         \"UCOORD     1D m   U coordinate of the data\",\n",
      "         \"VCOORD     1D m   V coordinate of the data\",\n",
      "         \"STA_INDEX  2I -   station numbers contributing to the data\",\n",
      "         \"FLAG      -1L -   flag\"])\n",
      "\n",
      "# OI_T3 definition (1st revision):\n",
      "add_def(\"OI_T3\", 1,\n",
      "        [\"OI_REVN    1I -   revision number of the table definition\",\n",
      "         \"DATE-OBS   1A -   UTC start date of observations\",\n",
      "         \"ARRNAME    0A -   name of corresponding array\",\n",
      "         \"INSNAME    1A -   name of corresponding detector\",\n",
      "         \"------------------------------------------------------------\",\n",
      "         \"TARGET_ID  1I -   target number as index into OI_TARGET table\",\n",
      "         \"TIME       1D s   UTC time of observation\",\n",
      "         \"MJD        1D day modified Julian Day\",\n",
      "         \"INT_TIME   1D s   integration time\",\n",
      "         \"T3AMP     -1D -   triple product amplitude\",\n",
      "         \"T3AMPERR  -1D -   error in triple product amplitude\",\n",
      "         \"T3PHI     -1D deg triple product phase\",\n",
      "         \"T3PHIERR  -1D deg error in triple product phase\",\n",
      "         \"U1COORD    1D m   U coordinate of baseline AB of the triangle\",\n",
      "         \"V1COORD    1D m   V coordinate of baseline AB of the triangle\",\n",
      "         \"U2COORD    1D m   U coordinate of baseline BC of the triangle\",\n",
      "         \"V2COORD    1D m   V coordinate of baseline BC of the triangle\",\n",
      "         \"STA_INDEX  3I -   station numbers contributing to the data\",\n",
      "         \"FLAG      -1L -   flag\"])\n",
      "\n",
      "# OI_SPECTRUM definition (1st revision):\n",
      "add_def(\"OI_SPECTRUM\", 1,\n",
      "        [\"OI_REVN    1I -   revision number of the table definition\",\n",
      "         \"DATE-OBS   1A -   UTC start date of observations\",\n",
      "         \"INSNAME    1A -   name of corresponding detector\",\n",
      "        #\"FOV        1D -   area of sky over which flux is integrated\",\n",
      "         \"------------------------------------------------------------\",\n",
      "         \"TARGET_ID  1I -   target number as index into OI_TARGET table\",\n",
      "         \"MJD        1D day modified Julian Day\",\n",
      "         \"INT_TIME   1D s   integration time\",\n",
      "         \"FLUXDATA  -1D -   flux\",\n",
      "         \"FLUXERR   -1D -   flux error\"])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  96\n",
      "snystrom/Mycelia\n",
      "src/graph-construction.jl\n",
      "########################################\n",
      "\n",
      "\"\"\"\n",
      "$(DocStringExtensions.TYPEDSIGNATURES)\n",
      "\n",
      "A short description of the function\n",
      "\n",
      "```jldoctest\n",
      "julia> 1 + 1\n",
      "2\n",
      "```\n",
      "\"\"\"\n",
      "function construct(args)\n",
      "    @show args\n",
      "    @assert (0 < args[\"k\"] < 64) && isodd(args[\"k\"]) \n",
      "    KMER_TYPE = BioSequences.BigDNAMer{args[\"k\"]}\n",
      "    graph = fastx_to_kmer_graph(KMER_TYPE, args[\"fastx\"])\n",
      "    mkpath(dirname(args[\"out\"]))\n",
      "    if !occursin(r\"\\.jld2$\", args[\"out\"])\n",
      "        args[\"out\"] *= \".jld2\"\n",
      "    end\n",
      "    FileIO.save(args[\"out\"], Dict(\"graph\" => graph))\n",
      "end\n",
      "\n",
      "# \"\"\"\n",
      "# $(DocStringExtensions.TYPEDSIGNATURES)\n",
      "\n",
      "# A short description of the function\n",
      "\n",
      "# ```jldoctest\n",
      "# julia> 1 + 1\n",
      "# 2\n",
      "# ```\n",
      "# \"\"\"\n",
      "# function add_edge_to_graph(graph, edge_mer, kmers)\n",
      "#     edge = BioSequences.LongDNASeq(edge_mer.fw)\n",
      "#     k = length(first(kmers))\n",
      "# #     canonical_src = BioSequences.DNAMer{k}(BioSequences.canonical!(edge[1:end-1]))\n",
      "# #     canonical_dst = BioSequences.DNAMer{k}(BioSequences.canonical!(edge[2:end]))\n",
      "\n",
      "#     canonical_src = BioSequences.canonical(BioSequences.DNAMer{k}(edge[1:end-1]))\n",
      "    \n",
      "#     src_index_range = searchsorted(kmers, canonical_src)\n",
      "#     if isempty(src_index_range)\n",
      "#         return\n",
      "#     else\n",
      "#         @assert length(src_index_range) == 1\n",
      "#     end\n",
      "#     src_index = first(src_index_range)\n",
      "\n",
      "#     canonical_dst = BioSequences.canonical(BioSequences.DNAMer{k}(edge[2:end]))\n",
      "#     dst_index_range = searchsorted(kmers, canonical_dst)\n",
      "#     if isempty(dst_index_range)\n",
      "#         return\n",
      "#     else\n",
      "#         @assert length(dst_index_range) == 1\n",
      "#     end\n",
      "#     dst_index = first(dst_index_range)\n",
      "#     graph_edge = Graphs.Edge(src_index, dst_index)\n",
      "#     Graphs.add_edge!(graph, graph_edge)\n",
      "# end\n",
      "\n",
      "\"\"\"\n",
      "$(DocStringExtensions.TYPEDSIGNATURES)\n",
      "\n",
      "Create an in-memory kmer-graph that records:\n",
      "- all kmers\n",
      "- counts\n",
      "- all *observed* edges between kmers\n",
      "- edge orientations\n",
      "- edge counts\n",
      "\n",
      "```jldoctest\n",
      "julia> 1 + 1\n",
      "2\n",
      "```\n",
      "\"\"\"\n",
      "function fastx_to_kmer_graph(KMER_TYPE, fastxs::AbstractVector{<:AbstractString})\n",
      "    \n",
      "    @info \"counting kmers\"\n",
      "    @time kmer_counts = Mycelia.count_canonical_kmers(KMER_TYPE, fastxs)\n",
      "    \n",
      "    @info \"initializing graph\"\n",
      "    K = length(keys(kmer_counts))\n",
      "    k = length(first(keys(kmer_counts)))\n",
      "    # create an undirected kmer graph from the sequence\n",
      "    graph = MetaGraphs.MetaGraph(K)\n",
      "    # graph = Graphs.SimpleGraph(K)\n",
      "\n",
      "    MetaGraphs.set_prop!(graph, :kmer_counts, kmer_counts)\n",
      "    MetaGraphs.set_prop!(graph, :k, k)\n",
      "\n",
      "    @info \"adding node metadata\"\n",
      "    ProgressMeter.@showprogress for (i, (kmer, count)) in enumerate(kmer_counts)\n",
      "    #     @show i, kmer, count\n",
      "        MetaGraphs.set_prop!(graph, i, :kmer, kmer)\n",
      "        MetaGraphs.set_prop!(graph, i, :count, count)\n",
      "    end\n",
      "\n",
      "    kmers = collect(keys(kmer_counts))\n",
      "\n",
      "    # p = ProgressMeter.Progress(8452, 1)\n",
      "    # 50 minutes\n",
      "    # 40 minutes\n",
      "    # 0:09:51!\n",
      "    ProgressMeter.@showprogress for fastx in fastxs\n",
      "        n_records = count_records(fastx)\n",
      "        p = ProgressMeter.Progress(n_records, 1)\n",
      "        for record in Mycelia.open_fastx(fastx)\n",
      "            for edge_mer in BioSequences.each(BioSequences.BigDNAMer{k+1}, FASTX.sequence(record))\n",
      "#                 add_edge_to_graph(graph, edge_mer, kmers)\n",
      "                add_edge_to_simple_kmer_graph!(graph, kmers, edge_mer)\n",
      "            end\n",
      "            ProgressMeter.next!(p)\n",
      "        end\n",
      "    end\n",
      "    # allow graph[kmer, :kmer] to dict-lookup the index of a kmer\n",
      "    MetaGraphs.set_indexing_prop!(graph, :kmer)\n",
      "    return graph\n",
      "end\n",
      "\n",
      "function fastx_to_kmer_graph(KMER_TYPE, fastx::AbstractString)\n",
      "    fastx_to_kmer_graph(KMER_TYPE, [fastx])\n",
      "end\n",
      "\n",
      "\n",
      "function edgemer_to_vertex_kmers(edgemer)\n",
      "    a = BioSequences.BigDNAMer(edgemer[i] for i in 1:length(edgemer)-1)\n",
      "    b = BioSequences.BigDNAMer(edgemer[i] for i in 2:length(edgemer))\n",
      "    return a, b\n",
      "end\n",
      "\n",
      "@inline function add_edge_to_simple_kmer_graph!(simple_kmer_graph, kmers, sequence_edge)\n",
      "    observed_source_kmer, observed_destination_kmer = Mycelia.edgemer_to_vertex_kmers(sequence_edge.fw)\n",
      "    canonical_source_kmer = BioSequences.canonical(observed_source_kmer)\n",
      "    source_kmer_in_graph = !isempty(searchsorted(kmers, canonical_source_kmer))\n",
      "    if !source_kmer_in_graph\n",
      "        return\n",
      "    end\n",
      "    canonical_destination_kmer = BioSequences.canonical(observed_destination_kmer)\n",
      "    destination_kmer_in_graph = !isempty(searchsorted(kmers, canonical_destination_kmer))\n",
      "    if !destination_kmer_in_graph\n",
      "        return\n",
      "    end\n",
      "\n",
      "    oriented_source_kmer = \n",
      "        (canonical_kmer = canonical_source_kmer,\n",
      "         orientation = BioSequences.iscanonical(observed_source_kmer))\n",
      "\n",
      "    oriented_destination_kmer = \n",
      "        (canonical_kmer = canonical_destination_kmer,\n",
      "         orientation = BioSequences.iscanonical(observed_destination_kmer))\n",
      "\n",
      "    oriented_source_vertex = \n",
      "        (vertex = searchsortedfirst(kmers, oriented_source_kmer.canonical_kmer),\n",
      "         orientation = oriented_source_kmer.orientation)\n",
      "\n",
      "    oriented_destination_vertex = \n",
      "        (vertex = searchsortedfirst(kmers, oriented_destination_kmer.canonical_kmer),\n",
      "         orientation = oriented_destination_kmer.orientation)\n",
      "\n",
      "    forward_edge = Graphs.Edge(oriented_source_vertex.vertex, oriented_destination_vertex.vertex)\n",
      "    forward_edge_orientations = \n",
      "        (source_orientation = oriented_source_vertex.orientation,\n",
      "         destination_orientation = oriented_destination_vertex.orientation)\n",
      "    \n",
      "    reverse_edge = Graphs.Edge(oriented_destination_vertex.vertex, oriented_source_vertex.vertex)\n",
      "    reverse_edge_orientations = \n",
      "        (source_orientation = !oriented_destination_vertex.orientation,\n",
      "         destination_orientation = !oriented_source_vertex.orientation)\n",
      "    \n",
      "    orientations = Set([forward_edge_orientations, reverse_edge_orientations])\n",
      "    if Graphs.has_edge(simple_kmer_graph, forward_edge)\n",
      "        edge_weight = MetaGraphs.get_prop(simple_kmer_graph, forward_edge, :weight) + 1\n",
      "        orientations = union(MetaGraphs.get_prop(simple_kmer_graph, forward_edge, :orientations), orientations)\n",
      "    else\n",
      "        Graphs.add_edge!(simple_kmer_graph, forward_edge)\n",
      "        edge_weight = 1\n",
      "    end\n",
      "    MetaGraphs.set_prop!(simple_kmer_graph, forward_edge, :weight, edge_weight)\n",
      "    MetaGraphs.set_prop!(simple_kmer_graph, forward_edge, :orientations, orientations)\n",
      "end\n",
      "\n",
      "# function fastx_to_simple_kmer_graph(KMER_TYPE, fastx::AbstractString; minimum_coverage::Int=1)\n",
      "#     fastx_to_simple_kmer_graph(KMER_TYPE, [fastx], minimum_coverage=minimum_coverage)\n",
      "# end\n",
      "\n",
      "# function fastx_to_simple_kmer_graph(KMER_TYPE, fastxs::AbstractVector{<:AbstractString}; minimum_coverage::Int=1)\n",
      "#     @info \"counting kmers\"\n",
      "#     canonical_kmer_counts = Mycelia.count_canonical_kmers(KMER_TYPE, fastxs)\n",
      "#     # hard filter any nodes that are less frequent than minimum coverage threshold\n",
      "#     canonical_kmer_counts = filter(canonical_kmer_count -> last(canonical_kmer_count) >= minimum_coverage, canonical_kmer_counts)\n",
      "#     simple_kmer_graph = MetaGraphs.MetaDiGraph(length(canonical_kmer_counts))\n",
      "    \n",
      "#     k = length(first(keys(canonical_kmer_counts)))\n",
      "\n",
      "#     MetaGraphs.set_prop!(simple_kmer_graph, :k, k)\n",
      "\n",
      "#     @info \"setting metadata on vertices\"\n",
      "#     ProgressMeter.@showprogress for (vertex, (kmer, count)) in enumerate(canonical_kmer_counts)\n",
      "#         MetaGraphs.set_prop!(simple_kmer_graph, vertex, :kmer, kmer)\n",
      "#         MetaGraphs.set_prop!(simple_kmer_graph, vertex, :weight, count)\n",
      "#     end\n",
      "\n",
      "#     kmers = collect(keys(canonical_kmer_counts))\n",
      "\n",
      "#     EDGE_MER = BioSequences.BigDNAMer{k+1}\n",
      "#     @info \"loading fastx files into graph\"\n",
      "#     ProgressMeter.@showprogress for fastx in fastxs\n",
      "#         n_records = 0\n",
      "#         for record in (Mycelia.open_fastx(fastx))\n",
      "#             n_records += 1\n",
      "#         end\n",
      "#         p = ProgressMeter.Progress(n_records, 1)   # minimum update interval: 1 second\n",
      "#         for record in (Mycelia.open_fastx(fastx))\n",
      "#             sequence = FASTX.sequence(record)\n",
      "#             edge_iterator = BioSequences.each(EDGE_MER, sequence)\n",
      "#             for sequence_edge in edge_iterator\n",
      "#                 add_edge_to_simple_kmer_graph!(simple_kmer_graph, kmers, sequence_edge)\n",
      "#             end\n",
      "#             ProgressMeter.next!(p)\n",
      "#         end\n",
      "#     end\n",
      "#     return simple_kmer_graph\n",
      "# end\n",
      "\n",
      "\n",
      "\n",
      "# @inline function add_edge_to_kmer_graph!(kmer_graph, kmers, sequence_edge, record_identifier)\n",
      "#     observed_source_kmer, observed_destination_kmer = edgemer_to_vertex_kmers(sequence_edge.fw)\n",
      "\n",
      "#     oriented_source_kmer = \n",
      "#         (canonical_kmer = BioSequences.canonical(observed_source_kmer),\n",
      "#          orientation = BioSequences.iscanonical(observed_source_kmer))\n",
      "\n",
      "#     oriented_destination_kmer = \n",
      "#         (canonical_kmer = BioSequences.canonical(observed_destination_kmer),\n",
      "#          orientation = BioSequences.iscanonical(observed_destination_kmer))\n",
      "\n",
      "#     oriented_source_vertex = \n",
      "#         (vertex = searchsortedfirst(kmers, oriented_source_kmer.canonical_kmer),\n",
      "#          orientation = oriented_source_kmer.orientation)\n",
      "\n",
      "#     oriented_destination_vertex = \n",
      "#         (vertex = searchsortedfirst(kmers, oriented_destination_kmer.canonical_kmer),\n",
      "#          orientation = oriented_destination_kmer.orientation)\n",
      "\n",
      "#     source_evidence = \n",
      "#         (record = record_identifier,\n",
      "#          index = sequence_edge.position,\n",
      "#          orientation = oriented_source_vertex.orientation)\n",
      "\n",
      "#     destination_evidence = \n",
      "#         (record = record_identifier,\n",
      "#          index = sequence_edge.position + 1,\n",
      "#          orientation = oriented_destination_vertex.orientation)\n",
      "\n",
      "#     set_metadata!(kmer_graph, oriented_source_vertex.vertex, :evidence, source_evidence)\n",
      "#     new_weight = length(kmer_graph.vprops[oriented_source_vertex.vertex][:evidence])\n",
      "#     MetaGraphs.set_prop!(kmer_graph, oriented_source_vertex.vertex, :weight, new_weight)\n",
      "\n",
      "#     set_metadata!(kmer_graph, oriented_destination_vertex.vertex, :evidence, destination_evidence)\n",
      "#     new_weight = length(kmer_graph.vprops[oriented_destination_vertex.vertex][:evidence])\n",
      "#     MetaGraphs.set_prop!(kmer_graph, oriented_destination_vertex.vertex, :weight, new_weight)\n",
      "    \n",
      "\n",
      "#     forward_edge = Graphs.Edge(oriented_source_vertex.vertex, oriented_destination_vertex.vertex)\n",
      "\n",
      "#     Graphs.add_edge!(kmer_graph, forward_edge)\n",
      "\n",
      "#     forward_edge_orientations = \n",
      "#         (source_orientation = oriented_source_vertex.orientation,\n",
      "#          destination_orientation = oriented_destination_vertex.orientation)\n",
      "\n",
      "#     set_metadata!(kmer_graph, forward_edge, :orientations, forward_edge_orientations)\n",
      "\n",
      "#     forward_edge_evidence = (\n",
      "#         record = record_identifier,\n",
      "#         index = sequence_edge.position,\n",
      "#         orientation = true\n",
      "#     )\n",
      "\n",
      "#     set_metadata!(kmer_graph, forward_edge, :evidence, forward_edge_evidence)\n",
      "#     new_weight = length(kmer_graph.eprops[forward_edge][:evidence])\n",
      "#     MetaGraphs.set_prop!(kmer_graph, forward_edge, :weight, new_weight)\n",
      "\n",
      "#     reverse_edge = Graphs.Edge(oriented_destination_vertex.vertex, oriented_source_vertex.vertex)\n",
      "\n",
      "#     Graphs.add_edge!(kmer_graph, reverse_edge)\n",
      "\n",
      "#     reverse_edge_orientations = \n",
      "#         (source_orientation = !oriented_destination_vertex.orientation,\n",
      "#          destination_orientation = !oriented_source_vertex.orientation)\n",
      "\n",
      "#     set_metadata!(kmer_graph, reverse_edge, :orientations, reverse_edge_orientations)\n",
      "\n",
      "#     reverse_edge_evidence = (\n",
      "#         record = record_identifier,\n",
      "#         index = sequence_edge.position,\n",
      "#         orientation = false\n",
      "#     )\n",
      "\n",
      "#     set_metadata!(kmer_graph, reverse_edge, :evidence, reverse_edge_evidence)\n",
      "#     new_weight = length(kmer_graph.eprops[reverse_edge][:evidence])\n",
      "#     MetaGraphs.set_prop!(kmer_graph, reverse_edge, :weight, new_weight)\n",
      "# end\n",
      "\n",
      "# # function fastx_to_kmer_graph(::Type{KMER_TYPE}, fastxs) where {KMER_TYPE <: BioSequences.AbstractMer{A, K}} where {A, K}\n",
      "# function fastx_to_kmer_graph(KMER_TYPE, fastx::AbstractString)\n",
      "#     fastx_to_kmer_graph(KMER_TYPE, [fastx])\n",
      "# end\n",
      "\n",
      "# function fastx_to_kmer_graph(KMER_TYPE, fastxs::AbstractVector{<:AbstractString})\n",
      "#     @info \"assessing kmers\"\n",
      "#     kmer_counts = Mycelia.count_canonical_kmers(KMER_TYPE, fastxs)\n",
      "# #     kmer_set = Set{KMER_TYPE}()\n",
      "# #     for fastxs in fastxs\n",
      "# #         kmer_set = union!(kmer_set, collect(keys(Mycelia.count_canonical_kmers(KMER_TYPE, fastxs))))\n",
      "# #     end\n",
      "# #     kmers = unique(sort(collect(kmer_set)))\n",
      "    \n",
      "#     kmer_graph = MetaGraphs.MetaDiGraph(length(kmer_counts))\n",
      "#     k = length(first(keys(kmer_counts)))\n",
      "#     kmers = collect(keys(kmer_counts))\n",
      "#     MetaGraphs.set_prop!(kmer_graph, :k, k)\n",
      "#     # don't set this since when we filter an induced subgraph, these don't update\n",
      "# #     MetaGraphs.set_prop!(kmer_graph, :kmers, kmers)\n",
      "#     for (vertex, (kmer, count)) in enumerate(kmer_counts)\n",
      "#         MetaGraphs.set_prop!(kmer_graph, vertex, :kmer, kmer)\n",
      "#         MetaGraphs.set_prop!(kmer_graph, vertex, :weight, count)\n",
      "#     end\n",
      "#     EDGE_MER = BioSequences.BigDNAMer{k+1}\n",
      "#     @info \"creating graph\"\n",
      "#     ProgressMeter.@showprogress for fastx in fastxs\n",
      "#         fastx_io = open_fastx(fastx)\n",
      "#         for record in fastx_io\n",
      "#             sequence = FASTX.sequence(record)\n",
      "#             record_identifier = FASTX.identifier(record) \n",
      "#             edge_iterator = BioSequences.each(EDGE_MER, sequence)\n",
      "#             for sequence_edge in edge_iterator\n",
      "#                 add_edge_to_kmer_graph!(kmer_graph, kmers, sequence_edge, record_identifier)\n",
      "#             end\n",
      "#         end\n",
      "#         close(fastx_io)\n",
      "#     end\n",
      "#     return kmer_graph\n",
      "# end\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  97\n",
      "UnofficialJuliaMirrorSnapshots/ArrayFire.jl-b19378d9-d87a-599a-927f-45f220a2c452\n",
      "test/array.jl\n",
      "########################################\n",
      "\n",
      "@testset \"Array\" begin\n",
      "    @testset \"range\" begin\n",
      "        x = range(AFArray{Float32}, 1, 5)\n",
      "        @test Array(x) == Array{Float32}(collect(1.0:5.0))\n",
      "        @test typeof(x) == AFArray{Float32, 1}\n",
      "        x = range(AFArray{Float32}, 3, 5)\n",
      "        @test Array(x) == Array{Float32}(collect(3.0:7.0))\n",
      "        @test typeof(x) == AFArray{Float32, 1}\n",
      "        x = range(AFArray{Float32}, 2, 3, 10)\n",
      "        @test Array(x) == collect(2.0:3:29.0)\n",
      "        @test typeof(x) == AFArray{Float32, 1}\n",
      "\n",
      "        @test sum(@inferred iota((2,3))) == 21\n",
      "    end\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  98\n",
      "rbontekoe/AppliAR\n",
      "functions.jl\n",
      "########################################\n",
      "\n",
      "function template(t::String)\n",
      "    \"\"\"\n",
      "    <!DOCTYPE html>\n",
      "    <html lang=\"en\">\n",
      "        <head>\n",
      "            <title>BAWJ</title>\n",
      "            <meta charset=\"utf-8\">\n",
      "            <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
      "            <link rel=\"shortcut icon\" href=\"/favicon.ico\" type=\"image/x-icon\" />\n",
      "            <link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css\">\n",
      "            <script src=\"https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js\"></script>\n",
      "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js\"></script>\n",
      "            <script src=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js\"></script>\n",
      "\n",
      "            <style>\n",
      "                table, th, td {\n",
      "                    border: 1px solid black;\n",
      "                    padding: 0.5em;\n",
      "                    border-collapse: collapse;\n",
      "                }\n",
      "            </style>\n",
      "        </head>\n",
      "        <body>\n",
      "            <nav class=\"navbar navbar-expand-md bg-dark navbar-dark\">\n",
      "            <!-- Brand -->\n",
      "            <a class=\"navbar-brand\" href=\"#\">AppliGate</a>\n",
      "    \n",
      "            <!-- Toggler/collapsibe Button -->\n",
      "            <button class=\"navbar-toggler\" type=\"button\" data-toggle=\"collapse\" data-target=\"#collapsibleNavbar\">\n",
      "            <span class=\"navbar-toggler-icon\"></span>\n",
      "            </button>\n",
      "    \n",
      "            <!-- Navbar links -->\n",
      "                <div class=\"collapse navbar-collapse\" id=\"collapsibleNavbar\">\n",
      "                    <ul class=\"navbar-nav\">\n",
      "                        <li class=\"nav-item\">\n",
      "                            <a class=\"nav-link\" href=\"/\">Home</a>\n",
      "                        </li>\n",
      "                        <li class=\"nav-item\">\n",
      "                            <a class=\"nav-link\" href=\"/agingreport\">Aging Report</a>\n",
      "                        </li>\n",
      "                    </ul>\n",
      "                </div>\n",
      "            </nav>\n",
      "          \n",
      "            $(t)\n",
      "          \n",
      "        </body>\n",
      "    </html>\n",
      "    \"\"\"\n",
      "end\n",
      "\n",
      "function index(c::WebController)\n",
      "    render(HTML, template(\"<h2>Hello World!</h2>\"))\n",
      "end\n",
      "\n",
      "function aging_report(c::WebController)\n",
      "    r = @fetchfrom ar_pid report()\n",
      "    result = \n",
      "  \"\"\"\n",
      "    <h1>Aging Report</h1>\n",
      "    <table>\n",
      "    <th>Invoice</th><th>Customer</th><th>Date</th><th>Amount</th><th>Age</th>\n",
      "  \"\"\"\n",
      "    for n = 1:length(r)\n",
      "      result = result * \"\"\"\n",
      "        <tr>\n",
      "          <td>$(r[n].id_inv)</td>\n",
      "          <td>$(r[n].csm)</td><td>$(r[n].inv_date)</td>\n",
      "          <td style='text-align:right'>$(r[n].amount)</td>\n",
      "          <td>$(r[n].days)</td>\n",
      "        </tr>\"\"\"\n",
      "    end\n",
      "    result * \"</table>\"\n",
      "    render(HTML, template(\"$(result)\"))\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n",
      "STARTING EXAMPLE  99\n",
      "RXGottlieb/EAGO.jl\n",
      "src/eago_optimizer/functions/nonlinear/forward_pass.jl\n",
      "########################################\n",
      "\n",
      "# Copyright (c) 2018: Matthew Wilhelm & Matthew Stuber.\n",
      "# This code is licensed under MIT license (see LICENSE.md for full details)\n",
      "#############################################################################\n",
      "# EAGO\n",
      "# A development environment for robust and global optimization\n",
      "# See https://github.com/PSORLab/EAGO.jl\n",
      "#############################################################################\n",
      "# src/eago_optimizer/evaluator/passes.jl\n",
      "# Functions used to compute forward pass of nonlinear functions which include:\n",
      "# set_value_post, overwrite_or_intersect, forward_pass_kernel, associated blocks\n",
      "#############################################################################\n",
      "\n",
      "const FORWARD_DEBUG = false\n",
      "\n",
      "\"\"\"\n",
      "$(FUNCTIONNAME)\n",
      "\n",
      "Post process set_value operator. By default, performs the affine interval cut on\n",
      "a MC structure.\n",
      "\"\"\"\n",
      "function set_value_post(x_values::Vector{Float64}, val::MC{N,T}, lower_variable_bounds::Vector{Float64},\n",
      "                        upper_variable_bounds::Vector{Float64}, sparsity::Vector{Int},\n",
      "                        subgrad_tol::Float64) where {N, T<:RelaxTag}\n",
      "\n",
      "    lower = val.cv\n",
      "    upper = val.cc\n",
      "    lower_refinement = true\n",
      "    upper_refinement = true\n",
      "\n",
      "    for i = 1:N\n",
      "\n",
      "        cv_val = @inbounds val.cv_grad[i]\n",
      "        cc_val = @inbounds val.cc_grad[i]\n",
      "\n",
      "        i_sol = @inbounds sparsity[i]\n",
      "        x_val = @inbounds x_values[i_sol]\n",
      "        lower_bound = @inbounds lower_variable_bounds[i_sol]\n",
      "        upper_bound = @inbounds upper_variable_bounds[i_sol]\n",
      "\n",
      "        if lower_refinement\n",
      "            if cv_val > 0.0\n",
      "                if isinf(lower_bound)\n",
      "                    !upper_refinement && break\n",
      "                    lower_refinement = false\n",
      "                else\n",
      "                    lower += cv_val*(lower_bound - x_val)\n",
      "                    #delX = sub_round(lower_bound, x_val, RoundDown)\n",
      "                    #lower = add_round(lower, mul_round(cv_val, delX, RoundDown), RoundDown)\n",
      "                end\n",
      "            else\n",
      "                if isinf(upper_bound)\n",
      "                    !upper_refinement && break\n",
      "                    lower_refinement = false\n",
      "                else\n",
      "                    lower += cv_val*(upper_bound - x_val)\n",
      "                    #delX = sub_round(upper_bound, x_val, RoundUp)\n",
      "                    #lower = add_round(lower, mul_round(cv_val, delX, RoundDown), RoundDown)\n",
      "                end\n",
      "            end\n",
      "        end\n",
      "\n",
      "        if upper_refinement\n",
      "            if cc_val > 0.0\n",
      "                if isinf(lower_bound)\n",
      "                    !lower_refinement && break\n",
      "                    upper_refinement = false\n",
      "                else\n",
      "                    upper += cc_val*(upper_bound - x_val)\n",
      "                    #delX = sub_round(upper_bound, x_val, RoundUp)\n",
      "                    #upper = add_round(upper, mul_round(cc_val, delX, RoundUp), RoundUp)\n",
      "                end\n",
      "            else\n",
      "                if isinf(upper_bound)\n",
      "                    !lower_refinement && break\n",
      "                    upper_refinement = false\n",
      "                else\n",
      "                    upper += cc_val*(lower_bound - x_val)\n",
      "                    #delX = sub_round(lower_bound, x_val, RoundDown)\n",
      "                    #upper = add_round(upper, mul_round(cc_val, delX, RoundUp), RoundUp)\n",
      "                end\n",
      "            end\n",
      "        end\n",
      "    end\n",
      "\n",
      "    if lower_refinement && (val.Intv.lo + subgrad_tol > lower)\n",
      "        lower = val.Intv.lo\n",
      "    elseif !lower_refinement\n",
      "        lower = val.Intv.lo\n",
      "    else\n",
      "        lower -= subgrad_tol #sub_round(lower, subgrad_tol, RoundDown)\n",
      "    end\n",
      "\n",
      "    if upper_refinement && (val.Intv.hi - subgrad_tol < upper)\n",
      "        upper = val.Intv.hi\n",
      "    elseif !upper_refinement\n",
      "        upper = val.Intv.hi\n",
      "    else\n",
      "        upper += subgrad_tol #add_round(upper, subgrad_tol, RoundUp)\n",
      "    end\n",
      "\n",
      "    return MC{N,T}(val.cv, val.cc, Interval{Float64}(lower, upper), val.cv_grad, val.cc_grad, val.cnst)\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "$(FUNCTIONNAME)\n",
      "\n",
      "Intersects the new set valued operator with the prior and performs affine bound tightening\n",
      "\n",
      "- First forward pass: `is_post` should be set by user option, `is_intersect` should be false\n",
      "  so that the tape overwrites existing values, and the `interval_intersect` flag could be set\n",
      "  to either value.\n",
      "- Forward CP pass (assumes same reference point): `is_post` should be set by user option,\n",
      "  `is_intersect` should be true so that the tape intersects with  existing values, and the\n",
      "  `interval_intersect` flag should be false.\n",
      "- Forward CP pass (assumes same reference point): `is_post` should be set by user option,\n",
      "  `is_intersect` should be true so that the tape intersects with existing values, and the\n",
      "  `interval_intersect` flag should be false.\n",
      "- Subsequent forward passes at new points: is_post` should be set by user option,\n",
      "  `is_intersect` should be true so that the tape intersects with existing values, and the\n",
      "  `interval_intersect` flag should be `true` as predetermined interval bounds are valid but\n",
      "   the prior values may correspond to different points of evaluation.\n",
      "\"\"\"\n",
      "function overwrite_or_intersect(xMC::MC{N,T}, past_xMC::MC{N,T}, x::Vector{Float64}, lbd::Vector{Float64},\n",
      "                                ubd::Vector{Float64}, subgrad_tol::Float64, sparsity::Vector{Int}, is_post::Bool,\n",
      "                                is_intersect::Bool,\n",
      "                                interval_intersect::Bool) where {N,T<:RelaxTag}\n",
      "\n",
      "    if is_post && is_intersect && interval_intersect\n",
      "        return set_value_post(x, xMC ∩ past_xMC.Intv, lbd, ubd, sparsity, subgrad_tol)\n",
      "\n",
      "    elseif is_post && is_intersect && !interval_intersect\n",
      "        return set_value_post(x, xMC ∩ past_xMC, lbd, ubd, sparsity, subgrad_tol)\n",
      "\n",
      "    elseif is_post && !is_intersect\n",
      "        return set_value_post(x, xMC, lbd, ubd, sparsity, subgrad_tol)\n",
      "\n",
      "    elseif !is_post && is_intersect && interval_intersect\n",
      "        return xMC ∩ past_xMC.Intv\n",
      "\n",
      "    elseif !is_post && is_intersect && !interval_intersect\n",
      "        return xMC ∩ past_xMC\n",
      "\n",
      "    end\n",
      "    return xMC\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "$(FUNCTIONNAME)\n",
      "\n",
      "Updates storage tapes with forward evalution of node representing `n = x + y`.\n",
      "\"\"\"\n",
      "function forward_plus_binary!(k::Int64, children_arr::Vector{Int64}, children_idx::UnitRange{Int64},\n",
      "                              numvalued::Vector{Bool}, numberstorage::Vector{Float64}, setstorage::Vector{MC{N,T}},\n",
      "                              x::Vector{Float64}, lbd::Vector{Float64}, ubd::Vector{Float64}, subgrad_tol::Float64,\n",
      "                              sparsity::Vector{Int},\n",
      "                              is_post::Bool, is_intersect::Bool, is_first_eval::Bool, interval_intersect::Bool) where {N,T<:RelaxTag}\n",
      "\n",
      "    # get row indices\n",
      "    idx1 = first(children_idx)\n",
      "    idx2 = last(children_idx)\n",
      "\n",
      "    # extract values for argument 1\n",
      "    arg1_index =  children_arr[idx1]\n",
      "    arg1_is_number = numvalued[arg1_index]\n",
      "    if arg1_is_number\n",
      "        set1 = zero(MC{N,T})\n",
      "        num1 = numberstorage[arg1_index]\n",
      "    else\n",
      "        num1 = 0.0\n",
      "        set1 = setstorage[arg1_index]\n",
      "    end\n",
      "\n",
      "    # extract values for argument 2\n",
      "    arg2_index = children_arr[idx2]\n",
      "    arg2_is_number = numvalued[arg2_index]\n",
      "    if arg2_is_number\n",
      "        num2 = numberstorage[arg2_index]\n",
      "        set2 = zero(MC{N,T})\n",
      "    else\n",
      "        set2 = setstorage[arg2_index]\n",
      "        num2 = 0.0\n",
      "    end\n",
      "\n",
      "    output_is_number = arg1_is_number && arg2_is_number\n",
      "\n",
      "    # a + b\n",
      "    if output_is_number\n",
      "         numberstorage[k] = num1 + num2\n",
      "\n",
      "    # x + b\n",
      "    elseif !arg1_is_number && arg2_is_number\n",
      "        outset = set1 + num2\n",
      "        # is_first_eval ? (set1 + num2) : plus_kernel(set1, num2, setstorage[k].Intv)\n",
      "\n",
      "    # a + y\n",
      "    elseif arg1_is_number && !arg2_is_number\n",
      "        outset = num1 + set2\n",
      "        # is_first_eval ? (num1 + set2) : plus_kernel(num1, set2, setstorage[k].Intv)\n",
      "\n",
      "    # x + y\n",
      "    else\n",
      "        outset = set1 + set2\n",
      "        # is_first_eval ? (set1 + set2) : plus_kernel(set1, set2, setstorage[k].Intv)\n",
      "\n",
      "    end\n",
      "\n",
      "     numvalued[k] = output_is_number\n",
      "    if !output_is_number\n",
      "         setstorage[k] = overwrite_or_intersect(outset, setstorage[k], x, lbd, ubd, subgrad_tol, sparsity, false,\n",
      "                                                         is_intersect, interval_intersect)\n",
      "    end\n",
      "\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "$(FUNCTIONNAME)\n",
      "\n",
      "Updates storage tapes with forward evalution of node representing `n = +(x, y, z,...)`.\n",
      "\"\"\"\n",
      "function forward_plus_narity!(k::Int64, children_arr::Vector{Int64}, children_idx::UnitRange{Int64},\n",
      "                              numvalued::Vector{Bool}, numberstorage::Vector{Float64}, setstorage::Vector{MC{N,T}},\n",
      "                              x::Vector{Float64}, lbd::Vector{Float64}, ubd::Vector{Float64},\n",
      "                              subgrad_tol::Float64, sparsity::Vector{Int},\n",
      "                              is_post::Bool, is_intersect::Bool, interval_intersect::Bool) where {N,T<:RelaxTag}\n",
      "\n",
      "\n",
      "    # get row indices\n",
      "    idx = first(children_idx)\n",
      "\n",
      "    # extract values for argument 1\n",
      "    arg_index =  children_arr[idx]\n",
      "    output_is_number = numvalued[arg_index]\n",
      "    if output_is_number\n",
      "       tmp_set = zero(MC{N,T})\n",
      "       tmp_num = numberstorage[arg_index]\n",
      "    else\n",
      "       tmp_num = 0.0\n",
      "       tmp_set = setstorage[arg_index]\n",
      "    end\n",
      "    output_is_number = true\n",
      "\n",
      "    for idx = 2:length(children_idx)\n",
      "        cidx = children_idx[idx]\n",
      "        arg_index =  children_arr[cidx]\n",
      "        arg_is_number = numvalued[arg_index]\n",
      "        if arg_is_number\n",
      "            tmp_num += numberstorage[arg_index]\n",
      "        else\n",
      "            tmp_set += setstorage[arg_index]\n",
      "        end\n",
      "        output_is_number &= arg_is_number\n",
      "    end\n",
      "\n",
      "     numvalued[k] = output_is_number\n",
      "    if output_is_number\n",
      "         numberstorage[k] = tmp_num\n",
      "    else\n",
      "        tmp_set += tmp_num\n",
      "        setstorage[k] = overwrite_or_intersect(tmp_set, setstorage[k], x, lbd, ubd, subgrad_tol, sparsity, false, is_intersect,\n",
      "                                               interval_intersect)\n",
      "    end\n",
      "\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "$(FUNCTIONNAME)\n",
      "\n",
      "Updates storage tapes with forward evalution for node representing `n = x*y`.\n",
      "\"\"\"\n",
      "function forward_multiply_binary!(k::Int64, children_arr::Vector{Int64}, children_idx::UnitRange{Int64},\n",
      "                                  numvalued::Vector{Bool}, numberstorage::Vector{Float64}, setstorage::Vector{MC{N,T}},\n",
      "                                  x::Vector{Float64}, lbd::Vector{Float64}, ubd::Vector{Float64}, subgrad_tol::Float64,\n",
      "                                  sparsity::Vector{Int},\n",
      "                                  is_post::Bool, is_intersect::Bool, is_first_eval::Bool, interval_intersect::Bool) where {N,T<:RelaxTag}\n",
      "    # get row indices\n",
      "    idx1 = first(children_idx)\n",
      "    idx2 = last(children_idx)\n",
      "\n",
      "    # extract values for argument 1\n",
      "    arg1_index = children_arr[idx1]\n",
      "    arg1_is_number = numvalued[arg1_index]\n",
      "    if arg1_is_number\n",
      "        set1 = one(MC{N,T})\n",
      "        num1 = numberstorage[arg1_index]\n",
      "    else\n",
      "        num1 = 1.0\n",
      "        set1 = setstorage[arg1_index]\n",
      "    end\n",
      "\n",
      "    # extract values for argument 2\n",
      "    arg2_index =  children_arr[idx2]\n",
      "    arg2_is_number = numvalued[arg2_index]\n",
      "    if arg2_is_number\n",
      "        num2 = numberstorage[arg2_index]\n",
      "        set2 = one(MC{N,T})\n",
      "    else\n",
      "        set2 = setstorage[arg2_index]\n",
      "        num2 = 1.0\n",
      "    end\n",
      "\n",
      "    output_is_number = arg1_is_number && arg2_is_number\n",
      "\n",
      "    # a * b\n",
      "    if output_is_number\n",
      "         numberstorage[k] = num1 * num2\n",
      "\n",
      "    # x * b\n",
      "    elseif !arg1_is_number && arg2_is_number\n",
      "        outset = set1*num2 #is_first_eval ? (set1 * num2) : mult_kernel(set1, num2, setstorage[k].Intv)\n",
      "\n",
      "    # a * y\n",
      "    elseif arg1_is_number && !arg2_is_number\n",
      "        outset = num1*set2 #is_first_eval ? (num1 * set2) : mult_kernel(set2, num1, setstorage[k].Intv)\n",
      "\n",
      "    # x * y\n",
      "    else\n",
      "        outset = set1*set2 #is_first_eval ? (set1 * set2) : mult_kernel(set1, set2, setstorage[k].Intv)\n",
      "\n",
      "    end\n",
      "\n",
      "    numvalued[k] = output_is_number\n",
      "    if !output_is_number\n",
      "         setstorage[k] = overwrite_or_intersect(outset, setstorage[k], x, lbd, ubd, subgrad_tol, sparsity, is_post, is_intersect,\n",
      "                                                         interval_intersect)\n",
      "    end\n",
      "\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "$(FUNCTIONNAME)\n",
      "\n",
      "Updates storage tapes with forward evalution of node representing `n = *(x, y, z,...)`.\n",
      "\"\"\"\n",
      "function forward_multiply_narity!(k::Int64, children_arr::Vector{Int64}, children_idx::UnitRange{Int64},\n",
      "                                  numvalued::Vector{Bool}, numberstorage::Vector{Float64}, setstorage::Vector{MC{N,T}},\n",
      "                                  x::Vector{Float64}, lbd::Vector{Float64}, ubd::Vector{Float64}, subgrad_tol::Float64,\n",
      "                                  sparsity::Vector{Int},\n",
      "                                  is_post::Bool, is_intersect::Bool, interval_intersect::Bool) where {N,T<:RelaxTag}\n",
      "    # get row indices\n",
      "    idx = first(children_idx)\n",
      "\n",
      "    # extract values for argument 1\n",
      "    arg_index =  children_arr[idx]\n",
      "    output_is_number =  numvalued[arg_index]\n",
      "    if output_is_number\n",
      "        tmp_set = 1.0#one(MC{N,T})\n",
      "        tmp_num = numberstorage[arg_index]\n",
      "    else\n",
      "        tmp_num = 1.0\n",
      "        tmp_set = setstorage[arg_index]\n",
      "    end\n",
      "\n",
      "\n",
      "    for idx = 2:length(children_idx)\n",
      "        cidx =  children_idx[idx]\n",
      "        arg_index_t =  children_arr[cidx]\n",
      "        arg_is_number_t = numvalued[arg_index_t]\n",
      "        if arg_is_number_t\n",
      "            tmp_num = tmp_num*numberstorage[arg_index_t]\n",
      "        else\n",
      "            tmp_set = tmp_set*setstorage[arg_index_t]\n",
      "        end\n",
      "        output_is_number &= arg_is_number_t\n",
      "    end\n",
      "\n",
      "     numvalued[k] = output_is_number\n",
      "    if output_is_number\n",
      "         numberstorage[k] = tmp_num\n",
      "    else\n",
      "       tmp_set *= tmp_num\n",
      "       setstorage[k] = overwrite_or_intersect(tmp_set, setstorage[k], x, lbd, ubd, subgrad_tol, sparsity, is_post, is_intersect,\n",
      "                                              interval_intersect)\n",
      "    end\n",
      "\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "$(FUNCTIONNAME)\n",
      "\n",
      "Updates storage tapes with forward evalution for node representing `n = x-y`.\n",
      "\"\"\"\n",
      "function forward_minus!(k::Int64, children_arr::Vector{Int64}, children_idx::UnitRange{Int64},\n",
      "                        numvalued::Vector{Bool}, numberstorage::Vector{Float64}, setstorage::Vector{MC{N,T}},\n",
      "                        x::Vector{Float64}, lbd::Vector{Float64}, ubd::Vector{Float64}, subgrad_tol::Float64,\n",
      "                        sparsity::Vector{Int},\n",
      "                        is_post::Bool, is_intersect::Bool, is_first_eval::Bool, interval_intersect::Bool) where {N,T<:RelaxTag}\n",
      "\n",
      "    # get row indices\n",
      "    idx1 = first(children_idx)\n",
      "    idx2 = last(children_idx)\n",
      "\n",
      "    # extract values for argument 1\n",
      "    arg1_index = children_arr[idx1]\n",
      "    arg1_is_number = numvalued[arg1_index]\n",
      "    if arg1_is_number\n",
      "        set1 = zero(MC{N,T})\n",
      "        num1 = numberstorage[arg1_index]\n",
      "    else\n",
      "        num1 = 0.0\n",
      "        set1 = setstorage[arg1_index]\n",
      "    end\n",
      "\n",
      "    # extract values for argument 2\n",
      "    arg2_index = children_arr[idx2]\n",
      "    arg2_is_number = numvalued[arg2_index]\n",
      "    if arg2_is_number\n",
      "        num2 = numberstorage[arg2_index]\n",
      "        set2 = zero(MC{N,T})\n",
      "    else\n",
      "        set2 =  setstorage[arg2_index]\n",
      "        num2 = 0.0\n",
      "    end\n",
      "\n",
      "    output_is_number = arg1_is_number && arg2_is_number\n",
      "\n",
      "    # a - b\n",
      "    if output_is_number\n",
      "         numberstorage[k] = num1 - num2\n",
      "\n",
      "    # x - b\n",
      "    elseif !arg1_is_number && arg2_is_number\n",
      "        outset = set1 - num2 #is_first_eval ? (set1 - num2) : minus_kernel(set1, num2, setstorage[k].Intv)\n",
      "\n",
      "    # a - y\n",
      "    elseif arg1_is_number && !arg2_is_number\n",
      "        outset = num1 - set2 #is_first_eval ? (num1 - set2) : minus_kernel(num1, set2, setstorage[k].Intv)\n",
      "\n",
      "    # x - y\n",
      "    else\n",
      "        outset = set1 - set2 #is_first_eval ? (set1 - set2) : minus_kernel(set1, set2, setstorage[k].Intv)\n",
      "\n",
      "    end\n",
      "\n",
      "    numvalued[k] = output_is_number\n",
      "    if !output_is_number\n",
      "         setstorage[k] = overwrite_or_intersect(outset, setstorage[k], x, lbd, ubd, subgrad_tol, sparsity, is_post, is_intersect,\n",
      "                                                         interval_intersect)\n",
      "    end\n",
      "\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "$(FUNCTIONNAME)\n",
      "\n",
      "Updates storage tapes with forward evalution for node representing `n = x^y`.\n",
      "\"\"\"\n",
      "function forward_power!(k::Int64, children_arr::Vector{Int64}, children_idx::UnitRange{Int64},\n",
      "                        numvalued::Vector{Bool}, numberstorage::Vector{Float64}, setstorage::Vector{MC{N,T}},\n",
      "                        x::Vector{Float64}, lbd::Vector{Float64}, ubd::Vector{Float64},\n",
      "                        subgrad_tol::Float64, sparsity::Vector{Int},\n",
      "                        is_post::Bool, is_intersect::Bool, is_first_eval::Bool, interval_intersect::Bool,\n",
      "                        ctx::GuardCtx) where {N,T<:RelaxTag}\n",
      "\n",
      "    # get row indices\n",
      "    idx1 = first(children_idx)\n",
      "    idx2 = last(children_idx)\n",
      "\n",
      "    # extract values for argument 1\n",
      "    arg1_index = children_arr[idx1]\n",
      "    arg1_is_number = numvalued[arg1_index]\n",
      "    if arg1_is_number\n",
      "        set1 = zero(MC{N,T})\n",
      "        num1 =  numberstorage[arg1_index]\n",
      "    else\n",
      "        num1 = 0.0\n",
      "        set1 =  setstorage[arg1_index]\n",
      "    end\n",
      "\n",
      "    # extract values for argument 2\n",
      "    arg2_index =  children_arr[idx2]\n",
      "    arg2_is_number = numvalued[arg2_index]\n",
      "    if arg2_is_number\n",
      "        num2 = numberstorage[arg2_index]\n",
      "        set2 = zero(MC{N,T})\n",
      "    else\n",
      "        set2 = setstorage[arg2_index]\n",
      "        num2 = 0.0\n",
      "    end\n",
      "\n",
      "    # is output a number (by closure of the reals)\n",
      "    output_is_number = arg1_is_number && arg2_is_number\n",
      "    numvalued[k] = output_is_number\n",
      "\n",
      "    # x^1 = x\n",
      "    if arg2_is_number && (num2 == 1.0)\n",
      "        if arg1_is_number\n",
      "             numberstorage[k] = num1\n",
      "        else\n",
      "             setstorage[k] = set1\n",
      "        end\n",
      "        return nothing\n",
      "\n",
      "    # x^0 = 1\n",
      "    elseif arg2_is_number && (num2 == 0.0)\n",
      "        if arg1_is_number\n",
      "             numberstorage[k] = 1.0\n",
      "        else\n",
      "             setstorage[k] = zero(MC{N,T})\n",
      "        end\n",
      "        return nothing\n",
      "\n",
      "    else\n",
      "        # a^b\n",
      "        if arg1_is_number && arg2_is_number\n",
      "             numberstorage[k] = num1^num2\n",
      "\n",
      "        # x^b\n",
      "        elseif !arg1_is_number && arg2_is_number\n",
      "            outset = set1^num2\n",
      "            #is_first_eval ? pow(set1, num2) : ^(set1, num2, setstorage[k].Intv)\n",
      "\n",
      "        # a^y\n",
      "        elseif arg1_is_number  && !arg2_is_number\n",
      "            guard_on = ctx.metadata.guard_on\n",
      "            outset = guard_on ? overdub(ctx, ^, num1, set2) : num1^set2 # overdub(ctx, pow, num1, set2)\n",
      "            #is_first_eval ? overdub(ctx, pow, num1, set2) : overdub(ctx, ^, num1, set2, setstorage[k].Intv)\n",
      "\n",
      "        # x^y\n",
      "        elseif !arg1_is_number && !arg2_is_number\n",
      "            guard_on = ctx.metadata.guard_on\n",
      "            outset = guard_on ? overdub(ctx, ^, set1, set2) : set1^set2\n",
      "            #is_first_eval ? overdub(ctx, pow, set1, set2) : overdub(ctx, ^, set1, set2, setstorage[k].Intv)\n",
      "\n",
      "        end\n",
      "    end\n",
      "\n",
      "    if !output_is_number\n",
      "        setstorage[k] = overwrite_or_intersect(outset, setstorage[k], x, lbd, ubd, subgrad_tol, sparsity, is_post, is_intersect,\n",
      "                                               interval_intersect)\n",
      "    end\n",
      "\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "$(FUNCTIONNAME)\n",
      "\n",
      "Updates storage tapes with forward evalution for node representing `n = x/y`.\n",
      "\"\"\"\n",
      "function forward_divide!(k::Int64, children_arr::Vector{Int64}, children_idx::UnitRange{Int64},\n",
      "                         numvalued::Vector{Bool}, numberstorage::Vector{Float64}, setstorage::Vector{MC{N,T}},\n",
      "                         x::Vector{Float64}, lbd::Vector{Float64}, ubd::Vector{Float64}, subgrad_tol::Float64,\n",
      "                         sparsity::Vector{Int},\n",
      "                         is_post::Bool, is_intersect::Bool, is_first_eval::Bool, interval_intersect::Bool,\n",
      "                         ctx::GuardCtx) where {N,T<:RelaxTag}\n",
      "\n",
      "    # get row indices\n",
      "    idx1 = first(children_idx)\n",
      "    idx2 = last(children_idx)\n",
      "\n",
      "    # extract values for argument 1\n",
      "    arg1_index = children_arr[idx1]\n",
      "    arg1_is_number = numvalued[arg1_index]\n",
      "    if arg1_is_number\n",
      "        set1 = zero(MC{N,T})\n",
      "        num1 = numberstorage[arg1_index]\n",
      "    else\n",
      "        num1 = 0.0\n",
      "        set1 = setstorage[arg1_index]\n",
      "    end\n",
      "\n",
      "    # extract values for argument 2\n",
      "    arg2_index = children_arr[idx2]\n",
      "    arg2_is_number = numvalued[arg2_index]\n",
      "    if arg2_is_number\n",
      "        num2 = numberstorage[arg2_index]\n",
      "        set2 = zero(MC{N,T})\n",
      "    else\n",
      "        set2 = setstorage[arg2_index]\n",
      "        num2 = 0.0\n",
      "    end\n",
      "\n",
      "    # is output a number (by closure of the reals)?\n",
      "    output_is_number = arg1_is_number && arg2_is_number\n",
      "    numvalued[k] = output_is_number\n",
      "\n",
      "    # a/b\n",
      "    if output_is_number\n",
      "         numberstorage[k] = num1/num2\n",
      "\n",
      "    # x/b\n",
      "    elseif !arg1_is_number && arg2_is_number\n",
      "\n",
      "        guard_on = ctx.metadata.guard_on\n",
      "        if guard_on\n",
      "            outset = Cassette.overdub(ctx, /, set1, num2)\n",
      "        else\n",
      "            outset = set1/num2\n",
      "        end\n",
      "        # is_first_eval ? set1/num2 : div_kernel(set1, num2, setstorage[k].Intv)\n",
      "\n",
      "    # a/y\n",
      "    elseif arg1_is_number && !arg2_is_number\n",
      "\n",
      "        guard_on = ctx.metadata.guard_on\n",
      "        if guard_on\n",
      "            outset = Cassette.overdub(ctx, /, num1, set2)\n",
      "        else\n",
      "            outset = num1/set2\n",
      "        end\n",
      "        # is_first_eval ? num1/set2 : div_kernel(num1, set2, setstorage[k].Intv)\n",
      "\n",
      "    # x/y\n",
      "    else\n",
      "\n",
      "        guard_on = ctx.metadata.guard_on\n",
      "        if guard_on\n",
      "            outset = Cassette.overdub(ctx, /, set1, set2)\n",
      "        else\n",
      "            outset = set1/set2\n",
      "        end\n",
      "        # is_first_eval ? set1/set2 : div_kernel(set1, set2, setstorage[k].Intv)\n",
      "\n",
      "    end\n",
      "\n",
      "    if !output_is_number\n",
      "        setstorage[k] = overwrite_or_intersect(outset, setstorage[k], x, lbd, ubd, subgrad_tol, sparsity, is_post,\n",
      "                                               is_intersect, interval_intersect)\n",
      "    end\n",
      "\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "$(FUNCTIONNAME)\n",
      "\n",
      "Updates storage tapes with forward evalution for node representing `n = user_f(x, y...)`.\n",
      "\"\"\"\n",
      "function forward_user_multivariate!(k::Int64, op::Int64, children_arr::Vector{Int64}, children_idx::UnitRange{Int64},\n",
      "                                    numvalued::Vector{Bool}, numberstorage::Vector{Float64}, setstorage::Vector{MC{N,T}},\n",
      "                                    x::Vector{Float64}, lbd::Vector{Float64}, ubd::Vector{Float64}, subgrad_tol::Float64,\n",
      "                                    sparsity::Vector{Int},\n",
      "                                    is_post::Bool, is_intersect::Bool, interval_intersect::Bool, ctx::GuardCtx,\n",
      "                                    user_operators::JuMP._Derivatives.UserOperatorRegistry,\n",
      "                                    num_mv_buffer::Vector{Float64}) where {N, T<:RelaxTag}\n",
      "\n",
      "    n = length(children_idx)\n",
      "    evaluator = user_operators.multivariate_operator_evaluator[op - JuMP._Derivatives.USER_OPERATOR_ID_START + 1]\n",
      "    set_input = zeros(MC{N,T}, n)\n",
      "    num_input = view(num_mv_buffer, 1:n)\n",
      "    fill!(num_input, -Inf)\n",
      "\n",
      "    buffer_count = 1\n",
      "    output_is_number = true\n",
      "    for c_idx in children_idx\n",
      "        arg_index = children_arr[c_idx]\n",
      "        arg_is_number = numvalued[arg_index]\n",
      "        if arg_is_number\n",
      "            num_input[buffer_count] = numberstorage[arg_index]\n",
      "        else\n",
      "            set_input[buffer_count] = setstorage[arg_index]\n",
      "        end\n",
      "        output_is_number &= arg_is_number\n",
      "        buffer_count += 1\n",
      "    end\n",
      "\n",
      "    if output_is_number\n",
      "        numberstorage[k] = MOI.eval_objective(evaluator, num_input)\n",
      "    else\n",
      "        for i = 1:(buffer_count - 1)\n",
      "            if !isinf(num_input[i])\n",
      "                 set_input[buffer_count] = MC{N,T}(num_input[buffer_count])\n",
      "            end\n",
      "        end\n",
      "        guard_on = ctx.metadata.guard_on\n",
      "        if guard_on\n",
      "            outset = Cassette.overdub(ctx, MOI.eval_objective, evaluator, set_input)\n",
      "        else\n",
      "            outset = MOI.eval_objective(evaluator, set_input)\n",
      "        end\n",
      "        setstorage[k] = overwrite_or_intersect(outset, setstorage[k], x, lbd, ubd, subgrad_tol, sparsity, is_post, is_intersect,\n",
      "                                               interval_intersect)\n",
      "    end\n",
      "    numvalued[k] = output_is_number\n",
      "\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "$(FUNCTIONNAME)\n",
      "\n",
      "Updates storage tapes with forward evalution for node representing `n = f(c)` where f is standard function\n",
      "and `c` is a number.\n",
      "\"\"\"\n",
      "function forward_univariate_number!(k::Int64, op::Int64, arg_idx::Int, numvalued::Vector{Bool}, numberstorage::Vector{Float64})\n",
      "\n",
      "    tmp_num = numberstorage[arg_idx]\n",
      "    outnum = eval_univariate_set(op, tmp_num)\n",
      "\n",
      "    numberstorage[k] = outnum\n",
      "    numvalued[k] = true\n",
      "\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "$(FUNCTIONNAME)\n",
      "\n",
      "Updates storage tapes with forward evalution for node representing `n = f(x)` where f is standard function\n",
      "that requires a single tiepoint calculation per convex/concave relaxation (e.g. tan).\n",
      "\"\"\"\n",
      "function forward_univariate_tiepnt_1!(k::Int64, op::Int64, child_idx::Int64, setstorage::Vector{V},\n",
      "                                      x::Vector{Float64}, lbd::Vector{Float64}, ubd::Vector{Float64}, subgrad_tol::Float64,\n",
      "                                      sparsity::Vector{Int},\n",
      "                                      tpdict::Dict{Int64, Tuple{Int64,Int64,Int64,Int64}},\n",
      "                                      tp1storage::Vector{Float64}, tp2storage::Vector{Float64},\n",
      "                                      is_post::Bool, is_intersect::Bool, is_first_eval::Bool, interval_intersect::Bool, ctx::GuardCtx) where V\n",
      "\n",
      "    tmp_set = setstorage[child_idx]\n",
      "\n",
      "    tidx1, tidx2 = tpdict[k]\n",
      "    tp1 =  tp1storage[tidx1]\n",
      "    tp2 =  tp2storage[tidx1]\n",
      "    new_tie_points = tp1 === Inf\n",
      "\n",
      "    guard_on = ctx.metadata.guard_on\n",
      "    if guard_on\n",
      "        outset, tp1, tp2 = Cassette.overdub(ctx, single_tp_set, op, tmp_set, setstorage[k], tp1, tp2, is_first_eval)\n",
      "    else\n",
      "        outset, tp1, tp2 = single_tp_set(op, tmp_set, setstorage[k], tp1, tp2, is_first_eval)\n",
      "    end\n",
      "\n",
      "    if new_tie_points\n",
      "         tp1storage[tidx1] = tp1\n",
      "         tp2storage[tidx1] = tp2\n",
      "    end\n",
      "\n",
      "    setstorage[k] = overwrite_or_intersect(outset, setstorage[k], x, lbd, ubd, subgrad_tol, sparsity, is_post, is_intersect,\n",
      "                                           interval_intersect)\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "$(FUNCTIONNAME)\n",
      "\n",
      "Updates storage tapes with forward evalution for node representing `n = f(x)` where f is standard function\n",
      "that requires a two tiepoint calculations per convex/concave relaxation (e.g. sin).\n",
      "\"\"\"\n",
      "function forward_univariate_tiepnt_2!(k::Int64, op::Int64, child_idx::Int64, setstorage::Vector{V},\n",
      "                                      x::Vector{Float64}, lbd::Vector{Float64}, ubd::Vector{Float64},\n",
      "                                      subgrad_tol::Float64, sparsity::Vector{Int},\n",
      "                                      tpdict::Dict{Int64, Tuple{Int64,Int64,Int64,Int64}},\n",
      "                                      tp1storage::Vector{Float64}, tp2storage::Vector{Float64},\n",
      "                                      tp3storage::Vector{Float64}, tp4storage::Vector{Float64},\n",
      "                                      is_post::Bool, is_intersect::Bool, is_first_eval::Bool,\n",
      "                                      interval_intersect::Bool, ctx::GuardCtx) where V\n",
      "\n",
      "    tmp_set = setstorage[child_idx]\n",
      "\n",
      "    # retreive previously calculated tie-points\n",
      "    # These are re-initialize to Inf for each box\n",
      "    tidx1, tidx2 = tpdict[k]\n",
      "    tp1 = tp1storage[tidx1]\n",
      "    tp2 = tp2storage[tidx1]\n",
      "    tp3 = tp3storage[tidx2]\n",
      "    tp4 = tp4storage[tidx2]\n",
      "\n",
      "    new_tie_points = tp1 === Inf\n",
      "\n",
      "    # Perform an evaluation of the univariate function overdubbed with Cassette.jl\n",
      "    guard_on = ctx.metadata.guard_on\n",
      "    if guard_on\n",
      "        outset, tp1, tp2, tp3, tp4 = Cassette.overdub(ctx, double_tp_set, op, tmp_set, setstorage[k],\n",
      "                                                      tp1, tp2, tp3, tp4, is_first_eval)\n",
      "    else\n",
      "        outset, tp1, tp2, tp3, tp4 = double_tp_set(op, tmp_set, setstorage[k], tp1, tp2, tp3, tp4, is_first_eval)\n",
      "    end\n",
      "    #Cassette.overdub(ctx, double_tp_set, op, tmp_set, setstorage[k], tp1, tp2, tp3, tp4, is_first_eval)\n",
      "\n",
      "    # Store new tiepoints if new evaluation\n",
      "    if new_tie_points\n",
      "         tp1storage[tidx1] = tp1\n",
      "         tp2storage[tidx1] = tp2\n",
      "         tp3storage[tidx2] = tp3\n",
      "         tp4storage[tidx2] = tp4\n",
      "    end\n",
      "\n",
      "    setstorage[k] = overwrite_or_intersect(outset, setstorage[k], x, lbd, ubd, subgrad_tol, sparsity, is_post, is_intersect,\n",
      "                                           interval_intersect)\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "$(FUNCTIONNAME)\n",
      "\n",
      "Updates storage tapes with forward evalution for node representing `n = user_f(x)`.\n",
      "\"\"\"\n",
      "function forward_univariate_user!(k::Int64, op::Int64, child_idx::Int64, arg_is_number::Bool,\n",
      "                                  setstorage::Vector{V}, x::Vector{Float64}, lbd::Vector{Float64},\n",
      "                                  ubd::Vector{Float64}, subgrad_tol::Float64, sparsity::Vector{Int},\n",
      "                                  is_post::Bool, is_intersect::Bool, is_first_eval::Bool,\n",
      "                                  interval_intersect::Bool, ctx::GuardCtx, user_operators) where V\n",
      "\n",
      "    userop = op - JuMP._Derivatives.USER_UNIVAR_OPERATOR_ID_START + 1\n",
      "    f = user_operators.univariate_operator_f[userop]\n",
      "\n",
      "    if arg_is_number\n",
      "        tmp_num = setstorage[child_idx]\n",
      "        outnum = f(tmp_num)\n",
      "        numberstorage[k] = outnum\n",
      "\n",
      "    else\n",
      "        tmp_set = setstorage[child_idx]\n",
      "\n",
      "        guard_on = ctx.metadata.guard_on\n",
      "        if guard_on\n",
      "            outset = Cassette.overdub(ctx, f, tmp_set)\n",
      "        else\n",
      "            outset = f(tmp_set)\n",
      "        end\n",
      "\n",
      "        setstorage[k] = overwrite_or_intersect(outset, setstorage[k], x, lbd, ubd, subgrad_tol, sparsity,\n",
      "                                               is_post, is_intersect, interval_intersect)\n",
      "    end\n",
      "\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "$(FUNCTIONNAME)\n",
      "\n",
      "Updates storage tapes with forward evalution for node representing `n = f(x)` where `f` is a standard function\n",
      "that does not require a tiepoint evaluation (e.g. exp).\n",
      "\"\"\"\n",
      "function forward_univariate_other!(k::Int64, op::Int64, child_idx::Int64, setstorage::Vector{V},\n",
      "                                   x::Vector{Float64}, lbd::Vector{Float64}, ubd::Vector{Float64},\n",
      "                                   subgrad_tol::Float64, sparsity::Vector{Int}, is_post::Bool,\n",
      "                                   is_intersect::Bool, is_first_eval::Bool, interval_intersect::Bool,\n",
      "                                   ctx::GuardCtx) where V\n",
      "\n",
      "    tmp_set = setstorage[child_idx]\n",
      "\n",
      "    guard_on = ctx.metadata.guard_on\n",
      "    if guard_on\n",
      "        outset = Cassette.overdub(ctx, eval_univariate_set, op, tmp_set)\n",
      "    else\n",
      "        outset = eval_univariate_set(op, tmp_set)\n",
      "    end\n",
      "    setstorage[k] = overwrite_or_intersect(outset, setstorage[k], x, lbd, ubd, subgrad_tol, sparsity,\n",
      "                                           is_post, is_intersect, interval_intersect)\n",
      "\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "$(FUNCTIONNAME)\n",
      "\n",
      "\"\"\"\n",
      "function expand_set(::Type{MC{N2,T}}, x::MC{N1,T}, fsparse::Vector{Int64},\n",
      "                    subsparse::Vector{Int64}, cv_buffer::Vector{Float64},\n",
      "                    cc_buffer::Vector{Float64}) where {N1 ,N2, T<:RelaxTag}\n",
      "\n",
      "    # TODO: Perform this in a manner that does not allocate via an ntuple\n",
      "    # operator or via generated code\n",
      "    cvg = x.cv_grad\n",
      "    ccg = x.cc_grad\n",
      "    xcount = 1\n",
      "    xcurrent = subsparse[1]\n",
      "    for i = 1:N2\n",
      "        if fsparse[i] === xcurrent\n",
      "            cv_buffer[i] = cvg[xcount]\n",
      "            cc_buffer[i] = ccg[xcount]\n",
      "            xcount += 1\n",
      "            if xcount <= N1\n",
      "                xcurrent = subsparse[xcount]\n",
      "            else\n",
      "                break\n",
      "            end\n",
      "        else\n",
      "            cv_buffer[i] = 0.0\n",
      "        end\n",
      "    end\n",
      "    cv_grad = SVector{N2,Float64}(cv_buffer)\n",
      "    cc_grad = SVector{N2,Float64}(cc_buffer)\n",
      "    return MC{N2,T}(x.cv, x.cc, x.Intv, cv_grad, cc_grad, x.cnst)\n",
      "end\n",
      "\n",
      "\"\"\"\n",
      "$(FUNCTIONNAME)\n",
      "\n",
      "Unpacks the `MC{N1,T}` in the subexpression to a `MC{N2,T}` where `N1` is the sparsity of the\n",
      "subexpression and `N2` is the sparsity of the function tape. Note that the sparsity of the\n",
      "subexpression is less than the sparsity of the function itself. This limits the storage\n",
      "required by tapes but prevents reverse mode subgradient propagation through expressions\n",
      "[This may be subject to change in the future once the reverse mode propagation becomes\n",
      "more robust].\n",
      "\"\"\"\n",
      "function forward_get_subexpression!(k::Int64, active_subexpr::NonlinearExpression{MC{N,T}},\n",
      "                                    setstorage::Vector{MC{Q,T}}, numberstorage::Vector{Float64},\n",
      "                                    numvalued::Vector{Bool}, fsparsity::Vector{Int64},\n",
      "                                    cv_buffer::Vector{Float64}, cc_buffer::Vector{Float64}) where {N,Q,T<:RelaxTag}\n",
      "\n",
      "    is_number = active_subexpr.isnumber[1]\n",
      "    if is_number\n",
      "        numberstorage[k] = active_subexpr.setstorage[1]\n",
      "    else\n",
      "        set_arg = active_subexpr.setstorage[1]\n",
      "        setstorage[k] = expand_set(MC{Q,T}, set_arg, fsparsity, active_subexpr.grad_sparsity, cv_buffer, cc_buffer)\n",
      "    end\n",
      "    numvalued[k] = is_number\n",
      "\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "const id_to_operator = Dict(value => key for (key, value) in JuMP.univariate_operator_to_id)\n",
      "\n",
      "\"\"\"\n",
      "$(FUNCTIONNAME)\n",
      "\n",
      "Performs a forward pass using the tape information passed as arguments. Each variety of node calls an associated\n",
      "forward_xxx function where xxx is a descriptor.\n",
      "\"\"\"\n",
      "function forward_pass_kernel!(nd::Vector{JuMP.NodeData}, adj::SparseMatrixCSC{Bool,Int64}, x::Vector{Float64},\n",
      "                              lbd::Vector{Float64}, ubd::Vector{Float64}, sparsity::Vector{Int},\n",
      "                              setstorage::Vector{MC{N,T}}, numberstorage::Vector{Float64}, numvalued::Vector{Bool},\n",
      "                              tpdict::Dict{Int64,Tuple{Int64,Int64,Int64,Int64}}, tp1storage::Vector{Float64},\n",
      "                              tp2storage::Vector{Float64}, tp3storage::Vector{Float64}, tp4storage::Vector{Float64},\n",
      "                              user_operators::JuMP._Derivatives.UserOperatorRegistry, subexpressions::Vector{NonlinearExpression},\n",
      "                              func_sparsity::Vector{Int64}, reverse_sparsity::Vector{Int64},\n",
      "                              num_mv_buffer::Vector{Float64}, ctx::GuardCtx,\n",
      "                              is_post::Bool, is_intersect::Bool, is_first_eval::Bool, interval_intersect::Bool,\n",
      "                              cv_buffer::Vector{Float64}, cc_buffer::Vector{Float64},\n",
      "                              treat_x_as_number::Vector{Bool}, subgrad_tol::Float64) where {N, T<:RelaxTag}\n",
      "\n",
      "    children_arr = rowvals(adj)\n",
      "\n",
      "    FORWARD_DEBUG && println(\" \")\n",
      "    for k = length(nd):-1:1\n",
      "\n",
      "        oldset = setstorage[k]\n",
      "        nod = nd[k]\n",
      "        op = nod.index\n",
      "\n",
      "        if nod.nodetype == JuMP._Derivatives.VALUE\n",
      "            numvalued[k] = true\n",
      "            FORWARD_DEBUG && println(\"value[$op]    at k = $k -> $(numberstorage[k])\")\n",
      "\n",
      "        elseif nod.nodetype == JuMP._Derivatives.PARAMETER\n",
      "            numvalued[k] = true\n",
      "            FORWARD_DEBUG && println(\"parameter[$op] at k = $k -> $(numberstorage[k])\")\n",
      "\n",
      "        elseif nod.nodetype == JuMP._Derivatives.VARIABLE\n",
      "            isa_number =  treat_x_as_number[op]\n",
      "            numvalued[k] = isa_number\n",
      "            xval = x[op]\n",
      "            if isa_number\n",
      "                 numberstorage[k] = xval\n",
      "            else\n",
      "                seed_index = reverse_sparsity[op]\n",
      "                seed_grad = seed_gradient(seed_index, Val{N}())\n",
      "                lower_bnd_val = lbd[op]\n",
      "                upper_bnd_val = ubd[op]\n",
      "                xcv_eps = xval - (xval - lower_bnd_val)*1E-8\n",
      "                xcc_eps = xval + (upper_bnd_val - xval)*1E-8\n",
      "                xMC = MC{N,T}(xcv_eps, xcc_eps, Interval{Float64}(lower_bnd_val, upper_bnd_val),\n",
      "                              seed_grad, seed_grad, false)\n",
      "                setstorage[k] = is_first_eval ? xMC : (xMC ∩ setstorage[k].Intv)\n",
      "            end\n",
      "            FORWARD_DEBUG && println(\"variable[$op] at k = $k -> $(setstorage[k])\")\n",
      "        elseif nod.nodetype == JuMP._Derivatives.SUBEXPRESSION\n",
      "            active_subexpr = subexpressions[op]\n",
      "            forward_get_subexpression!(k, active_subexpr, setstorage, numberstorage, numvalued, func_sparsity,\n",
      "                                       cv_buffer, cc_buffer)\n",
      "\n",
      "        elseif nod.nodetype == JuMP._Derivatives.CALL\n",
      "\n",
      "            children_idx = nzrange(adj, k)\n",
      "            n_children = length(children_idx)\n",
      "\n",
      "            # :+ with arity two or greater\n",
      "            if op === 1\n",
      "                n = length(children_idx)\n",
      "                if n === 2\n",
      "                    forward_plus_binary!(k, children_arr, children_idx, numvalued, numberstorage,\n",
      "                                         setstorage, x, lbd, ubd, subgrad_tol, sparsity, is_post, is_intersect, is_first_eval,\n",
      "                                         interval_intersect)\n",
      "                else\n",
      "                    forward_plus_narity!(k, children_arr, children_idx, numvalued, numberstorage,\n",
      "                                         setstorage, x, lbd, ubd, subgrad_tol, sparsity, is_post, is_intersect, interval_intersect)\n",
      "                end\n",
      "                FORWARD_DEBUG && println(\"plus[$n]     at k = $k -> $(setstorage[k])\")\n",
      "\n",
      "            # :- with arity two\n",
      "            elseif op === 2\n",
      "                forward_minus!(k, children_arr, children_idx, numvalued, numberstorage,\n",
      "                               setstorage, x, lbd, ubd, subgrad_tol, sparsity, is_post, is_intersect, is_first_eval,\n",
      "                               interval_intersect)\n",
      "                FORWARD_DEBUG && println(\"minus        at k = $k -> $(setstorage[k])\")\n",
      "\n",
      "            # :* with arity two or greater\n",
      "            elseif op === 3\n",
      "                n = length(children_idx)\n",
      "                if n === 2\n",
      "                    forward_multiply_binary!(k, children_arr, children_idx, numvalued,\n",
      "                                             numberstorage, setstorage, x, lbd, ubd, subgrad_tol, sparsity, is_post,\n",
      "                                             is_intersect, is_first_eval, interval_intersect)\n",
      "                else\n",
      "                    forward_multiply_narity!(k, children_arr, children_idx, numvalued,\n",
      "                                             numberstorage, setstorage, x, lbd, ubd, subgrad_tol,\n",
      "                                             sparsity, is_post, is_intersect, interval_intersect)\n",
      "                end\n",
      "                FORWARD_DEBUG && println(\"mult[$n]     at k = $k -> $(setstorage[k])\")\n",
      "\n",
      "            # :^\n",
      "            elseif op === 4\n",
      "                forward_power!(k, children_arr, children_idx, numvalued, numberstorage,\n",
      "                               setstorage, x, lbd, ubd, subgrad_tol, sparsity, is_post, is_intersect, is_first_eval,\n",
      "                               interval_intersect, ctx)\n",
      "\n",
      "                FORWARD_DEBUG && println(\"power       at k = $k -> $(setstorage[k])\")\n",
      "\n",
      "            # :/\n",
      "            elseif op === 5\n",
      "                forward_divide!(k, children_arr, children_idx, numvalued, numberstorage,\n",
      "                                setstorage, x, lbd, ubd, subgrad_tol, sparsity, is_post, is_intersect, is_first_eval,\n",
      "                                interval_intersect, ctx)\n",
      "\n",
      "                FORWARD_DEBUG && println(\"divide      at k = $k -> $(setstorage[k])\")\n",
      "\n",
      "            # user multivariate function\n",
      "            elseif op >= JuMP._Derivatives.USER_OPERATOR_ID_START\n",
      "                forward_user_multivariate!(k, op, children_arr, children_idx, numvalued, numberstorage,\n",
      "                                           setstorage, x, lbd, ubd, subgrad_tol, sparsity, is_post, is_intersect,\n",
      "                                           interval_intersect, ctx, user_operators, num_mv_buffer)\n",
      "                FORWARD_DEBUG && println(\"user_mult   at k = $k -> $(setstorage[k])\")\n",
      "\n",
      "            else\n",
      "               error(\"Unsupported operation $(operators[op])\")\n",
      "            end\n",
      "\n",
      "        elseif nod.nodetype == JuMP._Derivatives.CALLUNIVAR\n",
      "\n",
      "            # checks to see if operator is a number\n",
      "            child_idx = first(nzrange(adj, k))\n",
      "            arg_idx = children_arr[adj.colptr[k]]\n",
      "            arg_is_number =  numvalued[arg_idx]\n",
      "            numvalued[k] = arg_is_number\n",
      "\n",
      "            # performs univariate operators on number valued inputs\n",
      "            if op >= JuMP._Derivatives.USER_UNIVAR_OPERATOR_ID_START\n",
      "                forward_univariate_user!(k, op, arg_idx, arg_is_number, setstorage, x, lbd, ubd, subgrad_tol,\n",
      "                                         sparsity, is_post, is_intersect, is_first_eval, interval_intersect, ctx,\n",
      "                                         user_operators)\n",
      "\n",
      "            elseif arg_is_number\n",
      "                forward_univariate_number!(k, op, arg_idx, numvalued, numberstorage)\n",
      "\n",
      "            # performs set valued operators that require a single tiepoint calculation\n",
      "            elseif single_tp(op)\n",
      "                forward_univariate_tiepnt_1!(k, op, arg_idx, setstorage, x, lbd, ubd,  subgrad_tol, sparsity, tpdict,\n",
      "                                             tp1storage, tp2storage, is_post, is_intersect,\n",
      "                                             is_first_eval, interval_intersect, ctx)\n",
      "\n",
      "            # performs set valued operators that require two tiepoint calculations\n",
      "            elseif double_tp(op)\n",
      "                forward_univariate_tiepnt_2!(k, op, arg_idx, setstorage, x, lbd, ubd,  subgrad_tol, sparsity, tpdict,\n",
      "                                             tp1storage, tp2storage, tp3storage, tp4storage,\n",
      "                                             is_post, is_intersect, is_first_eval,\n",
      "                                             interval_intersect, ctx)\n",
      "\n",
      "            # performs set valued operator on other functions in base library\n",
      "            else\n",
      "                forward_univariate_other!(k, op, arg_idx, setstorage, x, lbd, ubd, subgrad_tol, sparsity, is_post,\n",
      "                                          is_intersect, is_first_eval, interval_intersect, ctx)\n",
      "\n",
      "            end\n",
      "            FORWARD_DEBUG && println(\"fop[$op]   at k = $k -> $(setstorage[k])\")\n",
      "        else\n",
      "            error(\"Unrecognized node type $(nod.nodetype).\")\n",
      "\n",
      "        end\n",
      "\n",
      "    end\n",
      "\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "\n",
      "###\n",
      "### Define forward evaluation pass\n",
      "###\n",
      "function forward_pass!(evaluator::Evaluator, d::NonlinearExpression{V}) where V\n",
      "    # check that prior subexpressions have been evaluated\n",
      "    # i.e. box_id is same and reference point is the same\n",
      "    for i = 1:d.dependent_subexpression_count\n",
      "        if !prior_eval(evaluator, i)\n",
      "            subexpr = evaluator.subexpressions[i]\n",
      "            forward_pass!(evaluator, subexpr)\n",
      "        end\n",
      "    end\n",
      "\n",
      "    forward_pass_kernel!(d.nd, d.adj, evaluator.x, evaluator.lower_variable_bounds,\n",
      "                         evaluator.upper_variable_bounds, d.grad_sparsity,\n",
      "                         d.setstorage,\n",
      "                         d.numberstorage, d.isnumber, d.tpdict,\n",
      "                         d.tp1storage, d.tp2storage, d.tp3storage, d.tp4storage,\n",
      "                         evaluator.user_operators, evaluator.subexpressions,\n",
      "                         d.grad_sparsity, d.reverse_sparsity,\n",
      "                         evaluator.num_mv_buffer, evaluator.ctx,\n",
      "                         evaluator.is_post, evaluator.is_intersect,\n",
      "                         evaluator.is_first_eval, evaluator.interval_intersect,\n",
      "                         d.cv_grad_buffer, d.cc_grad_buffer,\n",
      "                         evaluator.treat_x_as_number, evaluator.subgrad_tol)\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "function forward_pass!(evaluator::Evaluator, d::BufferedNonlinearFunction{V}) where V\n",
      "\n",
      "    forward_pass!(evaluator, d.expr)\n",
      "    d.has_value = true\n",
      "    d.last_past_reverse = false\n",
      "\n",
      "    return nothing\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################################################################################\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(ds)\n",
    "for i in range(100):\n",
    "    text = ds[i]\n",
    "    print(\"STARTING EXAMPLE \", i)\n",
    "    print_ex(text)\n",
    "    print(\"\\n\" * 2)\n",
    "    print(\"#\" * 80)\n",
    "    print(\"\\n\" * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_json_filter(example):\n",
    "    return example[\"content\"][0] != \"{\"\n",
    "\n",
    "def filtered_out(filter):\n",
    "    return [d for d in ds if not filter(d)]\n",
    "\n",
    "filtered_out(no_json_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds[0][\"content\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we want for a Julia filter:\n",
    "- Some files only include another file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math-lm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
